cpu-bind=MASK - n2gpu1214, task  0  0 [266458]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
-------------------------------------------------------------------------------
The following dependent module(s) are not currently loaded: compiler/GCCcore/11.3.0 (required by: tools/binutils/2.38-GCCcore-11.3.0, compiler/GCC/11.3.0, tools/XZ/5.2.5-GCCcore-11.3.0, lib/libxml2/2.9.13-GCCcore-11.3.0, system/libpciaccess/0.16-GCCcore-11.3.0, system/hwloc/2.7.1-GCCcore-11.3.0, lib/libevent/2.1.12-GCCcore-11.3.0, lib/libfabric/1.15.1-GCCcore-11.3.0, lib/PMIx/4.1.2-GCCcore-11.3.0, lib/UCC/1.0.0-GCCcore-11.3.0, tools/Ninja/1.10.2-GCCcore-11.3.0, tools/bzip2/1.0.8-GCCcore-11.3.0, devel/ncurses/6.3-GCCcore-11.3.0, lib/libreadline/8.1.2-GCCcore-11.3.0, lang/Tcl/8.6.12-GCCcore-11.3.0, devel/SQLite/3.38.3-GCCcore-11.3.0, math/GMP/6.2.1-GCCcore-11.3.0, lib/libffi/3.4.2-GCCcore-11.3.0, lang/Python/3.10.4-GCCcore-11.3.0, devel/protobuf/3.19.4-GCCcore-11.3.0, devel/protobuf-python/3.19.4-GCCcore-11.3.0, lib/pybind11/2.9.2-GCCcore-11.3.0, lib/libyaml/0.2.5-GCCcore-11.3.0, lib/PyYAML/6.0-GCCcore-11.3.0, math/MPFR/4.1.0-GCCcore-11.3.0, lang/NASM/2.15.05-GCCcore-11.3.0, vis/x264/20220620-GCCcore-11.3.0, data/LAME/3.100-GCCcore-11.3.0, vis/x265/3.5-GCCcore-11.3.0, tools/expat/2.4.8-GCCcore-11.3.0, lib/libpng/1.6.37-GCCcore-11.3.0, lib/Brotli/1.0.9-GCCcore-11.3.0, vis/freetype/2.12.1-GCCcore-11.3.0, tools/util-linux/2.38-GCCcore-11.3.0, vis/fontconfig/2.14.0-GCCcore-11.3.0, devel/xorg-macros/1.19.3-GCCcore-11.3.0, vis/X11/20220504-GCCcore-11.3.0, lang/FriBidi/1.0.12-GCCcore-11.3.0, vis/FFmpeg/4.4.2-GCCcore-11.3.0, lib/libjpeg-turbo/2.1.3-GCCcore-11.3.0, vis/jbigkit/2.1-GCCcore-11.3.0, tools/gzip/1.12-GCCcore-11.3.0, lib/lz4/1.9.3-GCCcore-11.3.0, lib/zstd/1.5.2-GCCcore-11.3.0, system/libdeflate/1.10-GCCcore-11.3.0, lib/LibTIFF/4.3.0-GCCcore-11.3.0, vis/Pillow/9.1.1-GCCcore-11.3.0, tools/expecttest/0.1.3-GCCcore-11.3.0), lib/NCCL/2.12.12-GCCcore-11.3.0-CUDA-11.7.0 (required by: ai/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0), lib/UCX-CUDA/1.12.1-GCCcore-11.3.0-CUDA-11.7.0 (required by: math/magma/2.6.2-foss-2022a-CUDA-11.7.0), lib/UCX/1.12.1-GCCcore-11.3.0 (required by: lib/UCC/1.0.0-GCCcore-11.3.0, mpi/OpenMPI/4.1.4-GCC-11.3.0), lib/zlib/1.2.12-GCCcore-11.3.0 (required by: tools/binutils/2.38-GCCcore-11.3.0, lib/libxml2/2.9.13-GCCcore-11.3.0, lib/libevent/2.1.12-GCCcore-11.3.0, lib/PMIx/4.1.2-GCCcore-11.3.0, mpi/OpenMPI/4.1.4-GCC-11.3.0, lang/Tcl/8.6.12-GCCcore-11.3.0, lang/Python/3.10.4-GCCcore-11.3.0, lib/libpng/1.6.37-GCCcore-11.3.0, vis/freetype/2.12.1-GCCcore-11.3.0, tools/util-linux/2.38-GCCcore-11.3.0, vis/X11/20220504-GCCcore-11.3.0, vis/FFmpeg/4.4.2-GCCcore-11.3.0, lib/zstd/1.5.2-GCCcore-11.3.0, lib/LibTIFF/4.3.0-GCCcore-11.3.0, vis/Pillow/9.1.1-GCCcore-11.3.0), system/CUDA/11.7.0 (required by: numlib/cuDNN/8.4.1.50-CUDA-11.7.0, math/magma/2.6.2-foss-2022a-CUDA-11.7.0, ai/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0), tools/numactl/2.0.14-GCCcore-11.3.0 (required by: system/hwloc/2.7.1-GCCcore-11.3.0, lib/libfabric/1.15.1-GCCcore-11.3.0, ai/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0)
-------------------------------------------------------------------------------

The following have been reloaded with a version change:
  1) compiler/GCCcore/11.3.0 => compiler/GCCcore/12.2.0
  2) lib/GDRCopy/2.3-GCCcore-11.3.0 => lib/GDRCopy/2.3-GCCcore-12.2.0
  3) lib/NCCL/2.12.12-GCCcore-11.3.0-CUDA-11.7.0 => lib/NCCL/2.16.2-GCCcore-12.2.0-CUDA-12.0.0
  4) lib/UCX-CUDA/1.12.1-GCCcore-11.3.0-CUDA-11.7.0 => lib/UCX-CUDA/1.13.1-GCCcore-12.2.0-CUDA-12.0.0
  5) lib/UCX/1.12.1-GCCcore-11.3.0 => lib/UCX/1.13.1-GCCcore-12.2.0
  6) lib/zlib/1.2.12-GCCcore-11.3.0 => lib/zlib/1.2.12-GCCcore-12.2.0
  7) system/CUDA/11.7.0 => system/CUDA/12.0.0
  8) tools/numactl/2.0.14-GCCcore-11.3.0 => tools/numactl/2.0.16-GCCcore-12.2.0


The following have been reloaded with a version change:
  1) compiler/GCCcore/12.2.0 => compiler/GCCcore/11.3.0
  2) lib/GDRCopy/2.3-GCCcore-12.2.0 => lib/GDRCopy/2.3-GCCcore-11.3.0
  3) lib/NCCL/2.16.2-GCCcore-12.2.0-CUDA-12.0.0 => lib/NCCL/2.12.12-GCCcore-11.3.0-CUDA-11.7.0
  4) lib/UCX-CUDA/1.13.1-GCCcore-12.2.0-CUDA-12.0.0 => lib/UCX-CUDA/1.12.1-GCCcore-11.3.0-CUDA-11.7.0
  5) lib/UCX/1.13.1-GCCcore-12.2.0 => lib/UCX/1.12.1-GCCcore-11.3.0
  6) lib/zlib/1.2.12-GCCcore-12.2.0 => lib/zlib/1.2.12-GCCcore-11.3.0
  7) system/CUDA/12.0.0 => system/CUDA/11.7.0
  8) tools/numactl/2.0.16-GCCcore-12.2.0 => tools/numactl/2.0.14-GCCcore-11.3.0

LAUNCHER: python -u -m torch.distributed.run --nproc_per_node 2 --nnodes 2 --rdzv_id=12843 --rdzv_endpoint n2gpu1214:6005 --rdzv_backend c10d --max_restarts 0 --tee 3
CMD: pretrain_gpt.py --tensor-model-parallel-size 1 --pipeline-model-parallel-size 1 --distributed-backend nccl --num-layers 24 --hidden-size 1024 --num-attention-heads 16 --seq-length 1024 --max-position-embeddings 1024 --micro-batch-size 1 --global-batch-size 4 --train-samples 100000 --optimizer adam --adam-beta1 0.9 --adam-beta2 0.95 --adam-eps 1e-8 --lr 1e-4 --min-lr 1e-6 --lr-decay-style cosine --clip-grad 1.0 --weight-decay 1e-1 --fp16 --partition-activations --seed 42 --vocab-file data/gpt2-vocab.json --merge-file data/gpt2-merges.txt --exit-interval 1000 --log-interval 1 --save-interval 500 --eval-interval 50 --eval-iters 10 --checkpoint-activations --save checkpoints/gpt2-b-dist-2023-07-20_173703 --load checkpoints/gpt2-b-dist-2023-07-20_173703 --data-path data/meg-gpt2-oscar-en-10k_text_document --tensorboard-dir output_dir/tensorboard-dist-2023-07-20_173703 --tensorboard-queue-size 5 --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --deepspeed --no-pipeline-parallel --zero-stage 2 --deepspeed_config ./ds_config.json --deepspeed-activation-checkpointing
cpu-bind=MASK - n2gpu1217, task  1  0 [221894]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1214, task  0  0 [266581]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[default0]:[2023-07-20 17:37:09,368] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:[2023-07-20 17:37:09,368] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default1]:[2023-07-20 17:37:09,363] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:[2023-07-20 17:37:09,363] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.10.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.10.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:**** Git info for Megatron: git_hash=a18bb88 git_branch=main ****
[default1]:**** Git info for Megatron: git_hash=a18bb88 git_branch=main ****
[default0]:[2023-07-20 17:37:23,722] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[default0]:[2023-07-20 17:37:23,744] [INFO] [comm.py:616:init_distributed] cdb=None
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.10.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.10.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:**** Git info for Megatron: git_hash=a18bb88 git_branch=main ****
[default0]:using world size: 4, data-parallel-size: 4, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
[default0]:using torch.float16 for parameters ...
[default0]:------------------------ arguments ------------------------
[default0]:  accumulate_allreduce_grads_in_fp32 .............. False
[default0]:  adam_beta1 ...................................... 0.9
[default0]:  adam_beta2 ...................................... 0.95
[default0]:  adam_eps ........................................ 1e-08
[default0]:  add_bias_linear ................................. True
[default0]:  add_position_embedding .......................... True
[default0]:  adlr_autoresume ................................. False
[default0]:  adlr_autoresume_interval ........................ 1000
[default0]:  aml_data_download_path .......................... None
[default0]:  apply_layernorm_1p .............................. False
[default0]:  apply_query_key_layer_scaling ................... True
[default0]:  apply_residual_connection_post_layernorm ........ False
[default0]:  async_tensor_model_parallel_allreduce ........... False
[default0]:  attention_dropout ............................... 0.1
[default0]:  attention_softmax_in_fp32 ....................... False
[default0]:  barrier_with_L1_time ............................ True
[default0]:  bert_binary_head ................................ True
[default0]:  bert_embedder_type .............................. megatron
[default0]:  bert_load ....................................... None
[default0]:  bf16 ............................................ False
[default0]:  bias_dropout_fusion ............................. True
[default0]:  bias_gelu_fusion ................................ True
[default0]:  biencoder_projection_dim ........................ 0
[default0]:  biencoder_shared_query_context_model ............ False
[default0]:  block_data_path ................................. None
[default0]:  checkpoint_activations .......................... True
[default0]:  checkpoint_in_cpu ............................... False
[default0]:  checkpoint_num_layers ........................... 1
[default0]:  classes_fraction ................................ 1.0
[default0]:  clip_grad ....................................... 1.0
[default0]:  compression_training ............................ False
[default0]:  consumed_train_samples .......................... 0
[default0]:  consumed_train_tokens ........................... 0
[default0]:  consumed_valid_samples .......................... 0
[default0]:  contigious_checkpointing ........................ False
[default0]:  cpu_optimizer ................................... False
[default0]:  cpu_torch_adam .................................. False
[default0]:  create_moe_param_group .......................... False
[default0]:  curriculum_learning_legacy ...................... False
[default0]:  data_cache_path ................................. None
[default0]:  data_efficiency_curriculum_learning ............. False
[default0]:  data_impl ....................................... infer
[default0]:  data_parallel_random_init ....................... False
[default0]:  data_parallel_size .............................. 4
[default0]:  data_path ....................................... ['data/meg-gpt2-oscar-en-10k_text_document']
[default0]:  data_per_class_fraction ......................... 1.0
[default0]:  data_sharding ................................... True
[default0]:  dataloader_type ................................. single
[default0]:  DDP_impl ........................................ local
[default0]:  decoder_num_layers .............................. None
[default0]:  decoder_seq_length .............................. None
[default0]:  deepscale ....................................... False
[default0]:  deepscale_config ................................ None
[default0]:  deepspeed ....................................... True
[default0]:  deepspeed_activation_checkpointing .............. True
[default0]:  deepspeed_config ................................ ./ds_config.json
[default0]:  deepspeed_mpi ................................... False
[default0]:  dino_bottleneck_size ............................ 256
[default0]:  dino_freeze_last_layer .......................... 1
[default0]:  dino_head_hidden_size ........................... 2048
[default0]:  dino_local_crops_number ......................... 10
[default0]:  dino_local_img_size ............................. 96
[default0]:  dino_norm_last_layer ............................ False
[default0]:  dino_teacher_temp ............................... 0.07
[default0]:  dino_warmup_teacher_temp ........................ 0.04
[default0]:  dino_warmup_teacher_temp_epochs ................. 30
[default0]:  distribute_checkpointed_activations ............. False
[default0]:  distribute_saved_activations .................... False
[default0]:  distributed_backend ............................. nccl
[default0]:  distributed_timeout_minutes ..................... 10
[default0]:  ds_inference .................................... False
[default0]:  ds_pipeline_enabled ............................. False
[default0]:  embedding_path .................................. None
[default0]:  embedding_weights_in_fp32 ....................... False
[default0]:  empty_unused_memory_level ....................... 0
[default0]:  enable_expert_tensor_parallelism ................ False
[default0]:  encoder_num_layers .............................. 24
[default0]:  encoder_seq_length .............................. 1024
[default0]:  end_weight_decay ................................ 0.1
[default0]:  eod_mask_loss ................................... False
[default0]:  eval_interval ................................... 50
[default0]:  eval_iters ...................................... 10
[default0]:  evidence_data_path .............................. None
[default0]:  exit_duration_in_mins ........................... None
[default0]:  exit_interval ................................... 1000
[default0]:  exit_on_missing_checkpoint ...................... False
[default0]:  exit_signal_handler ............................. False
[default0]:  expert_interval ................................. 2
[default0]:  ffn_hidden_size ................................. 4096
[default0]:  finetune ........................................ False
[default0]:  fp16 ............................................ True
[default0]:  fp16_lm_cross_entropy ........................... False
[default0]:  fp32_residual_connection ........................ False
[default0]:  fp8_amax_compute_algo ........................... most_recent
[default0]:  fp8_amax_history_len ............................ 1
[default0]:  fp8_e4m3 ........................................ False
[default0]:  fp8_hybrid ...................................... False
[default0]:  fp8_interval .................................... 1
[default0]:  fp8_margin ...................................... 0
[default0]:  fp8_wgrad ....................................... True
[default0]:  global_batch_size ............................... 4
[default0]:  gradient_accumulation_fusion .................... True
[default0]:  head_lr_mult .................................... 1.0
[default0]:  hidden_dropout .................................. 0.1
[default0]:  hidden_size ..................................... 1024
[default0]:  hidden_size_teacher ............................. None
[default0]:  hysteresis ...................................... 2
[default0]:  ict_head_size ................................... None
[default0]:  ict_load ........................................ None
[default0]:  img_h ........................................... 224
[default0]:  img_w ........................................... 224
[default0]:  indexer_batch_size .............................. 128
[default0]:  indexer_log_interval ............................ 1000
[default0]:  inference ....................................... False
[default0]:  inference_batch_times_seqlen_threshold .......... 512
[default0]:  init_method_std ................................. 0.02
[default0]:  init_method_xavier_uniform ...................... False
[default0]:  initial_loss_scale .............................. 4294967296
[default0]:  iter_per_epoch .................................. 1250
[default0]:  kd .............................................. False
[default0]:  kd_alpha_ce ..................................... 1
[default0]:  kd_beta_ce ...................................... 1
[default0]:  kd_temp ......................................... 1.0
[default0]:  kv_channels ..................................... 64
[default0]:  layernorm_epsilon ............................... 1e-05
[default0]:  lazy_mpu_init ................................... None
[default0]:  load ............................................ checkpoints/gpt2-b-dist-2023-07-20_173703
[default0]:  load_teacher .................................... None
[default0]:  local_rank ...................................... None
[default0]:  log_batch_size_to_tensorboard ................... True
[default0]:  log_interval .................................... 1
[default0]:  log_learning_rate_to_tensorboard ................ True
[default0]:  log_loss_scale_to_tensorboard ................... True
[default0]:  log_memory_to_tensorboard ....................... False
[default0]:  log_num_zeros_in_grad ........................... False
[default0]:  log_optimizer_states_to_tensorboard ............. False
[default0]:  log_params_norm ................................. False
[default0]:  log_timers_to_tensorboard ....................... True
[default0]:  log_validation_ppl_to_tensorboard ............... True
[default0]:  log_world_size_to_tensorboard ................... False
[default0]:  loss_scale ...................................... None
[default0]:  loss_scale_window ............................... 1000
[default0]:  lr .............................................. 0.0001
[default0]:  lr_decay_iters .................................. None
[default0]:  lr_decay_samples ................................ None
[default0]:  lr_decay_style .................................. cosine
[default0]:  lr_decay_tokens ................................. None
[default0]:  lr_warmup_fraction .............................. None
[default0]:  lr_warmup_iters ................................. 0
[default0]:  lr_warmup_samples ............................... 0
[default0]:  lr_warmup_tokens ................................ None
[default0]:  make_vocab_size_divisible_by .................... 128
[default0]:  mask_factor ..................................... 1.0
[default0]:  mask_prob ....................................... 0.15
[default0]:  mask_type ....................................... random
[default0]:  masked_softmax_fusion ........................... True
[default0]:  max_position_embeddings ......................... 1024
[default0]:  max_tokens_to_oom ............................... 12000
[default0]:  memory_centric_tiled_linear ..................... False
[default0]:  merge_file ...................................... data/gpt2-merges.txt
[default0]:  micro_batch_size ................................ 1
[default0]:  min_loss_scale .................................. 1.0
[default0]:  min_lr .......................................... 1e-06
[default0]:  mlp_type ........................................ standard
[default0]:  mmap_warmup ..................................... False
[default0]:  moe_eval_capacity_factor ........................ 1.0
[default0]:  moe_expert_parallel_size ........................ 1
[default0]:  moe_loss_coeff .................................. 0.1
[default0]:  moe_min_capacity ................................ 4
[default0]:  moe_token_dropping .............................. True
[default0]:  moe_train_capacity_factor ....................... 1.0
[default0]:  mos ............................................. False
[default0]:  no_load_lr_state ................................ False
[default0]:  no_load_optim ................................... None
[default0]:  no_load_rng ..................................... None
[default0]:  no_persist_layer_norm ........................... False
[default0]:  no_pipeline_parallel ............................ True
[default0]:  no_save_optim ................................... None
[default0]:  no_save_rng ..................................... None
[default0]:  normalization ................................... layernorm
[default0]:  num_attention_heads ............................. 16
[default0]:  num_attention_heads_teacher ..................... None
[default0]:  num_channels .................................... 3
[default0]:  num_classes ..................................... 1000
[default0]:  num_experts ..................................... [1]
[default0]:  num_experts_switch .............................. None
[default0]:  num_experts_teacher ............................. [1]
[default0]:  num_layers ...................................... 24
[default0]:  num_layers_per_virtual_pipeline_stage ........... None
[default0]:  num_layers_teacher .............................. None
[default0]:  num_workers ..................................... 2
[default0]:  onnx_safe ....................................... None
[default0]:  openai_gelu ..................................... False
[default0]:  optimizer ....................................... adam
[default0]:  output_bert_embeddings .......................... False
[default0]:  overlap_p2p_comm ................................ False
[default0]:  override_opt_param_scheduler .................... False
[default0]:  params_dtype .................................... torch.float16
[default0]:  partition_activations ........................... True
[default0]:  patch_dim ....................................... 16
[default0]:  perform_initialization .......................... True
[default0]:  pipeline_model_parallel_size .................... 1
[default0]:  pipeline_model_parallel_split_rank .............. None
[default0]:  profile_backward ................................ False
[default0]:  query_in_block_prob ............................. 0.1
[default0]:  rampup_batch_size ............................... None
[default0]:  random_ltd ...................................... False
[default0]:  rank ............................................ 0
[default0]:  recompute_granularity ........................... None
[default0]:  recompute_method ................................ None
[default0]:  recompute_num_layers ............................ 1
[default0]:  remote_device ................................... none
[default0]:  reset_attention_mask ............................ False
[default0]:  reset_iteration ................................. False
[default0]:  reset_position_ids .............................. False
[default0]:  retriever_report_topk_accuracies ................ []
[default0]:  retriever_score_scaling ......................... False
[default0]:  retriever_seq_length ............................ 256
[default0]:  retro_add_retriever ............................. False
[default0]:  retro_cyclic_train_iters ........................ None
[default0]:  retro_encoder_attention_dropout ................. 0.1
[default0]:  retro_encoder_hidden_dropout .................... 0.1
[default0]:  retro_encoder_layers ............................ 2
[default0]:  retro_num_neighbors ............................. 2
[default0]:  retro_num_retrieved_chunks ...................... 2
[default0]:  retro_return_doc_ids ............................ False
[default0]:  retro_workdir ................................... None
[default0]:  return_data_index ............................... False
[default0]:  rotary_percent .................................. 1.0
[default0]:  sample_rate ..................................... 1.0
[default0]:  save ............................................ checkpoints/gpt2-b-dist-2023-07-20_173703
[default0]:  save_interval ................................... 500
[default0]:  scatter_gather_tensors_in_pipeline .............. True
[default0]:  scattered_embeddings ............................ False
[default0]:  seed ............................................ 42
[default0]:  seq_length ...................................... 1024
[default0]:  sequence_parallel ............................... False
[default0]:  sgd_momentum .................................... 0.9
[default0]:  short_seq_prob .................................. 0.1
[default0]:  skip_train ...................................... False
[default0]:  split ........................................... 969, 30, 1
[default0]:  split_transformers .............................. False
[default0]:  squared_relu .................................... False
[default0]:  standalone_embedding_stage ...................... False
[default0]:  start_weight_decay .............................. 0.1
[default0]:  swiglu .......................................... False
[default0]:  swin_backbone_type .............................. tiny
[default0]:  synchronize_each_layer .......................... False
[default0]:  tensor_model_parallel_size ...................... 1
[default0]:  tensorboard_dir ................................. output_dir/tensorboard-dist-2023-07-20_173703
[default0]:  tensorboard_log_interval ........................ 1
[default0]:  tensorboard_queue_size .......................... 5
[default0]:  test_data_path .................................. None
[default0]:  tile_factor ..................................... 1
[default0]:  timing_log_level ................................ 0
[default0]:  timing_log_option ............................... minmax
[default0]:  titles_data_path ................................ None
[default0]:  tokenizer_model ................................. None
[default0]:  tokenizer_type .................................. GPT2BPETokenizer
[default0]:  topk ............................................ 1
[default0]:  train_data_exact_num_epochs ..................... None
[default0]:  train_data_path ................................. None
[default0]:  train_desc_path ................................. None
[default0]:  train_doc_idx_path .............................. None
[default0]:  train_idx_path .................................. None
[default0]:  train_iters ..................................... None
[default0]:  train_sample_idx_path ........................... None
[default0]:  train_samples ................................... 100000
[default0]:  train_shuffle_idx_path .......................... None
[default0]:  train_tokens .................................... None
[default0]:  transformer_impl ................................ local
[default0]:  transformer_pipeline_model_parallel_size ........ 1
[default0]:  untie_embeddings_and_output_weights ............. False
[default0]:  use_checkpoint_args ............................. False
[default0]:  use_checkpoint_opt_param_scheduler .............. False
[default0]:  use_contiguous_buffers_in_local_ddp ............. True
[default0]:  use_cpu_initialization .......................... None
[default0]:  use_distributed_optimizer ....................... False
[default0]:  use_flash_attn .................................. False
[default0]:  use_one_sent_docs ............................... False
[default0]:  use_pin_memory .................................. False
[default0]:  use_ring_exchange_p2p ........................... False
[default0]:  use_rotary_position_embeddings .................. False
[default0]:  use_tutel ....................................... False
[default0]:  valid_data_path ................................. None
[default0]:  variable_seq_lengths ............................ False
[default0]:  virtual_pipeline_model_parallel_size ............ None
[default0]:  vision_backbone_type ............................ vit
[default0]:  vision_pretraining .............................. False
[default0]:  vision_pretraining_type ......................... classify
[default0]:  vocab_extra_ids ................................. 0
[default0]:  vocab_file ...................................... data/gpt2-vocab.json
[default0]:  vocab_size ...................................... None
[default0]:  weight_decay .................................... 0.1
[default0]:  weight_decay_incr_style ......................... constant
[default0]:  world_size ...................................... 4
[default0]:  zero_allgather_bucket_size ...................... 0.0
[default0]:  zero_contigious_gradients ....................... False
[default0]:  zero_reduce_bucket_size ......................... 0.0
[default0]:  zero_reduce_scatter ............................. False
[default0]:  zero_stage ...................................... 2
[default0]:-------------------- end of arguments ---------------------
[default0]:setting number of micro-batches to constant 1
[default0]:> building GPT2BPETokenizer tokenizer ...
[default1]:**** Git info for Megatron: git_hash=a18bb88 git_branch=main ****
[default1]:[2023-07-20 17:37:24,181] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[default1]:[2023-07-20 17:37:24,181] [INFO] [comm.py:616:init_distributed] cdb=None
[default0]: > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
[default0]:> initializing torch distributed ...
[default0]:[2023-07-20 17:37:24,204] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[default0]:[2023-07-20 17:37:24,204] [INFO] [comm.py:616:init_distributed] cdb=None
[default0]:[2023-07-20 17:37:24,204] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[default1]:> setting tensorboard ...
[default1]:[2023-07-20 17:37:25,662] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[default1]:[2023-07-20 17:37:25,662] [INFO] [comm.py:616:init_distributed] cdb=None
[default0]:> initialized tensor model parallel with size 1
[default0]:> initialized pipeline model parallel with size 1
[default0]:> setting random seeds to 42 ...
[default0]:> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 2760 and data parallel seed: 42
[default0]:> compiling dataset index builder ...
[default0]:make: Entering directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/data'
[default0]:make: Nothing to be done for 'default'.
[default0]:make: Leaving directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/data'
[default0]:>>> done with dataset index builder. Compilation time: 0.338 seconds
[default0]:> compiling and loading fused kernels ...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:[1/3] c++ -MMD -MF scaled_upper_triang_masked_softmax.o.d -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++14 -O3 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/scaled_upper_triang_masked_softmax.cpp -o scaled_upper_triang_masked_softmax.o 
[default0]:[2/3] /opt/software/pc2/EB-SW/software/CUDA/11.7.0/bin/nvcc  -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -std=c++14 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/scaled_upper_triang_masked_softmax_cuda.cu -o scaled_upper_triang_masked_softmax_cuda.cuda.o 
[default0]:[3/3] c++ scaled_upper_triang_masked_softmax.o scaled_upper_triang_masked_softmax_cuda.cuda.o -shared -L/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/software/pc2/EB-SW/software/CUDA/11.7.0/lib64 -lcudart -o scaled_upper_triang_masked_softmax_cuda.so
[default0]:Loading extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:[1/3] c++ -MMD -MF scaled_masked_softmax.o.d -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++14 -O3 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/scaled_masked_softmax.cpp -o scaled_masked_softmax.o 
[default0]:[2/3] /opt/software/pc2/EB-SW/software/CUDA/11.7.0/bin/nvcc  -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -std=c++14 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/scaled_masked_softmax_cuda.cu -o scaled_masked_softmax_cuda.cuda.o 
[default0]:[3/3] c++ scaled_masked_softmax.o scaled_masked_softmax_cuda.cuda.o -shared -L/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/software/pc2/EB-SW/software/CUDA/11.7.0/lib64 -lcudart -o scaled_masked_softmax_cuda.so
[default0]:Loading extension module scaled_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:[1/3] c++ -MMD -MF scaled_softmax.o.d -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++14 -O3 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/scaled_softmax.cpp -o scaled_softmax.o 
[default0]:[2/3] /opt/software/pc2/EB-SW/software/CUDA/11.7.0/bin/nvcc  -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -std=c++14 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/scaled_softmax_cuda.cu -o scaled_softmax_cuda.cuda.o 
[default0]:[3/3] c++ scaled_softmax.o scaled_softmax_cuda.cuda.o -shared -L/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/software/pc2/EB-SW/software/CUDA/11.7.0/lib64 -lcudart -o scaled_softmax_cuda.so
[default0]:Loading extension module scaled_softmax_cuda...
[default0]:n2gpu1214:266594:266594 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.82<0>
[default0]:n2gpu1214:266594:266594 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1214:266594:266594 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.82<0>
[default0]:n2gpu1214:266594:266594 [0] NCCL INFO Using network IB
[default0]:NCCL version 2.12.12+cuda11.7
[default1]:n2gpu1214:266595:266595 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.82<0>
[default1]:n2gpu1214:266595:266595 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1217:221912:221912 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.85<0>
[default1]:n2gpu1217:221912:221912 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1217:221912:221912 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.85<0>
[default1]:n2gpu1217:221912:221912 [1] NCCL INFO Using network IB
[default0]:n2gpu1217:221911:221911 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.85<0>
[default0]:n2gpu1217:221911:221911 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1217:221911:221911 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.85<0>
[default0]:n2gpu1217:221911:221911 [0] NCCL INFO Using network IB
[default1]:n2gpu1214:266595:266595 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.82<0>
[default1]:n2gpu1214:266595:266595 [1] NCCL INFO Using network IB
[default1]:n2gpu1214:266595:266885 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Channel 00/02 :    0   1   2   3
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Channel 01/02 :    0   1   2   3
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Trees [0] 1/2/-1->0->-1 [1] 1/-1/-1->0->2
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO Trees [0] 3/-1/-1->2->0 [1] 3/0/-1->2->-1
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO Channel 00/0 : 1[44000] -> 2[3000] [receive] via NET/IB/0
[default1]:n2gpu1217:221912:222050 [1] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Channel 00/0 : 3[c4000] -> 0[3000] [receive] via NET/IB/1
[default1]:n2gpu1214:266595:266885 [1] NCCL INFO Channel 00/0 : 1[44000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Channel 01/0 : 3[c4000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO Channel 01/0 : 1[44000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO Channel 00 : 2[3000] -> 3[c4000] via P2P/IPC/read
[default1]:n2gpu1217:221912:222050 [1] NCCL INFO Channel 00/0 : 3[c4000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1214:266595:266885 [1] NCCL INFO Channel 01/0 : 1[44000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO Channel 01 : 2[3000] -> 3[c4000] via P2P/IPC/read
[default1]:n2gpu1217:221912:222050 [1] NCCL INFO Channel 01/0 : 3[c4000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1214:266595:266885 [1] NCCL INFO Connected all rings
[default1]:n2gpu1214:266595:266885 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1217:221912:222050 [1] NCCL INFO Connected all rings
[default1]:n2gpu1217:221912:222050 [1] NCCL INFO Channel 00 : 3[c4000] -> 2[3000] via P2P/IPC/read
[default1]:n2gpu1217:221912:222050 [1] NCCL INFO Channel 01 : 3[c4000] -> 2[3000] via P2P/IPC/read
[default1]:n2gpu1214:266595:266885 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Connected all rings
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO Connected all rings
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Channel 00/0 : 0[3000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Channel 01/0 : 0[3000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO Channel 00/0 : 0[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO Channel 01/0 : 0[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1214:266595:266885 [1] NCCL INFO Connected all trees
[default1]:n2gpu1214:266595:266885 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default1]:n2gpu1214:266595:266885 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1214:266595:266885 [1] NCCL INFO comm 0x14cad80090d0 rank 1 nranks 4 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO Connected all trees
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1214:266594:266882 [0] NCCL INFO comm 0x150d640090d0 rank 0 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1214:266594:266594 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1217:221912:222050 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:221912:222050 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default1]:n2gpu1217:221912:222050 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1217:221911:222052 [0] NCCL INFO comm 0x14ba200090d0 rank 2 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1217:221912:222050 [1] NCCL INFO comm 0x1479cc0090d0 rank 3 nranks 4 cudaDev 1 busId c4000 - Init COMPLETE
[default0]:>>> done with compiling and loading fused kernels. Compilation time: 283.594 seconds
[default0]:time to initialize megatron (seconds): 289.768
[default0]:[after megatron is initialized] datetime: 2023-07-20 17:42:12 
[default0]:building GPT model ...
[default0]:[2023-07-20 17:42:12,899] [INFO] [utils.py:785:see_memory_usage] Before Building Model
[default0]:[2023-07-20 17:42:12,900] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.13 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-07-20 17:42:12,900] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.51 GB, percent = 4.5%
[default0]:[2023-07-20 17:42:13,333] [INFO] [utils.py:785:see_memory_usage] After Building Model
[default0]:[2023-07-20 17:42:13,334] [INFO] [utils.py:786:see_memory_usage] MA 0.66 GB         Max_MA 0.66 GB         CA 0.71 GB         Max_CA 1 GB 
[default0]:[2023-07-20 17:42:13,334] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 22.51 GB, percent = 4.5%
[default0]: > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 354871296
[default0]:setting training iterations to 25000
[default0]:> learning rate decay style: cosine
[default0]:DeepSpeed is enabled.
[default0]:[2023-07-20 17:42:13,337] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Channel 00/02 :    0   1   2   3
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Channel 01/02 :    0   1   2   3
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Trees [0] 1/2/-1->0->-1 [1] 1/-1/-1->0->2
[default1]:n2gpu1214:266595:266908 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO Trees [0] 3/-1/-1->2->0 [1] 3/0/-1->2->-1
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO Channel 00/0 : 1[44000] -> 2[3000] [receive] via NET/IB/0
[default1]:n2gpu1217:221912:222096 [1] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO Channel 01/0 : 1[44000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO Channel 00 : 2[3000] -> 3[c4000] via P2P/IPC/read
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Channel 00/0 : 3[c4000] -> 0[3000] [receive] via NET/IB/1
[default1]:n2gpu1214:266595:266908 [1] NCCL INFO Channel 00/0 : 1[44000] -> 2[3000] [send] via NET/IB/1
[default1]:n2gpu1214:266595:266908 [1] NCCL INFO Channel 01/0 : 1[44000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO Channel 01 : 2[3000] -> 3[c4000] via P2P/IPC/read
[default1]:n2gpu1217:221912:222096 [1] NCCL INFO Channel 00/0 : 3[c4000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1217:221912:222096 [1] NCCL INFO Channel 01/0 : 3[c4000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Channel 01/0 : 3[c4000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1214:266595:266908 [1] NCCL INFO Connected all rings
[default1]:n2gpu1214:266595:266908 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1214:266595:266908 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1217:221912:222096 [1] NCCL INFO Connected all rings
[default1]:n2gpu1217:221912:222096 [1] NCCL INFO Channel 00 : 3[c4000] -> 2[3000] via P2P/IPC/read
[default1]:n2gpu1217:221912:222096 [1] NCCL INFO Channel 01 : 3[c4000] -> 2[3000] via P2P/IPC/read
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO Connected all rings
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO Channel 00/0 : 0[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Channel 00/0 : 0[3000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Channel 01/0 : 0[3000] -> 2[3000] [send] via NET/IB/1
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO Channel 01/0 : 0[3000] -> 2[3000] [receive] via NET/IB/0
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO Channel 00/0 : 2[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO Channel 01/0 : 2[3000] -> 0[3000] [send] via NET/IB/0
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO Connected all trees
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1214:266595:266908 [1] NCCL INFO Connected all trees
[default1]:n2gpu1214:266595:266908 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default1]:n2gpu1214:266595:266908 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1214:266595:266908 [1] NCCL INFO comm 0x14ca900090d0 rank 1 nranks 4 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1214:266594:266907 [0] NCCL INFO comm 0x150d280090d0 rank 0 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1214:266594:266594 [0] NCCL INFO Launch mode Parallel
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1217:221911:222095 [0] NCCL INFO comm 0x14b9d80090d0 rank 2 nranks 4 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1217:221912:222096 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:221912:222096 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
[default1]:n2gpu1217:221912:222096 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1217:221912:222096 [1] NCCL INFO comm 0x1479880090d0 rank 3 nranks 4 cudaDev 1 busId c4000 - Init COMPLETE
[default0]:[2023-07-20 17:42:22,103] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[default0]:[2023-07-20 17:42:22,114] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[default0]:[2023-07-20 17:42:22,125] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[default0]:[2023-07-20 17:42:22,134] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[default0]:[2023-07-20 17:42:22,134] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'apex.optimizers.fused_adam.FusedAdam'>
[default0]:[2023-07-20 17:42:22,134] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[default0]:[2023-07-20 17:42:22,134] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500000000
[default0]:[2023-07-20 17:42:22,134] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500000000
[default0]:[2023-07-20 17:42:22,134] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[default0]:[2023-07-20 17:42:22,134] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
[default0]:Rank: 0 partition count [4, 4] and sizes[(88637440, False), (80384, False)] 
[default1]:Rank: 1 partition count [4, 4] and sizes[(88637440, False), (80384, False)] 
[default1]:Rank: 3 partition count [4, 4] and sizes[(88637440, False), (80384, False)] 
[default0]:Rank: 2 partition count [4, 4] and sizes[(88637440, False), (80384, False)] 
[default0]:[2023-07-20 17:42:23,321] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[default0]:[2023-07-20 17:42:23,322] [INFO] [utils.py:786:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.0 GB         Max_CA 1 GB 
[default0]:[2023-07-20 17:42:23,322] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 23.74 GB, percent = 4.7%
[default0]:[2023-07-20 17:42:23,442] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[default0]:[2023-07-20 17:42:23,443] [INFO] [utils.py:786:see_memory_usage] MA 1.65 GB         Max_MA 1.98 GB         CA 1.99 GB         Max_CA 2 GB 
[default0]:[2023-07-20 17:42:23,443] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 23.73 GB, percent = 4.7%
[default0]:[2023-07-20 17:42:23,443] [INFO] [stage_1_and_2.py:493:__init__] optimizer state initialized
[default0]:[2023-07-20 17:42:23,524] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[default0]:[2023-07-20 17:42:23,524] [INFO] [utils.py:786:see_memory_usage] MA 1.65 GB         Max_MA 1.65 GB         CA 1.99 GB         Max_CA 2 GB 
[default0]:[2023-07-20 17:42:23,525] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 23.73 GB, percent = 4.7%
[default0]:[2023-07-20 17:42:23,526] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[default0]:[2023-07-20 17:42:23,526] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[default0]:[2023-07-20 17:42:23,526] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.optimizer_param_scheduler.OptimizerParamScheduler object at 0x150df04f7fa0>
[default0]:[2023-07-20 17:42:23,526] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0001], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-20 17:42:23,527] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[default0]:[2023-07-20 17:42:23,527] [INFO] [config.py:964:print]   activation_checkpointing_config  {
[default0]:    "partition_activations": false, 
[default0]:    "contiguous_memory_optimization": false, 
[default0]:    "cpu_checkpointing": false, 
[default0]:    "number_checkpoints": null, 
[default0]:    "synchronize_checkpoint_boundary": false, 
[default0]:    "profile": false
[default0]:}
[default0]:[2023-07-20 17:42:23,527] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[default0]:[2023-07-20 17:42:23,527] [INFO] [config.py:964:print]   amp_enabled .................. False
[default0]:[2023-07-20 17:42:23,527] [INFO] [config.py:964:print]   amp_params ................... False
[default0]:[2023-07-20 17:42:23,527] [INFO] [config.py:964:print]   autotuning_config ............ {
[default0]:    "enabled": false, 
[default0]:    "start_step": null, 
[default0]:    "end_step": null, 
[default0]:    "metric_path": null, 
[default0]:    "arg_mappings": null, 
[default0]:    "metric": "throughput", 
[default0]:    "model_info": null, 
[default0]:    "results_dir": "autotuning_results", 
[default0]:    "exps_dir": "autotuning_exps", 
[default0]:    "overwrite": true, 
[default0]:    "fast": true, 
[default0]:    "start_profile_step": 3, 
[default0]:    "end_profile_step": 5, 
[default0]:    "tuner_type": "gridsearch", 
[default0]:    "tuner_early_stopping": 5, 
[default0]:    "tuner_num_trials": 50, 
[default0]:    "model_info_path": null, 
[default0]:    "mp_size": 1, 
[default0]:    "max_train_batch_size": null, 
[default0]:    "min_train_batch_size": 1, 
[default0]:    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[default0]:    "min_train_micro_batch_size_per_gpu": 1, 
[default0]:    "num_tuning_micro_batch_sizes": 3
[default0]:}
[default0]:[2023-07-20 17:42:23,527] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[default0]:[2023-07-20 17:42:23,527] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[default0]:[2023-07-20 17:42:23,527] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[default0]:[2023-07-20 17:42:23,527] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x150df04f7a30>
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   communication_data_type ...... None
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   disable_allgather ............ False
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   dump_state ................... False
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 500, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[default0]:[2023-07-20 17:42:23,528] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   flops_profiler_config ........ {
[default0]:    "enabled": false, 
[default0]:    "recompute_fwd_factor": 0.0, 
[default0]:    "profile_step": 1, 
[default0]:    "module_depth": -1, 
[default0]:    "top_modules": 1, 
[default0]:    "detailed": true, 
[default0]:    "output_file": null
[default0]:}
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   fp16_enabled ................. True
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   global_rank .................. 0
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   gradient_clipping ............ 1
[default0]:[2023-07-20 17:42:23,529] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[default0]:[2023-07-20 17:42:23,556] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[default0]:[2023-07-20 17:42:23,556] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 4096
[default0]:[2023-07-20 17:42:23,556] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[default0]:[2023-07-20 17:42:23,556] [INFO] [config.py:964:print]   loss_scale ................... 0
[default0]:[2023-07-20 17:42:23,556] [INFO] [config.py:964:print]   memory_breakdown ............. False
[default0]:[2023-07-20 17:42:23,556] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[default0]:[2023-07-20 17:42:23,556] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[default0]:[2023-07-20 17:42:23,556] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[default0]:[2023-07-20 17:42:23,556] [INFO] [config.py:964:print]   nebula_config ................ {
[default0]:    "enabled": false, 
[default0]:    "persistent_storage_path": null, 
[default0]:    "persistent_time_interval": 100, 
[default0]:    "num_of_version_in_retention": 2, 
[default0]:    "enable_nebula_load": true, 
[default0]:    "load_path": null
[default0]:}
[default0]:[2023-07-20 17:42:23,556] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[default0]:[2023-07-20 17:42:23,556] [INFO] [config.py:964:print]   optimizer_name ............... None
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   optimizer_params ............. None
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   pld_enabled .................. False
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   pld_params ................... False
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   prescale_gradients ........... False
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   scheduler_name ............... None
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   scheduler_params ............. None
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   sparse_attention ............. None
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   steps_per_print .............. 2000
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   train_batch_size ............. 4
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   world_size ................... 4
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  False
[default0]:[2023-07-20 17:42:23,557] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[default0]:[2023-07-20 17:42:23,558] [INFO] [config.py:964:print]   zero_enabled ................. True
[default0]:[2023-07-20 17:42:23,558] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[default0]:[2023-07-20 17:42:23,558] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2
[default0]:[2023-07-20 17:42:23,558] [INFO] [config.py:950:print_user_config]   json = {
[default0]:    "train_micro_batch_size_per_gpu": 1, 
[default0]:    "train_batch_size": 4, 
[default0]:    "gradient_clipping": 1, 
[default0]:    "zero_optimization": {
[default0]:        "stage": 2, 
[default0]:        "contiguous_gradients": true, 
[default0]:        "overlap_comm": true, 
[default0]:        "reduce_scatter": true, 
[default0]:        "reduce_bucket_size": 5.000000e+08, 
[default0]:        "allgather_bucket_size": 5.000000e+08
[default0]:    }, 
[default0]:    "fp16": {
[default0]:        "enabled": true, 
[default0]:        "loss_scale": 0, 
[default0]:        "loss_scale_window": 500, 
[default0]:        "hysteresis": 2, 
[default0]:        "min_loss_scale": 1, 
[default0]:        "initial_scale_power": 12
[default0]:    }, 
[default0]:    "steps_per_print": 2.000000e+03, 
[default0]:    "wall_clock_breakdown": false
[default0]:}
[default1]:[2023-07-20 17:42:23,577] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at checkpoints/gpt2-b-dist-2023-07-20_173703/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-07-20 17:42:23,588] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at checkpoints/gpt2-b-dist-2023-07-20_173703/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-07-20 17:42:23,577] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at checkpoints/gpt2-b-dist-2023-07-20_173703/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:WARNING: could not find the metadata file checkpoints/gpt2-b-dist-2023-07-20_173703 
[default0]:    will not load any checkpoints and will start from random
[default1]:[2023-07-20 17:42:23,587] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at checkpoints/gpt2-b-dist-2023-07-20_173703/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:(min, max) time across ranks (ms):
[default1]:    load-checkpoint ................................: (31.26, 31.38)
[default0]:[after model, optimizer, and learning rate scheduler are built] datetime: 2023-07-20 17:42:23 
[default0]:> building train, validation, and test datasets ...
[default0]: > datasets target sizes (minimum size):
[default0]:    train:      100000
[default0]:    validation: 20040
[default0]:    test:       40
[default0]:> building train, validation, and test datasets for GPT ...
[default0]:Single data path provided for train, valid & test
[default0]: > building dataset index ...
[default0]:    reading sizes...
[default0]:    reading pointers...
[default0]:    reading document index...
[default0]:    creating numpy buffer of mmap...
[default0]:    creating memory view of numpy buffer...
[default0]: > finished creating indexed dataset in 0.039607 seconds
[default0]:    number of documents: 10000
[default0]: > dataset split:
[default0]:    train:
[default0]:     document indices in [0, 9690) total of 9690 documents
[default0]:    validation:
[default0]:     document indices in [9690, 9990) total of 300 documents
[default0]:    test:
[default0]:     document indices in [9990, 10000) total of 10 documents
[default0]: > WARNING: could not find index map files, building the indices on rank 0 ...
[default0]: > last epoch number of samples (15498) is smaller than 80% of number of samples per epoch (28167), setting separate_last_epoch to True
[default0]: > elasped time to build and save doc-idx mapping (seconds): 0.002395
[default0]:    using:
[default0]:     number of documents:       9690
[default0]:     number of epochs:          4
[default0]:     sequence length:           1024
[default0]:     total number of samples:   112669
[default0]: > elasped time to build and save sample-idx mapping (seconds): 0.023661
[default0]: > building shuffle index with split [0, 84502) and [84502, 112669) ...
[default0]: > elasped time to build and save shuffle-idx mapping (seconds): 0.003742
[default1]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:NCCL version 2.12.12+cuda11.7
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Connected all rings
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Connected all rings
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO Connected all trees
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1214:266594:266915 [0] NCCL INFO comm 0x150cac0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]: > loading doc-idx mapping from data/index-cache/5832c3497dd14891c50a2ab2eb6de8d4_doc_idx.npy
[default0]: > loading sample-idx mapping from data/index-cache/5832c3497dd14891c50a2ab2eb6de8d4_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/index-cache/5832c3497dd14891c50a2ab2eb6de8d4_shuffle_idx.npy
[default0]:    loaded indexed file in 0.018 seconds
[default0]:    total number of samples: 112670
[default0]:    total number of epochs: 4
[default0]: > WARNING: could not find index map files, building the indices on rank 0 ...
[default0]: > last epoch number of samples (826) is larger than 80% of number of samples per epoch (914), setting separate_last_epoch to False
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Connected all rings
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO Connected all trees
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1214:266595:266917 [1] NCCL INFO comm 0x14caac0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1217:221912:222103 [1] NCCL INFO comm 0x1479100090d0 rank 0 nranks 1 cudaDev 1 busId c4000 - Init COMPLETE
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1217:221911:222105 [0] NCCL INFO comm 0x14b9f80090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]: > elasped time to build and save doc-idx mapping (seconds): 0.002003
[default0]:    using:
[default0]:     number of documents:       300
[default0]:     number of epochs:          22
[default0]:     sequence length:           1024
[default0]:     total number of samples:   20129
[default0]: > elasped time to build and save sample-idx mapping (seconds): 0.002086
[default0]: > building shuffle index with split [0, 20129) and [20129, 20129) ...
[default0]: > elasped time to build and save shuffle-idx mapping (seconds): 0.001801
[default0]: > loading doc-idx mapping from data/index-cache/a3ad0980b6379b9223473697dd33fa29_doc_idx.npy
[default0]: > loading sample-idx mapping from data/index-cache/a3ad0980b6379b9223473697dd33fa29_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/index-cache/a3ad0980b6379b9223473697dd33fa29_shuffle_idx.npy
[default0]:    loaded indexed file in 0.002 seconds
[default0]:    total number of samples: 20130
[default0]:    total number of epochs: 22
[default0]: > WARNING: could not find index map files, building the indices on rank 0 ...
[default0]: > last epoch number of samples (9) is smaller than 80% of number of samples per epoch (31), setting separate_last_epoch to True
[default0]: > elasped time to build and save doc-idx mapping (seconds): 0.003498
[default0]:    using:
[default0]:     number of documents:       10
[default0]:     number of epochs:          2
[default0]:     sequence length:           1024
[default0]:     total number of samples:   63
[default0]: > elasped time to build and save sample-idx mapping (seconds): 0.001718
[default0]: > building shuffle index with split [0, 31) and [31, 63) ...
[default0]: > elasped time to build and save shuffle-idx mapping (seconds): 0.001347
[default0]: > loading doc-idx mapping from data/index-cache/1e68a7d2f04b1d480404f552cd53e228_doc_idx.npy
[default0]: > loading sample-idx mapping from data/index-cache/1e68a7d2f04b1d480404f552cd53e228_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/index-cache/1e68a7d2f04b1d480404f552cd53e228_shuffle_idx.npy
[default0]:    loaded indexed file in 0.002 seconds
[default0]:    total number of samples: 64
[default0]:    total number of epochs: 2
[default0]:> finished creating GPT datasets ...
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Connected all rings
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO Connected all trees
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Connected all rings
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO Connected all trees
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1214:266595:266923 [1] NCCL INFO comm 0x14ca0c0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Connected all rings
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO Connected all trees
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1217:221912:222113 [1] NCCL INFO comm 0x1479040090d0 rank 0 nranks 1 cudaDev 1 busId c4000 - Init COMPLETE
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Connected all rings
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO Connected all trees
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1217:221911:222111 [0] NCCL INFO comm 0x14b9540090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1214:266594:266926 [0] NCCL INFO comm 0x150ca00090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:[after dataloaders are built] datetime: 2023-07-20 17:42:36 
[default0]:done with setup ...
[default0]:training ...
[default1]:(min, max) time across ranks (ms):
[default1]:    model-and-optimizer-setup ......................: (10845.22, 10857.10)
[default1]:    train/valid/test-data-iterators-setup ..........: (12420.55, 12580.89)
[default0]:[before the start of training step] datetime: 2023-07-20 17:42:36 
[default1]: iteration        1/   25000 | consumed samples:            4 | consumed tokens:         4096 | elapsed time per iteration (ms): 5452.4 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 1.101036E+01 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.734 | TFLOPs: 0.59 |
[default0]:[Rank 0] (after 1 iterations) memory (MB) | allocated: 1724.16015625 | max allocated: 3980.93505859375 | reserved: 4522.0 | max reserved: 4522.0
[default1]: iteration        2/   25000 | consumed samples:            8 | consumed tokens:         8192 | elapsed time per iteration (ms): 2430.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 9.919950E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.646 | TFLOPs: 1.32 |
[default1]: iteration        3/   25000 | consumed samples:           12 | consumed tokens:        12288 | elapsed time per iteration (ms): 2359.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 9.855112E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.695 | TFLOPs: 1.36 |
[default1]: iteration        4/   25000 | consumed samples:           16 | consumed tokens:        16384 | elapsed time per iteration (ms): 2392.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 9.451264E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.672 | TFLOPs: 1.34 |
[default1]: iteration        5/   25000 | consumed samples:           20 | consumed tokens:        20480 | elapsed time per iteration (ms): 2379.7 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 9.545372E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.681 | TFLOPs: 1.35 |
[default1]: iteration        6/   25000 | consumed samples:           24 | consumed tokens:        24576 | elapsed time per iteration (ms): 2560.7 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 9.435808E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.562 | TFLOPs: 1.25 |
[default1]: iteration        7/   25000 | consumed samples:           28 | consumed tokens:        28672 | elapsed time per iteration (ms): 2453.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 9.182366E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.630 | TFLOPs: 1.31 |
[default1]: iteration        8/   25000 | consumed samples:           32 | consumed tokens:        32768 | elapsed time per iteration (ms): 2563.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 9.314082E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.561 | TFLOPs: 1.25 |
[default1]: iteration        9/   25000 | consumed samples:           36 | consumed tokens:        36864 | elapsed time per iteration (ms): 2340.4 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 9.048479E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.709 | TFLOPs: 1.37 |
[default1]: iteration       10/   25000 | consumed samples:           40 | consumed tokens:        40960 | elapsed time per iteration (ms): 2516.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.987621E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.590 | TFLOPs: 1.27 |
[default1]: iteration       11/   25000 | consumed samples:           44 | consumed tokens:        45056 | elapsed time per iteration (ms): 2436.4 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 9.063411E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.642 | TFLOPs: 1.31 |
[default1]: iteration       12/   25000 | consumed samples:           48 | consumed tokens:        49152 | elapsed time per iteration (ms): 2405.5 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.891442E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.663 | TFLOPs: 1.33 |
[default1]: iteration       13/   25000 | consumed samples:           52 | consumed tokens:        53248 | elapsed time per iteration (ms): 2552.5 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.700676E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.567 | TFLOPs: 1.25 |
[default1]: iteration       14/   25000 | consumed samples:           56 | consumed tokens:        57344 | elapsed time per iteration (ms): 2219.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 9.037027E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.803 | TFLOPs: 1.44 |
[default1]: iteration       15/   25000 | consumed samples:           60 | consumed tokens:        61440 | elapsed time per iteration (ms): 2494.8 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.803801E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.603 | TFLOPs: 1.28 |
[default1]: iteration       16/   25000 | consumed samples:           64 | consumed tokens:        65536 | elapsed time per iteration (ms): 2357.4 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.722116E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.697 | TFLOPs: 1.36 |
[default1]: iteration       17/   25000 | consumed samples:           68 | consumed tokens:        69632 | elapsed time per iteration (ms): 2445.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.445209E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.636 | TFLOPs: 1.31 |
[default1]: iteration       18/   25000 | consumed samples:           72 | consumed tokens:        73728 | elapsed time per iteration (ms): 2379.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.648333E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.681 | TFLOPs: 1.35 |
[default1]: iteration       19/   25000 | consumed samples:           76 | consumed tokens:        77824 | elapsed time per iteration (ms): 2531.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.228197E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.580 | TFLOPs: 1.27 |
[default1]: iteration       20/   25000 | consumed samples:           80 | consumed tokens:        81920 | elapsed time per iteration (ms): 2296.2 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.758333E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.742 | TFLOPs: 1.39 |
[default1]: iteration       21/   25000 | consumed samples:           84 | consumed tokens:        86016 | elapsed time per iteration (ms): 2512.9 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.512340E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.592 | TFLOPs: 1.27 |
[default1]: iteration       22/   25000 | consumed samples:           88 | consumed tokens:        90112 | elapsed time per iteration (ms): 2535.9 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.448372E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.577 | TFLOPs: 1.26 |
[default1]: iteration       23/   25000 | consumed samples:           92 | consumed tokens:        94208 | elapsed time per iteration (ms): 2637.1 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.169928E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.517 | TFLOPs: 1.21 |
[default1]: iteration       24/   25000 | consumed samples:           96 | consumed tokens:        98304 | elapsed time per iteration (ms): 2385.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.309509E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.677 | TFLOPs: 1.34 |
[default1]: iteration       25/   25000 | consumed samples:          100 | consumed tokens:       102400 | elapsed time per iteration (ms): 2221.8 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.316252E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.800 | TFLOPs: 1.44 |
[default1]: iteration       26/   25000 | consumed samples:          104 | consumed tokens:       106496 | elapsed time per iteration (ms): 2261.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.615446E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.769 | TFLOPs: 1.42 |
[default1]: iteration       27/   25000 | consumed samples:          108 | consumed tokens:       110592 | elapsed time per iteration (ms): 2432.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.033484E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.645 | TFLOPs: 1.32 |
[default1]: iteration       28/   25000 | consumed samples:          112 | consumed tokens:       114688 | elapsed time per iteration (ms): 2291.4 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.006241E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.746 | TFLOPs: 1.40 |
[default1]: iteration       29/   25000 | consumed samples:          116 | consumed tokens:       118784 | elapsed time per iteration (ms): 2582.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.165880E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.549 | TFLOPs: 1.24 |
[default1]: iteration       30/   25000 | consumed samples:          120 | consumed tokens:       122880 | elapsed time per iteration (ms): 2335.2 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.125429E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.713 | TFLOPs: 1.37 |
[default1]: iteration       31/   25000 | consumed samples:          124 | consumed tokens:       126976 | elapsed time per iteration (ms): 2465.7 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.684864E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.622 | TFLOPs: 1.30 |
[default1]: iteration       32/   25000 | consumed samples:          128 | consumed tokens:       131072 | elapsed time per iteration (ms): 2510.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.344813E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.593 | TFLOPs: 1.28 |
[default1]: iteration       33/   25000 | consumed samples:          132 | consumed tokens:       135168 | elapsed time per iteration (ms): 2659.9 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.064339E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.504 | TFLOPs: 1.20 |
[default1]: iteration       34/   25000 | consumed samples:          136 | consumed tokens:       139264 | elapsed time per iteration (ms): 2482.2 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.708628E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.612 | TFLOPs: 1.29 |
[default1]: iteration       35/   25000 | consumed samples:          140 | consumed tokens:       143360 | elapsed time per iteration (ms): 2443.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.745066E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.637 | TFLOPs: 1.31 |
[default1]: iteration       36/   25000 | consumed samples:          144 | consumed tokens:       147456 | elapsed time per iteration (ms): 2445.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.892136E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.636 | TFLOPs: 1.31 |
[default1]: iteration       37/   25000 | consumed samples:          148 | consumed tokens:       151552 | elapsed time per iteration (ms): 2375.7 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.156974E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.684 | TFLOPs: 1.35 |
[default1]: iteration       38/   25000 | consumed samples:          152 | consumed tokens:       155648 | elapsed time per iteration (ms): 2466.5 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.432605E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.622 | TFLOPs: 1.30 |
[default1]: iteration       39/   25000 | consumed samples:          156 | consumed tokens:       159744 | elapsed time per iteration (ms): 2334.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.437685E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.713 | TFLOPs: 1.37 |
[default1]: iteration       40/   25000 | consumed samples:          160 | consumed tokens:       163840 | elapsed time per iteration (ms): 2459.1 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.702587E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.627 | TFLOPs: 1.30 |
[default1]: iteration       41/   25000 | consumed samples:          164 | consumed tokens:       167936 | elapsed time per iteration (ms): 2473.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.998784E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.617 | TFLOPs: 1.29 |
[default1]: iteration       42/   25000 | consumed samples:          168 | consumed tokens:       172032 | elapsed time per iteration (ms): 2509.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.408659E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.594 | TFLOPs: 1.28 |
[default1]: iteration       43/   25000 | consumed samples:          172 | consumed tokens:       176128 | elapsed time per iteration (ms): 2421.7 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.538496E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.652 | TFLOPs: 1.32 |
[default1]: iteration       44/   25000 | consumed samples:          176 | consumed tokens:       180224 | elapsed time per iteration (ms): 2594.8 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.911654E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.542 | TFLOPs: 1.23 |
[default1]: iteration       45/   25000 | consumed samples:          180 | consumed tokens:       184320 | elapsed time per iteration (ms): 2401.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.717638E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.666 | TFLOPs: 1.33 |
[default1]: iteration       46/   25000 | consumed samples:          184 | consumed tokens:       188416 | elapsed time per iteration (ms): 2349.8 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.524832E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.702 | TFLOPs: 1.36 |
[default1]: iteration       47/   25000 | consumed samples:          188 | consumed tokens:       192512 | elapsed time per iteration (ms): 2475.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.797348E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.616 | TFLOPs: 1.29 |
[default1]: iteration       48/   25000 | consumed samples:          192 | consumed tokens:       196608 | elapsed time per iteration (ms): 2346.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.420953E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.705 | TFLOPs: 1.36 |
[default1]: iteration       49/   25000 | consumed samples:          196 | consumed tokens:       200704 | elapsed time per iteration (ms): 2418.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.335157E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.654 | TFLOPs: 1.32 |
[default1]: iteration       50/   25000 | consumed samples:          200 | consumed tokens:       204800 | elapsed time per iteration (ms): 2587.2 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.516787E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.546 | TFLOPs: 1.24 |
[default1]:----------------------------------------------------------------------------------------------
[default1]: validation loss at iteration 50 | lm loss value: 7.690791E+00 | lm loss PPL: 2.188104E+03 | 
[default1]:----------------------------------------------------------------------------------------------
[default1]: iteration       51/   25000 | consumed samples:          204 | consumed tokens:       208896 | elapsed time per iteration (ms): 4108.5 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.855198E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.974 | TFLOPs: 0.78 |
[default1]: iteration       52/   25000 | consumed samples:          208 | consumed tokens:       212992 | elapsed time per iteration (ms): 2386.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.823327E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.676 | TFLOPs: 1.34 |
[default1]: iteration       53/   25000 | consumed samples:          212 | consumed tokens:       217088 | elapsed time per iteration (ms): 2454.7 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.869451E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.630 | TFLOPs: 1.30 |
[default1]: iteration       54/   25000 | consumed samples:          216 | consumed tokens:       221184 | elapsed time per iteration (ms): 2500.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.869527E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.600 | TFLOPs: 1.28 |
[default1]: iteration       55/   25000 | consumed samples:          220 | consumed tokens:       225280 | elapsed time per iteration (ms): 2466.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.832477E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.622 | TFLOPs: 1.30 |
[default1]: iteration       56/   25000 | consumed samples:          224 | consumed tokens:       229376 | elapsed time per iteration (ms): 2403.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.281932E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.665 | TFLOPs: 1.33 |
[default1]: iteration       57/   25000 | consumed samples:          228 | consumed tokens:       233472 | elapsed time per iteration (ms): 2593.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.789832E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.542 | TFLOPs: 1.23 |
[default1]: iteration       58/   25000 | consumed samples:          232 | consumed tokens:       237568 | elapsed time per iteration (ms): 2520.9 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.550521E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.587 | TFLOPs: 1.27 |
[default1]: iteration       59/   25000 | consumed samples:          236 | consumed tokens:       241664 | elapsed time per iteration (ms): 2431.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.886112E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.645 | TFLOPs: 1.32 |
[default1]: iteration       60/   25000 | consumed samples:          240 | consumed tokens:       245760 | elapsed time per iteration (ms): 2680.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.184806E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.492 | TFLOPs: 1.19 |
[default1]: iteration       61/   25000 | consumed samples:          244 | consumed tokens:       249856 | elapsed time per iteration (ms): 2564.4 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.963735E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.560 | TFLOPs: 1.25 |
[default1]: iteration       62/   25000 | consumed samples:          248 | consumed tokens:       253952 | elapsed time per iteration (ms): 2722.2 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.480073E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.469 | TFLOPs: 1.18 |
[default1]: iteration       63/   25000 | consumed samples:          252 | consumed tokens:       258048 | elapsed time per iteration (ms): 2432.5 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.512263E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.644 | TFLOPs: 1.32 |
[default1]: iteration       64/   25000 | consumed samples:          256 | consumed tokens:       262144 | elapsed time per iteration (ms): 2365.7 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.512570E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.691 | TFLOPs: 1.35 |
[default1]: iteration       65/   25000 | consumed samples:          260 | consumed tokens:       266240 | elapsed time per iteration (ms): 2411.2 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.392235E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.659 | TFLOPs: 1.33 |
[default1]: iteration       66/   25000 | consumed samples:          264 | consumed tokens:       270336 | elapsed time per iteration (ms): 2395.9 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.578752E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.669 | TFLOPs: 1.34 |
[default1]: iteration       67/   25000 | consumed samples:          268 | consumed tokens:       274432 | elapsed time per iteration (ms): 2540.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.486832E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.575 | TFLOPs: 1.26 |
[default1]: iteration       68/   25000 | consumed samples:          272 | consumed tokens:       278528 | elapsed time per iteration (ms): 2573.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.689421E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.554 | TFLOPs: 1.24 |
[default1]: iteration       69/   25000 | consumed samples:          276 | consumed tokens:       282624 | elapsed time per iteration (ms): 2702.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.261049E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.480 | TFLOPs: 1.19 |
[default1]: iteration       70/   25000 | consumed samples:          280 | consumed tokens:       286720 | elapsed time per iteration (ms): 2566.5 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.198868E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.559 | TFLOPs: 1.25 |
[default1]: iteration       71/   25000 | consumed samples:          284 | consumed tokens:       290816 | elapsed time per iteration (ms): 2478.1 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.567920E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.614 | TFLOPs: 1.29 |
[default1]: iteration       72/   25000 | consumed samples:          288 | consumed tokens:       294912 | elapsed time per iteration (ms): 2274.9 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.992415E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.758 | TFLOPs: 1.41 |
[default1]: iteration       73/   25000 | consumed samples:          292 | consumed tokens:       299008 | elapsed time per iteration (ms): 2359.9 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.306112E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.695 | TFLOPs: 1.36 |
[default1]: iteration       74/   25000 | consumed samples:          296 | consumed tokens:       303104 | elapsed time per iteration (ms): 2478.5 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.350047E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.614 | TFLOPs: 1.29 |
[default1]: iteration       75/   25000 | consumed samples:          300 | consumed tokens:       307200 | elapsed time per iteration (ms): 2576.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.294127E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.552 | TFLOPs: 1.24 |
[default1]: iteration       76/   25000 | consumed samples:          304 | consumed tokens:       311296 | elapsed time per iteration (ms): 2453.3 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.409999E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.630 | TFLOPs: 1.31 |
[default1]: iteration       77/   25000 | consumed samples:          308 | consumed tokens:       315392 | elapsed time per iteration (ms): 2505.8 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.326796E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.596 | TFLOPs: 1.28 |
[default1]: iteration       78/   25000 | consumed samples:          312 | consumed tokens:       319488 | elapsed time per iteration (ms): 2431.2 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.588758E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.645 | TFLOPs: 1.32 |
[default1]: iteration       79/   25000 | consumed samples:          316 | consumed tokens:       323584 | elapsed time per iteration (ms): 2356.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.274026E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.697 | TFLOPs: 1.36 |
[default1]: iteration       80/   25000 | consumed samples:          320 | consumed tokens:       327680 | elapsed time per iteration (ms): 2494.2 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.584877E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.604 | TFLOPs: 1.28 |
[default1]: iteration       81/   25000 | consumed samples:          324 | consumed tokens:       331776 | elapsed time per iteration (ms): 2348.1 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.605204E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.704 | TFLOPs: 1.36 |
[default1]: iteration       82/   25000 | consumed samples:          328 | consumed tokens:       335872 | elapsed time per iteration (ms): 2544.1 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.535396E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.572 | TFLOPs: 1.26 |
[default1]: iteration       83/   25000 | consumed samples:          332 | consumed tokens:       339968 | elapsed time per iteration (ms): 2406.4 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.574862E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.662 | TFLOPs: 1.33 |
[default1]: iteration       84/   25000 | consumed samples:          336 | consumed tokens:       344064 | elapsed time per iteration (ms): 2376.7 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.566497E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.683 | TFLOPs: 1.35 |
[default1]: iteration       85/   25000 | consumed samples:          340 | consumed tokens:       348160 | elapsed time per iteration (ms): 2597.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.475285E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.540 | TFLOPs: 1.23 |
[default1]: iteration       86/   25000 | consumed samples:          344 | consumed tokens:       352256 | elapsed time per iteration (ms): 2434.4 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.512221E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.643 | TFLOPs: 1.32 |
[default1]: iteration       87/   25000 | consumed samples:          348 | consumed tokens:       356352 | elapsed time per iteration (ms): 2572.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.433224E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.555 | TFLOPs: 1.24 |
[default1]: iteration       89/   25000 | consumed samples:          356 | consumed tokens:       364544 | elapsed time per iteration (ms): 2510.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.369469E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.594 | TFLOPs: 1.28 |
[default1]: iteration       90/   25000 | consumed samples:          360 | consumed tokens:       368640 | elapsed time per iteration (ms): 2448.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.267854E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.634 | TFLOPs: 1.31 |
[default1]: iteration       91/   25000 | consumed samples:          364 | consumed tokens:       372736 | elapsed time per iteration (ms): 2485.5 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.663534E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.609 | TFLOPs: 1.29 |
[default1]: iteration       92/   25000 | consumed samples:          368 | consumed tokens:       376832 | elapsed time per iteration (ms): 2454.7 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.710967E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.630 | TFLOPs: 1.30 |
[default1]: iteration       93/   25000 | consumed samples:          372 | consumed tokens:       380928 | elapsed time per iteration (ms): 2379.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.981897E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.681 | TFLOPs: 1.35 |
[default1]: iteration       94/   25000 | consumed samples:          376 | consumed tokens:       385024 | elapsed time per iteration (ms): 2283.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.314520E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.752 | TFLOPs: 1.40 |
[default1]: iteration       95/   25000 | consumed samples:          380 | consumed tokens:       389120 | elapsed time per iteration (ms): 2470.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.189736E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.619 | TFLOPs: 1.30 |
[default1]: iteration       96/   25000 | consumed samples:          384 | consumed tokens:       393216 | elapsed time per iteration (ms): 2451.4 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.496776E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.632 | TFLOPs: 1.31 |
[default1]: iteration       97/   25000 | consumed samples:          388 | consumed tokens:       397312 | elapsed time per iteration (ms): 2451.9 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.295903E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.631 | TFLOPs: 1.31 |
[default1]: iteration       98/   25000 | consumed samples:          392 | consumed tokens:       401408 | elapsed time per iteration (ms): 2497.8 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.174608E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.601 | TFLOPs: 1.28 |
[default1]: iteration       99/   25000 | consumed samples:          396 | consumed tokens:       405504 | elapsed time per iteration (ms): 2414.2 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.589715E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.657 | TFLOPs: 1.33 |
[default1]: iteration      100/   25000 | consumed samples:          400 | consumed tokens:       409600 | elapsed time per iteration (ms): 2565.8 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 8.043124E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.559 | TFLOPs: 1.25 |
[default1]:-----------------------------------------------------------------------------------------------
[default1]: validation loss at iteration 100 | lm loss value: 7.625431E+00 | lm loss PPL: 2.049663E+03 | 
[default1]:-----------------------------------------------------------------------------------------------
[default1]: iteration      101/   25000 | consumed samples:          404 | consumed tokens:       413696 | elapsed time per iteration (ms): 3622.0 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.261272E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.104 | TFLOPs: 0.88 |
[default1]: iteration      102/   25000 | consumed samples:          408 | consumed tokens:       417792 | elapsed time per iteration (ms): 2476.5 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.265584E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.615 | TFLOPs: 1.29 |
[default1]: iteration      103/   25000 | consumed samples:          412 | consumed tokens:       421888 | elapsed time per iteration (ms): 2398.9 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.304036E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.667 | TFLOPs: 1.34 |
[default1]: iteration      104/   25000 | consumed samples:          416 | consumed tokens:       425984 | elapsed time per iteration (ms): 2408.2 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.183846E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.661 | TFLOPs: 1.33 |
[default1]: iteration      105/   25000 | consumed samples:          420 | consumed tokens:       430080 | elapsed time per iteration (ms): 2294.8 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.998222E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.743 | TFLOPs: 1.40 |
[default1]: iteration      106/   25000 | consumed samples:          424 | consumed tokens:       434176 | elapsed time per iteration (ms): 2536.1 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.597990E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.577 | TFLOPs: 1.26 |
[default1]: iteration      107/   25000 | consumed samples:          428 | consumed tokens:       438272 | elapsed time per iteration (ms): 2439.5 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.250839E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.640 | TFLOPs: 1.31 |
[default1]: iteration      108/   25000 | consumed samples:          432 | consumed tokens:       442368 | elapsed time per iteration (ms): 2575.6 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.826941E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.553 | TFLOPs: 1.24 |
[default1]: iteration      109/   25000 | consumed samples:          436 | consumed tokens:       446464 | elapsed time per iteration (ms): 2381.1 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.110746E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.680 | TFLOPs: 1.35 |
[default1]: iteration      111/   25000 | consumed samples:          444 | consumed tokens:       454656 | elapsed time per iteration (ms): 2536.7 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.497922E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.577 | TFLOPs: 1.26 |
[default1]: iteration      112/   25000 | consumed samples:          448 | consumed tokens:       458752 | elapsed time per iteration (ms): 2530.2 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.350692E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.581 | TFLOPs: 1.27 |
[default1]: iteration      113/   25000 | consumed samples:          452 | consumed tokens:       462848 | elapsed time per iteration (ms): 2362.2 | learning rate: 1.000E-04 | global batch size:     4 | lm loss: 7.644704E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.693 | TFLOPs: 1.36 |
[default1]: iteration      114/   25000 | consumed samples:          456 | consumed tokens:       466944 | elapsed time per iteration (ms): 2391.8 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.601328E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.672 | TFLOPs: 1.34 |
[default1]: iteration      115/   25000 | consumed samples:          460 | consumed tokens:       471040 | elapsed time per iteration (ms): 2494.2 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.156890E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.604 | TFLOPs: 1.28 |
[default1]: iteration      116/   25000 | consumed samples:          464 | consumed tokens:       475136 | elapsed time per iteration (ms): 2556.0 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.452023E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.565 | TFLOPs: 1.25 |
[default1]: iteration      117/   25000 | consumed samples:          468 | consumed tokens:       479232 | elapsed time per iteration (ms): 2379.7 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.226232E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.681 | TFLOPs: 1.35 |
[default1]: iteration      118/   25000 | consumed samples:          472 | consumed tokens:       483328 | elapsed time per iteration (ms): 2483.4 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.309105E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.611 | TFLOPs: 1.29 |
[default1]: iteration      119/   25000 | consumed samples:          476 | consumed tokens:       487424 | elapsed time per iteration (ms): 2520.0 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.691682E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.587 | TFLOPs: 1.27 |
[default1]: iteration      120/   25000 | consumed samples:          480 | consumed tokens:       491520 | elapsed time per iteration (ms): 2595.9 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 6.812328E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.541 | TFLOPs: 1.23 |
[default1]: iteration      121/   25000 | consumed samples:          484 | consumed tokens:       495616 | elapsed time per iteration (ms): 2367.2 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.642071E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.690 | TFLOPs: 1.35 |
[default1]: iteration      122/   25000 | consumed samples:          488 | consumed tokens:       499712 | elapsed time per iteration (ms): 2302.6 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.307219E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.737 | TFLOPs: 1.39 |
[default1]: iteration      123/   25000 | consumed samples:          492 | consumed tokens:       503808 | elapsed time per iteration (ms): 2632.8 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.597849E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.519 | TFLOPs: 1.22 |
[default1]: iteration      124/   25000 | consumed samples:          496 | consumed tokens:       507904 | elapsed time per iteration (ms): 2723.0 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.376967E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.469 | TFLOPs: 1.18 |
[default1]: iteration      125/   25000 | consumed samples:          500 | consumed tokens:       512000 | elapsed time per iteration (ms): 2392.1 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.390687E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.672 | TFLOPs: 1.34 |
[default1]: iteration      126/   25000 | consumed samples:          504 | consumed tokens:       516096 | elapsed time per iteration (ms): 2436.4 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.458168E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.642 | TFLOPs: 1.31 |
[default1]: iteration      127/   25000 | consumed samples:          508 | consumed tokens:       520192 | elapsed time per iteration (ms): 2467.5 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.222587E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.621 | TFLOPs: 1.30 |
[default1]: iteration      128/   25000 | consumed samples:          512 | consumed tokens:       524288 | elapsed time per iteration (ms): 2473.0 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.121731E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.617 | TFLOPs: 1.30 |
[default1]: iteration      129/   25000 | consumed samples:          516 | consumed tokens:       528384 | elapsed time per iteration (ms): 2513.0 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.605215E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.592 | TFLOPs: 1.27 |
[default1]: iteration      130/   25000 | consumed samples:          520 | consumed tokens:       532480 | elapsed time per iteration (ms): 2486.6 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.241224E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.609 | TFLOPs: 1.29 |
[default1]: iteration      131/   25000 | consumed samples:          524 | consumed tokens:       536576 | elapsed time per iteration (ms): 2325.5 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.442937E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.720 | TFLOPs: 1.38 |
[default1]: iteration      132/   25000 | consumed samples:          528 | consumed tokens:       540672 | elapsed time per iteration (ms): 2566.7 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.116924E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.558 | TFLOPs: 1.25 |
[default1]: iteration      133/   25000 | consumed samples:          532 | consumed tokens:       544768 | elapsed time per iteration (ms): 2426.4 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.432195E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.649 | TFLOPs: 1.32 |
[default1]: iteration      134/   25000 | consumed samples:          536 | consumed tokens:       548864 | elapsed time per iteration (ms): 2365.0 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.292687E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.691 | TFLOPs: 1.35 |
[default1]: iteration      135/   25000 | consumed samples:          540 | consumed tokens:       552960 | elapsed time per iteration (ms): 2583.5 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 6.937217E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.548 | TFLOPs: 1.24 |
[default1]: iteration      136/   25000 | consumed samples:          544 | consumed tokens:       557056 | elapsed time per iteration (ms): 2410.8 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.418915E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.659 | TFLOPs: 1.33 |
[default1]: iteration      137/   25000 | consumed samples:          548 | consumed tokens:       561152 | elapsed time per iteration (ms): 2470.2 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.271294E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.619 | TFLOPs: 1.30 |
[default1]: iteration      138/   25000 | consumed samples:          552 | consumed tokens:       565248 | elapsed time per iteration (ms): 2359.2 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.261642E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.695 | TFLOPs: 1.36 |
[default1]: iteration      139/   25000 | consumed samples:          556 | consumed tokens:       569344 | elapsed time per iteration (ms): 2634.2 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.908561E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.519 | TFLOPs: 1.22 |
[default1]: iteration      140/   25000 | consumed samples:          560 | consumed tokens:       573440 | elapsed time per iteration (ms): 2575.3 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.424751E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.553 | TFLOPs: 1.24 |
[default1]: iteration      141/   25000 | consumed samples:          564 | consumed tokens:       577536 | elapsed time per iteration (ms): 2449.0 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.254780E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.633 | TFLOPs: 1.31 |
[default1]: iteration      142/   25000 | consumed samples:          568 | consumed tokens:       581632 | elapsed time per iteration (ms): 2541.3 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 6.813395E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.574 | TFLOPs: 1.26 |
[default1]: iteration      143/   25000 | consumed samples:          572 | consumed tokens:       585728 | elapsed time per iteration (ms): 2581.2 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 8.565665E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.550 | TFLOPs: 1.24 |
[default1]: iteration      144/   25000 | consumed samples:          576 | consumed tokens:       589824 | elapsed time per iteration (ms): 2386.1 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.196256E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.676 | TFLOPs: 1.34 |
[default1]: iteration      145/   25000 | consumed samples:          580 | consumed tokens:       593920 | elapsed time per iteration (ms): 2630.8 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.397042E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.520 | TFLOPs: 1.22 |
[default1]: iteration      146/   25000 | consumed samples:          584 | consumed tokens:       598016 | elapsed time per iteration (ms): 2363.4 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.077110E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.692 | TFLOPs: 1.36 |
[default1]: iteration      147/   25000 | consumed samples:          588 | consumed tokens:       602112 | elapsed time per iteration (ms): 2366.9 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.390302E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.690 | TFLOPs: 1.35 |
[default1]: iteration      148/   25000 | consumed samples:          592 | consumed tokens:       606208 | elapsed time per iteration (ms): 2354.3 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.834306E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.699 | TFLOPs: 1.36 |
[default1]: iteration      149/   25000 | consumed samples:          596 | consumed tokens:       610304 | elapsed time per iteration (ms): 2424.1 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.234691E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.650 | TFLOPs: 1.32 |
[default1]: iteration      150/   25000 | consumed samples:          600 | consumed tokens:       614400 | elapsed time per iteration (ms): 2484.2 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.720994E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.610 | TFLOPs: 1.29 |
[default1]:-----------------------------------------------------------------------------------------------
[default1]: validation loss at iteration 150 | lm loss value: 7.258691E+00 | lm loss PPL: 1.420396E+03 | 
[default1]:-----------------------------------------------------------------------------------------------
[default1]: iteration      151/   25000 | consumed samples:          604 | consumed tokens:       618496 | elapsed time per iteration (ms): 3837.4 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.467715E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.042 | TFLOPs: 0.83 |
[default1]: iteration      152/   25000 | consumed samples:          608 | consumed tokens:       622592 | elapsed time per iteration (ms): 2423.6 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.550468E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.650 | TFLOPs: 1.32 |
[default1]: iteration      153/   25000 | consumed samples:          612 | consumed tokens:       626688 | elapsed time per iteration (ms): 2405.9 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 6.642467E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.663 | TFLOPs: 1.33 |
[default1]: iteration      154/   25000 | consumed samples:          616 | consumed tokens:       630784 | elapsed time per iteration (ms): 2542.9 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.045528E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.573 | TFLOPs: 1.26 |
[default1]: iteration      155/   25000 | consumed samples:          620 | consumed tokens:       634880 | elapsed time per iteration (ms): 2468.4 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 6.912847E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.620 | TFLOPs: 1.30 |
[default1]: iteration      156/   25000 | consumed samples:          624 | consumed tokens:       638976 | elapsed time per iteration (ms): 2345.5 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.111818E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.705 | TFLOPs: 1.37 |
[default1]: iteration      157/   25000 | consumed samples:          628 | consumed tokens:       643072 | elapsed time per iteration (ms): 2333.6 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.045090E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.714 | TFLOPs: 1.37 |
[default1]: iteration      158/   25000 | consumed samples:          632 | consumed tokens:       647168 | elapsed time per iteration (ms): 2299.7 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.202477E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.739 | TFLOPs: 1.39 |
[default1]: iteration      159/   25000 | consumed samples:          636 | consumed tokens:       651264 | elapsed time per iteration (ms): 2443.6 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.803747E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.637 | TFLOPs: 1.31 |
[default1]: iteration      160/   25000 | consumed samples:          640 | consumed tokens:       655360 | elapsed time per iteration (ms): 2390.2 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.731584E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.673 | TFLOPs: 1.34 |
[default1]: iteration      161/   25000 | consumed samples:          644 | consumed tokens:       659456 | elapsed time per iteration (ms): 2264.7 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.060736E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.766 | TFLOPs: 1.41 |
[default1]: iteration      162/   25000 | consumed samples:          648 | consumed tokens:       663552 | elapsed time per iteration (ms): 2428.1 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.186256E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.647 | TFLOPs: 1.32 |
[default1]: iteration      163/   25000 | consumed samples:          652 | consumed tokens:       667648 | elapsed time per iteration (ms): 2451.0 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 6.980355E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.632 | TFLOPs: 1.31 |
[default1]: iteration      164/   25000 | consumed samples:          656 | consumed tokens:       671744 | elapsed time per iteration (ms): 2352.7 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.089229E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.700 | TFLOPs: 1.36 |
[default1]: iteration      165/   25000 | consumed samples:          660 | consumed tokens:       675840 | elapsed time per iteration (ms): 2591.1 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.044776E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.544 | TFLOPs: 1.24 |
[default1]: iteration      166/   25000 | consumed samples:          664 | consumed tokens:       679936 | elapsed time per iteration (ms): 2508.0 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.064444E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.595 | TFLOPs: 1.28 |
[default1]: iteration      167/   25000 | consumed samples:          668 | consumed tokens:       684032 | elapsed time per iteration (ms): 2387.1 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.173026E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.676 | TFLOPs: 1.34 |
[default1]: iteration      168/   25000 | consumed samples:          672 | consumed tokens:       688128 | elapsed time per iteration (ms): 2510.7 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.332054E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.593 | TFLOPs: 1.28 |
[default1]: iteration      169/   25000 | consumed samples:          676 | consumed tokens:       692224 | elapsed time per iteration (ms): 2623.8 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 6.963744E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.525 | TFLOPs: 1.22 |
[default1]: iteration      170/   25000 | consumed samples:          680 | consumed tokens:       696320 | elapsed time per iteration (ms): 2491.7 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.838296E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.605 | TFLOPs: 1.29 |
[default1]: iteration      171/   25000 | consumed samples:          684 | consumed tokens:       700416 | elapsed time per iteration (ms): 2579.7 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.503897E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.551 | TFLOPs: 1.24 |
[default1]: iteration      172/   25000 | consumed samples:          688 | consumed tokens:       704512 | elapsed time per iteration (ms): 2285.3 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.188279E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.750 | TFLOPs: 1.40 |
[default1]: iteration      173/   25000 | consumed samples:          692 | consumed tokens:       708608 | elapsed time per iteration (ms): 2485.8 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.568464E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.609 | TFLOPs: 1.29 |
[default1]: iteration      174/   25000 | consumed samples:          696 | consumed tokens:       712704 | elapsed time per iteration (ms): 2383.6 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.166946E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.678 | TFLOPs: 1.34 |
[default1]: iteration      175/   25000 | consumed samples:          700 | consumed tokens:       716800 | elapsed time per iteration (ms): 2400.4 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.508054E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.666 | TFLOPs: 1.33 |
[default1]: iteration      176/   25000 | consumed samples:          704 | consumed tokens:       720896 | elapsed time per iteration (ms): 2467.5 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.163535E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.621 | TFLOPs: 1.30 |
[default1]: iteration      177/   25000 | consumed samples:          708 | consumed tokens:       724992 | elapsed time per iteration (ms): 2419.1 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.198996E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.654 | TFLOPs: 1.32 |
[default1]: iteration      178/   25000 | consumed samples:          712 | consumed tokens:       729088 | elapsed time per iteration (ms): 2642.3 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.015882E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.514 | TFLOPs: 1.21 |
[default1]: iteration      179/   25000 | consumed samples:          716 | consumed tokens:       733184 | elapsed time per iteration (ms): 2644.4 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.765598E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.513 | TFLOPs: 1.21 |
[default1]: iteration      180/   25000 | consumed samples:          720 | consumed tokens:       737280 | elapsed time per iteration (ms): 2470.6 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.708239E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.619 | TFLOPs: 1.30 |
[default1]: iteration      181/   25000 | consumed samples:          724 | consumed tokens:       741376 | elapsed time per iteration (ms): 2427.1 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.686440E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.648 | TFLOPs: 1.32 |
[default1]: iteration      182/   25000 | consumed samples:          728 | consumed tokens:       745472 | elapsed time per iteration (ms): 2555.3 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 6.666674E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.565 | TFLOPs: 1.25 |
[default1]: iteration      183/   25000 | consumed samples:          732 | consumed tokens:       749568 | elapsed time per iteration (ms): 2473.3 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.106392E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.617 | TFLOPs: 1.29 |
[default1]: iteration      184/   25000 | consumed samples:          736 | consumed tokens:       753664 | elapsed time per iteration (ms): 2551.3 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.070036E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.568 | TFLOPs: 1.26 |
[default1]: iteration      185/   25000 | consumed samples:          740 | consumed tokens:       757760 | elapsed time per iteration (ms): 2485.5 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.268352E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.609 | TFLOPs: 1.29 |
[default1]: iteration      186/   25000 | consumed samples:          744 | consumed tokens:       761856 | elapsed time per iteration (ms): 2302.0 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 6.969769E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.738 | TFLOPs: 1.39 |
[default1]: iteration      187/   25000 | consumed samples:          748 | consumed tokens:       765952 | elapsed time per iteration (ms): 2563.6 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 6.750978E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.560 | TFLOPs: 1.25 |
[default1]: iteration      188/   25000 | consumed samples:          752 | consumed tokens:       770048 | elapsed time per iteration (ms): 2405.8 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.374234E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.663 | TFLOPs: 1.33 |
[default1]: iteration      189/   25000 | consumed samples:          756 | consumed tokens:       774144 | elapsed time per iteration (ms): 2845.7 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.275902E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.406 | TFLOPs: 1.13 |
[default1]: iteration      190/   25000 | consumed samples:          760 | consumed tokens:       778240 | elapsed time per iteration (ms): 2564.1 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.295075E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.560 | TFLOPs: 1.25 |
[default1]: iteration      191/   25000 | consumed samples:          764 | consumed tokens:       782336 | elapsed time per iteration (ms): 2354.0 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.155650E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.699 | TFLOPs: 1.36 |
[default1]: iteration      192/   25000 | consumed samples:          768 | consumed tokens:       786432 | elapsed time per iteration (ms): 2439.5 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.196234E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.640 | TFLOPs: 1.31 |
[default1]: iteration      193/   25000 | consumed samples:          772 | consumed tokens:       790528 | elapsed time per iteration (ms): 2605.0 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.008453E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.535 | TFLOPs: 1.23 |
[default1]: iteration      194/   25000 | consumed samples:          776 | consumed tokens:       794624 | elapsed time per iteration (ms): 2507.3 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 6.939807E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.595 | TFLOPs: 1.28 |
[default1]: iteration      195/   25000 | consumed samples:          780 | consumed tokens:       798720 | elapsed time per iteration (ms): 2386.5 | learning rate: 9.999E-05 | global batch size:     4 | lm loss: 7.001882E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.676 | TFLOPs: 1.34 |
[default1]: iteration      196/   25000 | consumed samples:          784 | consumed tokens:       802816 | elapsed time per iteration (ms): 2494.0 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.016233E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.604 | TFLOPs: 1.28 |
[default1]: iteration      197/   25000 | consumed samples:          788 | consumed tokens:       806912 | elapsed time per iteration (ms): 2530.2 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.284934E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.581 | TFLOPs: 1.27 |
[default1]: iteration      198/   25000 | consumed samples:          792 | consumed tokens:       811008 | elapsed time per iteration (ms): 2492.6 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.726794E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.605 | TFLOPs: 1.28 |
[default1]: iteration      199/   25000 | consumed samples:          796 | consumed tokens:       815104 | elapsed time per iteration (ms): 2497.8 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.930924E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.601 | TFLOPs: 1.28 |
[default1]: iteration      200/   25000 | consumed samples:          800 | consumed tokens:       819200 | elapsed time per iteration (ms): 2513.7 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.552175E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.591 | TFLOPs: 1.27 |
[default1]:-----------------------------------------------------------------------------------------------
[default1]: validation loss at iteration 200 | lm loss value: 7.267284E+00 | lm loss PPL: 1.432654E+03 | 
[default1]:-----------------------------------------------------------------------------------------------
[default1]: iteration      201/   25000 | consumed samples:          804 | consumed tokens:       823296 | elapsed time per iteration (ms): 3662.6 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.151570E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.092 | TFLOPs: 0.87 |
[default1]: iteration      202/   25000 | consumed samples:          808 | consumed tokens:       827392 | elapsed time per iteration (ms): 2558.7 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.175815E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.563 | TFLOPs: 1.25 |
[default1]: iteration      203/   25000 | consumed samples:          812 | consumed tokens:       831488 | elapsed time per iteration (ms): 2391.4 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.059680E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.673 | TFLOPs: 1.34 |
[default1]: iteration      204/   25000 | consumed samples:          816 | consumed tokens:       835584 | elapsed time per iteration (ms): 2679.6 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.453012E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.493 | TFLOPs: 1.20 |
[default1]: iteration      205/   25000 | consumed samples:          820 | consumed tokens:       839680 | elapsed time per iteration (ms): 2534.7 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.136364E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.578 | TFLOPs: 1.26 |
[default1]: iteration      206/   25000 | consumed samples:          824 | consumed tokens:       843776 | elapsed time per iteration (ms): 2586.3 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.846879E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.547 | TFLOPs: 1.24 |
[default1]: iteration      207/   25000 | consumed samples:          828 | consumed tokens:       847872 | elapsed time per iteration (ms): 2761.1 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.210739E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.449 | TFLOPs: 1.16 |
[default1]: iteration      208/   25000 | consumed samples:          832 | consumed tokens:       851968 | elapsed time per iteration (ms): 2700.0 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.003294E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.481 | TFLOPs: 1.19 |
[default1]: iteration      209/   25000 | consumed samples:          836 | consumed tokens:       856064 | elapsed time per iteration (ms): 2344.1 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.021745E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.706 | TFLOPs: 1.37 |
[default1]: iteration      210/   25000 | consumed samples:          840 | consumed tokens:       860160 | elapsed time per iteration (ms): 2494.6 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.533822E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.603 | TFLOPs: 1.28 |
[default1]: iteration      211/   25000 | consumed samples:          844 | consumed tokens:       864256 | elapsed time per iteration (ms): 2507.7 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.431276E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.595 | TFLOPs: 1.28 |
[default1]: iteration      212/   25000 | consumed samples:          848 | consumed tokens:       868352 | elapsed time per iteration (ms): 2544.9 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.313651E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.572 | TFLOPs: 1.26 |
[default1]: iteration      213/   25000 | consumed samples:          852 | consumed tokens:       872448 | elapsed time per iteration (ms): 2392.9 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.242763E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.672 | TFLOPs: 1.34 |
[default1]: iteration      214/   25000 | consumed samples:          856 | consumed tokens:       876544 | elapsed time per iteration (ms): 2605.1 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.471536E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.535 | TFLOPs: 1.23 |
[default1]: iteration      215/   25000 | consumed samples:          860 | consumed tokens:       880640 | elapsed time per iteration (ms): 2562.9 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.837858E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.561 | TFLOPs: 1.25 |
[default1]: iteration      216/   25000 | consumed samples:          864 | consumed tokens:       884736 | elapsed time per iteration (ms): 2454.3 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.109109E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.630 | TFLOPs: 1.30 |
[default1]: iteration      217/   25000 | consumed samples:          868 | consumed tokens:       888832 | elapsed time per iteration (ms): 2248.0 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.185417E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.779 | TFLOPs: 1.42 |
[default1]: iteration      218/   25000 | consumed samples:          872 | consumed tokens:       892928 | elapsed time per iteration (ms): 2530.6 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.862926E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.581 | TFLOPs: 1.27 |
[default1]: iteration      219/   25000 | consumed samples:          876 | consumed tokens:       897024 | elapsed time per iteration (ms): 2539.1 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.649988E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.575 | TFLOPs: 1.26 |
[default1]: iteration      220/   25000 | consumed samples:          880 | consumed tokens:       901120 | elapsed time per iteration (ms): 2416.0 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.113799E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.656 | TFLOPs: 1.33 |
[default1]: iteration      221/   25000 | consumed samples:          884 | consumed tokens:       905216 | elapsed time per iteration (ms): 2572.8 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.103639E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.555 | TFLOPs: 1.24 |
[default1]: iteration      222/   25000 | consumed samples:          888 | consumed tokens:       909312 | elapsed time per iteration (ms): 2258.4 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.265204E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.771 | TFLOPs: 1.42 |
[default1]: iteration      223/   25000 | consumed samples:          892 | consumed tokens:       913408 | elapsed time per iteration (ms): 2461.7 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.382063E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.625 | TFLOPs: 1.30 |
[default1]: iteration      224/   25000 | consumed samples:          896 | consumed tokens:       917504 | elapsed time per iteration (ms): 2334.3 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.962614E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.714 | TFLOPs: 1.37 |
[default1]: iteration      225/   25000 | consumed samples:          900 | consumed tokens:       921600 | elapsed time per iteration (ms): 2411.2 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.860936E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.659 | TFLOPs: 1.33 |
[default1]: iteration      226/   25000 | consumed samples:          904 | consumed tokens:       925696 | elapsed time per iteration (ms): 2481.7 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.701273E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.612 | TFLOPs: 1.29 |
[default1]: iteration      227/   25000 | consumed samples:          908 | consumed tokens:       929792 | elapsed time per iteration (ms): 2281.1 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.410933E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.754 | TFLOPs: 1.40 |
[default1]: iteration      228/   25000 | consumed samples:          912 | consumed tokens:       933888 | elapsed time per iteration (ms): 2444.2 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.338614E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.637 | TFLOPs: 1.31 |
[default1]: iteration      229/   25000 | consumed samples:          916 | consumed tokens:       937984 | elapsed time per iteration (ms): 2410.9 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.021234E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.659 | TFLOPs: 1.33 |
[default1]: iteration      230/   25000 | consumed samples:          920 | consumed tokens:       942080 | elapsed time per iteration (ms): 2140.2 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.888314E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.869 | TFLOPs: 1.50 |
[default1]: iteration      231/   25000 | consumed samples:          924 | consumed tokens:       946176 | elapsed time per iteration (ms): 2292.5 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.836457E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.745 | TFLOPs: 1.40 |
[default1]: iteration      233/   25000 | consumed samples:          932 | consumed tokens:       954368 | elapsed time per iteration (ms): 2623.1 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.033500E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.525 | TFLOPs: 1.22 |
[default1]: iteration      234/   25000 | consumed samples:          936 | consumed tokens:       958464 | elapsed time per iteration (ms): 2610.2 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.315663E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.532 | TFLOPs: 1.23 |
[default1]: iteration      235/   25000 | consumed samples:          940 | consumed tokens:       962560 | elapsed time per iteration (ms): 2566.0 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.654600E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.559 | TFLOPs: 1.25 |
[default1]: iteration      236/   25000 | consumed samples:          944 | consumed tokens:       966656 | elapsed time per iteration (ms): 2455.0 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.573829E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.629 | TFLOPs: 1.30 |
[default1]: iteration      237/   25000 | consumed samples:          948 | consumed tokens:       970752 | elapsed time per iteration (ms): 2489.1 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.309318E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.607 | TFLOPs: 1.29 |
[default1]: iteration      238/   25000 | consumed samples:          952 | consumed tokens:       974848 | elapsed time per iteration (ms): 2546.7 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.125353E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.571 | TFLOPs: 1.26 |
[default1]: iteration      239/   25000 | consumed samples:          956 | consumed tokens:       978944 | elapsed time per iteration (ms): 2505.0 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.164477E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.597 | TFLOPs: 1.28 |
[default1]: iteration      240/   25000 | consumed samples:          960 | consumed tokens:       983040 | elapsed time per iteration (ms): 2417.7 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.323871E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.654 | TFLOPs: 1.32 |
[default1]: iteration      241/   25000 | consumed samples:          964 | consumed tokens:       987136 | elapsed time per iteration (ms): 2542.8 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.916872E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.573 | TFLOPs: 1.26 |
[default1]: iteration      242/   25000 | consumed samples:          968 | consumed tokens:       991232 | elapsed time per iteration (ms): 2498.3 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.231743E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.601 | TFLOPs: 1.28 |
[default1]: iteration      243/   25000 | consumed samples:          972 | consumed tokens:       995328 | elapsed time per iteration (ms): 2505.5 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.026654E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.596 | TFLOPs: 1.28 |
[default1]: iteration      244/   25000 | consumed samples:          976 | consumed tokens:       999424 | elapsed time per iteration (ms): 2501.5 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.322917E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.599 | TFLOPs: 1.28 |
[default1]: iteration      245/   25000 | consumed samples:          980 | consumed tokens:      1003520 | elapsed time per iteration (ms): 2392.6 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.119165E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.672 | TFLOPs: 1.34 |
[default1]: iteration      246/   25000 | consumed samples:          984 | consumed tokens:      1007616 | elapsed time per iteration (ms): 2313.4 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.435873E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.729 | TFLOPs: 1.38 |
[default1]: iteration      247/   25000 | consumed samples:          988 | consumed tokens:      1011712 | elapsed time per iteration (ms): 2618.1 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.273847E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.528 | TFLOPs: 1.22 |
[default1]: iteration      248/   25000 | consumed samples:          992 | consumed tokens:      1015808 | elapsed time per iteration (ms): 2469.0 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.032455E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.620 | TFLOPs: 1.30 |
[default1]: iteration      249/   25000 | consumed samples:          996 | consumed tokens:      1019904 | elapsed time per iteration (ms): 2546.7 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 6.814654E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.571 | TFLOPs: 1.26 |
[default1]: iteration      250/   25000 | consumed samples:         1000 | consumed tokens:      1024000 | elapsed time per iteration (ms): 2585.4 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.283939E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.547 | TFLOPs: 1.24 |
[default1]:-----------------------------------------------------------------------------------------------
[default1]: validation loss at iteration 250 | lm loss value: 7.338063E+00 | lm loss PPL: 1.537731E+03 | 
[default1]:-----------------------------------------------------------------------------------------------
[default1]: iteration      251/   25000 | consumed samples:         1004 | consumed tokens:      1028096 | elapsed time per iteration (ms): 3556.0 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.286290E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.125 | TFLOPs: 0.90 |
[default1]: iteration      252/   25000 | consumed samples:         1008 | consumed tokens:      1032192 | elapsed time per iteration (ms): 2706.3 | learning rate: 9.998E-05 | global batch size:     4 | lm loss: 7.348339E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.478 | TFLOPs: 1.18 |
[default1]: iteration      253/   25000 | consumed samples:         1012 | consumed tokens:      1036288 | elapsed time per iteration (ms): 2332.7 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.240086E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.715 | TFLOPs: 1.37 |
[default1]: iteration      254/   25000 | consumed samples:         1016 | consumed tokens:      1040384 | elapsed time per iteration (ms): 2427.0 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.482195E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.648 | TFLOPs: 1.32 |
[default1]: iteration      255/   25000 | consumed samples:         1020 | consumed tokens:      1044480 | elapsed time per iteration (ms): 2475.7 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.336192E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.616 | TFLOPs: 1.29 |
[default1]: iteration      256/   25000 | consumed samples:         1024 | consumed tokens:      1048576 | elapsed time per iteration (ms): 2459.0 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.899348E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.627 | TFLOPs: 1.30 |
[default1]: iteration      257/   25000 | consumed samples:         1028 | consumed tokens:      1052672 | elapsed time per iteration (ms): 2428.6 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.858077E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.647 | TFLOPs: 1.32 |
[default1]: iteration      258/   25000 | consumed samples:         1032 | consumed tokens:      1056768 | elapsed time per iteration (ms): 2432.1 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.258826E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.645 | TFLOPs: 1.32 |
[default1]: iteration      259/   25000 | consumed samples:         1036 | consumed tokens:      1060864 | elapsed time per iteration (ms): 2472.8 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.045340E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.618 | TFLOPs: 1.30 |
[default1]: iteration      260/   25000 | consumed samples:         1040 | consumed tokens:      1064960 | elapsed time per iteration (ms): 2364.7 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.279881E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.692 | TFLOPs: 1.35 |
[default1]: iteration      261/   25000 | consumed samples:         1044 | consumed tokens:      1069056 | elapsed time per iteration (ms): 2389.0 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.993685E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.674 | TFLOPs: 1.34 |
[default1]: iteration      262/   25000 | consumed samples:         1048 | consumed tokens:      1073152 | elapsed time per iteration (ms): 2542.2 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.166858E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.573 | TFLOPs: 1.26 |
[default1]: iteration      263/   25000 | consumed samples:         1052 | consumed tokens:      1077248 | elapsed time per iteration (ms): 2642.6 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.723114E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.514 | TFLOPs: 1.21 |
[default1]: iteration      264/   25000 | consumed samples:         1056 | consumed tokens:      1081344 | elapsed time per iteration (ms): 2385.0 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.449503E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.677 | TFLOPs: 1.34 |
[default1]: iteration      265/   25000 | consumed samples:         1060 | consumed tokens:      1085440 | elapsed time per iteration (ms): 2389.2 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.896433E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.674 | TFLOPs: 1.34 |
[default1]: iteration      266/   25000 | consumed samples:         1064 | consumed tokens:      1089536 | elapsed time per iteration (ms): 2553.1 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.855347E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.567 | TFLOPs: 1.25 |
[default1]: iteration      267/   25000 | consumed samples:         1068 | consumed tokens:      1093632 | elapsed time per iteration (ms): 2577.0 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.039413E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.552 | TFLOPs: 1.24 |
[default1]: iteration      268/   25000 | consumed samples:         1072 | consumed tokens:      1097728 | elapsed time per iteration (ms): 2199.7 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.852436E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.818 | TFLOPs: 1.46 |
[default1]: iteration      269/   25000 | consumed samples:         1076 | consumed tokens:      1101824 | elapsed time per iteration (ms): 2420.3 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.229102E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.653 | TFLOPs: 1.32 |
[default1]: iteration      270/   25000 | consumed samples:         1080 | consumed tokens:      1105920 | elapsed time per iteration (ms): 2234.0 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.159045E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.791 | TFLOPs: 1.43 |
[default1]: iteration      271/   25000 | consumed samples:         1084 | consumed tokens:      1110016 | elapsed time per iteration (ms): 2383.8 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.491742E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.678 | TFLOPs: 1.34 |
[default1]: iteration      272/   25000 | consumed samples:         1088 | consumed tokens:      1114112 | elapsed time per iteration (ms): 2662.0 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.988488E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.503 | TFLOPs: 1.20 |
[default1]: iteration      273/   25000 | consumed samples:         1092 | consumed tokens:      1118208 | elapsed time per iteration (ms): 2391.7 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.413799E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.672 | TFLOPs: 1.34 |
[default1]: iteration      274/   25000 | consumed samples:         1096 | consumed tokens:      1122304 | elapsed time per iteration (ms): 2376.3 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.001068E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.683 | TFLOPs: 1.35 |
[default1]: iteration      275/   25000 | consumed samples:         1100 | consumed tokens:      1126400 | elapsed time per iteration (ms): 2443.9 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.366967E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.637 | TFLOPs: 1.31 |
[default1]: iteration      276/   25000 | consumed samples:         1104 | consumed tokens:      1130496 | elapsed time per iteration (ms): 2524.5 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.435110E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.584 | TFLOPs: 1.27 |
[default1]: iteration      277/   25000 | consumed samples:         1108 | consumed tokens:      1134592 | elapsed time per iteration (ms): 2343.6 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.787616E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.707 | TFLOPs: 1.37 |
[default1]: iteration      278/   25000 | consumed samples:         1112 | consumed tokens:      1138688 | elapsed time per iteration (ms): 2489.0 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.332128E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.607 | TFLOPs: 1.29 |
[default1]: iteration      279/   25000 | consumed samples:         1116 | consumed tokens:      1142784 | elapsed time per iteration (ms): 2479.7 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.515425E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.613 | TFLOPs: 1.29 |
[default1]: iteration      280/   25000 | consumed samples:         1120 | consumed tokens:      1146880 | elapsed time per iteration (ms): 2443.9 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.869763E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.637 | TFLOPs: 1.31 |
[default1]: iteration      281/   25000 | consumed samples:         1124 | consumed tokens:      1150976 | elapsed time per iteration (ms): 2382.4 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.283100E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.679 | TFLOPs: 1.34 |
[default1]: iteration      282/   25000 | consumed samples:         1128 | consumed tokens:      1155072 | elapsed time per iteration (ms): 2415.2 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.048719E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.656 | TFLOPs: 1.33 |
[default1]: iteration      283/   25000 | consumed samples:         1132 | consumed tokens:      1159168 | elapsed time per iteration (ms): 2422.6 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.647571E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.651 | TFLOPs: 1.32 |
[default1]: iteration      284/   25000 | consumed samples:         1136 | consumed tokens:      1163264 | elapsed time per iteration (ms): 2243.7 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.959918E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.783 | TFLOPs: 1.43 |
[default1]: iteration      285/   25000 | consumed samples:         1140 | consumed tokens:      1167360 | elapsed time per iteration (ms): 2481.5 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.174525E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.612 | TFLOPs: 1.29 |
[default1]: iteration      286/   25000 | consumed samples:         1144 | consumed tokens:      1171456 | elapsed time per iteration (ms): 2434.7 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.186377E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.643 | TFLOPs: 1.32 |
[default1]: iteration      287/   25000 | consumed samples:         1148 | consumed tokens:      1175552 | elapsed time per iteration (ms): 2530.9 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.851074E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.580 | TFLOPs: 1.27 |
[default1]: iteration      288/   25000 | consumed samples:         1152 | consumed tokens:      1179648 | elapsed time per iteration (ms): 2470.3 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.259710E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.619 | TFLOPs: 1.30 |
[default1]: iteration      289/   25000 | consumed samples:         1156 | consumed tokens:      1183744 | elapsed time per iteration (ms): 2563.7 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.674731E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.560 | TFLOPs: 1.25 |
[default1]: iteration      290/   25000 | consumed samples:         1160 | consumed tokens:      1187840 | elapsed time per iteration (ms): 2514.0 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.035294E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.591 | TFLOPs: 1.27 |
[default1]: iteration      291/   25000 | consumed samples:         1164 | consumed tokens:      1191936 | elapsed time per iteration (ms): 2469.5 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.369087E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.620 | TFLOPs: 1.30 |
[default1]: iteration      292/   25000 | consumed samples:         1168 | consumed tokens:      1196032 | elapsed time per iteration (ms): 2583.9 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.644644E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.548 | TFLOPs: 1.24 |
[default1]: iteration      293/   25000 | consumed samples:         1172 | consumed tokens:      1200128 | elapsed time per iteration (ms): 2353.4 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.123137E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.700 | TFLOPs: 1.36 |
[default1]: iteration      294/   25000 | consumed samples:         1176 | consumed tokens:      1204224 | elapsed time per iteration (ms): 2356.7 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.131925E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.697 | TFLOPs: 1.36 |
[default1]: iteration      295/   25000 | consumed samples:         1180 | consumed tokens:      1208320 | elapsed time per iteration (ms): 2388.5 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.251491E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.675 | TFLOPs: 1.34 |
[default1]: iteration      296/   25000 | consumed samples:         1184 | consumed tokens:      1212416 | elapsed time per iteration (ms): 2471.5 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.112514E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.618 | TFLOPs: 1.30 |
[default1]: iteration      297/   25000 | consumed samples:         1188 | consumed tokens:      1216512 | elapsed time per iteration (ms): 2658.6 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.406477E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.505 | TFLOPs: 1.20 |
[default1]: iteration      298/   25000 | consumed samples:         1192 | consumed tokens:      1220608 | elapsed time per iteration (ms): 2357.9 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 6.932881E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.696 | TFLOPs: 1.36 |
[default1]: iteration      299/   25000 | consumed samples:         1196 | consumed tokens:      1224704 | elapsed time per iteration (ms): 2358.2 | learning rate: 9.997E-05 | global batch size:     4 | lm loss: 7.392470E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.696 | TFLOPs: 1.36 |
[default1]: iteration      300/   25000 | consumed samples:         1200 | consumed tokens:      1228800 | elapsed time per iteration (ms): 2340.0 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.981033E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.709 | TFLOPs: 1.37 |
[default1]:-----------------------------------------------------------------------------------------------
[default1]: validation loss at iteration 300 | lm loss value: 7.221083E+00 | lm loss PPL: 1.367970E+03 | 
[default1]:-----------------------------------------------------------------------------------------------
[default1]: iteration      301/   25000 | consumed samples:         1204 | consumed tokens:      1232896 | elapsed time per iteration (ms): 3762.9 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.513073E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.063 | TFLOPs: 0.85 |
[default1]: iteration      302/   25000 | consumed samples:         1208 | consumed tokens:      1236992 | elapsed time per iteration (ms): 2165.3 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.151344E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.847 | TFLOPs: 1.48 |
[default1]: iteration      303/   25000 | consumed samples:         1212 | consumed tokens:      1241088 | elapsed time per iteration (ms): 2629.0 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.138031E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.521 | TFLOPs: 1.22 |
[default1]: iteration      304/   25000 | consumed samples:         1216 | consumed tokens:      1245184 | elapsed time per iteration (ms): 2533.6 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.114461E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.579 | TFLOPs: 1.26 |
[default1]: iteration      305/   25000 | consumed samples:         1220 | consumed tokens:      1249280 | elapsed time per iteration (ms): 2636.3 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.618876E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.517 | TFLOPs: 1.21 |
[default1]: iteration      306/   25000 | consumed samples:         1224 | consumed tokens:      1253376 | elapsed time per iteration (ms): 2462.5 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.221930E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.624 | TFLOPs: 1.30 |
[default1]: iteration      307/   25000 | consumed samples:         1228 | consumed tokens:      1257472 | elapsed time per iteration (ms): 2334.7 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.960315E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.713 | TFLOPs: 1.37 |
[default1]: iteration      308/   25000 | consumed samples:         1232 | consumed tokens:      1261568 | elapsed time per iteration (ms): 2564.5 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.900252E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.560 | TFLOPs: 1.25 |
[default1]: iteration      309/   25000 | consumed samples:         1236 | consumed tokens:      1265664 | elapsed time per iteration (ms): 2548.2 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.106174E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.570 | TFLOPs: 1.26 |
[default1]: iteration      310/   25000 | consumed samples:         1240 | consumed tokens:      1269760 | elapsed time per iteration (ms): 2401.5 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.119199E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.666 | TFLOPs: 1.33 |
[default1]: iteration      311/   25000 | consumed samples:         1244 | consumed tokens:      1273856 | elapsed time per iteration (ms): 2439.3 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.705724E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.640 | TFLOPs: 1.31 |
[default1]: iteration      312/   25000 | consumed samples:         1248 | consumed tokens:      1277952 | elapsed time per iteration (ms): 2263.1 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.772346E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.768 | TFLOPs: 1.42 |
[default1]: iteration      313/   25000 | consumed samples:         1252 | consumed tokens:      1282048 | elapsed time per iteration (ms): 2661.4 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.718231E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.503 | TFLOPs: 1.20 |
[default1]: iteration      314/   25000 | consumed samples:         1256 | consumed tokens:      1286144 | elapsed time per iteration (ms): 2572.7 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.088972E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.555 | TFLOPs: 1.24 |
[default1]: iteration      315/   25000 | consumed samples:         1260 | consumed tokens:      1290240 | elapsed time per iteration (ms): 2472.0 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.936284E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.618 | TFLOPs: 1.30 |
[default1]: iteration      316/   25000 | consumed samples:         1264 | consumed tokens:      1294336 | elapsed time per iteration (ms): 2678.9 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.144765E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.493 | TFLOPs: 1.20 |
[default1]: iteration      317/   25000 | consumed samples:         1268 | consumed tokens:      1298432 | elapsed time per iteration (ms): 2530.0 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.717398E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.581 | TFLOPs: 1.27 |
[default1]: iteration      318/   25000 | consumed samples:         1272 | consumed tokens:      1302528 | elapsed time per iteration (ms): 2369.2 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.233825E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.688 | TFLOPs: 1.35 |
[default1]: iteration      319/   25000 | consumed samples:         1276 | consumed tokens:      1306624 | elapsed time per iteration (ms): 2366.1 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.723096E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.691 | TFLOPs: 1.35 |
[default1]: iteration      320/   25000 | consumed samples:         1280 | consumed tokens:      1310720 | elapsed time per iteration (ms): 2292.6 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.746517E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.745 | TFLOPs: 1.40 |
[default1]: iteration      321/   25000 | consumed samples:         1284 | consumed tokens:      1314816 | elapsed time per iteration (ms): 2385.3 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.023325E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.677 | TFLOPs: 1.34 |
[default1]: iteration      322/   25000 | consumed samples:         1288 | consumed tokens:      1318912 | elapsed time per iteration (ms): 2691.0 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.974618E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.486 | TFLOPs: 1.19 |
[default1]: iteration      323/   25000 | consumed samples:         1292 | consumed tokens:      1323008 | elapsed time per iteration (ms): 2622.6 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 8.022133E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.525 | TFLOPs: 1.22 |
[default1]: iteration      324/   25000 | consumed samples:         1296 | consumed tokens:      1327104 | elapsed time per iteration (ms): 2500.0 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.698625E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.600 | TFLOPs: 1.28 |
[default1]: iteration      325/   25000 | consumed samples:         1300 | consumed tokens:      1331200 | elapsed time per iteration (ms): 2428.2 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.104123E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.647 | TFLOPs: 1.32 |
[default1]: iteration      326/   25000 | consumed samples:         1304 | consumed tokens:      1335296 | elapsed time per iteration (ms): 2514.9 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.411509E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.591 | TFLOPs: 1.27 |
[default1]: iteration      327/   25000 | consumed samples:         1308 | consumed tokens:      1339392 | elapsed time per iteration (ms): 2346.1 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.784500E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.705 | TFLOPs: 1.37 |
[default1]: iteration      328/   25000 | consumed samples:         1312 | consumed tokens:      1343488 | elapsed time per iteration (ms): 2388.0 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.052529E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.675 | TFLOPs: 1.34 |
[default1]: iteration      329/   25000 | consumed samples:         1316 | consumed tokens:      1347584 | elapsed time per iteration (ms): 2514.0 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.261096E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.591 | TFLOPs: 1.27 |
[default1]: iteration      330/   25000 | consumed samples:         1320 | consumed tokens:      1351680 | elapsed time per iteration (ms): 2346.9 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.139801E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.704 | TFLOPs: 1.36 |
[default1]: iteration      331/   25000 | consumed samples:         1324 | consumed tokens:      1355776 | elapsed time per iteration (ms): 2499.6 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.682619E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.600 | TFLOPs: 1.28 |
[default1]: iteration      332/   25000 | consumed samples:         1328 | consumed tokens:      1359872 | elapsed time per iteration (ms): 2504.3 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.892673E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.597 | TFLOPs: 1.28 |
[default1]: iteration      333/   25000 | consumed samples:         1332 | consumed tokens:      1363968 | elapsed time per iteration (ms): 2349.7 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.128813E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.702 | TFLOPs: 1.36 |
[default1]: iteration      334/   25000 | consumed samples:         1336 | consumed tokens:      1368064 | elapsed time per iteration (ms): 2395.0 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.288193E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.670 | TFLOPs: 1.34 |
[default1]: iteration      335/   25000 | consumed samples:         1340 | consumed tokens:      1372160 | elapsed time per iteration (ms): 2489.7 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.175555E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.607 | TFLOPs: 1.29 |
[default1]: iteration      336/   25000 | consumed samples:         1344 | consumed tokens:      1376256 | elapsed time per iteration (ms): 2500.5 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 7.301832E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.600 | TFLOPs: 1.28 |
[default1]: iteration      337/   25000 | consumed samples:         1348 | consumed tokens:      1380352 | elapsed time per iteration (ms): 2527.7 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.906728E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.582 | TFLOPs: 1.27 |
[default1]: iteration      338/   25000 | consumed samples:         1352 | consumed tokens:      1384448 | elapsed time per iteration (ms): 2427.1 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.254853E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.648 | TFLOPs: 1.32 |
[default1]: iteration      339/   25000 | consumed samples:         1356 | consumed tokens:      1388544 | elapsed time per iteration (ms): 2617.9 | learning rate: 9.996E-05 | global batch size:     4 | lm loss: 6.942641E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.528 | TFLOPs: 1.22 |
[default1]: iteration      340/   25000 | consumed samples:         1360 | consumed tokens:      1392640 | elapsed time per iteration (ms): 2608.6 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.138809E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.533 | TFLOPs: 1.23 |
[default1]: iteration      341/   25000 | consumed samples:         1364 | consumed tokens:      1396736 | elapsed time per iteration (ms): 2292.1 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.955519E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.745 | TFLOPs: 1.40 |
[default1]: iteration      342/   25000 | consumed samples:         1368 | consumed tokens:      1400832 | elapsed time per iteration (ms): 2441.0 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.900699E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.639 | TFLOPs: 1.31 |
[default1]: iteration      343/   25000 | consumed samples:         1372 | consumed tokens:      1404928 | elapsed time per iteration (ms): 2432.2 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.011630E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.645 | TFLOPs: 1.32 |
[default1]: iteration      344/   25000 | consumed samples:         1376 | consumed tokens:      1409024 | elapsed time per iteration (ms): 2509.9 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.019525E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.594 | TFLOPs: 1.28 |
[default1]: iteration      345/   25000 | consumed samples:         1380 | consumed tokens:      1413120 | elapsed time per iteration (ms): 2657.5 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.346693E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.505 | TFLOPs: 1.21 |
[default1]: iteration      346/   25000 | consumed samples:         1384 | consumed tokens:      1417216 | elapsed time per iteration (ms): 2522.6 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.863580E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.586 | TFLOPs: 1.27 |
[default1]: iteration      347/   25000 | consumed samples:         1388 | consumed tokens:      1421312 | elapsed time per iteration (ms): 2383.0 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.762059E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.679 | TFLOPs: 1.34 |
[default1]: iteration      348/   25000 | consumed samples:         1392 | consumed tokens:      1425408 | elapsed time per iteration (ms): 2309.0 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.341704E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.732 | TFLOPs: 1.39 |
[default1]: iteration      349/   25000 | consumed samples:         1396 | consumed tokens:      1429504 | elapsed time per iteration (ms): 2557.0 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.879673E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.564 | TFLOPs: 1.25 |
[default1]: iteration      350/   25000 | consumed samples:         1400 | consumed tokens:      1433600 | elapsed time per iteration (ms): 2368.1 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.879702E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.689 | TFLOPs: 1.35 |
[default1]:-----------------------------------------------------------------------------------------------
[default1]: validation loss at iteration 350 | lm loss value: 7.248785E+00 | lm loss PPL: 1.406394E+03 | 
[default1]:-----------------------------------------------------------------------------------------------
[default1]: iteration      351/   25000 | consumed samples:         1404 | consumed tokens:      1437696 | elapsed time per iteration (ms): 3606.1 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.794895E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.109 | TFLOPs: 0.89 |
[default1]: iteration      352/   25000 | consumed samples:         1408 | consumed tokens:      1441792 | elapsed time per iteration (ms): 2465.7 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.688237E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.622 | TFLOPs: 1.30 |
[default1]: iteration      353/   25000 | consumed samples:         1412 | consumed tokens:      1445888 | elapsed time per iteration (ms): 2537.0 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.740551E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.577 | TFLOPs: 1.26 |
[default1]: iteration      354/   25000 | consumed samples:         1416 | consumed tokens:      1449984 | elapsed time per iteration (ms): 2450.5 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.478200E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.632 | TFLOPs: 1.31 |
[default1]: iteration      355/   25000 | consumed samples:         1420 | consumed tokens:      1454080 | elapsed time per iteration (ms): 2402.6 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.914963E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.665 | TFLOPs: 1.33 |
[default1]: iteration      356/   25000 | consumed samples:         1424 | consumed tokens:      1458176 | elapsed time per iteration (ms): 2472.2 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.238112E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.618 | TFLOPs: 1.30 |
[default1]: iteration      357/   25000 | consumed samples:         1428 | consumed tokens:      1462272 | elapsed time per iteration (ms): 2473.0 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.415971E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.617 | TFLOPs: 1.30 |
[default1]: iteration      358/   25000 | consumed samples:         1432 | consumed tokens:      1466368 | elapsed time per iteration (ms): 2377.1 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.870433E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.683 | TFLOPs: 1.35 |
[default1]: iteration      359/   25000 | consumed samples:         1436 | consumed tokens:      1470464 | elapsed time per iteration (ms): 2384.6 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.991309E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.677 | TFLOPs: 1.34 |
[default1]: iteration      360/   25000 | consumed samples:         1440 | consumed tokens:      1474560 | elapsed time per iteration (ms): 2176.2 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.020139E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.838 | TFLOPs: 1.47 |
[default1]: iteration      361/   25000 | consumed samples:         1444 | consumed tokens:      1478656 | elapsed time per iteration (ms): 2285.6 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.644755E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.750 | TFLOPs: 1.40 |
[default1]: iteration      362/   25000 | consumed samples:         1448 | consumed tokens:      1482752 | elapsed time per iteration (ms): 2579.8 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.861878E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.551 | TFLOPs: 1.24 |
[default1]: iteration      363/   25000 | consumed samples:         1452 | consumed tokens:      1486848 | elapsed time per iteration (ms): 2487.1 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.203906E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.608 | TFLOPs: 1.29 |
[default1]: iteration      364/   25000 | consumed samples:         1456 | consumed tokens:      1490944 | elapsed time per iteration (ms): 2433.0 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.429420E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.644 | TFLOPs: 1.32 |
[default1]: iteration      365/   25000 | consumed samples:         1460 | consumed tokens:      1495040 | elapsed time per iteration (ms): 2419.7 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.110872E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.653 | TFLOPs: 1.32 |
[default1]: iteration      366/   25000 | consumed samples:         1464 | consumed tokens:      1499136 | elapsed time per iteration (ms): 2326.0 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.123353E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.720 | TFLOPs: 1.38 |
[default1]: iteration      367/   25000 | consumed samples:         1468 | consumed tokens:      1503232 | elapsed time per iteration (ms): 2505.3 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.241877E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.597 | TFLOPs: 1.28 |
[default1]: iteration      368/   25000 | consumed samples:         1472 | consumed tokens:      1507328 | elapsed time per iteration (ms): 2515.7 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.093263E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.590 | TFLOPs: 1.27 |
[default1]: iteration      369/   25000 | consumed samples:         1476 | consumed tokens:      1511424 | elapsed time per iteration (ms): 2335.8 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.154724E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.713 | TFLOPs: 1.37 |
[default1]: iteration      370/   25000 | consumed samples:         1480 | consumed tokens:      1515520 | elapsed time per iteration (ms): 2533.0 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.634711E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.579 | TFLOPs: 1.26 |
[default1]: iteration      371/   25000 | consumed samples:         1484 | consumed tokens:      1519616 | elapsed time per iteration (ms): 2481.5 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.179627E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.612 | TFLOPs: 1.29 |
[default1]: iteration      372/   25000 | consumed samples:         1488 | consumed tokens:      1523712 | elapsed time per iteration (ms): 2354.3 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 7.036122E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.699 | TFLOPs: 1.36 |
[default1]: iteration      373/   25000 | consumed samples:         1492 | consumed tokens:      1527808 | elapsed time per iteration (ms): 2511.1 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.865563E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.593 | TFLOPs: 1.28 |
[default1]: iteration      375/   25000 | consumed samples:         1500 | consumed tokens:      1536000 | elapsed time per iteration (ms): 2518.0 | learning rate: 9.995E-05 | global batch size:     4 | lm loss: 6.687575E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.589 | TFLOPs: 1.27 |
[default1]: iteration      376/   25000 | consumed samples:         1504 | consumed tokens:      1540096 | elapsed time per iteration (ms): 2314.9 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.552838E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.728 | TFLOPs: 1.38 |
[default1]: iteration      377/   25000 | consumed samples:         1508 | consumed tokens:      1544192 | elapsed time per iteration (ms): 2369.0 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.689184E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.688 | TFLOPs: 1.35 |
[default1]: iteration      378/   25000 | consumed samples:         1512 | consumed tokens:      1548288 | elapsed time per iteration (ms): 2407.1 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.895322E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.662 | TFLOPs: 1.33 |
[default1]: iteration      379/   25000 | consumed samples:         1516 | consumed tokens:      1552384 | elapsed time per iteration (ms): 2380.3 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.136262E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.680 | TFLOPs: 1.35 |
[default1]: iteration      380/   25000 | consumed samples:         1520 | consumed tokens:      1556480 | elapsed time per iteration (ms): 2479.8 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.453464E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.613 | TFLOPs: 1.29 |
[default1]: iteration      381/   25000 | consumed samples:         1524 | consumed tokens:      1560576 | elapsed time per iteration (ms): 2264.7 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.733142E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.766 | TFLOPs: 1.41 |
[default1]: iteration      382/   25000 | consumed samples:         1528 | consumed tokens:      1564672 | elapsed time per iteration (ms): 2510.9 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.026748E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.593 | TFLOPs: 1.28 |
[default1]: iteration      384/   25000 | consumed samples:         1536 | consumed tokens:      1572864 | elapsed time per iteration (ms): 2446.5 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.897519E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.635 | TFLOPs: 1.31 |
[default1]: iteration      385/   25000 | consumed samples:         1540 | consumed tokens:      1576960 | elapsed time per iteration (ms): 2455.7 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.695644E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.629 | TFLOPs: 1.30 |
[default1]: iteration      386/   25000 | consumed samples:         1544 | consumed tokens:      1581056 | elapsed time per iteration (ms): 2618.2 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.944340E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.528 | TFLOPs: 1.22 |
[default1]: iteration      387/   25000 | consumed samples:         1548 | consumed tokens:      1585152 | elapsed time per iteration (ms): 2760.7 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.524122E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.449 | TFLOPs: 1.16 |
[default1]: iteration      388/   25000 | consumed samples:         1552 | consumed tokens:      1589248 | elapsed time per iteration (ms): 2378.7 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.077243E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.682 | TFLOPs: 1.35 |
[default1]: iteration      389/   25000 | consumed samples:         1556 | consumed tokens:      1593344 | elapsed time per iteration (ms): 2327.1 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.187865E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.719 | TFLOPs: 1.38 |
[default1]: iteration      390/   25000 | consumed samples:         1560 | consumed tokens:      1597440 | elapsed time per iteration (ms): 2418.6 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.436782E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.654 | TFLOPs: 1.32 |
[default1]: iteration      391/   25000 | consumed samples:         1564 | consumed tokens:      1601536 | elapsed time per iteration (ms): 2358.5 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.037764E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.696 | TFLOPs: 1.36 |
[default1]: iteration      392/   25000 | consumed samples:         1568 | consumed tokens:      1605632 | elapsed time per iteration (ms): 2533.9 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.376636E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.579 | TFLOPs: 1.26 |
[default1]: iteration      393/   25000 | consumed samples:         1572 | consumed tokens:      1609728 | elapsed time per iteration (ms): 2461.7 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.839314E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.625 | TFLOPs: 1.30 |
[default1]: iteration      394/   25000 | consumed samples:         1576 | consumed tokens:      1613824 | elapsed time per iteration (ms): 2541.4 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.186756E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.574 | TFLOPs: 1.26 |
[default1]: iteration      395/   25000 | consumed samples:         1580 | consumed tokens:      1617920 | elapsed time per iteration (ms): 2523.1 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.336081E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.585 | TFLOPs: 1.27 |
[default1]: iteration      396/   25000 | consumed samples:         1584 | consumed tokens:      1622016 | elapsed time per iteration (ms): 2334.4 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.176109E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.714 | TFLOPs: 1.37 |
[default1]: iteration      397/   25000 | consumed samples:         1588 | consumed tokens:      1626112 | elapsed time per iteration (ms): 2499.4 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.461893E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.600 | TFLOPs: 1.28 |
[default1]: iteration      398/   25000 | consumed samples:         1592 | consumed tokens:      1630208 | elapsed time per iteration (ms): 2395.6 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.087169E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.670 | TFLOPs: 1.34 |
[default1]: iteration      399/   25000 | consumed samples:         1596 | consumed tokens:      1634304 | elapsed time per iteration (ms): 2430.7 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.490466E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.646 | TFLOPs: 1.32 |
[default1]: iteration      400/   25000 | consumed samples:         1600 | consumed tokens:      1638400 | elapsed time per iteration (ms): 2635.8 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.259899E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.518 | TFLOPs: 1.22 |
[default1]:-----------------------------------------------------------------------------------------------
[default1]: validation loss at iteration 400 | lm loss value: 7.114944E+00 | lm loss PPL: 1.230215E+03 | 
[default1]:-----------------------------------------------------------------------------------------------
[default1]: iteration      401/   25000 | consumed samples:         1604 | consumed tokens:      1642496 | elapsed time per iteration (ms): 3584.7 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.866976E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.116 | TFLOPs: 0.89 |
[default1]: iteration      402/   25000 | consumed samples:         1608 | consumed tokens:      1646592 | elapsed time per iteration (ms): 2355.5 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.134876E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.698 | TFLOPs: 1.36 |
[default1]: iteration      404/   25000 | consumed samples:         1616 | consumed tokens:      1654784 | elapsed time per iteration (ms): 2690.0 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.390401E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.487 | TFLOPs: 1.19 |
[default1]: iteration      405/   25000 | consumed samples:         1620 | consumed tokens:      1658880 | elapsed time per iteration (ms): 2473.3 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 7.089671E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.617 | TFLOPs: 1.29 |
[default1]: iteration      406/   25000 | consumed samples:         1624 | consumed tokens:      1662976 | elapsed time per iteration (ms): 2457.8 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.650190E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.627 | TFLOPs: 1.30 |
[default1]: iteration      407/   25000 | consumed samples:         1628 | consumed tokens:      1667072 | elapsed time per iteration (ms): 2416.0 | learning rate: 9.994E-05 | global batch size:     4 | lm loss: 6.882336E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.656 | TFLOPs: 1.33 |
[default1]: iteration      408/   25000 | consumed samples:         1632 | consumed tokens:      1671168 | elapsed time per iteration (ms): 2476.5 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 7.202044E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.615 | TFLOPs: 1.29 |
[default1]: iteration      409/   25000 | consumed samples:         1636 | consumed tokens:      1675264 | elapsed time per iteration (ms): 2377.1 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 7.079660E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.683 | TFLOPs: 1.35 |
[default1]: iteration      410/   25000 | consumed samples:         1640 | consumed tokens:      1679360 | elapsed time per iteration (ms): 2409.8 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.479787E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.660 | TFLOPs: 1.33 |
[default1]: iteration      411/   25000 | consumed samples:         1644 | consumed tokens:      1683456 | elapsed time per iteration (ms): 2477.9 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 7.075405E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.614 | TFLOPs: 1.29 |
[default1]: iteration      412/   25000 | consumed samples:         1648 | consumed tokens:      1687552 | elapsed time per iteration (ms): 2529.7 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 7.366972E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.581 | TFLOPs: 1.27 |
[default1]: iteration      413/   25000 | consumed samples:         1652 | consumed tokens:      1691648 | elapsed time per iteration (ms): 2423.5 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 7.056528E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.651 | TFLOPs: 1.32 |
[default1]: iteration      414/   25000 | consumed samples:         1656 | consumed tokens:      1695744 | elapsed time per iteration (ms): 2479.4 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.833174E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.613 | TFLOPs: 1.29 |
[default1]: iteration      415/   25000 | consumed samples:         1660 | consumed tokens:      1699840 | elapsed time per iteration (ms): 2599.3 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.766577E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.539 | TFLOPs: 1.23 |
[default1]: iteration      416/   25000 | consumed samples:         1664 | consumed tokens:      1703936 | elapsed time per iteration (ms): 2385.0 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.326233E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.677 | TFLOPs: 1.34 |
[default1]: iteration      417/   25000 | consumed samples:         1668 | consumed tokens:      1708032 | elapsed time per iteration (ms): 2586.1 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.777685E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.547 | TFLOPs: 1.24 |
[default1]: iteration      418/   25000 | consumed samples:         1672 | consumed tokens:      1712128 | elapsed time per iteration (ms): 2379.6 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 7.269867E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.681 | TFLOPs: 1.35 |
[default1]: iteration      419/   25000 | consumed samples:         1676 | consumed tokens:      1716224 | elapsed time per iteration (ms): 2621.5 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.503358E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.526 | TFLOPs: 1.22 |
[default1]: iteration      420/   25000 | consumed samples:         1680 | consumed tokens:      1720320 | elapsed time per iteration (ms): 2417.6 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 7.412486E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.654 | TFLOPs: 1.32 |
[default1]: iteration      421/   25000 | consumed samples:         1684 | consumed tokens:      1724416 | elapsed time per iteration (ms): 2409.3 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 7.000761E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.660 | TFLOPs: 1.33 |
[default1]: iteration      422/   25000 | consumed samples:         1688 | consumed tokens:      1728512 | elapsed time per iteration (ms): 2605.3 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.398513E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.535 | TFLOPs: 1.23 |
[default1]: iteration      423/   25000 | consumed samples:         1692 | consumed tokens:      1732608 | elapsed time per iteration (ms): 2323.6 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 7.282029E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.721 | TFLOPs: 1.38 |
[default1]: iteration      424/   25000 | consumed samples:         1696 | consumed tokens:      1736704 | elapsed time per iteration (ms): 2357.3 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 7.287355E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.697 | TFLOPs: 1.36 |
[default1]: iteration      425/   25000 | consumed samples:         1700 | consumed tokens:      1740800 | elapsed time per iteration (ms): 2388.1 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.587501E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.675 | TFLOPs: 1.34 |
[default1]: iteration      426/   25000 | consumed samples:         1704 | consumed tokens:      1744896 | elapsed time per iteration (ms): 2496.2 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.651299E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.602 | TFLOPs: 1.28 |
[default1]: iteration      427/   25000 | consumed samples:         1708 | consumed tokens:      1748992 | elapsed time per iteration (ms): 2518.5 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.732168E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.588 | TFLOPs: 1.27 |
[default1]: iteration      428/   25000 | consumed samples:         1712 | consumed tokens:      1753088 | elapsed time per iteration (ms): 2504.0 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 8.300782E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.597 | TFLOPs: 1.28 |
[default1]: iteration      429/   25000 | consumed samples:         1716 | consumed tokens:      1757184 | elapsed time per iteration (ms): 2668.1 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.282931E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.499 | TFLOPs: 1.20 |
[default1]: iteration      430/   25000 | consumed samples:         1720 | consumed tokens:      1761280 | elapsed time per iteration (ms): 2431.0 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.394309E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.645 | TFLOPs: 1.32 |
[default1]: iteration      431/   25000 | consumed samples:         1724 | consumed tokens:      1765376 | elapsed time per iteration (ms): 2570.0 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 7.430744E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.556 | TFLOPs: 1.25 |
[default1]: iteration      432/   25000 | consumed samples:         1728 | consumed tokens:      1769472 | elapsed time per iteration (ms): 2519.9 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.970270E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.587 | TFLOPs: 1.27 |
[default1]: iteration      433/   25000 | consumed samples:         1732 | consumed tokens:      1773568 | elapsed time per iteration (ms): 2529.7 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.604266E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.581 | TFLOPs: 1.27 |
[default1]: iteration      434/   25000 | consumed samples:         1736 | consumed tokens:      1777664 | elapsed time per iteration (ms): 2659.0 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.797283E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.504 | TFLOPs: 1.20 |
[default1]: iteration      435/   25000 | consumed samples:         1740 | consumed tokens:      1781760 | elapsed time per iteration (ms): 2478.4 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.861719E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.614 | TFLOPs: 1.29 |
[default1]: iteration      436/   25000 | consumed samples:         1744 | consumed tokens:      1785856 | elapsed time per iteration (ms): 2540.6 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.941984E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.574 | TFLOPs: 1.26 |
[default1]: iteration      437/   25000 | consumed samples:         1748 | consumed tokens:      1789952 | elapsed time per iteration (ms): 2339.4 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 7.311092E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.710 | TFLOPs: 1.37 |
[default1]: iteration      438/   25000 | consumed samples:         1752 | consumed tokens:      1794048 | elapsed time per iteration (ms): 2668.8 | learning rate: 9.993E-05 | global batch size:     4 | lm loss: 6.872654E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.499 | TFLOPs: 1.20 |
[default1]: iteration      439/   25000 | consumed samples:         1756 | consumed tokens:      1798144 | elapsed time per iteration (ms): 2493.6 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.806495E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.604 | TFLOPs: 1.28 |
[default1]: iteration      440/   25000 | consumed samples:         1760 | consumed tokens:      1802240 | elapsed time per iteration (ms): 2460.6 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.747505E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.626 | TFLOPs: 1.30 |
[default1]: iteration      441/   25000 | consumed samples:         1764 | consumed tokens:      1806336 | elapsed time per iteration (ms): 2410.6 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.950332E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.659 | TFLOPs: 1.33 |
[default1]: iteration      442/   25000 | consumed samples:         1768 | consumed tokens:      1810432 | elapsed time per iteration (ms): 2499.5 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.747120E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.600 | TFLOPs: 1.28 |
[default1]: iteration      443/   25000 | consumed samples:         1772 | consumed tokens:      1814528 | elapsed time per iteration (ms): 2484.0 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 7.230465E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.610 | TFLOPs: 1.29 |
[default1]: iteration      444/   25000 | consumed samples:         1776 | consumed tokens:      1818624 | elapsed time per iteration (ms): 2455.1 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.991252E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.629 | TFLOPs: 1.30 |
[default1]: iteration      445/   25000 | consumed samples:         1780 | consumed tokens:      1822720 | elapsed time per iteration (ms): 2594.4 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.669097E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.542 | TFLOPs: 1.23 |
[default1]: iteration      446/   25000 | consumed samples:         1784 | consumed tokens:      1826816 | elapsed time per iteration (ms): 2470.1 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 7.426058E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.619 | TFLOPs: 1.30 |
[default1]: iteration      447/   25000 | consumed samples:         1788 | consumed tokens:      1830912 | elapsed time per iteration (ms): 2558.7 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.764307E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.563 | TFLOPs: 1.25 |
[default1]: iteration      448/   25000 | consumed samples:         1792 | consumed tokens:      1835008 | elapsed time per iteration (ms): 2402.0 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.822475E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.665 | TFLOPs: 1.33 |
[default1]: iteration      449/   25000 | consumed samples:         1796 | consumed tokens:      1839104 | elapsed time per iteration (ms): 2382.1 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.786644E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.679 | TFLOPs: 1.34 |
[default1]: iteration      450/   25000 | consumed samples:         1800 | consumed tokens:      1843200 | elapsed time per iteration (ms): 2168.8 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.438851E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.844 | TFLOPs: 1.48 |
[default1]:-----------------------------------------------------------------------------------------------
[default1]: validation loss at iteration 450 | lm loss value: 7.021107E+00 | lm loss PPL: 1.120025E+03 | 
[default1]:-----------------------------------------------------------------------------------------------
[default1]: iteration      451/   25000 | consumed samples:         1804 | consumed tokens:      1847296 | elapsed time per iteration (ms): 3614.7 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.882115E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.107 | TFLOPs: 0.89 |
[default1]: iteration      452/   25000 | consumed samples:         1808 | consumed tokens:      1851392 | elapsed time per iteration (ms): 2640.4 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 7.660823E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.515 | TFLOPs: 1.21 |
[default1]: iteration      453/   25000 | consumed samples:         1812 | consumed tokens:      1855488 | elapsed time per iteration (ms): 2238.1 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 7.001750E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.787 | TFLOPs: 1.43 |
[default1]: iteration      454/   25000 | consumed samples:         1816 | consumed tokens:      1859584 | elapsed time per iteration (ms): 2317.4 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.950562E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.726 | TFLOPs: 1.38 |
[default1]: iteration      455/   25000 | consumed samples:         1820 | consumed tokens:      1863680 | elapsed time per iteration (ms): 2430.5 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 7.138327E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.646 | TFLOPs: 1.32 |
[default1]: iteration      456/   25000 | consumed samples:         1824 | consumed tokens:      1867776 | elapsed time per iteration (ms): 2453.1 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.923119E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.631 | TFLOPs: 1.31 |
[default1]: iteration      457/   25000 | consumed samples:         1828 | consumed tokens:      1871872 | elapsed time per iteration (ms): 2594.4 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.268687E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.542 | TFLOPs: 1.23 |
[default1]: iteration      458/   25000 | consumed samples:         1832 | consumed tokens:      1875968 | elapsed time per iteration (ms): 2479.1 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.610971E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.614 | TFLOPs: 1.29 |
[default1]: iteration      459/   25000 | consumed samples:         1836 | consumed tokens:      1880064 | elapsed time per iteration (ms): 2619.6 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.894963E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.527 | TFLOPs: 1.22 |
[default1]: iteration      460/   25000 | consumed samples:         1840 | consumed tokens:      1884160 | elapsed time per iteration (ms): 2730.5 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 7.138801E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.465 | TFLOPs: 1.17 |
[default1]: iteration      461/   25000 | consumed samples:         1844 | consumed tokens:      1888256 | elapsed time per iteration (ms): 2388.0 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 7.225269E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.675 | TFLOPs: 1.34 |
[default1]: iteration      462/   25000 | consumed samples:         1848 | consumed tokens:      1892352 | elapsed time per iteration (ms): 2528.0 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.454008E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.582 | TFLOPs: 1.27 |
[default1]: iteration      463/   25000 | consumed samples:         1852 | consumed tokens:      1896448 | elapsed time per iteration (ms): 2411.0 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 7.312723E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.659 | TFLOPs: 1.33 |
[default1]: iteration      464/   25000 | consumed samples:         1856 | consumed tokens:      1900544 | elapsed time per iteration (ms): 2548.6 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 7.325065E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.569 | TFLOPs: 1.26 |
[default1]: iteration      465/   25000 | consumed samples:         1860 | consumed tokens:      1904640 | elapsed time per iteration (ms): 2319.0 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 7.357761E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.725 | TFLOPs: 1.38 |
[default1]: iteration      466/   25000 | consumed samples:         1864 | consumed tokens:      1908736 | elapsed time per iteration (ms): 2484.6 | learning rate: 9.992E-05 | global batch size:     4 | lm loss: 6.614414E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.610 | TFLOPs: 1.29 |
[default1]: iteration      467/   25000 | consumed samples:         1868 | consumed tokens:      1912832 | elapsed time per iteration (ms): 2399.4 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.656721E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.667 | TFLOPs: 1.33 |
[default1]: iteration      468/   25000 | consumed samples:         1872 | consumed tokens:      1916928 | elapsed time per iteration (ms): 2774.1 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.733887E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.442 | TFLOPs: 1.15 |
[default1]: iteration      469/   25000 | consumed samples:         1876 | consumed tokens:      1921024 | elapsed time per iteration (ms): 2448.1 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 7.271043E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.634 | TFLOPs: 1.31 |
[default1]: iteration      470/   25000 | consumed samples:         1880 | consumed tokens:      1925120 | elapsed time per iteration (ms): 2435.0 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 7.162789E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.643 | TFLOPs: 1.32 |
[default1]: iteration      471/   25000 | consumed samples:         1884 | consumed tokens:      1929216 | elapsed time per iteration (ms): 2348.5 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.795765E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.703 | TFLOPs: 1.36 |
[default1]: iteration      472/   25000 | consumed samples:         1888 | consumed tokens:      1933312 | elapsed time per iteration (ms): 2498.2 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.925468E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.601 | TFLOPs: 1.28 |
[default1]: iteration      473/   25000 | consumed samples:         1892 | consumed tokens:      1937408 | elapsed time per iteration (ms): 2356.5 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.516459E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.697 | TFLOPs: 1.36 |
[default1]: iteration      474/   25000 | consumed samples:         1896 | consumed tokens:      1941504 | elapsed time per iteration (ms): 2443.4 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 7.070165E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.637 | TFLOPs: 1.31 |
[default1]: iteration      475/   25000 | consumed samples:         1900 | consumed tokens:      1945600 | elapsed time per iteration (ms): 2424.5 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.543265E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.650 | TFLOPs: 1.32 |
[default1]: iteration      476/   25000 | consumed samples:         1904 | consumed tokens:      1949696 | elapsed time per iteration (ms): 2571.3 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 7.137324E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.556 | TFLOPs: 1.25 |
[default1]: iteration      477/   25000 | consumed samples:         1908 | consumed tokens:      1953792 | elapsed time per iteration (ms): 2292.1 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 7.183431E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.745 | TFLOPs: 1.40 |
[default1]: iteration      478/   25000 | consumed samples:         1912 | consumed tokens:      1957888 | elapsed time per iteration (ms): 2250.0 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 7.223625E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.778 | TFLOPs: 1.42 |
[default1]: iteration      479/   25000 | consumed samples:         1916 | consumed tokens:      1961984 | elapsed time per iteration (ms): 2614.9 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.734687E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.530 | TFLOPs: 1.22 |
[default1]: iteration      480/   25000 | consumed samples:         1920 | consumed tokens:      1966080 | elapsed time per iteration (ms): 2521.0 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.893191E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.587 | TFLOPs: 1.27 |
[default1]: iteration      481/   25000 | consumed samples:         1924 | consumed tokens:      1970176 | elapsed time per iteration (ms): 2979.0 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.805732E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.343 | TFLOPs: 1.08 |
[default1]: iteration      482/   25000 | consumed samples:         1928 | consumed tokens:      1974272 | elapsed time per iteration (ms): 2651.3 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.538844E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.509 | TFLOPs: 1.21 |
[default1]: iteration      483/   25000 | consumed samples:         1932 | consumed tokens:      1978368 | elapsed time per iteration (ms): 2331.5 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.543145E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.716 | TFLOPs: 1.37 |
[default1]: iteration      484/   25000 | consumed samples:         1936 | consumed tokens:      1982464 | elapsed time per iteration (ms): 2386.2 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 7.210940E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.676 | TFLOPs: 1.34 |
[default1]: iteration      485/   25000 | consumed samples:         1940 | consumed tokens:      1986560 | elapsed time per iteration (ms): 2889.5 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.894007E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.384 | TFLOPs: 1.11 |
[default1]: iteration      486/   25000 | consumed samples:         1944 | consumed tokens:      1990656 | elapsed time per iteration (ms): 2612.8 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.866491E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.531 | TFLOPs: 1.23 |
[default1]: iteration      487/   25000 | consumed samples:         1948 | consumed tokens:      1994752 | elapsed time per iteration (ms): 2491.5 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 7.263590E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.605 | TFLOPs: 1.29 |
[default1]: iteration      488/   25000 | consumed samples:         1952 | consumed tokens:      1998848 | elapsed time per iteration (ms): 2489.6 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 7.419346E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.607 | TFLOPs: 1.29 |
[default1]: iteration      489/   25000 | consumed samples:         1956 | consumed tokens:      2002944 | elapsed time per iteration (ms): 2951.5 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.162678E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.355 | TFLOPs: 1.09 |
[default1]: iteration      490/   25000 | consumed samples:         1960 | consumed tokens:      2007040 | elapsed time per iteration (ms): 2748.6 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 7.158734E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.455 | TFLOPs: 1.17 |
[default1]: iteration      491/   25000 | consumed samples:         1964 | consumed tokens:      2011136 | elapsed time per iteration (ms): 2559.0 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 7.039346E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.563 | TFLOPs: 1.25 |
[default1]: iteration      492/   25000 | consumed samples:         1968 | consumed tokens:      2015232 | elapsed time per iteration (ms): 2555.4 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.575377E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.565 | TFLOPs: 1.25 |
[default1]: iteration      493/   25000 | consumed samples:         1972 | consumed tokens:      2019328 | elapsed time per iteration (ms): 2666.0 | learning rate: 9.991E-05 | global batch size:     4 | lm loss: 6.750457E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.500 | TFLOPs: 1.20 |
[default1]: iteration      494/   25000 | consumed samples:         1976 | consumed tokens:      2023424 | elapsed time per iteration (ms): 2650.5 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 7.524313E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.509 | TFLOPs: 1.21 |
[default1]: iteration      495/   25000 | consumed samples:         1980 | consumed tokens:      2027520 | elapsed time per iteration (ms): 2395.6 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 7.041301E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.670 | TFLOPs: 1.34 |
[default1]: iteration      496/   25000 | consumed samples:         1984 | consumed tokens:      2031616 | elapsed time per iteration (ms): 2536.7 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 7.213347E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.577 | TFLOPs: 1.26 |
[default1]: iteration      497/   25000 | consumed samples:         1988 | consumed tokens:      2035712 | elapsed time per iteration (ms): 2410.0 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.949671E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.660 | TFLOPs: 1.33 |
[default1]: iteration      498/   25000 | consumed samples:         1992 | consumed tokens:      2039808 | elapsed time per iteration (ms): 2457.8 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.739322E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.627 | TFLOPs: 1.30 |
[default1]: iteration      499/   25000 | consumed samples:         1996 | consumed tokens:      2043904 | elapsed time per iteration (ms): 2396.6 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.571537E+00 | loss scale: 4096.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.669 | TFLOPs: 1.34 |
[default1]: iteration      500/   25000 | consumed samples:         2000 | consumed tokens:      2048000 | elapsed time per iteration (ms): 2396.3 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.943532E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.669 | TFLOPs: 1.34 |
[default1]:-----------------------------------------------------------------------------------------------
[default1]: validation loss at iteration 500 | lm loss value: 6.976230E+00 | lm loss PPL: 1.070874E+03 | 
[default1]:-----------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration     500 to checkpoints/gpt2-b-dist-2023-07-20_173703
[default0]:[2023-07-20 18:03:44,113] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step500 is about to be saved!
[default0]:[2023-07-20 18:03:44,187] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/mp_rank_00_model_states.pt
[default0]:[2023-07-20 18:03:44,187] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/mp_rank_00_model_states.pt...
[default0]:[2023-07-20 18:03:46,776] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/mp_rank_00_model_states.pt.
[default0]:[2023-07-20 18:03:46,881] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default1]:[2023-07-20 18:03:46,881] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/zero_pp_rank_1_mp_rank_00_optim_states.pt...
[default1]:[2023-07-20 18:03:46,881] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/zero_pp_rank_3_mp_rank_00_optim_states.pt...
[default0]:[2023-07-20 18:03:46,881] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/zero_pp_rank_2_mp_rank_00_optim_states.pt...
[default1]:[2023-07-20 18:03:49,507] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/zero_pp_rank_3_mp_rank_00_optim_states.pt.
[default1]:[2023-07-20 18:03:49,545] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/zero_pp_rank_3_mp_rank_00_optim_states.pt
[default1]:[2023-07-20 18:03:49,545] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
[default0]:[2023-07-20 18:03:49,512] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/zero_pp_rank_2_mp_rank_00_optim_states.pt.
[default0]:[2023-07-20 18:03:49,512] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/zero_pp_rank_2_mp_rank_00_optim_states.pt
[default0]:[2023-07-20 18:03:49,512] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
[default0]:[2023-07-20 18:03:49,531] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default1]:[2023-07-20 18:03:49,538] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/zero_pp_rank_1_mp_rank_00_optim_states.pt.
[default1]:[2023-07-20 18:03:49,538] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/zero_pp_rank_1_mp_rank_00_optim_states.pt
[default1]:[2023-07-20 18:03:49,538] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
[default0]:[2023-07-20 18:03:49,605] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved checkpoints/gpt2-b-dist-2023-07-20_173703/global_step500/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-07-20 18:03:49,606] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
[default0]:  successfully saved checkpoint at iteration     500 to checkpoints/gpt2-b-dist-2023-07-20_173703
[default0]:Checkpoint Save GB: 4.968, GB/Sec: 0.87, Latency(second): 5.697
[default1]:(min, max) time across ranks (ms):
[default1]:    save-checkpoint ................................: (5697.37, 5728.25)
[default1]: iteration      501/   25000 | consumed samples:         2004 | consumed tokens:      2052096 | elapsed time per iteration (ms): 9531.4 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.797785E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.420 | TFLOPs: 0.34 |
[default1]: iteration      502/   25000 | consumed samples:         2008 | consumed tokens:      2056192 | elapsed time per iteration (ms): 2336.6 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.544771E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.712 | TFLOPs: 1.37 |
[default1]: iteration      503/   25000 | consumed samples:         2012 | consumed tokens:      2060288 | elapsed time per iteration (ms): 2395.3 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.715514E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.670 | TFLOPs: 1.34 |
[default1]: iteration      504/   25000 | consumed samples:         2016 | consumed tokens:      2064384 | elapsed time per iteration (ms): 2662.0 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.811558E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.503 | TFLOPs: 1.20 |
[default1]: iteration      505/   25000 | consumed samples:         2020 | consumed tokens:      2068480 | elapsed time per iteration (ms): 2483.4 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 7.047131E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.611 | TFLOPs: 1.29 |
[default1]: iteration      506/   25000 | consumed samples:         2024 | consumed tokens:      2072576 | elapsed time per iteration (ms): 2649.4 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 7.177692E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.510 | TFLOPs: 1.21 |
[default1]: iteration      507/   25000 | consumed samples:         2028 | consumed tokens:      2076672 | elapsed time per iteration (ms): 2257.8 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.711697E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.772 | TFLOPs: 1.42 |
[default1]: iteration      508/   25000 | consumed samples:         2032 | consumed tokens:      2080768 | elapsed time per iteration (ms): 2366.7 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.516601E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.690 | TFLOPs: 1.35 |
[default1]: iteration      509/   25000 | consumed samples:         2036 | consumed tokens:      2084864 | elapsed time per iteration (ms): 2357.6 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.299559E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.697 | TFLOPs: 1.36 |
[default1]: iteration      510/   25000 | consumed samples:         2040 | consumed tokens:      2088960 | elapsed time per iteration (ms): 2178.5 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.866234E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.836 | TFLOPs: 1.47 |
[default1]: iteration      511/   25000 | consumed samples:         2044 | consumed tokens:      2093056 | elapsed time per iteration (ms): 2547.1 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.857817E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.570 | TFLOPs: 1.26 |
[default1]: iteration      512/   25000 | consumed samples:         2048 | consumed tokens:      2097152 | elapsed time per iteration (ms): 2638.3 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.878600E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.516 | TFLOPs: 1.21 |
[default1]: iteration      513/   25000 | consumed samples:         2052 | consumed tokens:      2101248 | elapsed time per iteration (ms): 2179.3 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 7.086902E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.835 | TFLOPs: 1.47 |
[default1]: iteration      514/   25000 | consumed samples:         2056 | consumed tokens:      2105344 | elapsed time per iteration (ms): 2572.1 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 7.313060E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.555 | TFLOPs: 1.25 |
[default1]: iteration      515/   25000 | consumed samples:         2060 | consumed tokens:      2109440 | elapsed time per iteration (ms): 2534.7 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.568108E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.578 | TFLOPs: 1.26 |
[default1]: iteration      516/   25000 | consumed samples:         2064 | consumed tokens:      2113536 | elapsed time per iteration (ms): 2679.0 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 7.157108E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.493 | TFLOPs: 1.20 |
[default1]: iteration      517/   25000 | consumed samples:         2068 | consumed tokens:      2117632 | elapsed time per iteration (ms): 2374.4 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 7.032368E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.685 | TFLOPs: 1.35 |
[default1]: iteration      518/   25000 | consumed samples:         2072 | consumed tokens:      2121728 | elapsed time per iteration (ms): 2353.4 | learning rate: 9.990E-05 | global batch size:     4 | lm loss: 6.694686E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.700 | TFLOPs: 1.36 |
[default1]: iteration      519/   25000 | consumed samples:         2076 | consumed tokens:      2125824 | elapsed time per iteration (ms): 2512.8 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 6.553037E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.592 | TFLOPs: 1.27 |
[default1]: iteration      520/   25000 | consumed samples:         2080 | consumed tokens:      2129920 | elapsed time per iteration (ms): 2545.2 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 7.620954E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.572 | TFLOPs: 1.26 |
[default1]: iteration      521/   25000 | consumed samples:         2084 | consumed tokens:      2134016 | elapsed time per iteration (ms): 2398.7 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 7.070161E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.668 | TFLOPs: 1.34 |
[default1]: iteration      522/   25000 | consumed samples:         2088 | consumed tokens:      2138112 | elapsed time per iteration (ms): 2535.4 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 7.173521E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.578 | TFLOPs: 1.26 |
[default1]: iteration      523/   25000 | consumed samples:         2092 | consumed tokens:      2142208 | elapsed time per iteration (ms): 2323.9 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 6.864424E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.721 | TFLOPs: 1.38 |
[default1]: iteration      524/   25000 | consumed samples:         2096 | consumed tokens:      2146304 | elapsed time per iteration (ms): 2590.0 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 7.260442E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.544 | TFLOPs: 1.24 |
[default1]: iteration      525/   25000 | consumed samples:         2100 | consumed tokens:      2150400 | elapsed time per iteration (ms): 2483.2 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 7.089570E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.611 | TFLOPs: 1.29 |
[default1]: iteration      526/   25000 | consumed samples:         2104 | consumed tokens:      2154496 | elapsed time per iteration (ms): 2361.1 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 6.968899E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.694 | TFLOPs: 1.36 |
[default1]: iteration      527/   25000 | consumed samples:         2108 | consumed tokens:      2158592 | elapsed time per iteration (ms): 2407.2 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 7.251227E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.662 | TFLOPs: 1.33 |
[default1]: iteration      528/   25000 | consumed samples:         2112 | consumed tokens:      2162688 | elapsed time per iteration (ms): 2319.2 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 6.701428E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.725 | TFLOPs: 1.38 |
[default1]: iteration      529/   25000 | consumed samples:         2116 | consumed tokens:      2166784 | elapsed time per iteration (ms): 2613.3 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 6.701121E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.531 | TFLOPs: 1.23 |
[default1]: iteration      530/   25000 | consumed samples:         2120 | consumed tokens:      2170880 | elapsed time per iteration (ms): 2591.0 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 6.930444E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.544 | TFLOPs: 1.24 |
[default1]: iteration      531/   25000 | consumed samples:         2124 | consumed tokens:      2174976 | elapsed time per iteration (ms): 2531.9 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 7.399148E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.580 | TFLOPs: 1.26 |
[default1]: iteration      532/   25000 | consumed samples:         2128 | consumed tokens:      2179072 | elapsed time per iteration (ms): 2631.4 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 6.760634E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.520 | TFLOPs: 1.22 |
[default1]: iteration      533/   25000 | consumed samples:         2132 | consumed tokens:      2183168 | elapsed time per iteration (ms): 2615.2 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 6.279915E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.530 | TFLOPs: 1.22 |
[default1]: iteration      534/   25000 | consumed samples:         2136 | consumed tokens:      2187264 | elapsed time per iteration (ms): 2375.7 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 7.365265E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.684 | TFLOPs: 1.35 |
[default1]: iteration      535/   25000 | consumed samples:         2140 | consumed tokens:      2191360 | elapsed time per iteration (ms): 2500.6 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 6.908486E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.600 | TFLOPs: 1.28 |
[default1]: iteration      536/   25000 | consumed samples:         2144 | consumed tokens:      2195456 | elapsed time per iteration (ms): 2308.0 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 7.093538E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.733 | TFLOPs: 1.39 |
[default1]: iteration      537/   25000 | consumed samples:         2148 | consumed tokens:      2199552 | elapsed time per iteration (ms): 2539.7 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 6.134656E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.575 | TFLOPs: 1.26 |
[default1]: iteration      538/   25000 | consumed samples:         2152 | consumed tokens:      2203648 | elapsed time per iteration (ms): 2443.4 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 6.683195E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.637 | TFLOPs: 1.31 |
[default1]: iteration      540/   25000 | consumed samples:         2160 | consumed tokens:      2211840 | elapsed time per iteration (ms): 2544.0 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 7.093293E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.572 | TFLOPs: 1.26 |
[default1]: iteration      541/   25000 | consumed samples:         2164 | consumed tokens:      2215936 | elapsed time per iteration (ms): 2292.3 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 7.323719E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.745 | TFLOPs: 1.40 |
[default1]: iteration      542/   25000 | consumed samples:         2168 | consumed tokens:      2220032 | elapsed time per iteration (ms): 2406.9 | learning rate: 9.989E-05 | global batch size:     4 | lm loss: 6.412878E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.662 | TFLOPs: 1.33 |
[default1]: iteration      543/   25000 | consumed samples:         2172 | consumed tokens:      2224128 | elapsed time per iteration (ms): 2340.8 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.764380E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.709 | TFLOPs: 1.37 |
[default1]: iteration      544/   25000 | consumed samples:         2176 | consumed tokens:      2228224 | elapsed time per iteration (ms): 2459.7 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 7.125685E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.626 | TFLOPs: 1.30 |
[default1]: iteration      545/   25000 | consumed samples:         2180 | consumed tokens:      2232320 | elapsed time per iteration (ms): 2569.1 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.993793E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.557 | TFLOPs: 1.25 |
[default1]: iteration      546/   25000 | consumed samples:         2184 | consumed tokens:      2236416 | elapsed time per iteration (ms): 2307.2 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.426440E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.734 | TFLOPs: 1.39 |
[default1]: iteration      547/   25000 | consumed samples:         2188 | consumed tokens:      2240512 | elapsed time per iteration (ms): 2412.0 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.880234E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.658 | TFLOPs: 1.33 |
[default1]: iteration      548/   25000 | consumed samples:         2192 | consumed tokens:      2244608 | elapsed time per iteration (ms): 2303.4 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 7.046419E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.737 | TFLOPs: 1.39 |
[default1]: iteration      549/   25000 | consumed samples:         2196 | consumed tokens:      2248704 | elapsed time per iteration (ms): 2444.0 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.877993E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.637 | TFLOPs: 1.31 |
[default1]: iteration      550/   25000 | consumed samples:         2200 | consumed tokens:      2252800 | elapsed time per iteration (ms): 2351.9 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.525640E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.701 | TFLOPs: 1.36 |
[default1]:-----------------------------------------------------------------------------------------------
[default1]: validation loss at iteration 550 | lm loss value: 6.931279E+00 | lm loss PPL: 1.023803E+03 | 
[default1]:-----------------------------------------------------------------------------------------------
[default1]: iteration      551/   25000 | consumed samples:         2204 | consumed tokens:      2256896 | elapsed time per iteration (ms): 3880.8 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.761293E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.031 | TFLOPs: 0.83 |
[default1]: iteration      552/   25000 | consumed samples:         2208 | consumed tokens:      2260992 | elapsed time per iteration (ms): 2438.2 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.662963E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.641 | TFLOPs: 1.31 |
[default1]: iteration      553/   25000 | consumed samples:         2212 | consumed tokens:      2265088 | elapsed time per iteration (ms): 2401.4 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.633771E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.666 | TFLOPs: 1.33 |
[default1]: iteration      554/   25000 | consumed samples:         2216 | consumed tokens:      2269184 | elapsed time per iteration (ms): 2488.1 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.530955E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.608 | TFLOPs: 1.29 |
[default1]: iteration      555/   25000 | consumed samples:         2220 | consumed tokens:      2273280 | elapsed time per iteration (ms): 2468.1 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.812267E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.621 | TFLOPs: 1.30 |
[default1]: iteration      557/   25000 | consumed samples:         2228 | consumed tokens:      2281472 | elapsed time per iteration (ms): 2812.0 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.932947E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.422 | TFLOPs: 1.14 |
[default1]: iteration      558/   25000 | consumed samples:         2232 | consumed tokens:      2285568 | elapsed time per iteration (ms): 2558.4 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.852138E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.563 | TFLOPs: 1.25 |
[default1]: iteration      559/   25000 | consumed samples:         2236 | consumed tokens:      2289664 | elapsed time per iteration (ms): 2403.7 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.711435E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.664 | TFLOPs: 1.33 |
[default1]: iteration      560/   25000 | consumed samples:         2240 | consumed tokens:      2293760 | elapsed time per iteration (ms): 2367.0 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.926297E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.690 | TFLOPs: 1.35 |
[default1]: iteration      561/   25000 | consumed samples:         2244 | consumed tokens:      2297856 | elapsed time per iteration (ms): 2357.9 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 7.157914E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.696 | TFLOPs: 1.36 |
[default1]: iteration      562/   25000 | consumed samples:         2248 | consumed tokens:      2301952 | elapsed time per iteration (ms): 2304.1 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.822225E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.736 | TFLOPs: 1.39 |
[default1]: iteration      563/   25000 | consumed samples:         2252 | consumed tokens:      2306048 | elapsed time per iteration (ms): 2707.8 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 7.036050E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.477 | TFLOPs: 1.18 |
[default1]: iteration      564/   25000 | consumed samples:         2256 | consumed tokens:      2310144 | elapsed time per iteration (ms): 2541.9 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 7.039056E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.574 | TFLOPs: 1.26 |
[default1]: iteration      565/   25000 | consumed samples:         2260 | consumed tokens:      2314240 | elapsed time per iteration (ms): 2363.3 | learning rate: 9.988E-05 | global batch size:     4 | lm loss: 6.816198E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.693 | TFLOPs: 1.36 |
[default1]: iteration      566/   25000 | consumed samples:         2264 | consumed tokens:      2318336 | elapsed time per iteration (ms): 2702.0 | learning rate: 9.987E-05 | global batch size:     4 | lm loss: 6.718232E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.480 | TFLOPs: 1.19 |
[default1]: iteration      567/   25000 | consumed samples:         2268 | consumed tokens:      2322432 | elapsed time per iteration (ms): 2359.2 | learning rate: 9.987E-05 | global batch size:     4 | lm loss: 7.140856E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.696 | TFLOPs: 1.36 |
[default1]: iteration      568/   25000 | consumed samples:         2272 | consumed tokens:      2326528 | elapsed time per iteration (ms): 2305.7 | learning rate: 9.987E-05 | global batch size:     4 | lm loss: 6.908392E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.735 | TFLOPs: 1.39 |
[default1]: iteration      569/   25000 | consumed samples:         2276 | consumed tokens:      2330624 | elapsed time per iteration (ms): 2466.0 | learning rate: 9.987E-05 | global batch size:     4 | lm loss: 7.066625E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.622 | TFLOPs: 1.30 |
[default1]: iteration      570/   25000 | consumed samples:         2280 | consumed tokens:      2334720 | elapsed time per iteration (ms): 2546.1 | learning rate: 9.987E-05 | global batch size:     4 | lm loss: 6.748377E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.571 | TFLOPs: 1.26 |
[default1]: iteration      571/   25000 | consumed samples:         2284 | consumed tokens:      2338816 | elapsed time per iteration (ms): 2370.9 | learning rate: 9.987E-05 | global batch size:     4 | lm loss: 6.281894E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.687 | TFLOPs: 1.35 |
[default1]: iteration      572/   25000 | consumed samples:         2288 | consumed tokens:      2342912 | elapsed time per iteration (ms): 2419.7 | learning rate: 9.987E-05 | global batch size:     4 | lm loss: 7.469163E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.653 | TFLOPs: 1.32 |
[default1]: iteration      573/   25000 | consumed samples:         2292 | consumed tokens:      2347008 | elapsed time per iteration (ms): 2511.4 | learning rate: 9.987E-05 | global batch size:     4 | lm loss: 6.832920E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.593 | TFLOPs: 1.28 |
[default1]: iteration      574/   25000 | consumed samples:         2296 | consumed tokens:      2351104 | elapsed time per iteration (ms): 2511.0 | learning rate: 9.987E-05 | global batch size:     4 | lm loss: 7.136095E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.593 | TFLOPs: 1.28 |
[default1]: iteration      575/   25000 | consumed samples:         2300 | consumed tokens:      2355200 | elapsed time per iteration (ms): 2394.6 | learning rate: 9.987E-05 | global batch size:     4 | lm loss: 6.353854E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.670 | TFLOPs: 1.34 |
[default1]: iteration      576/   25000 | consumed samples:         2304 | consumed tokens:      2359296 | elapsed time per iteration (ms): 2291.4 | learning rate: 9.987E-05 | global batch size:     4 | lm loss: 7.583838E+00 | loss scale: 8192.0 | actual seqlen:  1024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.746 | TFLOPs: 1.40 |
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 4460695 ON n2gpu1214 CANCELLED AT 2023-07-20T18:07:00 DUE TO TIME LIMIT ***
slurmstepd: error: *** STEP 4460695.0 ON n2gpu1214 CANCELLED AT 2023-07-20T18:07:00 DUE TO TIME LIMIT ***
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 221911 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 221912 closing signal SIGTERM
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 266594 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 266595 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.tail_log:error in log tailor for default0. SignalException: Process 266581 got signal: 15
