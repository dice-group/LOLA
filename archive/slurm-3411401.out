cpu-bind=MASK - n2gpu1201, task  0  0 [986443]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
LAUNCHER: python -u -m torch.distributed.run --nproc_per_node 4 --nnodes 16 --rdzv_id=28004 --rdzv_endpoint n2gpu1201:6005 --rdzv_backend c10d --max_restarts 0 --tee 3
CMD: pretrain_gpt.py --tensor-model-parallel-size 1 --pipeline-model-parallel-size 1 --distributed-backend nccl --num-layers 50 --hidden-size 4096 --num-attention-heads 32 --seq-length 1024 --max-position-embeddings 1024 --micro-batch-size 1 --global-batch-size 64 --train-samples 1000000 --optimizer adam --adam-beta1 0.9 --adam-beta2 0.95 --adam-eps 1e-8 --lr 1e-4 --min-lr 1e-6 --lr-decay-style cosine --clip-grad 1.0 --weight-decay 1e-1 --fp16 --partition-activations --seed 42 --vocab-file data/gpt2-vocab.json --merge-file data/gpt2-merges.txt --exit-interval 1000 --log-interval 1 --save-interval 500 --eval-interval 50 --eval-iters 10 --checkpoint-activations --save checkpoints/gpt2-10b-dist-2023-04-24_080429 --load checkpoints/gpt2-10b-dist-2023-04-24_080429 --data-path data/meg-gpt2-oscar-en-10k_text_document --tensorboard-dir output_dir/tensorboard-dist-2023-04-24_080429 --tensorboard-queue-size 5 --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --deepspeed --no-pipeline-parallel --zero-stage 2 --deepspeed_config ./ds_config.json --deepspeed-activation-checkpointing
cpu-bind=MASK - n2gpu1205, task  3  0 [143270]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1209, task  6  0 [135969]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1201, task  0  0 [986584]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1227, task 13  0 [190503]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1207, task  5  0 [144592]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1230, task 15  0 [125937]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1210, task  7  0 [143985]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1204, task  2  0 [138109]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1224, task 12  0 [124632]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1219, task  8  0 [266861]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1221, task 10  0 [160001]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1206, task  4  0 [143406]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1220, task  9  0 [386634]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1202, task  1  0 [1130064]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1229, task 14  0 [174578]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
cpu-bind=MASK - n2gpu1222, task 11  0 [146999]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default3]:--------------------------------------------------
[default3]:DeepSpeed C++/CUDA extension op report
[default3]:--------------------------------------------------
[default3]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default3]:      runtime if needed. Op compatibility means that your system
[default3]:      meet the required dependencies to JIT install the op.
[default3]:--------------------------------------------------
[default3]:JIT compiled ops requires ninja
[default3]:ninja .................. [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:op name ................ installed .. compatible
[default3]:--------------------------------------------------
[default2]:--------------------------------------------------
[default2]:DeepSpeed C++/CUDA extension op report
[default2]:--------------------------------------------------
[default2]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default2]:      runtime if needed. Op compatibility means that your system
[default2]:      meet the required dependencies to JIT install the op.
[default2]:--------------------------------------------------
[default2]:JIT compiled ops requires ninja
[default2]:ninja .................. [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:op name ................ installed .. compatible
[default2]:--------------------------------------------------
[default1]:--------------------------------------------------
[default1]:DeepSpeed C++/CUDA extension op report
[default1]:--------------------------------------------------
[default1]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default1]:      runtime if needed. Op compatibility means that your system
[default1]:      meet the required dependencies to JIT install the op.
[default1]:--------------------------------------------------
[default1]:JIT compiled ops requires ninja
[default1]:ninja .................. [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:op name ................ installed .. compatible
[default1]:--------------------------------------------------
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default2]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:using world size: 64, data-parallel-size: 64, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
[default0]:using torch.float16 for parameters ...
[default0]:------------------------ arguments ------------------------
[default0]:  accumulate_allreduce_grads_in_fp32 .............. False
[default0]:  adam_beta1 ...................................... 0.9
[default0]:  adam_beta2 ...................................... 0.95
[default0]:  adam_eps ........................................ 1e-08
[default0]:  adlr_autoresume ................................. False
[default0]:  adlr_autoresume_interval ........................ 1000
[default0]:  aml_data_download_path .......................... None
[default0]:  apply_query_key_layer_scaling ................... True
[default0]:  apply_residual_connection_post_layernorm ........ False
[default0]:  attention_dropout ............................... 0.1
[default0]:  attention_softmax_in_fp32 ....................... False
[default0]:  bert_binary_head ................................ True
[default0]:  bert_load ....................................... None
[default0]:  bf16 ............................................ False
[default0]:  bias_dropout_fusion ............................. True
[default0]:  bias_gelu_fusion ................................ True
[default0]:  biencoder_projection_dim ........................ 0
[default0]:  biencoder_shared_query_context_model ............ False
[default0]:  block_data_path ................................. None
[default0]:  checkpoint_activations .......................... True
[default0]:  checkpoint_in_cpu ............................... False
[default0]:  checkpoint_num_layers ........................... 1
[default0]:  clip_grad ....................................... 1.0
[default0]:  compression_training ............................ False
[default0]:  consumed_train_samples .......................... 0
[default0]:  consumed_train_tokens ........................... 0
[default0]:  consumed_valid_samples .......................... 0
[default0]:  contigious_checkpointing ........................ False
[default0]:  cpu_optimizer ................................... False
[default0]:  cpu_torch_adam .................................. False
[default0]:  create_moe_param_group .......................... False
[default0]:  curriculum_learning ............................. False
[default0]:  custom_token_counting ........................... False
[default0]:  data_impl ....................................... infer
[default0]:  data_parallel_size .............................. 64
[default0]:  data_path ....................................... ['data/meg-gpt2-oscar-en-10k_text_document']
[default0]:  dataloader_type ................................. single
[default0]:  DDP_impl ........................................ local
[default0]:  decoder_seq_length .............................. None
[default0]:  deepscale ....................................... False
[default0]:  deepscale_config ................................ None
[default0]:  deepspeed ....................................... True
[default0]:  deepspeed_activation_checkpointing .............. True
[default0]:  deepspeed_config ................................ ./ds_config.json
[default0]:  deepspeed_mpi ................................... False
[default0]:  distribute_checkpointed_activations ............. False
[default0]:  distributed_backend ............................. nccl
[default0]:  ds_inference .................................... False
[default0]:  ds_pipeline_enabled ............................. False
[default0]:  embedding_path .................................. None
[default0]:  enable_expert_tensor_parallelism ................ False
[default0]:  encoder_seq_length .............................. 1024
[default0]:  eod_mask_loss ................................... False
[default0]:  eval_interval ................................... 50
[default0]:  eval_iters ...................................... 10
[default0]:  evidence_data_path .............................. None
[default0]:  exit_duration_in_mins ........................... None
[default0]:  exit_interval ................................... 1000
[default0]:  expert_interval ................................. 2
[default0]:  ffn_hidden_size ................................. 16384
[default0]:  finetune ........................................ False
[default0]:  fp16 ............................................ True
[default0]:  fp16_lm_cross_entropy ........................... False
[default0]:  fp32_residual_connection ........................ False
[default0]:  global_batch_size ............................... 64
[default0]:  hidden_dropout .................................. 0.1
[default0]:  hidden_size ..................................... 4096
[default0]:  hidden_size_teacher ............................. None
[default0]:  hysteresis ...................................... 2
[default0]:  ict_head_size ................................... None
[default0]:  ict_load ........................................ None
[default0]:  img_dim ......................................... 224
[default0]:  indexer_batch_size .............................. 128
[default0]:  indexer_log_interval ............................ 1000
[default0]:  inference ....................................... False
[default0]:  init_method_std ................................. 0.02
[default0]:  init_method_xavier_uniform ...................... False
[default0]:  initial_loss_scale .............................. 4294967296
[default0]:  kd .............................................. False
[default0]:  kd_alpha_ce ..................................... 1
[default0]:  kd_beta_ce ...................................... 1
[default0]:  kd_temp ......................................... 1.0
[default0]:  kv_channels ..................................... 128
[default0]:  layernorm_epsilon ............................... 1e-05
[default0]:  lazy_mpu_init ................................... None
[default0]:  load ............................................ checkpoints/gpt2-10b-dist-2023-04-24_080429
[default0]:  load_teacher .................................... None
[default0]:  local_rank ...................................... None
[default0]:  log_batch_size_to_tensorboard ................... True
[default0]:  log_interval .................................... 1
[default0]:  log_learning_rate_to_tensorboard ................ True
[default0]:  log_loss_scale_to_tensorboard ................... True
[default0]:  log_num_zeros_in_grad ........................... False
[default0]:  log_optimizer_states_to_tensorboard ............. False
[default0]:  log_params_norm ................................. False
[default0]:  log_timers_to_tensorboard ....................... True
[default0]:  log_validation_ppl_to_tensorboard ............... True
[default0]:  loss_scale ...................................... None
[default0]:  loss_scale_window ............................... 1000
[default0]:  lr .............................................. 0.0001
[default0]:  lr_decay_iters .................................. None
[default0]:  lr_decay_samples ................................ None
[default0]:  lr_decay_style .................................. cosine
[default0]:  lr_decay_tokens ................................. None
[default0]:  lr_warmup_fraction .............................. None
[default0]:  lr_warmup_iters ................................. 0
[default0]:  lr_warmup_samples ............................... 0
[default0]:  lr_warmup_tokens ................................ None
[default0]:  make_vocab_size_divisible_by .................... 128
[default0]:  mask_prob ....................................... 0.15
[default0]:  masked_softmax_fusion ........................... True
[default0]:  max_position_embeddings ......................... 1024
[default0]:  memory_centric_tiled_linear ..................... False
[default0]:  merge_file ...................................... data/gpt2-merges.txt
[default0]:  micro_batch_size ................................ 1
[default0]:  min_loss_scale .................................. 1.0
[default0]:  min_lr .......................................... 1e-06
[default0]:  mlp_type ........................................ standard
[default0]:  mmap_warmup ..................................... False
[default0]:  moe_eval_capacity_factor ........................ 1.0
[default0]:  moe_expert_parallel_size ........................ 1
[default0]:  moe_loss_coeff .................................. 0.1
[default0]:  moe_min_capacity ................................ 4
[default0]:  moe_token_dropping .............................. True
[default0]:  moe_train_capacity_factor ....................... 1.0
[default0]:  mos ............................................. False
[default0]:  no_load_lr_state ................................ False
[default0]:  no_load_optim ................................... None
[default0]:  no_load_rng ..................................... None
[default0]:  no_pipeline_parallel ............................ True
[default0]:  no_save_optim ................................... None
[default0]:  no_save_rng ..................................... None
[default0]:  num_attention_heads ............................. 32
[default0]:  num_attention_heads_teacher ..................... None
[default0]:  num_channels .................................... 3
[default0]:  num_classes ..................................... 1000
[default0]:  num_experts ..................................... [1]
[default0]:  num_experts_teacher ............................. [1]
[default0]:  num_layers ...................................... 50
[default0]:  num_layers_per_virtual_pipeline_stage ........... None
[default0]:  num_layers_teacher .............................. None
[default0]:  num_workers ..................................... 2
[default0]:  onnx_safe ....................................... None
[default0]:  openai_gelu ..................................... False
[default0]:  optimizer ....................................... adam
[default0]:  override_lr_scheduler ........................... False
[default0]:  params_dtype .................................... torch.float16
[default0]:  partition_activations ........................... True
[default0]:  patch_dim ....................................... 16
[default0]:  pipeline_model_parallel_size .................... 1
[default0]:  profile_backward ................................ False
[default0]:  query_in_block_prob ............................. 0.1
[default0]:  rampup_batch_size ............................... None
[default0]:  rank ............................................ 0
[default0]:  remote_device ................................... none
[default0]:  reset_attention_mask ............................ False
[default0]:  reset_iteration ................................. False
[default0]:  reset_position_ids .............................. False
[default0]:  retriever_report_topk_accuracies ................ []
[default0]:  retriever_score_scaling ......................... False
[default0]:  retriever_seq_length ............................ 256
[default0]:  sample_rate ..................................... 1.0
[default0]:  save ............................................ checkpoints/gpt2-10b-dist-2023-04-24_080429
[default0]:  save_interval ................................... 500
[default0]:  scatter_gather_tensors_in_pipeline .............. True
[default0]:  scattered_embeddings ............................ False
[default0]:  seed ............................................ 42
[default0]:  seq_length ...................................... 1024
[default0]:  sgd_momentum .................................... 0.9
[default0]:  short_seq_prob .................................. 0.1
[default0]:  split ........................................... 969, 30, 1
[default0]:  split_transformers .............................. False
[default0]:  synchronize_each_layer .......................... False
[default0]:  tensor_model_parallel_size ...................... 1
[default0]:  tensorboard_dir ................................. output_dir/tensorboard-dist-2023-04-24_080429
[default0]:  tensorboard_log_interval ........................ 1
[default0]:  tensorboard_queue_size .......................... 5
[default0]:  tile_factor ..................................... 1
[default0]:  titles_data_path ................................ None
[default0]:  tokenizer_type .................................. GPT2BPETokenizer
[default0]:  topk ............................................ 1
[default0]:  train_iters ..................................... None
[default0]:  train_samples ................................... 1000000
[default0]:  train_tokens .................................... None
[default0]:  use_checkpoint_lr_scheduler ..................... False
[default0]:  use_contiguous_buffers_in_ddp ................... False
[default0]:  use_cpu_initialization .......................... None
[default0]:  use_one_sent_docs ............................... False
[default0]:  use_pin_memory .................................. False
[default0]:  use_tutel ....................................... False
[default0]:  virtual_pipeline_model_parallel_size ............ None
[default0]:  vocab_extra_ids ................................. 0
[default0]:  vocab_file ...................................... data/gpt2-vocab.json
[default0]:  weight_decay .................................... 0.1
[default0]:  world_size ...................................... 64
[default0]:  zero_allgather_bucket_size ...................... 0.0
[default0]:  zero_contigious_gradients ....................... False
[default0]:  zero_reduce_bucket_size ......................... 0.0
[default0]:  zero_reduce_scatter ............................. False
[default0]:  zero_stage ...................................... 2
[default0]:-------------------- end of arguments ---------------------
[default0]:setting number of micro-batches to constant 1
[default0]:> building GPT2BPETokenizer tokenizer ...
[default3]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default1]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default1]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default1]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default1]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default1]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default1]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default1]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.9.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default2]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default2]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default2]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default2]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default2]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default2]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default2]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default2]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default2]:--------------------------------------------------
[default2]:DeepSpeed general environment info:
[default2]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default2]:torch version .................... 1.12.0
[default2]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default2]:deepspeed info ................... 0.9.0, unknown, unknown
[default2]:torch cuda version ............... 11.7
[default2]:torch hip version ................ None
[default2]:nvcc version ..................... 11.7
[default2]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default3]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default3]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default3]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default3]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default3]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default1]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default1]:--------------------------------------------------
[default1]:DeepSpeed general environment info:
[default1]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default1]:torch version .................... 1.12.0
[default1]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default1]:deepspeed info ................... 0.9.0, unknown, unknown
[default1]:torch cuda version ............... 11.7
[default1]:torch hip version ................ None
[default1]:nvcc version ..................... 11.7
[default1]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default2]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default3]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:utils .................. [93m[NO][0m ....... [92m[OKAY][0m
[default3]:--------------------------------------------------
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]: > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
[default0]:> initializing torch distributed ...
[default0]:[2023-04-24 08:04:47,735] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[default3]:DeepSpeed general environment info:
[default3]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default3]:torch version .................... 1.12.0
[default3]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default3]:deepspeed info ................... 0.9.0, unknown, unknown
[default3]:torch cuda version ............... 11.7
[default3]:torch hip version ................ None
[default3]:nvcc version ..................... 11.7
[default3]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default3]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default1]:**** Git info for Megatron: git_hash=8243fd6 git_branch=develop ****
[default0]:> initializing tensor model parallel with size 1
[default0]:> initializing pipeline model parallel with size 1
[default3]:> setting tensorboard ...
[default0]:> setting random seeds to 42 ...
[default0]:[2023-04-24 08:05:03,432] [INFO] [checkpointing.py:226:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 2760 and data parallel seed: 42
[default0]:> compiling dataset index builder ...
[default0]:make: Entering directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/data'
[default0]:make: Nothing to be done for 'default'.
[default0]:make: Leaving directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/data'
[default0]:>>> done with dataset index builder. Compilation time: 1.662 seconds
[default0]:> compiling and loading fused kernels ...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module scaled_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module fused_mix_prec_layer_norm_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module fused_mix_prec_layer_norm_cuda...
[default0]:n2gpu1201:986607:986607 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.69<0>
[default0]:n2gpu1201:986607:986607 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1201:986607:986607 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.69<0>
[default0]:n2gpu1201:986607:986607 [0] NCCL INFO Using network IB
[default0]:NCCL version 2.12.12+cuda11.7
[default3]:n2gpu1224:124662:124662 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.92<0>
[default0]:n2gpu1206:143432:143432 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.74<0>
[default2]:n2gpu1220:386662:386662 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.88<0>
[default2]:n2gpu1202:1130095:1130095 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.70<0>
[default1]:n2gpu1209:135998:135998 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.77<0>
[default2]:n2gpu1207:144620:144620 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.75<0>
[default3]:n2gpu1230:125965:125965 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.98<0>
[default0]:n2gpu1204:138136:138136 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.72<0>
[default0]:n2gpu1220:386660:386660 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.88<0>
[default2]:n2gpu1222:147027:147027 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.90<0>
[default3]:n2gpu1227:190532:190532 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.95<0>
[default2]:n2gpu1230:125964:125964 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.98<0>
[default0]:n2gpu1219:266888:266888 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.87<0>
[default2]:n2gpu1219:266890:266890 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.87<0>
[default2]:n2gpu1206:143434:143434 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.74<0>
[default3]:n2gpu1206:143435:143435 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.74<0>
[default3]:n2gpu1205:143300:143300 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.73<0>
[default1]:n2gpu1205:143298:143298 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.73<0>
[default0]:n2gpu1205:143297:143297 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.73<0>
[default1]:n2gpu1230:125963:125963 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.98<0>
[default1]:n2gpu1230:125963:125963 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1205:143299:143299 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.73<0>
[default2]:n2gpu1205:143299:143299 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1229:174606:174606 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.97<0>
[default0]:n2gpu1229:174604:174604 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.97<0>
[default1]:n2gpu1227:190530:190530 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.95<0>
[default1]:n2gpu1227:190530:190530 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1227:190530:190530 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.95<0>
[default1]:n2gpu1227:190530:190530 [1] NCCL INFO Using network IB
[default0]:n2gpu1227:190529:190529 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.95<0>
[default0]:n2gpu1227:190529:190529 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1222:147025:147025 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.90<0>
[default0]:n2gpu1222:147025:147025 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1222:147025:147025 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.90<0>
[default0]:n2gpu1222:147025:147025 [0] NCCL INFO Using network IB
[default3]:n2gpu1222:147028:147028 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.90<0>
[default3]:n2gpu1222:147028:147028 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1209:135999:135999 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.77<0>
[default2]:n2gpu1209:135999:135999 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1209:135997:135997 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.77<0>
[default0]:n2gpu1209:135997:135997 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1209:135997:135997 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.77<0>
[default0]:n2gpu1209:135997:135997 [0] NCCL INFO Using network IB
[default3]:n2gpu1209:136000:136000 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.77<0>
[default3]:n2gpu1209:136000:136000 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1224:124659:124659 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.92<0>
[default0]:n2gpu1224:124659:124659 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1206:143433:143433 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.74<0>
[default1]:n2gpu1206:143433:143433 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1202:1130093:1130093 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.70<0>
[default0]:n2gpu1202:1130093:1130093 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1210:144012:144012 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.78<0>
[default1]:n2gpu1210:144012:144012 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1210:144012:144012 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.78<0>
[default1]:n2gpu1210:144012:144012 [1] NCCL INFO Using network IB
[default3]:n2gpu1224:124662:124662 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1224:124660:124660 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.92<0>
[default1]:n2gpu1224:124660:124660 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1224:124660:124660 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.92<0>
[default1]:n2gpu1224:124660:124660 [1] NCCL INFO Using network IB
[default2]:n2gpu1224:124661:124661 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.92<0>
[default2]:n2gpu1224:124661:124661 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1224:124661:124661 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.92<0>
[default2]:n2gpu1224:124661:124661 [2] NCCL INFO Using network IB
[default3]:n2gpu1221:160030:160030 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.89<0>
[default3]:n2gpu1221:160030:160030 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1221:160028:160028 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.89<0>
[default1]:n2gpu1221:160028:160028 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1221:160028:160028 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.89<0>
[default1]:n2gpu1221:160028:160028 [1] NCCL INFO Using network IB
[default2]:n2gpu1221:160029:160029 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.89<0>
[default2]:n2gpu1221:160029:160029 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1221:160027:160027 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.89<0>
[default1]:n2gpu1229:174605:174605 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.97<0>
[default1]:n2gpu1229:174605:174605 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1221:160027:160027 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1202:1130095:1130095 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1202:1130095:1130095 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.70<0>
[default2]:n2gpu1202:1130095:1130095 [2] NCCL INFO Using network IB
[default1]:n2gpu1202:1130094:1130094 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.70<0>
[default1]:n2gpu1202:1130094:1130094 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1202:1130096:1130096 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.70<0>
[default3]:n2gpu1202:1130096:1130096 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1210:144014:144014 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.78<0>
[default3]:n2gpu1210:144014:144014 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1210:144014:144014 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.78<0>
[default3]:n2gpu1210:144014:144014 [3] NCCL INFO Using network IB
[default1]:n2gpu1209:135998:135998 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1209:135998:135998 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.77<0>
[default1]:n2gpu1209:135998:135998 [1] NCCL INFO Using network IB
[default3]:n2gpu1207:144621:144621 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.75<0>
[default3]:n2gpu1207:144621:144621 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1207:144621:144621 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.75<0>
[default3]:n2gpu1207:144621:144621 [3] NCCL INFO Using network IB
[default1]:n2gpu1207:144619:144619 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.75<0>
[default1]:n2gpu1207:144619:144619 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1207:144618:144618 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.75<0>
[default0]:n2gpu1207:144618:144618 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1230:125962:125962 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.98<0>
[default0]:n2gpu1230:125962:125962 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1230:125962:125962 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.98<0>
[default0]:n2gpu1230:125962:125962 [0] NCCL INFO Using network IB
[default3]:n2gpu1230:125965:125965 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1230:125965:125965 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.98<0>
[default3]:n2gpu1230:125965:125965 [3] NCCL INFO Using network IB
[default3]:n2gpu1204:138139:138139 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.72<0>
[default3]:n2gpu1204:138139:138139 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1204:138137:138137 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.72<0>
[default1]:n2gpu1204:138137:138137 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1204:138137:138137 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.72<0>
[default1]:n2gpu1204:138137:138137 [1] NCCL INFO Using network IB
[default3]:n2gpu1219:266891:266891 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.87<0>
[default3]:n2gpu1219:266891:266891 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1219:266891:266891 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.87<0>
[default3]:n2gpu1219:266891:266891 [3] NCCL INFO Using network IB
[default1]:n2gpu1219:266889:266889 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.87<0>
[default1]:n2gpu1219:266889:266889 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1206:143432:143432 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1206:143432:143432 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.74<0>
[default0]:n2gpu1206:143432:143432 [0] NCCL INFO Using network IB
[default2]:n2gpu1222:147027:147027 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1222:147027:147027 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.90<0>
[default2]:n2gpu1222:147027:147027 [2] NCCL INFO Using network IB
[default1]:n2gpu1222:147026:147026 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1222:147026:147026 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.90<0>
[default1]:n2gpu1222:147026:147026 [1] NCCL INFO Using network IB
[default2]:n2gpu1230:125964:125964 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1230:125964:125964 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.98<0>
[default2]:n2gpu1230:125964:125964 [2] NCCL INFO Using network IB
[default3]:n2gpu1205:143300:143300 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1205:143298:143298 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1205:143298:143298 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.73<0>
[default1]:n2gpu1205:143298:143298 [1] NCCL INFO Using network IB
[default0]:n2gpu1205:143297:143297 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1205:143297:143297 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.73<0>
[default0]:n2gpu1205:143297:143297 [0] NCCL INFO Using network IB
[default2]:n2gpu1227:190531:190531 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.95<0>
[default2]:n2gpu1227:190531:190531 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1227:190531:190531 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.95<0>
[default2]:n2gpu1227:190531:190531 [2] NCCL INFO Using network IB
[default3]:n2gpu1227:190532:190532 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1227:190532:190532 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.95<0>
[default3]:n2gpu1227:190532:190532 [3] NCCL INFO Using network IB
[default2]:n2gpu1207:144620:144620 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1207:144620:144620 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.75<0>
[default2]:n2gpu1207:144620:144620 [2] NCCL INFO Using network IB
[default0]:n2gpu1204:138136:138136 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1204:138136:138136 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.72<0>
[default0]:n2gpu1204:138136:138136 [0] NCCL INFO Using network IB
[default0]:n2gpu1219:266888:266888 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1219:266888:266888 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.87<0>
[default0]:n2gpu1219:266888:266888 [0] NCCL INFO Using network IB
[default2]:n2gpu1206:143434:143434 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1206:143434:143434 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.74<0>
[default2]:n2gpu1206:143434:143434 [2] NCCL INFO Using network IB
[default3]:n2gpu1206:143435:143435 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1206:143435:143435 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.74<0>
[default3]:n2gpu1206:143435:143435 [3] NCCL INFO Using network IB
[default3]:n2gpu1220:386663:386663 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.88<0>
[default3]:n2gpu1220:386663:386663 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1220:386663:386663 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.88<0>
[default3]:n2gpu1220:386663:386663 [3] NCCL INFO Using network IB
[default2]:n2gpu1220:386662:386662 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1220:386661:386661 [1] NCCL INFO Bootstrap : Using ib1:10.10.103.88<0>
[default1]:n2gpu1220:386661:386661 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default1]:n2gpu1220:386661:386661 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.88<0>
[default1]:n2gpu1220:386661:386661 [1] NCCL INFO Using network IB
[default0]:n2gpu1220:386660:386660 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1219:266890:266890 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1219:266890:266890 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.87<0>
[default2]:n2gpu1219:266890:266890 [2] NCCL INFO Using network IB
[default1]:n2gpu1230:125963:125963 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.98<0>
[default1]:n2gpu1230:125963:125963 [1] NCCL INFO Using network IB
[default0]:n2gpu1210:144011:144011 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.78<0>
[default0]:n2gpu1210:144011:144011 [0] NCCL INFO Using network IB
[default2]:n2gpu1204:138138:138138 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.72<0>
[default2]:n2gpu1204:138138:138138 [2] NCCL INFO Using network IB
[default1]:n2gpu1206:143433:143433 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.74<0>
[default1]:n2gpu1206:143433:143433 [1] NCCL INFO Using network IB
[default3]:n2gpu1222:147028:147028 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.90<0>
[default3]:n2gpu1222:147028:147028 [3] NCCL INFO Using network IB
[default0]:n2gpu1227:190529:190529 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.95<0>
[default0]:n2gpu1227:190529:190529 [0] NCCL INFO Using network IB
[default0]:n2gpu1224:124659:124659 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.92<0>
[default0]:n2gpu1224:124659:124659 [0] NCCL INFO Using network IB
[default2]:n2gpu1229:174606:174606 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1229:174606:174606 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.97<0>
[default2]:n2gpu1229:174606:174606 [2] NCCL INFO Using network IB
[default3]:n2gpu1229:174607:174607 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.97<0>
[default3]:n2gpu1229:174607:174607 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1229:174604:174604 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default2]:n2gpu1209:135999:135999 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.77<0>
[default2]:n2gpu1209:135999:135999 [2] NCCL INFO Using network IB
[default3]:n2gpu1209:136000:136000 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.77<0>
[default3]:n2gpu1209:136000:136000 [3] NCCL INFO Using network IB
[default2]:n2gpu1201:986609:986609 [2] NCCL INFO Bootstrap : Using ib1:10.10.103.69<0>
[default2]:n2gpu1201:986609:986609 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1201:986610:986610 [3] NCCL INFO Bootstrap : Using ib1:10.10.103.69<0>
[default3]:n2gpu1201:986610:986610 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default3]:n2gpu1221:160030:160030 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.89<0>
[default3]:n2gpu1221:160030:160030 [3] NCCL INFO Using network IB
[default2]:n2gpu1221:160029:160029 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.89<0>
[default2]:n2gpu1221:160029:160029 [2] NCCL INFO Using network IB
[default0]:n2gpu1221:160027:160027 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.89<0>
[default0]:n2gpu1221:160027:160027 [0] NCCL INFO Using network IB
[default0]:n2gpu1202:1130093:1130093 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.70<0>
[default0]:n2gpu1202:1130093:1130093 [0] NCCL INFO Using network IB
[default2]:n2gpu1210:144013:144013 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.78<0>
[default2]:n2gpu1210:144013:144013 [2] NCCL INFO Using network IB
[default3]:n2gpu1224:124662:124662 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.92<0>
[default3]:n2gpu1224:124662:124662 [3] NCCL INFO Using network IB
[default1]:n2gpu1219:266889:266889 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.87<0>
[default1]:n2gpu1219:266889:266889 [1] NCCL INFO Using network IB
[default1]:n2gpu1202:1130094:1130094 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.70<0>
[default1]:n2gpu1202:1130094:1130094 [1] NCCL INFO Using network IB
[default3]:n2gpu1202:1130096:1130096 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.70<0>
[default3]:n2gpu1202:1130096:1130096 [3] NCCL INFO Using network IB
[default1]:n2gpu1229:174605:174605 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.97<0>
[default1]:n2gpu1229:174605:174605 [1] NCCL INFO Using network IB
[default1]:n2gpu1207:144619:144619 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.75<0>
[default1]:n2gpu1207:144619:144619 [1] NCCL INFO Using network IB
[default0]:n2gpu1207:144618:144618 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.75<0>
[default0]:n2gpu1207:144618:144618 [0] NCCL INFO Using network IB
[default3]:n2gpu1204:138139:138139 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.72<0>
[default3]:n2gpu1204:138139:138139 [3] NCCL INFO Using network IB
[default2]:n2gpu1220:386662:386662 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.88<0>
[default2]:n2gpu1220:386662:386662 [2] NCCL INFO Using network IB
[default0]:n2gpu1220:386660:386660 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.88<0>
[default0]:n2gpu1220:386660:386660 [0] NCCL INFO Using network IB
[default3]:n2gpu1205:143300:143300 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.73<0>
[default3]:n2gpu1205:143300:143300 [3] NCCL INFO Using network IB
[default2]:n2gpu1205:143299:143299 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.73<0>
[default2]:n2gpu1205:143299:143299 [2] NCCL INFO Using network IB
[default3]:n2gpu1229:174607:174607 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.97<0>
[default3]:n2gpu1229:174607:174607 [3] NCCL INFO Using network IB
[default0]:n2gpu1229:174604:174604 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.97<0>
[default0]:n2gpu1229:174604:174604 [0] NCCL INFO Using network IB
[default2]:n2gpu1201:986609:986609 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.69<0>
[default2]:n2gpu1201:986609:986609 [2] NCCL INFO Using network IB
[default3]:n2gpu1201:986610:986610 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.69<0>
[default3]:n2gpu1201:986610:986610 [3] NCCL INFO Using network IB
[default1]:n2gpu1201:986608:986608 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.69<0>
[default1]:n2gpu1201:986608:986608 [1] NCCL INFO Using network IB
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO Trees [0] 62/-1/-1->61->60 [1] 62/-1/-1->61->60 [2] 62/-1/-1->61->60 [3] 62/-1/-1->61->60
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO Trees [0] -1/-1/-1->63->62 [1] -1/-1/-1->63->62 [2] -1/-1/-1->63->62 [3] -1/-1/-1->63->62
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO Trees [0] 63/-1/-1->62->61 [1] 63/-1/-1->62->61 [2] 63/-1/-1->62->61 [3] 63/-1/-1->62->61
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Trees [0] 5/-1/-1->4->9 [1] 5/-1/-1->4->9 [2] 5/0/-1->4->12 [3] 5/0/-1->4->12
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 01/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 03/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Trees [0] 1/32/-1->0->-1 [1] 1/32/-1->0->-1 [2] 1/-1/-1->0->4 [3] 1/-1/-1->0->4
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 00/0 : 63[c4000] -> 0[3000] [receive] via NET/IB/0
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/8/-1->5->4 [3] 6/8/-1->5->4
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Trees [0] 9/12/-1->8->17 [1] 9/12/-1->8->17 [2] 9/-1/-1->8->5 [3] 9/-1/-1->8->5
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 00/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9 [2] 11/-1/-1->10->9 [3] 11/-1/-1->10->9
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Trees [0] 10/4/-1->9->8 [1] 10/4/-1->9->8 [2] 10/-1/-1->9->8 [3] 10/-1/-1->9->8
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 01/0 : 63[c4000] -> 0[3000] [receive] via NET/IB/0
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13 [2] 15/-1/-1->14->13 [3] 15/-1/-1->14->13
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12 [2] 14/20/-1->13->12 [3] 14/20/-1->13->12
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Trees [0] 34/16/-1->33->32 [1] 34/16/-1->33->32 [2] 34/-1/-1->33->32 [3] 34/-1/-1->33->32
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO Trees [0] -1/-1/-1->35->34 [1] -1/-1/-1->35->34 [2] -1/-1/-1->35->34 [3] -1/-1/-1->35->34
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 00/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10 [2] -1/-1/-1->11->10 [3] -1/-1/-1->11->10
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO Trees [0] 35/-1/-1->34->33 [1] 35/-1/-1->34->33 [2] 35/-1/-1->34->33 [3] 35/-1/-1->34->33
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Trees [0] 37/-1/-1->36->41 [1] 37/-1/-1->36->41 [2] 37/32/-1->36->44 [3] 37/32/-1->36->44
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/-1/-1->12->8 [2] 13/4/-1->12->28 [3] 13/4/-1->12->28
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Trees [0] 17/24/-1->16->33 [1] 17/24/-1->16->33 [2] 17/-1/-1->16->20 [3] 17/-1/-1->16->20
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14 [2] -1/-1/-1->15->14 [3] -1/-1/-1->15->14
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 01/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 01/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO Channel 00 : 61[44000] -> 62[84000] via P2P/IPC/read
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 02/0 : 63[c4000] -> 0[3000] [receive] via NET/IB/0
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO Trees [0] 39/-1/-1->38->37 [1] 39/-1/-1->38->37 [2] 39/-1/-1->38->37 [3] 39/-1/-1->38->37
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Trees [0] 38/-1/-1->37->36 [1] 38/-1/-1->37->36 [2] 38/40/-1->37->36 [3] 38/40/-1->37->36
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 00/0 : 35[c4000] -> 36[3000] [receive] via NET/IB/0
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Trees [0] 18/8/-1->17->16 [1] 18/8/-1->17->16 [2] 18/-1/-1->17->16 [3] 18/-1/-1->17->16
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 02/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 00/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO Channel 00 : 62[84000] -> 63[c4000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Trees [0] 22/-1/-1->21->20 [1] 22/-1/-1->21->20 [2] 22/24/-1->21->20 [3] 22/24/-1->21->20
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Trees [0] 21/-1/-1->20->25 [1] 21/-1/-1->20->25 [2] 21/16/-1->20->13 [3] 21/16/-1->20->13
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO Trees [0] 19/-1/-1->18->17 [1] 19/-1/-1->18->17 [2] 19/-1/-1->18->17 [3] 19/-1/-1->18->17
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO Trees [0] -1/-1/-1->19->18 [1] -1/-1/-1->19->18 [2] -1/-1/-1->19->18 [3] -1/-1/-1->19->18
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO Trees [0] -1/-1/-1->39->38 [1] -1/-1/-1->39->38 [2] -1/-1/-1->39->38 [3] -1/-1/-1->39->38
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Trees [0] 42/36/-1->41->40 [1] 42/36/-1->41->40 [2] 42/-1/-1->41->40 [3] 42/-1/-1->41->40
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Trees [0] 41/44/-1->40->49 [1] 41/44/-1->40->49 [2] 41/-1/-1->40->37 [3] 41/-1/-1->40->37
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 00/0 : 15[c4000] -> 16[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 03/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 00 : 4[3000] -> 5[44000] via P2P/IPC/read
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO Channel 00 : 1[44000] -> 2[84000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 02/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 03/0 : 63[c4000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 01/0 : 35[c4000] -> 36[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 00/0 : 19[c4000] -> 20[3000] [receive] via NET/IB/0
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO Channel 00/0 : 63[c4000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO Channel 01 : 61[44000] -> 62[84000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 01/0 : 15[c4000] -> 16[3000] [receive] via NET/IB/0
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO Trees [0] 43/-1/-1->42->41 [1] 43/-1/-1->42->41 [2] 43/-1/-1->42->41 [3] 43/-1/-1->42->41
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 00/0 : 39[c4000] -> 40[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 01 : 4[3000] -> 5[44000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Trees [0] 25/28/-1->24->16 [1] 25/28/-1->24->16 [2] 25/-1/-1->24->21 [3] 25/-1/-1->24->21
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO Trees [0] -1/-1/-1->23->22 [1] -1/-1/-1->23->22 [2] -1/-1/-1->23->22 [3] -1/-1/-1->23->22
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO Trees [0] 23/-1/-1->22->21 [1] 23/-1/-1->22->21 [2] 23/-1/-1->22->21 [3] 23/-1/-1->22->21
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO Channel 00 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 01/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO Channel 01 : 62[84000] -> 63[c4000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO Channel 01/0 : 63[c4000] -> 0[3000] [send] via NET/IB/0
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO Trees [0] -1/-1/-1->43->42 [1] -1/-1/-1->43->42 [2] -1/-1/-1->43->42 [3] -1/-1/-1->43->42
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Trees [0] 45/-1/-1->44->40 [1] 45/-1/-1->44->40 [2] 45/36/-1->44->29 [3] 45/36/-1->44->29
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO Trees [0] -1/-1/-1->27->26 [1] -1/-1/-1->27->26 [2] -1/-1/-1->27->26 [3] -1/-1/-1->27->26
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Trees [0] 26/20/-1->25->24 [1] 26/20/-1->25->24 [2] 26/-1/-1->25->24 [3] 26/-1/-1->25->24
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Channel 00 : 5[44000] -> 6[84000] via P2P/IPC/read
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO Channel 00 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 02 : 4[3000] -> 5[44000] via P2P/IPC/read
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO Channel 00/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 00/0 : 23[c4000] -> 24[3000] [receive] via NET/IB/0
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO Trees [0] 27/-1/-1->26->25 [1] 27/-1/-1->26->25 [2] 27/-1/-1->26->25 [3] 27/-1/-1->26->25
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO Channel 01 : 1[44000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO Channel 00/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO Channel 01/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 03/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 00 : 8[3000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Channel 00 : 9[44000] -> 10[84000] via P2P/IPC/read
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 02/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO Channel 02 : 62[84000] -> 63[c4000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO Channel 02/0 : 63[c4000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO Channel 02 : 61[44000] -> 62[84000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Trees [0] 61/-1/-1->60->56 [1] 61/-1/-1->60->56 [2] 61/28/-1->60->-1 [3] 61/28/-1->60->-1
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Trees [0] 49/56/-1->48->32 [1] 49/56/-1->48->32 [2] 49/-1/-1->48->52 [3] 49/-1/-1->48->52
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 01/0 : 19[c4000] -> 20[3000] [receive] via NET/IB/0
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 02/0 : 35[c4000] -> 36[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 02/0 : 15[c4000] -> 16[3000] [receive] via NET/IB/0
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 01/0 : 39[c4000] -> 40[3000] [receive] via NET/IB/0
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Channel 00 : 13[44000] -> 14[84000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO Trees [0] -1/-1/-1->47->46 [1] -1/-1/-1->47->46 [2] -1/-1/-1->47->46 [3] -1/-1/-1->47->46
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Trees [0] 46/-1/-1->45->44 [1] 46/-1/-1->45->44 [2] 46/52/-1->45->44 [3] 46/52/-1->45->44
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO Trees [0] 47/-1/-1->46->45 [1] 47/-1/-1->46->45 [2] 47/-1/-1->46->45 [3] 47/-1/-1->46->45
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO Channel 01 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO Channel 01/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Trees [0] 30/-1/-1->29->28 [1] 30/-1/-1->29->28 [2] 30/44/-1->29->28 [3] 30/44/-1->29->28
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Trees [0] 29/-1/-1->28->24 [1] 29/-1/-1->28->24 [2] 29/12/-1->28->60 [3] 29/12/-1->28->60
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO Channel 02 : 1[44000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO Channel 02/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO Channel 03/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO Channel 01 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 01 : 8[3000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Channel 01 : 9[44000] -> 10[84000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO Trees [0] -1/-1/-1->51->50 [1] -1/-1/-1->51->50 [2] -1/-1/-1->51->50 [3] -1/-1/-1->51->50
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO Trees [0] 51/-1/-1->50->49 [1] 51/-1/-1->50->49 [2] 51/-1/-1->50->49 [3] 51/-1/-1->50->49
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Trees [0] 50/40/-1->49->48 [1] 50/40/-1->49->48 [2] 50/-1/-1->49->48 [3] 50/-1/-1->49->48
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 03/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 00 : 12[3000] -> 13[44000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO Channel 00 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO Channel 03/0 : 63[c4000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO Channel 03 : 61[44000] -> 62[84000] via P2P/IPC/read
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO Channel 00/0 : 15[c4000] -> 16[3000] [send] via NET/IB/0
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Channel 01 : 13[44000] -> 14[84000] via P2P/IPC/read
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Channel 00 : 17[44000] -> 18[84000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 03/0 : 15[c4000] -> 16[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 00 : 16[3000] -> 17[44000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 00/0 : 43[c4000] -> 44[3000] [receive] via NET/IB/0
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 01/0 : 23[c4000] -> 24[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Trees [0] 53/-1/-1->52->57 [1] 53/-1/-1->52->57 [2] 53/48/-1->52->45 [3] 53/48/-1->52->45
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Channel 01 : 5[44000] -> 6[84000] via P2P/IPC/read
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO Channel 02 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 03 : 4[3000] -> 5[44000] via P2P/IPC/read
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO Channel 02/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO Channel 00 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Channel 00 : 33[44000] -> 34[84000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Trees [0] 33/48/-1->32->0 [1] 33/48/-1->32->0 [2] 33/-1/-1->32->36 [3] 33/-1/-1->32->36
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO Channel 02 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO Trees [0] -1/-1/-1->31->30 [1] -1/-1/-1->31->30 [2] -1/-1/-1->31->30 [3] -1/-1/-1->31->30
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO Trees [0] 31/-1/-1->30->29 [1] 31/-1/-1->30->29 [2] 31/-1/-1->30->29 [3] 31/-1/-1->30->29
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 00/0 : 27[c4000] -> 28[3000] [receive] via NET/IB/0
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO Channel 00 : 34[84000] -> 35[c4000] via P2P/IPC/read
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 02 : 8[3000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Channel 02 : 9[44000] -> 10[84000] via P2P/IPC/read
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 03/0 : 35[c4000] -> 36[3000] [receive] via NET/IB/0
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 00 : 36[3000] -> 37[44000] via P2P/IPC/read
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO Channel 03 : 62[84000] -> 63[c4000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 00/0 : 59[c4000] -> 60[3000] [receive] via NET/IB/0
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 02/0 : 39[c4000] -> 40[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 02/0 : 19[c4000] -> 20[3000] [receive] via NET/IB/0
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO Channel 01/0 : 15[c4000] -> 16[3000] [send] via NET/IB/0
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 01/0 : 43[c4000] -> 44[3000] [receive] via NET/IB/0
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Trees [0] 54/-1/-1->53->52 [1] 54/-1/-1->53->52 [2] 54/56/-1->53->52 [3] 54/56/-1->53->52
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 00/0 : 51[c4000] -> 52[3000] [receive] via NET/IB/0
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO Channel 01 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO Channel 03/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Channel 02 : 5[44000] -> 6[84000] via P2P/IPC/read
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO Channel 00/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Channel 01 : 33[44000] -> 34[84000] via P2P/IPC/read
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO Channel 03 : 1[44000] -> 2[84000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 01 : 12[3000] -> 13[44000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO Channel 01 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO Channel 00 : 38[84000] -> 39[c4000] via P2P/IPC/read
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Channel 00 : 37[44000] -> 38[84000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 00/0 : 47[c4000] -> 48[3000] [receive] via NET/IB/0
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 03/0 : 39[c4000] -> 40[3000] [receive] via NET/IB/0
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 00 : 40[3000] -> 41[44000] via P2P/IPC/read
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO Channel 02/0 : 15[c4000] -> 16[3000] [send] via NET/IB/0
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Channel 02 : 13[44000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 02/0 : 23[c4000] -> 24[3000] [receive] via NET/IB/0
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO Trees [0] -1/-1/-1->55->54 [1] -1/-1/-1->55->54 [2] -1/-1/-1->55->54 [3] -1/-1/-1->55->54
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO Trees [0] 55/-1/-1->54->53 [1] 55/-1/-1->54->53 [2] 55/-1/-1->54->53 [3] 55/-1/-1->54->53
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Channel 00 : 21[44000] -> 22[84000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 03/0 : 19[c4000] -> 20[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 00 : 20[3000] -> 21[44000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 01 : 16[3000] -> 17[44000] via P2P/IPC/read
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO Channel 00 : 18[84000] -> 19[c4000] via P2P/IPC/read
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Channel 01 : 17[44000] -> 18[84000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 03 : 8[3000] -> 9[44000] via P2P/IPC/read
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO Channel 01/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Channel 03 : 9[44000] -> 10[84000] via P2P/IPC/read
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO Channel 03 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Channel 02 : 33[44000] -> 34[84000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 00/0 : 31[c4000] -> 32[3000] [receive] via NET/IB/0
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO Channel 00/0 : 35[c4000] -> 36[3000] [send] via NET/IB/0
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO Channel 01/0 : 35[c4000] -> 36[3000] [send] via NET/IB/0
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO Channel 01 : 34[84000] -> 35[c4000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 01/0 : 27[c4000] -> 28[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 02 : 12[3000] -> 13[44000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO Channel 02 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO Channel 00 : 22[84000] -> 23[c4000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO Channel 00/0 : 39[c4000] -> 40[3000] [send] via NET/IB/0
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Channel 01 : 37[44000] -> 38[84000] via P2P/IPC/read
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 01 : 36[3000] -> 37[44000] via P2P/IPC/read
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO Connected all rings
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 01/0 : 59[c4000] -> 60[3000] [receive] via NET/IB/0
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Channel 00 : 41[44000] -> 42[84000] via P2P/IPC/read
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO Channel 00 : 42[84000] -> 43[c4000] via P2P/IPC/read
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 01 : 40[3000] -> 41[44000] via P2P/IPC/read
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO Channel 03/0 : 15[c4000] -> 16[3000] [send] via NET/IB/0
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Channel 03 : 13[44000] -> 14[84000] via P2P/IPC/read
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO Channel 02 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO Channel 03 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Channel 03 : 5[44000] -> 6[84000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 02/0 : 43[c4000] -> 44[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 01/0 : 51[c4000] -> 52[3000] [receive] via NET/IB/0
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO Channel 02/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO Channel 00/0 : 19[c4000] -> 20[3000] [send] via NET/IB/0
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO Channel 01 : 18[84000] -> 19[c4000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Trees [0] 57/60/-1->56->48 [1] 57/60/-1->56->48 [2] 57/-1/-1->56->53 [3] 57/-1/-1->56->53
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO Channel 02/0 : 35[c4000] -> 36[3000] [send] via NET/IB/0
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO Channel 02 : 34[84000] -> 35[c4000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 02/0 : 27[c4000] -> 28[3000] [receive] via NET/IB/0
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 02/0 : 59[c4000] -> 60[3000] [receive] via NET/IB/0
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 01/0 : 47[c4000] -> 48[3000] [receive] via NET/IB/0
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO Channel 01 : 38[84000] -> 39[c4000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO Channel 01/0 : 39[c4000] -> 40[3000] [send] via NET/IB/0
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO Channel 02/0 : 39[c4000] -> 40[3000] [send] via NET/IB/0
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 02 : 36[3000] -> 37[44000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Channel 01 : 21[44000] -> 22[84000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 01 : 20[3000] -> 21[44000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 03/0 : 23[c4000] -> 24[3000] [receive] via NET/IB/0
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 00 : 24[3000] -> 25[44000] via P2P/IPC/read
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO Channel 03 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO Channel 00 : 26[84000] -> 27[c4000] via P2P/IPC/read
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO Channel 01 : 26[84000] -> 27[c4000] via P2P/IPC/read
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO Channel 01/0 : 19[c4000] -> 20[3000] [send] via NET/IB/0
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 02 : 16[3000] -> 17[44000] via P2P/IPC/read
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Channel 02 : 17[44000] -> 18[84000] via P2P/IPC/read
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Channel 03 : 17[44000] -> 18[84000] via P2P/IPC/read
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO Connected all rings
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO Connected all rings
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO Channel 00 : 46[84000] -> 47[c4000] via P2P/IPC/read
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO Channel 03/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Trees [0] 58/52/-1->57->56 [1] 58/52/-1->57->56 [2] 58/-1/-1->57->56 [3] 58/-1/-1->57->56
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 03 : 12[3000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 01/0 : 31[c4000] -> 32[3000] [receive] via NET/IB/0
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO Channel 03/0 : 35[c4000] -> 36[3000] [send] via NET/IB/0
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Channel 03 : 33[44000] -> 34[84000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO Channel 00/0 : 23[c4000] -> 24[3000] [send] via NET/IB/0
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO Channel 01 : 22[84000] -> 23[c4000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 03/0 : 27[c4000] -> 28[3000] [receive] via NET/IB/0
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 00 : 28[3000] -> 29[44000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 02/0 : 47[c4000] -> 48[3000] [receive] via NET/IB/0
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO Channel 00 : 50[84000] -> 51[c4000] via P2P/IPC/read
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO Channel 02 : 38[84000] -> 39[c4000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO Channel 03/0 : 39[c4000] -> 40[3000] [send] via NET/IB/0
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Channel 02 : 37[44000] -> 38[84000] via P2P/IPC/read
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Channel 01 : 41[44000] -> 42[84000] via P2P/IPC/read
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO Channel 00/0 : 43[c4000] -> 44[3000] [send] via NET/IB/0
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO Channel 01 : 42[84000] -> 43[c4000] via P2P/IPC/read
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 02 : 40[3000] -> 41[44000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 01 : 24[3000] -> 25[44000] via P2P/IPC/read
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO Connected all rings
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Connected all rings
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Channel 02 : 21[44000] -> 22[84000] via P2P/IPC/read
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO Channel 02 : 18[84000] -> 19[c4000] via P2P/IPC/read
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Channel 00 : 25[44000] -> 26[84000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 03/0 : 43[c4000] -> 44[3000] [receive] via NET/IB/0
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 00 : 44[3000] -> 45[44000] via P2P/IPC/read
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Channel 00 : 45[44000] -> 46[84000] via P2P/IPC/read
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO Trees [0] -1/-1/-1->59->58 [1] -1/-1/-1->59->58 [2] -1/-1/-1->59->58 [3] -1/-1/-1->59->58
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO Trees [0] 59/-1/-1->58->57 [1] 59/-1/-1->58->57 [2] 59/-1/-1->58->57 [3] 59/-1/-1->58->57
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 00/0 : 55[c4000] -> 56[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 02/0 : 51[c4000] -> 52[3000] [receive] via NET/IB/0
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 02/0 : 31[c4000] -> 32[3000] [receive] via NET/IB/0
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO Channel 03 : 34[84000] -> 35[c4000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO Channel 03 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 03/0 : 59[c4000] -> 60[3000] [receive] via NET/IB/0
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 00 : 60[3000] -> 61[44000] via P2P/IPC/read
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Channel 00 : 29[44000] -> 30[84000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 01 : 28[3000] -> 29[44000] via P2P/IPC/read
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO Channel 02 : 42[84000] -> 43[c4000] via P2P/IPC/read
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 03 : 36[3000] -> 37[44000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 02 : 20[3000] -> 21[44000] via P2P/IPC/read
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO Connected all rings
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO Channel 02/0 : 19[c4000] -> 20[3000] [send] via NET/IB/0
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO Channel 03/0 : 19[c4000] -> 20[3000] [send] via NET/IB/0
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 03 : 16[3000] -> 17[44000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 01 : 44[3000] -> 45[44000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO Channel 00/0 : 47[c4000] -> 48[3000] [send] via NET/IB/0
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO Channel 01 : 46[84000] -> 47[c4000] via P2P/IPC/read
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Channel 01 : 25[44000] -> 26[84000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO Connected all rings
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 01 : 60[3000] -> 61[44000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO Channel 01/0 : 23[c4000] -> 24[3000] [send] via NET/IB/0
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO Channel 02 : 22[84000] -> 23[c4000] via P2P/IPC/read
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Channel 00 : 49[44000] -> 50[84000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 03/0 : 47[c4000] -> 48[3000] [receive] via NET/IB/0
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 00 : 48[3000] -> 49[44000] via P2P/IPC/read
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO Channel 01 : 50[84000] -> 51[c4000] via P2P/IPC/read
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO Channel 03 : 38[84000] -> 39[c4000] via P2P/IPC/read
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Channel 03 : 37[44000] -> 38[84000] via P2P/IPC/read
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO Channel 00/0 : 27[c4000] -> 28[3000] [send] via NET/IB/0
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO Channel 01/0 : 27[c4000] -> 28[3000] [send] via NET/IB/0
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO Channel 01/0 : 43[c4000] -> 44[3000] [send] via NET/IB/0
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO Channel 02/0 : 43[c4000] -> 44[3000] [send] via NET/IB/0
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 03 : 40[3000] -> 41[44000] via P2P/IPC/read
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Channel 02 : 41[44000] -> 42[84000] via P2P/IPC/read
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Connected all rings
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Channel 02/0 : 5[44000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 02 : 24[3000] -> 25[44000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Channel 03 : 21[44000] -> 22[84000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 03 : 20[3000] -> 21[44000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Connected all rings
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO Channel 03 : 18[84000] -> 19[c4000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 03/0 : 31[c4000] -> 32[3000] [receive] via NET/IB/0
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 00 : 32[3000] -> 33[44000] via P2P/IPC/read
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO Connected all rings
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 02 : 44[3000] -> 45[44000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO Channel 01/0 : 47[c4000] -> 48[3000] [send] via NET/IB/0
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Channel 01 : 45[44000] -> 46[84000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 01/0 : 55[c4000] -> 56[3000] [receive] via NET/IB/0
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO Channel 02 : 26[84000] -> 27[c4000] via P2P/IPC/read
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Channel 00 : 53[44000] -> 54[84000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 03/0 : 51[c4000] -> 52[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 00 : 52[3000] -> 53[44000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 01 : 52[3000] -> 53[44000] via P2P/IPC/read
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO Channel 03 : 22[84000] -> 23[c4000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO Channel 02/0 : 23[c4000] -> 24[3000] [send] via NET/IB/0
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Channel 01 : 29[44000] -> 30[84000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO Channel 00/0 : 31[c4000] -> 32[3000] [send] via NET/IB/0
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO Channel 00 : 30[84000] -> 31[c4000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 02 : 28[3000] -> 29[44000] via P2P/IPC/read
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Channel 01 : 49[44000] -> 50[84000] via P2P/IPC/read
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO Channel 02 : 50[84000] -> 51[c4000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO Channel 00/0 : 51[c4000] -> 52[3000] [send] via NET/IB/0
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO Channel 03/0 : 43[c4000] -> 44[3000] [send] via NET/IB/0
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO Channel 03 : 42[84000] -> 43[c4000] via P2P/IPC/read
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Channel 03 : 41[44000] -> 42[84000] via P2P/IPC/read
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Connected all rings
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 03 : 24[3000] -> 25[44000] via P2P/IPC/read
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Channel 03/0 : 5[44000] -> 8[3000] [send] via NET/IB/1
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Channel 00/0 : 4[3000] -> 9[44000] [receive] via NET/IB/1
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO Channel 03 : 26[84000] -> 27[c4000] via P2P/IPC/read
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO Channel 02 : 46[84000] -> 47[c4000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO Channel 03/0 : 23[c4000] -> 24[3000] [send] via NET/IB/0
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO Channel 00 : 62[84000] -> 61[44000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO Connected all rings
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO Channel 00 : 63[c4000] -> 62[84000] via P2P/IPC/read
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Channel 02 : 29[44000] -> 30[84000] via P2P/IPC/read
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO Channel 01 : 30[84000] -> 31[c4000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 01 : 48[3000] -> 49[44000] via P2P/IPC/read
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO Channel 03 : 50[84000] -> 51[c4000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO Channel 01/0 : 51[c4000] -> 52[3000] [send] via NET/IB/0
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO Connected all rings
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO Channel 02/0 : 27[c4000] -> 28[3000] [send] via NET/IB/0
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO Channel 03/0 : 27[c4000] -> 28[3000] [send] via NET/IB/0
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Channel 02/0 : 13[44000] -> 20[3000] [send] via NET/IB/1
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO Connected all rings
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Channel 02 : 25[44000] -> 26[84000] via P2P/IPC/read
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Channel 01 : 53[44000] -> 54[84000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 02 : 52[3000] -> 53[44000] via P2P/IPC/read
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO Channel 00 : 54[84000] -> 55[c4000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 01 : 32[3000] -> 33[44000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 03 : 44[3000] -> 45[44000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO Channel 02/0 : 47[c4000] -> 48[3000] [send] via NET/IB/0
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Channel 02 : 45[44000] -> 46[84000] via P2P/IPC/read
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO Connected all rings
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 02/0 : 55[c4000] -> 56[3000] [receive] via NET/IB/0
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 02 : 60[3000] -> 61[44000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO Channel 01/0 : 31[c4000] -> 32[3000] [send] via NET/IB/0
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO Channel 02/0 : 31[c4000] -> 32[3000] [send] via NET/IB/0
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 03 : 28[3000] -> 29[44000] via P2P/IPC/read
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Channel 02 : 49[44000] -> 50[84000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO Channel 02/0 : 51[c4000] -> 52[3000] [send] via NET/IB/0
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO Channel 03/0 : 51[c4000] -> 52[3000] [send] via NET/IB/0
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Connected all rings
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Channel 02/0 : 37[44000] -> 40[3000] [send] via NET/IB/1
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Channel 03/0 : 13[44000] -> 20[3000] [send] via NET/IB/1
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Connected all rings
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO Connected all rings
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO Channel 00 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 02 : 32[3000] -> 33[44000] via P2P/IPC/read
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Connected all rings
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Channel 03 : 25[44000] -> 26[84000] via P2P/IPC/read
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO Connected all rings
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO Channel 00 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO Channel 03/0 : 47[c4000] -> 48[3000] [send] via NET/IB/0
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO Channel 03 : 46[84000] -> 47[c4000] via P2P/IPC/read
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Channel 03 : 45[44000] -> 46[84000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 03/0 : 55[c4000] -> 56[3000] [receive] via NET/IB/0
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 00 : 56[3000] -> 57[44000] via P2P/IPC/read
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO Channel 00/0 : 55[c4000] -> 56[3000] [send] via NET/IB/0
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO Channel 01 : 54[84000] -> 55[c4000] via P2P/IPC/read
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO Channel 01 : 62[84000] -> 61[44000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO Channel 01 : 63[c4000] -> 62[84000] via P2P/IPC/read
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Channel 03 : 29[44000] -> 30[84000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO Channel 03/0 : 31[c4000] -> 32[3000] [send] via NET/IB/0
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO Channel 02 : 30[84000] -> 31[c4000] via P2P/IPC/read
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Channel 03 : 49[44000] -> 50[84000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 02 : 48[3000] -> 49[44000] via P2P/IPC/read
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO Connected all rings
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Channel 03/0 : 37[44000] -> 40[3000] [send] via NET/IB/1
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Channel 02/0 : 21[44000] -> 24[3000] [send] via NET/IB/1
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO Connected all rings
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO Channel 00 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Connected all rings
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO Channel 02 : 63[c4000] -> 62[84000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 03 : 60[3000] -> 61[44000] via P2P/IPC/read
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 01 : 56[3000] -> 57[44000] via P2P/IPC/read
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Channel 00 : 57[44000] -> 58[84000] via P2P/IPC/read
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Channel 01 : 57[44000] -> 58[84000] via P2P/IPC/read
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Channel 02 : 53[44000] -> 54[84000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 03 : 52[3000] -> 53[44000] via P2P/IPC/read
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO Channel 01/0 : 55[c4000] -> 56[3000] [send] via NET/IB/0
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO Channel 03 : 30[84000] -> 31[c4000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 03 : 48[3000] -> 49[44000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Channel 03/0 : 21[44000] -> 24[3000] [send] via NET/IB/1
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Connected all rings
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO Channel 01 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO Channel 02 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Channel 00/0 : 8[3000] -> 17[44000] [receive] via NET/IB/1
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO Connected all rings
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO Channel 00 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Connected all rings
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 02/0 : 5[44000] -> 8[3000] [receive] via NET/IB/1
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Channel 01/0 : 4[3000] -> 9[44000] [receive] via NET/IB/1
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 03 : 32[3000] -> 33[44000] via P2P/IPC/read
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO Channel 00 : 58[84000] -> 59[c4000] via P2P/IPC/read
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO Channel 01 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO Channel 00 : 2[84000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO Channel 02 : 62[84000] -> 61[44000] via P2P/IPC/read
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO Connected all rings
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Channel 03 : 53[44000] -> 54[84000] via P2P/IPC/read
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO Channel 02/0 : 55[c4000] -> 56[3000] [send] via NET/IB/0
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO Channel 02 : 54[84000] -> 55[c4000] via P2P/IPC/read
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO Connected all rings
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Connected all rings
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Channel 02 : 57[44000] -> 58[84000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Connected all rings
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO Connected all rings
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Channel 00/0 : 36[3000] -> 41[44000] [receive] via NET/IB/1
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO Channel 00 : 10[84000] -> 9[44000] via P2P/IPC/read
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO Channel 00 : 6[84000] -> 5[44000] via P2P/IPC/read
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO Connected all rings
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO Channel 01 : 2[84000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO Channel 03 : 63[c4000] -> 62[84000] via P2P/IPC/read
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Channel 02/0 : 45[44000] -> 52[3000] [send] via NET/IB/1
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO Channel 00/0 : 59[c4000] -> 60[3000] [send] via NET/IB/0
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Channel 03 : 57[44000] -> 58[84000] via P2P/IPC/read
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO Channel 03/0 : 55[c4000] -> 56[3000] [send] via NET/IB/0
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO Channel 03 : 54[84000] -> 55[c4000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO Connected all rings
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO Channel 00 : 23[c4000] -> 22[84000] via P2P/IPC/read
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO Connected all rings
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO Connected all rings
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO Channel 00 : 39[c4000] -> 38[84000] via P2P/IPC/read
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO Connected all rings
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO Channel 00 : 43[c4000] -> 42[84000] via P2P/IPC/read
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO Connected all rings
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO Channel 00 : 27[c4000] -> 26[84000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 02/0 : 0[3000] -> 4[3000] [receive] via NET/IB/1
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO Channel 03 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO Channel 01 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 03/0 : 5[44000] -> 8[3000] [receive] via NET/IB/1
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO Channel 00 : 34[84000] -> 33[44000] via P2P/IPC/read
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Connected all rings
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Connected all rings
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Channel 01/0 : 8[3000] -> 17[44000] [receive] via NET/IB/1
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO Channel 01 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO Channel 02 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO Channel 03 : 62[84000] -> 61[44000] via P2P/IPC/read
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Channel 03/0 : 45[44000] -> 52[3000] [send] via NET/IB/1
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO Channel 01/0 : 59[c4000] -> 60[3000] [send] via NET/IB/0
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO Channel 01 : 58[84000] -> 59[c4000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 02 : 56[3000] -> 57[44000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 00/0 : 8[3000] -> 12[3000] [receive] via NET/IB/1
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Connected all rings
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO Channel 00 : 14[84000] -> 13[44000] via P2P/IPC/read
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Connected all rings
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Connected all rings
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO Channel 01 : 10[84000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Channel 01/0 : 36[3000] -> 41[44000] [receive] via NET/IB/1
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO Channel 01 : 6[84000] -> 5[44000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 03/0 : 0[3000] -> 4[3000] [receive] via NET/IB/1
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Channel 00/0 : 20[3000] -> 25[44000] [receive] via NET/IB/1
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO Connected all rings
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO Channel 00 : 35[c4000] -> 34[84000] via P2P/IPC/read
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO Connected all rings
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO Channel 00 : 19[c4000] -> 18[84000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 02/0 : 16[3000] -> 20[3000] [send] via NET/IB/1
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Connected all rings
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO Channel 02 : 2[84000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Connected all rings
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO Connected all rings
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO Channel 02/0 : 59[c4000] -> 60[3000] [send] via NET/IB/0
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO Channel 03/0 : 59[c4000] -> 60[3000] [send] via NET/IB/0
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO Channel 02 : 58[84000] -> 59[c4000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Connected all rings
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO Channel 01 : 23[c4000] -> 22[84000] via P2P/IPC/read
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO Channel 00 : 38[84000] -> 37[44000] via P2P/IPC/read
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Connected all rings
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO Channel 01 : 27[c4000] -> 26[84000] via P2P/IPC/read
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO Channel 02 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO Channel 02 : 6[84000] -> 5[44000] via P2P/IPC/read
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO Channel 01 : 34[84000] -> 33[44000] via P2P/IPC/read
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Channel 00/0 : 16[3000] -> 33[44000] [receive] via NET/IB/1
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO Channel 02 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO Channel 03 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 02/0 : 0[3000] -> 4[3000] [send] via NET/IB/1
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO Channel 03 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO Connected all trees
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Channel 02/0 : 53[44000] -> 56[3000] [send] via NET/IB/1
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 03 : 56[3000] -> 57[44000] via P2P/IPC/read
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Channel 02/0 : 29[44000] -> 44[3000] [send] via NET/IB/1
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 01/0 : 8[3000] -> 12[3000] [receive] via NET/IB/1
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO Channel 01 : 14[84000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Connected all rings
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO Channel 02 : 27[c4000] -> 26[84000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Connected all rings
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO Channel 02 : 10[84000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Channel 00/0 : 40[3000] -> 49[44000] [receive] via NET/IB/1
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO Channel 01 : 43[c4000] -> 42[84000] via P2P/IPC/read
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO Channel 00 : 42[84000] -> 41[44000] via P2P/IPC/read
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO Channel 01 : 38[84000] -> 37[44000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO Channel 01 : 39[c4000] -> 38[84000] via P2P/IPC/read
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 02/0 : 32[3000] -> 36[3000] [receive] via NET/IB/1
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Channel 01/0 : 20[3000] -> 25[44000] [receive] via NET/IB/1
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO Channel 03 : 6[84000] -> 5[44000] via P2P/IPC/read
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO Channel 01 : 19[c4000] -> 18[84000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 03/0 : 16[3000] -> 20[3000] [send] via NET/IB/1
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO Channel 00 : 18[84000] -> 17[44000] via P2P/IPC/read
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Channel 03/0 : 53[44000] -> 56[3000] [send] via NET/IB/1
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO Channel 02 : 34[84000] -> 33[44000] via P2P/IPC/read
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO Channel 01 : 35[c4000] -> 34[84000] via P2P/IPC/read
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Channel 01/0 : 16[3000] -> 33[44000] [receive] via NET/IB/1
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO Channel 03 : 58[84000] -> 59[c4000] via P2P/IPC/read
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 03/0 : 0[3000] -> 4[3000] [send] via NET/IB/1
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO Channel 03 : 2[84000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Channel 03/0 : 29[44000] -> 44[3000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Connected all rings
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO Channel 00 : 22[84000] -> 21[44000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO Channel 02 : 23[c4000] -> 22[84000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO Channel 02 : 14[84000] -> 13[44000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO Channel 02 : 39[c4000] -> 38[84000] via P2P/IPC/read
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 02/0 : 37[44000] -> 40[3000] [receive] via NET/IB/1
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO Channel 03 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO Channel 03 : 34[84000] -> 33[44000] via P2P/IPC/read
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO Channel 02 : 35[c4000] -> 34[84000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO Connected all rings
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO Channel 00 : 47[c4000] -> 46[84000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 00/0 : 40[3000] -> 44[3000] [receive] via NET/IB/1
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO Connected all rings
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO Channel 00 : 31[c4000] -> 30[84000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 00/0 : 24[3000] -> 28[3000] [receive] via NET/IB/1
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 02/0 : 16[3000] -> 20[3000] [receive] via NET/IB/1
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 03/0 : 16[3000] -> 20[3000] [receive] via NET/IB/1
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 03/0 : 32[3000] -> 36[3000] [receive] via NET/IB/1
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO Channel 02 : 43[c4000] -> 42[84000] via P2P/IPC/read
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO Channel 03 : 43[c4000] -> 42[84000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 02/0 : 21[44000] -> 24[3000] [receive] via NET/IB/1
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO Channel 03 : 27[c4000] -> 26[84000] via P2P/IPC/read
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO Channel 03 : 10[84000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Channel 01/0 : 40[3000] -> 49[44000] [receive] via NET/IB/1
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO Connected all rings
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO Channel 00 : 51[c4000] -> 50[84000] via P2P/IPC/read
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Channel 02/0 : 8[3000] -> 5[44000] [receive] via NET/IB/1
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO Channel 02 : 19[c4000] -> 18[84000] via P2P/IPC/read
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO Channel 01 : 18[84000] -> 17[44000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 00/0 : 8[3000] -> 12[3000] [send] via NET/IB/1
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 01/0 : 8[3000] -> 12[3000] [send] via NET/IB/1
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO Connected all trees
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO Connected all trees
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO Channel 01 : 31[c4000] -> 30[84000] via P2P/IPC/read
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO Channel 00 : 30[84000] -> 29[44000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 01/0 : 24[3000] -> 28[3000] [receive] via NET/IB/1
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO Channel 00 : 46[84000] -> 45[44000] via P2P/IPC/read
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO Connected all rings
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Connected all rings
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO Channel 00 : 61[44000] -> 60[3000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO Channel 03 : 14[84000] -> 13[44000] via P2P/IPC/read
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO Channel 01 : 22[84000] -> 21[44000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO Channel 03 : 23[c4000] -> 22[84000] via P2P/IPC/read
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO Channel 01 : 42[84000] -> 41[44000] via P2P/IPC/read
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 03/0 : 37[44000] -> 40[3000] [receive] via NET/IB/1
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO Channel 02 : 38[84000] -> 37[44000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO Channel 03 : 39[c4000] -> 38[84000] via P2P/IPC/read
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO Connected all trees
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Channel 03/0 : 8[3000] -> 5[44000] [receive] via NET/IB/1
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO Channel 00 : 26[84000] -> 25[44000] via P2P/IPC/read
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO Connected all trees
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO Channel 03 : 35[c4000] -> 34[84000] via P2P/IPC/read
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 00/0 : 32[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Connected all rings
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO Channel 02 : 31[c4000] -> 30[84000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO Channel 01 : 47[c4000] -> 46[84000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 01/0 : 40[3000] -> 44[3000] [receive] via NET/IB/1
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO Channel 02 : 42[84000] -> 41[44000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 03/0 : 21[44000] -> 24[3000] [receive] via NET/IB/1
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Connected all rings
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO Channel 00 : 50[84000] -> 49[44000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO Channel 01 : 51[c4000] -> 50[84000] via P2P/IPC/read
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO Channel 03 : 38[84000] -> 37[44000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 00/0 : 4[3000] -> 9[44000] [send] via NET/IB/1
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO Channel 03 : 19[c4000] -> 18[84000] via P2P/IPC/read
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO Channel 02 : 18[84000] -> 17[44000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Connected all rings
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO Connected all trees
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 02/0 : 48[3000] -> 52[3000] [receive] via NET/IB/1
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO Channel 01 : 30[84000] -> 29[44000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO Channel 02 : 47[c4000] -> 46[84000] via P2P/IPC/read
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO Channel 01 : 46[84000] -> 45[44000] via P2P/IPC/read
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Channel 00/0 : 52[3000] -> 57[44000] [receive] via NET/IB/1
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO Channel 02 : 22[84000] -> 21[44000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 02/0 : 48[3000] -> 52[3000] [send] via NET/IB/1
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO Channel 02 : 51[c4000] -> 50[84000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 01/0 : 4[3000] -> 9[44000] [send] via NET/IB/1
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 00/0 : 16[3000] -> 24[3000] [send] via NET/IB/1
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO Channel 03 : 18[84000] -> 17[44000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 02/0 : 32[3000] -> 36[3000] [send] via NET/IB/1
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO Connected all trees
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO Connected all rings
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO Channel 00 : 55[c4000] -> 54[84000] via P2P/IPC/read
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 01/0 : 32[3000] -> 0[3000] [receive] via NET/IB/1
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO Channel 01 : 61[44000] -> 60[3000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO Channel 03 : 31[c4000] -> 30[84000] via P2P/IPC/read
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO Channel 03 : 22[84000] -> 21[44000] via P2P/IPC/read
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO Channel 03 : 42[84000] -> 41[44000] via P2P/IPC/read
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO Channel 01 : 26[84000] -> 25[44000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 03/0 : 48[3000] -> 52[3000] [send] via NET/IB/1
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO Channel 01 : 50[84000] -> 49[44000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO Channel 03 : 51[c4000] -> 50[84000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO Connected all trees
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 03/0 : 32[3000] -> 36[3000] [send] via NET/IB/1
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 01/0 : 16[3000] -> 24[3000] [send] via NET/IB/1
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 00/0 : 0[3000] -> 32[3000] [send] via NET/IB/1
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 01/0 : 0[3000] -> 32[3000] [send] via NET/IB/1
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 03/0 : 48[3000] -> 52[3000] [receive] via NET/IB/1
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 00/0 : 8[3000] -> 17[44000] [send] via NET/IB/1
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO Channel 02 : 61[44000] -> 60[3000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO Channel 03 : 47[c4000] -> 46[84000] via P2P/IPC/read
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO Channel 02 : 46[84000] -> 45[44000] via P2P/IPC/read
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO Channel 02 : 30[84000] -> 29[44000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 00/0 : 20[3000] -> 25[44000] [send] via NET/IB/1
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 00/0 : 40[3000] -> 44[3000] [send] via NET/IB/1
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Channel 01/0 : 52[3000] -> 57[44000] [receive] via NET/IB/1
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO Channel 02 : 50[84000] -> 49[44000] via P2P/IPC/read
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Channel 02/0 : 40[3000] -> 37[44000] [receive] via NET/IB/1
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 02/0 : 4[3000] -> 12[3000] [send] via NET/IB/1
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO Connected all trees
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO Channel 01 : 55[c4000] -> 54[84000] via P2P/IPC/read
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO Channel 00 : 54[84000] -> 53[44000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 01/0 : 8[3000] -> 17[44000] [send] via NET/IB/1
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO Channel 03 : 30[84000] -> 29[44000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO Connected all trees
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 01/0 : 20[3000] -> 25[44000] [send] via NET/IB/1
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO Connected all trees
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 01/0 : 40[3000] -> 44[3000] [send] via NET/IB/1
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Channel 03/0 : 40[3000] -> 37[44000] [receive] via NET/IB/1
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 03/0 : 4[3000] -> 12[3000] [send] via NET/IB/1
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO Channel 02 : 26[84000] -> 25[44000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Channel 00/0 : 9[44000] -> 4[3000] [send] via NET/IB/1
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Channel 01/0 : 9[44000] -> 4[3000] [send] via NET/IB/1
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO Channel 03 : 46[84000] -> 45[44000] via P2P/IPC/read
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO Channel 03 : 61[44000] -> 60[3000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO Connected all trees
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 02/0 : 4[3000] -> 12[3000] [receive] via NET/IB/1
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 03/0 : 4[3000] -> 12[3000] [receive] via NET/IB/1
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Channel 02/0 : 24[3000] -> 21[44000] [receive] via NET/IB/1
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO Connected all rings
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO Channel 00 : 59[c4000] -> 58[84000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Connected all rings
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO Channel 03 : 50[84000] -> 49[44000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 00/0 : 24[3000] -> 28[3000] [send] via NET/IB/1
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO Channel 03 : 26[84000] -> 25[44000] via P2P/IPC/read
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO Channel 02 : 55[c4000] -> 54[84000] via P2P/IPC/read
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO Channel 01 : 54[84000] -> 53[44000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 00/0 : 32[3000] -> 48[3000] [send] via NET/IB/1
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO Connected all trees
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Connected all rings
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO Channel 01 : 59[c4000] -> 58[84000] via P2P/IPC/read
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO Channel 00 : 58[84000] -> 57[44000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 02/0 : 53[44000] -> 56[3000] [receive] via NET/IB/1
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 00/0 : 48[3000] -> 56[3000] [send] via NET/IB/1
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 01/0 : 24[3000] -> 28[3000] [send] via NET/IB/1
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO Channel 03 : 55[c4000] -> 54[84000] via P2P/IPC/read
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO Channel 02 : 54[84000] -> 53[44000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 00/0 : 17[44000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 01/0 : 32[3000] -> 48[3000] [send] via NET/IB/1
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO Connected all trees
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Channel 03/0 : 24[3000] -> 21[44000] [receive] via NET/IB/1
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 00/0 : 40[3000] -> 49[44000] [send] via NET/IB/1
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 03/0 : 53[44000] -> 56[3000] [receive] via NET/IB/1
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 01/0 : 48[3000] -> 56[3000] [send] via NET/IB/1
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO Connected all trees
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 00/0 : 36[3000] -> 41[44000] [send] via NET/IB/1
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO Connected all trees
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Channel 00/0 : 17[44000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 00/0 : 52[3000] -> 57[44000] [send] via NET/IB/1
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 00/0 : 56[3000] -> 60[3000] [receive] via NET/IB/1
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 02/0 : 13[44000] -> 20[3000] [receive] via NET/IB/1
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 01/0 : 40[3000] -> 49[44000] [send] via NET/IB/1
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 01/0 : 36[3000] -> 41[44000] [send] via NET/IB/1
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO Channel 02 : 59[c4000] -> 58[84000] via P2P/IPC/read
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO Channel 01 : 58[84000] -> 57[44000] via P2P/IPC/read
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Channel 00/0 : 25[44000] -> 20[3000] [send] via NET/IB/1
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 01/0 : 52[3000] -> 57[44000] [send] via NET/IB/1
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO Channel 03 : 54[84000] -> 53[44000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 02/0 : 36[3000] -> 44[3000] [receive] via NET/IB/1
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 01/0 : 56[3000] -> 60[3000] [receive] via NET/IB/1
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 01/0 : 17[44000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 02/0 : 12[3000] -> 4[3000] [receive] via NET/IB/1
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Channel 01/0 : 17[44000] -> 8[3000] [send] via NET/IB/1
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Channel 01/0 : 25[44000] -> 20[3000] [send] via NET/IB/1
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 02/0 : 12[3000] -> 28[3000] [send] via NET/IB/1
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 03/0 : 13[44000] -> 20[3000] [receive] via NET/IB/1
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO Channel 03 : 59[c4000] -> 58[84000] via P2P/IPC/read
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO Channel 02 : 58[84000] -> 57[44000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 03/0 : 12[3000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 00/0 : 16[3000] -> 24[3000] [receive] via NET/IB/1
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Channel 02/0 : 56[3000] -> 53[44000] [receive] via NET/IB/1
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO Connected all trees
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 02/0 : 12[3000] -> 28[3000] [receive] via NET/IB/1
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 03/0 : 12[3000] -> 28[3000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 03/0 : 36[3000] -> 44[3000] [receive] via NET/IB/1
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Channel 00/0 : 49[44000] -> 40[3000] [send] via NET/IB/1
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 02/0 : 36[3000] -> 44[3000] [send] via NET/IB/1
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 03/0 : 36[3000] -> 44[3000] [send] via NET/IB/1
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO Channel 03 : 58[84000] -> 57[44000] via P2P/IPC/read
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Channel 01/0 : 49[44000] -> 40[3000] [send] via NET/IB/1
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 00/0 : 49[44000] -> 40[3000] [receive] via NET/IB/1
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Channel 00/0 : 41[44000] -> 36[3000] [send] via NET/IB/1
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 02/0 : 45[44000] -> 52[3000] [receive] via NET/IB/1
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 01/0 : 16[3000] -> 24[3000] [receive] via NET/IB/1
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 03/0 : 12[3000] -> 28[3000] [receive] via NET/IB/1
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 02/0 : 20[3000] -> 13[44000] [send] via NET/IB/1
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 01/0 : 49[44000] -> 40[3000] [receive] via NET/IB/1
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Channel 01/0 : 41[44000] -> 36[3000] [send] via NET/IB/1
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Channel 00/0 : 57[44000] -> 52[3000] [send] via NET/IB/1
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Channel 03/0 : 56[3000] -> 53[44000] [receive] via NET/IB/1
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 03/0 : 45[44000] -> 52[3000] [receive] via NET/IB/1
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Channel 02/0 : 20[3000] -> 13[44000] [receive] via NET/IB/1
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 00/0 : 12[3000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 03/0 : 20[3000] -> 13[44000] [send] via NET/IB/1
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO Connected all trees
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 00/0 : 56[3000] -> 60[3000] [send] via NET/IB/1
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Channel 01/0 : 57[44000] -> 52[3000] [send] via NET/IB/1
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 01/0 : 12[3000] -> 8[3000] [receive] via NET/IB/1
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Channel 03/0 : 20[3000] -> 13[44000] [receive] via NET/IB/1
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 01/0 : 56[3000] -> 60[3000] [send] via NET/IB/1
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 02/0 : 44[3000] -> 36[3000] [receive] via NET/IB/1
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 00/0 : 16[3000] -> 33[44000] [send] via NET/IB/1
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 02/0 : 28[3000] -> 12[3000] [receive] via NET/IB/1
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 03/0 : 44[3000] -> 36[3000] [receive] via NET/IB/1
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 01/0 : 16[3000] -> 33[44000] [send] via NET/IB/1
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 00/0 : 24[3000] -> 16[3000] [send] via NET/IB/1
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 02/0 : 60[3000] -> 28[3000] [receive] via NET/IB/1
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 02/0 : 29[44000] -> 44[3000] [receive] via NET/IB/1
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Channel 02/0 : 52[3000] -> 45[44000] [receive] via NET/IB/1
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 00/0 : 44[3000] -> 40[3000] [receive] via NET/IB/1
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Channel 00 : 17[44000] -> 16[3000] via P2P/IPC/read
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Channel 01 : 17[44000] -> 16[3000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 02/0 : 52[3000] -> 45[44000] [send] via NET/IB/1
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 02/0 : 28[3000] -> 60[3000] [receive] via NET/IB/1
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 03/0 : 60[3000] -> 28[3000] [receive] via NET/IB/1
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 03/0 : 28[3000] -> 12[3000] [receive] via NET/IB/1
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 00/0 : 25[44000] -> 20[3000] [receive] via NET/IB/1
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 00/0 : 48[3000] -> 56[3000] [receive] via NET/IB/1
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 01/0 : 24[3000] -> 16[3000] [send] via NET/IB/1
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 03/0 : 52[3000] -> 45[44000] [send] via NET/IB/1
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 02/0 : 28[3000] -> 60[3000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 03/0 : 29[44000] -> 44[3000] [receive] via NET/IB/1
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 01/0 : 48[3000] -> 56[3000] [receive] via NET/IB/1
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 01/0 : 44[3000] -> 40[3000] [receive] via NET/IB/1
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Channel 02 : 17[44000] -> 16[3000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 03/0 : 28[3000] -> 60[3000] [send] via NET/IB/1
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Channel 03/0 : 52[3000] -> 45[44000] [receive] via NET/IB/1
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 03/0 : 28[3000] -> 60[3000] [receive] via NET/IB/1
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 02/0 : 60[3000] -> 28[3000] [send] via NET/IB/1
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 01/0 : 25[44000] -> 20[3000] [receive] via NET/IB/1
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 00/0 : 33[44000] -> 16[3000] [receive] via NET/IB/1
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Channel 00/0 : 33[44000] -> 16[3000] [send] via NET/IB/1
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Channel 00 : 49[44000] -> 48[3000] via P2P/IPC/read
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Channel 02/0 : 44[3000] -> 29[44000] [receive] via NET/IB/1
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 03/0 : 60[3000] -> 28[3000] [send] via NET/IB/1
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 01/0 : 33[44000] -> 16[3000] [receive] via NET/IB/1
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Channel 01/0 : 33[44000] -> 16[3000] [send] via NET/IB/1
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Channel 01 : 49[44000] -> 48[3000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 00/0 : 57[44000] -> 52[3000] [receive] via NET/IB/1
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 00/0 : 56[3000] -> 48[3000] [send] via NET/IB/1
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Channel 02 : 49[44000] -> 48[3000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 01/0 : 57[44000] -> 52[3000] [receive] via NET/IB/1
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Channel 03/0 : 44[3000] -> 29[44000] [receive] via NET/IB/1
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 02/0 : 44[3000] -> 29[44000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 03/0 : 44[3000] -> 29[44000] [send] via NET/IB/1
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 02/0 : 20[3000] -> 16[3000] [send] via NET/IB/1
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Channel 03/0 : 20[3000] -> 16[3000] [send] via NET/IB/1
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Channel 00 : 13[44000] -> 12[3000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 01/0 : 56[3000] -> 48[3000] [send] via NET/IB/1
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 02/0 : 28[3000] -> 12[3000] [send] via NET/IB/1
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 00/0 : 60[3000] -> 56[3000] [send] via NET/IB/1
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Channel 03 : 49[44000] -> 48[3000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 00/0 : 32[3000] -> 48[3000] [receive] via NET/IB/1
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 01/0 : 32[3000] -> 48[3000] [receive] via NET/IB/1
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Channel 03 : 17[44000] -> 16[3000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Channel 01/0 : 60[3000] -> 56[3000] [send] via NET/IB/1
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Channel 01 : 13[44000] -> 12[3000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 00/0 : 24[3000] -> 16[3000] [receive] via NET/IB/1
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO Connected all trees
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 03/0 : 28[3000] -> 12[3000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 02/0 : 44[3000] -> 36[3000] [send] via NET/IB/1
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Channel 02 : 13[44000] -> 12[3000] via P2P/IPC/read
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO Connected all trees
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Channel 00 : 25[44000] -> 24[3000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 02/0 : 52[3000] -> 48[3000] [send] via NET/IB/1
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Channel 03/0 : 52[3000] -> 48[3000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 03/0 : 44[3000] -> 36[3000] [send] via NET/IB/1
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 00/0 : 0[3000] -> 32[3000] [receive] via NET/IB/1
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Channel 03 : 13[44000] -> 12[3000] via P2P/IPC/read
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Channel 01 : 25[44000] -> 24[3000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 01/0 : 24[3000] -> 16[3000] [receive] via NET/IB/1
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 00/0 : 28[3000] -> 24[3000] [send] via NET/IB/1
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Channel 00 : 45[44000] -> 44[3000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO Connected all trees
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Channel 00 : 33[44000] -> 32[3000] via P2P/IPC/read
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Channel 02 : 25[44000] -> 24[3000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 00/0 : 48[3000] -> 32[3000] [send] via NET/IB/1
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Channel 01/0 : 28[3000] -> 24[3000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 00/0 : 44[3000] -> 40[3000] [send] via NET/IB/1
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Channel 01 : 45[44000] -> 44[3000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 01/0 : 0[3000] -> 32[3000] [receive] via NET/IB/1
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 02/0 : 12[3000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 01/0 : 48[3000] -> 32[3000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Channel 01/0 : 44[3000] -> 40[3000] [send] via NET/IB/1
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 03/0 : 12[3000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 00/0 : 32[3000] -> 0[3000] [send] via NET/IB/1
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Channel 01 : 33[44000] -> 32[3000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 00/0 : 28[3000] -> 24[3000] [receive] via NET/IB/1
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Channel 03 : 25[44000] -> 24[3000] via P2P/IPC/read
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 00/0 : 41[44000] -> 36[3000] [receive] via NET/IB/1
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Channel 02 : 45[44000] -> 44[3000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 01/0 : 32[3000] -> 0[3000] [send] via NET/IB/1
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Channel 02 : 33[44000] -> 32[3000] via P2P/IPC/read
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Channel 00 : 57[44000] -> 56[3000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 02/0 : 20[3000] -> 16[3000] [receive] via NET/IB/1
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Channel 00 : 29[44000] -> 28[3000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 01/0 : 28[3000] -> 24[3000] [receive] via NET/IB/1
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO Connected all trees
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 01/0 : 41[44000] -> 36[3000] [receive] via NET/IB/1
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Channel 03 : 45[44000] -> 44[3000] via P2P/IPC/read
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Channel 01 : 57[44000] -> 56[3000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 00/0 : 12[3000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Channel 01/0 : 12[3000] -> 8[3000] [send] via NET/IB/1
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Channel 03 : 33[44000] -> 32[3000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Channel 03/0 : 20[3000] -> 16[3000] [receive] via NET/IB/1
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Channel 01 : 29[44000] -> 28[3000] via P2P/IPC/read
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO Connected all trees
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Channel 02 : 57[44000] -> 56[3000] via P2P/IPC/read
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 02/0 : 40[3000] -> 37[44000] [send] via NET/IB/1
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO Connected all trees
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Channel 03/0 : 40[3000] -> 37[44000] [send] via NET/IB/1
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Channel 02 : 29[44000] -> 28[3000] via P2P/IPC/read
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Channel 03 : 57[44000] -> 56[3000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 00/0 : 9[44000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 02/0 : 8[3000] -> 5[44000] [send] via NET/IB/1
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 02/0 : 4[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 02/0 : 24[3000] -> 21[44000] [send] via NET/IB/1
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Channel 03 : 29[44000] -> 28[3000] via P2P/IPC/read
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Channel 03/0 : 4[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 02/0 : 36[3000] -> 32[3000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO Connected all trees
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO Connected all trees
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 00/0 : 48[3000] -> 32[3000] [receive] via NET/IB/1
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 01/0 : 9[44000] -> 4[3000] [receive] via NET/IB/1
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO Connected all trees
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Channel 03/0 : 24[3000] -> 21[44000] [send] via NET/IB/1
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Channel 03/0 : 8[3000] -> 5[44000] [send] via NET/IB/1
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO Connected all trees
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Channel 03/0 : 36[3000] -> 32[3000] [send] via NET/IB/1
[default3]:n2gpu1222:147028:147205 [3] NCCL INFO comm 0x150a7c0090d0 rank 47 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1222:147025:147200 [0] NCCL INFO comm 0x15503c0090d0 rank 44 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1222:147027:147198 [2] NCCL INFO comm 0x14fe680090d0 rank 46 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1222:147026:147203 [1] NCCL INFO comm 0x150fec0090d0 rank 45 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 01/0 : 48[3000] -> 32[3000] [receive] via NET/IB/1
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO Connected all trees
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO Connected all trees
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1210:144012:144175 [1] NCCL INFO comm 0x14f2040090d0 rank 29 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1210:144014:144179 [3] NCCL INFO comm 0x146a740090d0 rank 31 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1210:144013:144184 [2] NCCL INFO comm 0x1524a00090d0 rank 30 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1210:144011:144181 [0] NCCL INFO comm 0x151dd80090d0 rank 28 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO Connected all trees
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO Connected all trees
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 02/0 : 4[3000] -> 0[3000] [send] via NET/IB/1
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Channel 03/0 : 4[3000] -> 0[3000] [send] via NET/IB/1
[default1]:n2gpu1205:143298:143463 [1] NCCL INFO comm 0x1551400090d0 rank 13 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Channel 00 : 37[44000] -> 36[3000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143470 [2] NCCL INFO comm 0x14e5440090d0 rank 14 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1205:143297:143465 [0] NCCL INFO comm 0x14e1780090d0 rank 12 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1205:143300:143468 [3] NCCL INFO comm 0x1529080090d0 rank 15 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO Connected all trees
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO Connected all trees
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1206:143435:143599 [3] NCCL INFO comm 0x14691c0090d0 rank 19 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1206:143432:143603 [0] NCCL INFO comm 0x14da980090d0 rank 16 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1206:143434:143601 [2] NCCL INFO comm 0x14fb200090d0 rank 18 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1206:143433:143606 [1] NCCL INFO comm 0x1489480090d0 rank 17 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Channel 00 : 41[44000] -> 40[3000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 00/0 : 56[3000] -> 48[3000] [receive] via NET/IB/1
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Channel 01 : 37[44000] -> 36[3000] via P2P/IPC/read
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Channel 02 : 37[44000] -> 36[3000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 02/0 : 36[3000] -> 32[3000] [receive] via NET/IB/1
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 01/0 : 56[3000] -> 48[3000] [receive] via NET/IB/1
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Channel 01 : 41[44000] -> 40[3000] via P2P/IPC/read
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO Connected all trees
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO Connected all trees
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Channel 00 : 5[44000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1209:135998:136169 [1] NCCL INFO comm 0x1532d40090d0 rank 25 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1209:136000:136173 [3] NCCL INFO comm 0x1515280090d0 rank 27 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1209:135997:136166 [0] NCCL INFO comm 0x14acbc0090d0 rank 24 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1209:135999:136171 [2] NCCL INFO comm 0x1467340090d0 rank 26 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Channel 03 : 37[44000] -> 36[3000] via P2P/IPC/read
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Channel 02 : 41[44000] -> 40[3000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Channel 03/0 : 36[3000] -> 32[3000] [receive] via NET/IB/1
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Channel 00 : 9[44000] -> 8[3000] via P2P/IPC/read
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Channel 01 : 5[44000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Channel 00 : 21[44000] -> 20[3000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Channel 01 : 9[44000] -> 8[3000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 00/0 : 60[3000] -> 56[3000] [receive] via NET/IB/1
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO Connected all trees
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Channel 01 : 21[44000] -> 20[3000] via P2P/IPC/read
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Channel 02 : 5[44000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Channel 03 : 41[44000] -> 40[3000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 01/0 : 60[3000] -> 56[3000] [receive] via NET/IB/1
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO Connected all trees
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO Connected all trees
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO Connected all trees
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 02/0 : 52[3000] -> 48[3000] [receive] via NET/IB/1
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Channel 02 : 9[44000] -> 8[3000] via P2P/IPC/read
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Channel 03 : 5[44000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Channel 02 : 21[44000] -> 20[3000] via P2P/IPC/read
[default2]:n2gpu1221:160029:160202 [2] NCCL INFO comm 0x14cd040090d0 rank 42 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1221:160027:160204 [0] NCCL INFO comm 0x1454f00090d0 rank 40 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1221:160028:160198 [1] NCCL INFO comm 0x1491f00090d0 rank 41 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Channel 03 : 9[44000] -> 8[3000] via P2P/IPC/read
[default3]:n2gpu1221:160030:160206 [3] NCCL INFO comm 0x1488040090d0 rank 43 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO Connected all trees
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO Connected all trees
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO Connected all trees
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO Connected all trees
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO Connected all trees
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Channel 03 : 21[44000] -> 20[3000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Channel 03/0 : 52[3000] -> 48[3000] [receive] via NET/IB/1
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO Connected all trees
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 02/0 : 56[3000] -> 53[44000] [send] via NET/IB/1
[default2]:n2gpu1201:986609:986929 [2] NCCL INFO comm 0x14aeb00090d0 rank 2 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1201:986607:986923 [0] NCCL INFO comm 0x1471480090d0 rank 0 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:986607:986607 [0] NCCL INFO Launch mode Parallel
[default1]:n2gpu1201:986608:986932 [1] NCCL INFO comm 0x14808c0090d0 rank 1 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1201:986610:986926 [3] NCCL INFO comm 0x14eaa00090d0 rank 3 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO Connected all trees
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1202:1130096:1130267 [3] NCCL INFO comm 0x14daac0090d0 rank 7 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1202:1130095:1130259 [2] NCCL INFO comm 0x152c100090d0 rank 6 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1202:1130093:1130265 [0] NCCL INFO comm 0x1538080090d0 rank 4 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1202:1130094:1130262 [1] NCCL INFO comm 0x14913c0090d0 rank 5 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO Connected all trees
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Channel 03/0 : 56[3000] -> 53[44000] [send] via NET/IB/1
[default2]:n2gpu1204:138138:138319 [2] NCCL INFO comm 0x1491740090d0 rank 10 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO Connected all trees
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO Connected all trees
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO Connected all trees
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO Connected all trees
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1204:138139:138317 [3] NCCL INFO comm 0x150e840090d0 rank 11 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1204:138136:138311 [0] NCCL INFO comm 0x14ed940090d0 rank 8 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1204:138137:138313 [1] NCCL INFO comm 0x1500240090d0 rank 9 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO Connected all trees
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO Connected all trees
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO Connected all trees
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1207:144620:144791 [2] NCCL INFO comm 0x14e0f00090d0 rank 22 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1207:144621:144789 [3] NCCL INFO comm 0x1456000090d0 rank 23 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1207:144619:144796 [1] NCCL INFO comm 0x1546580090d0 rank 21 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1207:144618:144794 [0] NCCL INFO comm 0x149f800090d0 rank 20 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1220:386662:386833 [2] NCCL INFO comm 0x1547800090d0 rank 38 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1220:386663:386827 [3] NCCL INFO comm 0x14b1cc0090d0 rank 39 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1220:386661:386831 [1] NCCL INFO comm 0x14feb80090d0 rank 37 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1220:386660:386835 [0] NCCL INFO comm 0x1514040090d0 rank 36 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1219:266888:267055 [0] NCCL INFO comm 0x14e6c00090d0 rank 32 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1219:266890:267060 [2] NCCL INFO comm 0x14928c0090d0 rank 34 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1219:266891:267062 [3] NCCL INFO comm 0x14fdd40090d0 rank 35 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1219:266889:267064 [1] NCCL INFO comm 0x145d280090d0 rank 33 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO Connected all trees
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO Connected all trees
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1230:125963:126139 [1] NCCL INFO comm 0x148b180090d0 rank 61 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1230:125964:126134 [2] NCCL INFO comm 0x14f6080090d0 rank 62 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1230:125962:126132 [0] NCCL INFO comm 0x150d800090d0 rank 60 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1230:125965:126136 [3] NCCL INFO comm 0x14dcd40090d0 rank 63 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO Connected all trees
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO Connected all trees
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO Connected all trees
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO Connected all trees
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1224:124660:124831 [1] NCCL INFO comm 0x14f4400090d0 rank 49 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1224:124659:124834 [0] NCCL INFO comm 0x14964c0090d0 rank 48 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1224:124661:124829 [2] NCCL INFO comm 0x1520900090d0 rank 50 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1224:124662:124836 [3] NCCL INFO comm 0x14cba00090d0 rank 51 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default3]:n2gpu1229:174607:174777 [3] NCCL INFO comm 0x14c4dc0090d0 rank 59 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1229:174606:174774 [2] NCCL INFO comm 0x1482600090d0 rank 58 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1229:174604:174779 [0] NCCL INFO comm 0x1535d40090d0 rank 56 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1229:174605:174772 [1] NCCL INFO comm 0x153a0c0090d0 rank 57 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Channel 00 : 53[44000] -> 52[3000] via P2P/IPC/read
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Channel 01 : 53[44000] -> 52[3000] via P2P/IPC/read
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Channel 02 : 53[44000] -> 52[3000] via P2P/IPC/read
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Channel 03 : 53[44000] -> 52[3000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO Connected all trees
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO Connected all trees
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1227:190532:190702 [3] NCCL INFO comm 0x147d240090d0 rank 55 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1227:190529:190705 [0] NCCL INFO comm 0x14785c0090d0 rank 52 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1227:190530:190698 [1] NCCL INFO comm 0x14ef4c0090d0 rank 53 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1227:190531:190700 [2] NCCL INFO comm 0x149e0c0090d0 rank 54 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:>>> done with compiling and loading fused kernels. Compilation time: 36.354 seconds
[default0]:time to initialize megatron (seconds): 53.546
[default0]:[after megatron is initialized] datetime: 2023-04-24 08:05:41 
[default0]:building GPT model ...
[default0]:[2023-04-24 08:05:41,680] [INFO] [utils.py:785:see_memory_usage] Before Building Model
[default0]:[2023-04-24 08:05:41,681] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-04-24 08:05:41,681] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 16.5 GB, percent = 3.3%
[default0]:[2023-04-24 08:05:42,473] [INFO] [utils.py:785:see_memory_usage] After Building Model
[default0]:[2023-04-24 08:05:42,474] [INFO] [utils.py:786:see_memory_usage] MA 19.14 GB         Max_MA 19.14 GB         CA 19.14 GB         Max_CA 19 GB 
[default0]:[2023-04-24 08:05:42,474] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 16.6 GB, percent = 3.3%
[default0]: > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 10279239680
[default0]:setting training iterations to 15625
[default0]:> learning rate decay style: cosine
[default0]:DeepSpeed is enabled.
[default0]:[2023-04-24 08:05:42,479] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.0, git-hash=unknown, git-branch=unknown
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO Trees [0] 47/-1/-1->46->45 [1] 47/-1/-1->46->45 [2] 47/-1/-1->46->45 [3] 47/-1/-1->46->45
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Trees [0] 46/-1/-1->45->44 [1] 46/-1/-1->45->44 [2] 46/52/-1->45->44 [3] 46/52/-1->45->44
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO Trees [0] -1/-1/-1->47->46 [1] -1/-1/-1->47->46 [2] -1/-1/-1->47->46 [3] -1/-1/-1->47->46
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Trees [0] 49/56/-1->48->32 [1] 49/56/-1->48->32 [2] 49/-1/-1->48->52 [3] 49/-1/-1->48->52
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Trees [0] 50/40/-1->49->48 [1] 50/40/-1->49->48 [2] 50/-1/-1->49->48 [3] 50/-1/-1->49->48
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 00/0 : 47[c4000] -> 48[3000] [receive] via NET/IB/0
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO Trees [0] 51/-1/-1->50->49 [1] 51/-1/-1->50->49 [2] 51/-1/-1->50->49 [3] 51/-1/-1->50->49
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Trees [0] 22/-1/-1->21->20 [1] 22/-1/-1->21->20 [2] 22/24/-1->21->20 [3] 22/24/-1->21->20
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Trees [0] 21/-1/-1->20->25 [1] 21/-1/-1->20->25 [2] 21/16/-1->20->13 [3] 21/16/-1->20->13
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO Trees [0] 23/-1/-1->22->21 [1] 23/-1/-1->22->21 [2] 23/-1/-1->22->21 [3] 23/-1/-1->22->21
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Trees [0] 54/-1/-1->53->52 [1] 54/-1/-1->53->52 [2] 54/56/-1->53->52 [3] 54/56/-1->53->52
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Trees [0] 53/-1/-1->52->57 [1] 53/-1/-1->52->57 [2] 53/48/-1->52->45 [3] 53/48/-1->52->45
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO Trees [0] -1/-1/-1->51->50 [1] -1/-1/-1->51->50 [2] -1/-1/-1->51->50 [3] -1/-1/-1->51->50
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 00/0 : 19[c4000] -> 20[3000] [receive] via NET/IB/0
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO Trees [0] -1/-1/-1->23->22 [1] -1/-1/-1->23->22 [2] -1/-1/-1->23->22 [3] -1/-1/-1->23->22
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 00/0 : 51[c4000] -> 52[3000] [receive] via NET/IB/0
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 01/0 : 47[c4000] -> 48[3000] [receive] via NET/IB/0
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Trees [0] 26/20/-1->25->24 [1] 26/20/-1->25->24 [2] 26/-1/-1->25->24 [3] 26/-1/-1->25->24
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO Trees [0] 27/-1/-1->26->25 [1] 27/-1/-1->26->25 [2] 27/-1/-1->26->25 [3] 27/-1/-1->26->25
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Trees [0] 25/28/-1->24->16 [1] 25/28/-1->24->16 [2] 25/-1/-1->24->21 [3] 25/-1/-1->24->21
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO Trees [0] 55/-1/-1->54->53 [1] 55/-1/-1->54->53 [2] 55/-1/-1->54->53 [3] 55/-1/-1->54->53
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO Trees [0] -1/-1/-1->55->54 [1] -1/-1/-1->55->54 [2] -1/-1/-1->55->54 [3] -1/-1/-1->55->54
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 02/0 : 47[c4000] -> 48[3000] [receive] via NET/IB/0
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO Trees [0] -1/-1/-1->27->26 [1] -1/-1/-1->27->26 [2] -1/-1/-1->27->26 [3] -1/-1/-1->27->26
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 00/0 : 23[c4000] -> 24[3000] [receive] via NET/IB/0
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Trees [0] 29/-1/-1->28->24 [1] 29/-1/-1->28->24 [2] 29/12/-1->28->60 [3] 29/12/-1->28->60
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 01/0 : 19[c4000] -> 20[3000] [receive] via NET/IB/0
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Trees [0] 57/60/-1->56->48 [1] 57/60/-1->56->48 [2] 57/-1/-1->56->53 [3] 57/-1/-1->56->53
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Trees [0] 30/-1/-1->29->28 [1] 30/-1/-1->29->28 [2] 30/44/-1->29->28 [3] 30/44/-1->29->28
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 01/0 : 51[c4000] -> 52[3000] [receive] via NET/IB/0
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 03/0 : 47[c4000] -> 48[3000] [receive] via NET/IB/0
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 00 : 48[3000] -> 49[44000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 00/0 : 27[c4000] -> 28[3000] [receive] via NET/IB/0
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Channel 00 : 45[44000] -> 46[84000] via P2P/IPC/read
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO Channel 00 : 46[84000] -> 47[c4000] via P2P/IPC/read
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Trees [0] 58/52/-1->57->56 [1] 58/52/-1->57->56 [2] 58/-1/-1->57->56 [3] 58/-1/-1->57->56
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 00/0 : 55[c4000] -> 56[3000] [receive] via NET/IB/0
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO Trees [0] -1/-1/-1->31->30 [1] -1/-1/-1->31->30 [2] -1/-1/-1->31->30 [3] -1/-1/-1->31->30
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 01/0 : 23[c4000] -> 24[3000] [receive] via NET/IB/0
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Channel 00 : 49[44000] -> 50[84000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Trees [0] 33/48/-1->32->0 [1] 33/48/-1->32->0 [2] 33/-1/-1->32->36 [3] 33/-1/-1->32->36
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Trees [0] 34/16/-1->33->32 [1] 34/16/-1->33->32 [2] 34/-1/-1->33->32 [3] 34/-1/-1->33->32
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Channel 01 : 45[44000] -> 46[84000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 02/0 : 19[c4000] -> 20[3000] [receive] via NET/IB/0
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 01/0 : 27[c4000] -> 28[3000] [receive] via NET/IB/0
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO Channel 00/0 : 47[c4000] -> 48[3000] [send] via NET/IB/0
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO Trees [0] 59/-1/-1->58->57 [1] 59/-1/-1->58->57 [2] 59/-1/-1->58->57 [3] 59/-1/-1->58->57
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO Trees [0] -1/-1/-1->59->58 [1] -1/-1/-1->59->58 [2] -1/-1/-1->59->58 [3] -1/-1/-1->59->58
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 02/0 : 51[c4000] -> 52[3000] [receive] via NET/IB/0
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO Trees [0] 62/-1/-1->61->60 [1] 62/-1/-1->61->60 [2] 62/-1/-1->61->60 [3] 62/-1/-1->61->60
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 01 : 48[3000] -> 49[44000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Channel 00 : 21[44000] -> 22[84000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 03/0 : 19[c4000] -> 20[3000] [receive] via NET/IB/0
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 00 : 20[3000] -> 21[44000] via P2P/IPC/read
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO Trees [0] 35/-1/-1->34->33 [1] 35/-1/-1->34->33 [2] 35/-1/-1->34->33 [3] 35/-1/-1->34->33
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Channel 02 : 45[44000] -> 46[84000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Trees [0] 61/-1/-1->60->56 [1] 61/-1/-1->60->56 [2] 61/28/-1->60->-1 [3] 61/28/-1->60->-1
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO Channel 01 : 46[84000] -> 47[c4000] via P2P/IPC/read
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO Channel 02 : 46[84000] -> 47[c4000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO Channel 01/0 : 47[c4000] -> 48[3000] [send] via NET/IB/0
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Channel 00 : 53[44000] -> 54[84000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 02 : 48[3000] -> 49[44000] via P2P/IPC/read
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Channel 01 : 49[44000] -> 50[84000] via P2P/IPC/read
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO Channel 00 : 50[84000] -> 51[c4000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 00/0 : 31[c4000] -> 32[3000] [receive] via NET/IB/0
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 02/0 : 23[c4000] -> 24[3000] [receive] via NET/IB/0
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Trees [0] 38/-1/-1->37->36 [1] 38/-1/-1->37->36 [2] 38/40/-1->37->36 [3] 38/40/-1->37->36
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Trees [0] 37/-1/-1->36->41 [1] 37/-1/-1->36->41 [2] 37/32/-1->36->44 [3] 37/32/-1->36->44
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 02/0 : 27[c4000] -> 28[3000] [receive] via NET/IB/0
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO Trees [0] -1/-1/-1->35->34 [1] -1/-1/-1->35->34 [2] -1/-1/-1->35->34 [3] -1/-1/-1->35->34
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO Channel 02/0 : 47[c4000] -> 48[3000] [send] via NET/IB/0
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 01/0 : 55[c4000] -> 56[3000] [receive] via NET/IB/0
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 00/0 : 59[c4000] -> 60[3000] [receive] via NET/IB/0
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO Trees [0] -1/-1/-1->63->62 [1] -1/-1/-1->63->62 [2] -1/-1/-1->63->62 [3] -1/-1/-1->63->62
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO Channel 00 : 22[84000] -> 23[c4000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 03/0 : 51[c4000] -> 52[3000] [receive] via NET/IB/0
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 00 : 52[3000] -> 53[44000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO Channel 00/0 : 51[c4000] -> 52[3000] [send] via NET/IB/0
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 03 : 48[3000] -> 49[44000] via P2P/IPC/read
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Channel 02 : 49[44000] -> 50[84000] via P2P/IPC/read
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO Channel 01 : 50[84000] -> 51[c4000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 01/0 : 31[c4000] -> 32[3000] [receive] via NET/IB/0
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Channel 00 : 25[44000] -> 26[84000] via P2P/IPC/read
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Trees [0] 42/36/-1->41->40 [1] 42/36/-1->41->40 [2] 42/-1/-1->41->40 [3] 42/-1/-1->41->40
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Trees [0] 41/44/-1->40->49 [1] 41/44/-1->40->49 [2] 41/-1/-1->40->37 [3] 41/-1/-1->40->37
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO Trees [0] 43/-1/-1->42->41 [1] 43/-1/-1->42->41 [2] 43/-1/-1->42->41 [3] 43/-1/-1->42->41
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO Trees [0] 39/-1/-1->38->37 [1] 39/-1/-1->38->37 [2] 39/-1/-1->38->37 [3] 39/-1/-1->38->37
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO Trees [0] -1/-1/-1->39->38 [1] -1/-1/-1->39->38 [2] -1/-1/-1->39->38 [3] -1/-1/-1->39->38
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 00/0 : 35[c4000] -> 36[3000] [receive] via NET/IB/0
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Channel 03 : 45[44000] -> 46[84000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Channel 01 : 21[44000] -> 22[84000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 01 : 20[3000] -> 21[44000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO Channel 03/0 : 47[c4000] -> 48[3000] [send] via NET/IB/0
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 02/0 : 55[c4000] -> 56[3000] [receive] via NET/IB/0
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO Channel 01 : 22[84000] -> 23[c4000] via P2P/IPC/read
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Channel 01 : 53[44000] -> 54[84000] via P2P/IPC/read
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO Channel 00/0 : 55[c4000] -> 56[3000] [send] via NET/IB/0
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO Channel 01/0 : 55[c4000] -> 56[3000] [send] via NET/IB/0
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO Channel 01/0 : 51[c4000] -> 52[3000] [send] via NET/IB/0
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 01/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 03/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Trees [0] 1/32/-1->0->-1 [1] 1/32/-1->0->-1 [2] 1/-1/-1->0->4 [3] 1/-1/-1->0->4
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 03/0 : 23[c4000] -> 24[3000] [receive] via NET/IB/0
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 00 : 24[3000] -> 25[44000] via P2P/IPC/read
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO Channel 00 : 54[84000] -> 55[c4000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Trees [0] 45/-1/-1->44->40 [1] 45/-1/-1->44->40 [2] 45/36/-1->44->29 [3] 45/36/-1->44->29
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 03/0 : 27[c4000] -> 28[3000] [receive] via NET/IB/0
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 00 : 28[3000] -> 29[44000] via P2P/IPC/read
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO Channel 03 : 46[84000] -> 47[c4000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO Channel 00/0 : 23[c4000] -> 24[3000] [send] via NET/IB/0
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO Channel 00 : 30[84000] -> 31[c4000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 01/0 : 59[c4000] -> 60[3000] [receive] via NET/IB/0
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Channel 02 : 53[44000] -> 54[84000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 01 : 52[3000] -> 53[44000] via P2P/IPC/read
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO Channel 02/0 : 55[c4000] -> 56[3000] [send] via NET/IB/0
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO Channel 02 : 22[84000] -> 23[c4000] via P2P/IPC/read
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Channel 01 : 25[44000] -> 26[84000] via P2P/IPC/read
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO Channel 00 : 26[84000] -> 27[c4000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 01 : 24[3000] -> 25[44000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO Channel 02/0 : 51[c4000] -> 52[3000] [send] via NET/IB/0
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Channel 03 : 49[44000] -> 50[84000] via P2P/IPC/read
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO Channel 02 : 50[84000] -> 51[c4000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 02/0 : 31[c4000] -> 32[3000] [receive] via NET/IB/0
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 00/0 : 63[c4000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 00/0 : 39[c4000] -> 40[3000] [receive] via NET/IB/0
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO Trees [0] -1/-1/-1->43->42 [1] -1/-1/-1->43->42 [2] -1/-1/-1->43->42 [3] -1/-1/-1->43->42
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 01/0 : 35[c4000] -> 36[3000] [receive] via NET/IB/0
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Channel 02 : 21[44000] -> 22[84000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 02 : 20[3000] -> 21[44000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO Channel 01/0 : 23[c4000] -> 24[3000] [send] via NET/IB/0
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO Connected all rings
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/8/-1->5->4 [3] 6/8/-1->5->4
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Trees [0] 5/-1/-1->4->9 [1] 5/-1/-1->4->9 [2] 5/0/-1->4->12 [3] 5/0/-1->4->12
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 03/0 : 55[c4000] -> 56[3000] [receive] via NET/IB/0
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 00 : 56[3000] -> 57[44000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 02 : 52[3000] -> 53[44000] via P2P/IPC/read
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO Channel 03/0 : 55[c4000] -> 56[3000] [send] via NET/IB/0
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Channel 00 : 29[44000] -> 30[84000] via P2P/IPC/read
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO Channel 00 : 61[44000] -> 62[84000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO Channel 03/0 : 51[c4000] -> 52[3000] [send] via NET/IB/0
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO Channel 03 : 50[84000] -> 51[c4000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 03/0 : 31[c4000] -> 32[3000] [receive] via NET/IB/0
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 00 : 32[3000] -> 33[44000] via P2P/IPC/read
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO Channel 00/0 : 27[c4000] -> 28[3000] [send] via NET/IB/0
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO Channel 01 : 26[84000] -> 27[c4000] via P2P/IPC/read
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 01/0 : 63[c4000] -> 0[3000] [receive] via NET/IB/0
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO Channel 01 : 54[84000] -> 55[c4000] via P2P/IPC/read
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Channel 00 : 33[44000] -> 34[84000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 01 : 28[3000] -> 29[44000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Channel 03 : 21[44000] -> 22[84000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 03 : 20[3000] -> 21[44000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO Channel 02/0 : 23[c4000] -> 24[3000] [send] via NET/IB/0
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO Channel 01 : 30[84000] -> 31[c4000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 00/0 : 43[c4000] -> 44[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 00/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO Channel 00 : 58[84000] -> 59[c4000] via P2P/IPC/read
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Channel 00 : 57[44000] -> 58[84000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 02/0 : 59[c4000] -> 60[3000] [receive] via NET/IB/0
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Channel 03 : 53[44000] -> 54[84000] via P2P/IPC/read
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO Channel 03 : 22[84000] -> 23[c4000] via P2P/IPC/read
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Channel 01 : 29[44000] -> 30[84000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO Channel 00/0 : 31[c4000] -> 32[3000] [send] via NET/IB/0
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO Channel 01/0 : 27[c4000] -> 28[3000] [send] via NET/IB/0
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO Channel 02/0 : 27[c4000] -> 28[3000] [send] via NET/IB/0
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Channel 02 : 25[44000] -> 26[84000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 02 : 24[3000] -> 25[44000] via P2P/IPC/read
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 01/0 : 39[c4000] -> 40[3000] [receive] via NET/IB/0
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO Channel 03/0 : 23[c4000] -> 24[3000] [send] via NET/IB/0
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO Channel 02 : 30[84000] -> 31[c4000] via P2P/IPC/read
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 02/0 : 35[c4000] -> 36[3000] [receive] via NET/IB/0
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 01 : 56[3000] -> 57[44000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 01/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 03/0 : 59[c4000] -> 60[3000] [receive] via NET/IB/0
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 00 : 60[3000] -> 61[44000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 03 : 52[3000] -> 53[44000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO Channel 01/0 : 31[c4000] -> 32[3000] [send] via NET/IB/0
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO Connected all rings
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Trees [0] 9/12/-1->8->17 [1] 9/12/-1->8->17 [2] 9/-1/-1->8->5 [3] 9/-1/-1->8->5
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Trees [0] 10/4/-1->9->8 [1] 10/4/-1->9->8 [2] 10/-1/-1->9->8 [3] 10/-1/-1->9->8
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO Channel 01 : 61[44000] -> 62[84000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 01 : 32[3000] -> 33[44000] via P2P/IPC/read
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO Channel 03/0 : 27[c4000] -> 28[3000] [send] via NET/IB/0
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Channel 03 : 25[44000] -> 26[84000] via P2P/IPC/read
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO Channel 02 : 26[84000] -> 27[c4000] via P2P/IPC/read
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO Channel 02 : 54[84000] -> 55[c4000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 02 : 28[3000] -> 29[44000] via P2P/IPC/read
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 02/0 : 63[c4000] -> 0[3000] [receive] via NET/IB/0
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Channel 01 : 33[44000] -> 34[84000] via P2P/IPC/read
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO Channel 00/0 : 35[c4000] -> 36[3000] [send] via NET/IB/0
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO Channel 00 : 34[84000] -> 35[c4000] via P2P/IPC/read
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Channel 00 : 37[44000] -> 38[84000] via P2P/IPC/read
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 03/0 : 35[c4000] -> 36[3000] [receive] via NET/IB/0
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 00 : 36[3000] -> 37[44000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 01/0 : 43[c4000] -> 44[3000] [receive] via NET/IB/0
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO Channel 03 : 30[84000] -> 31[c4000] via P2P/IPC/read
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO Channel 01 : 58[84000] -> 59[c4000] via P2P/IPC/read
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO Channel 00/0 : 59[c4000] -> 60[3000] [send] via NET/IB/0
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Channel 01 : 57[44000] -> 58[84000] via P2P/IPC/read
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO Channel 00 : 62[84000] -> 63[c4000] via P2P/IPC/read
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO Channel 00 : 1[44000] -> 2[84000] via P2P/IPC/read
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO Connected all rings
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Channel 02 : 29[44000] -> 30[84000] via P2P/IPC/read
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Connected all rings
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10 [2] -1/-1/-1->11->10 [3] -1/-1/-1->11->10
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9 [2] 11/-1/-1->10->9 [3] 11/-1/-1->10->9
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 03 : 24[3000] -> 25[44000] via P2P/IPC/read
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO Channel 03 : 54[84000] -> 55[c4000] via P2P/IPC/read
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO Channel 01/0 : 35[c4000] -> 36[3000] [send] via NET/IB/0
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO Channel 01 : 34[84000] -> 35[c4000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 02/0 : 43[c4000] -> 44[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/-1/-1->12->8 [2] 13/4/-1->12->28 [3] 13/4/-1->12->28
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12 [2] 14/20/-1->13->12 [3] 14/20/-1->13->12
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 03/0 : 63[c4000] -> 0[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 00 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Connected all rings
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 02/0 : 39[c4000] -> 40[3000] [receive] via NET/IB/0
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO Channel 00 : 38[84000] -> 39[c4000] via P2P/IPC/read
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO Channel 01 : 38[84000] -> 39[c4000] via P2P/IPC/read
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Channel 01 : 37[44000] -> 38[84000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 02/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO Channel 01/0 : 59[c4000] -> 60[3000] [send] via NET/IB/0
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO Channel 02/0 : 59[c4000] -> 60[3000] [send] via NET/IB/0
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 02 : 56[3000] -> 57[44000] via P2P/IPC/read
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO Channel 01 : 62[84000] -> 63[c4000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 01 : 60[3000] -> 61[44000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO Channel 00/0 : 63[c4000] -> 0[3000] [send] via NET/IB/0
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO Channel 02/0 : 31[c4000] -> 32[3000] [send] via NET/IB/0
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO Channel 02 : 61[44000] -> 62[84000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 00/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 03 : 28[3000] -> 29[44000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 02 : 32[3000] -> 33[44000] via P2P/IPC/read
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO Channel 03 : 26[84000] -> 27[c4000] via P2P/IPC/read
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO Channel 00 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 01 : 0[3000] -> 1[44000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Channel 02/0 : 21[44000] -> 24[3000] [send] via NET/IB/1
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Channel 02 : 33[44000] -> 34[84000] via P2P/IPC/read
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Channel 03 : 33[44000] -> 34[84000] via P2P/IPC/read
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO Channel 02/0 : 35[c4000] -> 36[3000] [send] via NET/IB/0
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Channel 00 : 41[44000] -> 42[84000] via P2P/IPC/read
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 03/0 : 39[c4000] -> 40[3000] [receive] via NET/IB/0
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 00 : 40[3000] -> 41[44000] via P2P/IPC/read
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO Channel 00 : 42[84000] -> 43[c4000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 03/0 : 3[c4000] -> 4[3000] [receive] via NET/IB/0
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 00 : 4[3000] -> 5[44000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO Channel 00/0 : 39[c4000] -> 40[3000] [send] via NET/IB/0
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 01 : 36[3000] -> 37[44000] via P2P/IPC/read
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO Channel 02 : 58[84000] -> 59[c4000] via P2P/IPC/read
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Channel 02 : 57[44000] -> 58[84000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 02 : 60[3000] -> 61[44000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO Channel 01/0 : 63[c4000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Channel 03 : 29[44000] -> 30[84000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO Channel 03/0 : 31[c4000] -> 32[3000] [send] via NET/IB/0
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Channel 00/0 : 40[3000] -> 49[44000] [receive] via NET/IB/1
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO Channel 01 : 1[44000] -> 2[84000] via P2P/IPC/read
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO Channel 03 : 61[44000] -> 62[84000] via P2P/IPC/read
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Connected all rings
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO Connected all rings
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 01/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 03 : 32[3000] -> 33[44000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 03/0 : 43[c4000] -> 44[3000] [receive] via NET/IB/0
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 00 : 44[3000] -> 45[44000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 00/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13 [2] 15/-1/-1->14->13 [3] 15/-1/-1->14->13
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Channel 03/0 : 21[44000] -> 24[3000] [send] via NET/IB/1
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO Channel 01 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO Connected all rings
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO Channel 03/0 : 35[c4000] -> 36[3000] [send] via NET/IB/0
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO Channel 02 : 34[84000] -> 35[c4000] via P2P/IPC/read
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Channel 01 : 41[44000] -> 42[84000] via P2P/IPC/read
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO Channel 01 : 42[84000] -> 43[c4000] via P2P/IPC/read
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO Channel 02 : 38[84000] -> 39[c4000] via P2P/IPC/read
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Channel 02 : 37[44000] -> 38[84000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO Channel 01/0 : 39[c4000] -> 40[3000] [send] via NET/IB/0
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 01 : 4[3000] -> 5[44000] via P2P/IPC/read
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO Channel 03 : 58[84000] -> 59[c4000] via P2P/IPC/read
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO Channel 03/0 : 59[c4000] -> 60[3000] [send] via NET/IB/0
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Channel 03 : 57[44000] -> 58[84000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 03 : 56[3000] -> 57[44000] via P2P/IPC/read
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO Channel 02 : 62[84000] -> 63[c4000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO Channel 02/0 : 63[c4000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Connected all rings
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Connected all rings
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14 [2] -1/-1/-1->15->14 [3] -1/-1/-1->15->14
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Trees [0] 17/24/-1->16->33 [1] 17/24/-1->16->33 [2] 17/-1/-1->16->20 [3] 17/-1/-1->16->20
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Trees [0] 18/8/-1->17->16 [1] 18/8/-1->17->16 [2] 18/-1/-1->17->16 [3] 18/-1/-1->17->16
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO Connected all rings
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO Channel 00 : 47[c4000] -> 46[84000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 01/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 01 : 40[3000] -> 41[44000] via P2P/IPC/read
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO Channel 00/0 : 43[c4000] -> 44[3000] [send] via NET/IB/0
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Channel 00 : 5[44000] -> 6[84000] via P2P/IPC/read
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO Channel 00/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 02 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO Connected all rings
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO Channel 03 : 38[84000] -> 39[c4000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO Channel 02/0 : 39[c4000] -> 40[3000] [send] via NET/IB/0
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 02 : 36[3000] -> 37[44000] via P2P/IPC/read
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 03 : 36[3000] -> 37[44000] via P2P/IPC/read
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO Channel 03 : 62[84000] -> 63[c4000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 03 : 60[3000] -> 61[44000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO Channel 03/0 : 63[c4000] -> 0[3000] [send] via NET/IB/0
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Connected all rings
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 02/0 : 48[3000] -> 52[3000] [send] via NET/IB/1
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Channel 01/0 : 40[3000] -> 49[44000] [receive] via NET/IB/1
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 00/0 : 15[c4000] -> 16[3000] [receive] via NET/IB/0
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO Trees [0] -1/-1/-1->19->18 [1] -1/-1/-1->19->18 [2] -1/-1/-1->19->18 [3] -1/-1/-1->19->18
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO Channel 00 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO Channel 02 : 1[44000] -> 2[84000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 02/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO Channel 03 : 34[84000] -> 35[c4000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 01 : 44[3000] -> 45[44000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 02 : 44[3000] -> 45[44000] via P2P/IPC/read
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO Channel 00 : 46[84000] -> 45[44000] via P2P/IPC/read
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO Trees [0] 19/-1/-1->18->17 [1] 19/-1/-1->18->17 [2] 19/-1/-1->18->17 [3] 19/-1/-1->18->17
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Channel 02 : 41[44000] -> 42[84000] via P2P/IPC/read
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 02 : 40[3000] -> 41[44000] via P2P/IPC/read
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO Channel 02 : 42[84000] -> 43[c4000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 02 : 4[3000] -> 5[44000] via P2P/IPC/read
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO Channel 02 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO Channel 01/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO Channel 02/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO Connected all rings
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Channel 02/0 : 53[44000] -> 56[3000] [send] via NET/IB/1
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Channel 03/0 : 53[44000] -> 56[3000] [send] via NET/IB/1
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO Connected all rings
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Channel 03 : 37[44000] -> 38[84000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO Channel 03/0 : 39[c4000] -> 40[3000] [send] via NET/IB/0
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO Connected all rings
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO Channel 00 : 51[c4000] -> 50[84000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 03/0 : 48[3000] -> 52[3000] [send] via NET/IB/1
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Channel 02/0 : 29[44000] -> 44[3000] [send] via NET/IB/1
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Channel 00/0 : 20[3000] -> 25[44000] [receive] via NET/IB/1
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO Channel 03 : 1[44000] -> 2[84000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Channel 00 : 9[44000] -> 10[84000] via P2P/IPC/read
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO Channel 01 : 46[84000] -> 45[44000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO Channel 01 : 47[c4000] -> 46[84000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 02/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 03 : 0[3000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO Channel 03 : 2[84000] -> 3[c4000] via P2P/IPC/read
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO Channel 03 : 42[84000] -> 43[c4000] via P2P/IPC/read
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO Channel 01/0 : 43[c4000] -> 44[3000] [send] via NET/IB/0
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO Channel 02/0 : 43[c4000] -> 44[3000] [send] via NET/IB/0
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Channel 01 : 5[44000] -> 6[84000] via P2P/IPC/read
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Connected all rings
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Connected all rings
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Channel 03/0 : 29[44000] -> 44[3000] [send] via NET/IB/1
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO Channel 01 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO Connected all rings
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 01/0 : 15[c4000] -> 16[3000] [receive] via NET/IB/0
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Connected all rings
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO Connected all rings
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO Channel 00/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 03/0 : 7[c4000] -> 8[3000] [receive] via NET/IB/0
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 00 : 8[3000] -> 9[44000] via P2P/IPC/read
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO Channel 00 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO Channel 03/0 : 3[c4000] -> 4[3000] [send] via NET/IB/0
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Channel 03 : 41[44000] -> 42[84000] via P2P/IPC/read
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 03 : 40[3000] -> 41[44000] via P2P/IPC/read
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO Channel 03/0 : 43[c4000] -> 44[3000] [send] via NET/IB/0
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 03 : 4[3000] -> 5[44000] via P2P/IPC/read
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO Channel 00/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Connected all rings
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO Channel 00 : 50[84000] -> 49[44000] via P2P/IPC/read
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO Channel 00 : 22[84000] -> 21[44000] via P2P/IPC/read
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO Connected all rings
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 02/0 : 15[c4000] -> 16[3000] [receive] via NET/IB/0
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Channel 01/0 : 20[3000] -> 25[44000] [receive] via NET/IB/1
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO Channel 01/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 03 : 44[3000] -> 45[44000] via P2P/IPC/read
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO Channel 02 : 46[84000] -> 45[44000] via P2P/IPC/read
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO Channel 02 : 47[c4000] -> 46[84000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO Connected all rings
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO Channel 00 : 23[c4000] -> 22[84000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 03/0 : 11[c4000] -> 12[3000] [receive] via NET/IB/0
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 00 : 12[3000] -> 13[44000] via P2P/IPC/read
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Channel 00 : 13[44000] -> 14[84000] via P2P/IPC/read
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Channel 02 : 5[44000] -> 6[84000] via P2P/IPC/read
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO Channel 01/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO Channel 02/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO Connected all rings
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Channel 00/0 : 52[3000] -> 57[44000] [receive] via NET/IB/1
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO Channel 01 : 50[84000] -> 49[44000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO Channel 01 : 51[c4000] -> 50[84000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 02/0 : 48[3000] -> 52[3000] [receive] via NET/IB/1
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO Connected all rings
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO Channel 00 : 55[c4000] -> 54[84000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO Connected all rings
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO Channel 00 : 31[c4000] -> 30[84000] via P2P/IPC/read
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Channel 02/0 : 37[44000] -> 40[3000] [send] via NET/IB/1
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO Connected all rings
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO Channel 02 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 03/0 : 15[c4000] -> 16[3000] [receive] via NET/IB/0
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 00 : 16[3000] -> 17[44000] via P2P/IPC/read
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO Channel 02/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 01 : 8[3000] -> 9[44000] via P2P/IPC/read
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO Channel 01 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Channel 01 : 9[44000] -> 10[84000] via P2P/IPC/read
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Channel 00/0 : 16[3000] -> 33[44000] [receive] via NET/IB/1
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO Channel 03 : 47[c4000] -> 46[84000] via P2P/IPC/read
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO Connected all rings
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 01 : 12[3000] -> 13[44000] via P2P/IPC/read
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Channel 01 : 13[44000] -> 14[84000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO Channel 00 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Channel 01/0 : 52[3000] -> 57[44000] [receive] via NET/IB/1
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Connected all rings
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Channel 03 : 5[44000] -> 6[84000] via P2P/IPC/read
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO Channel 03/0 : 7[c4000] -> 8[3000] [send] via NET/IB/0
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO Channel 01 : 55[c4000] -> 54[84000] via P2P/IPC/read
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO Channel 02 : 55[c4000] -> 54[84000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO Channel 01 : 31[c4000] -> 30[84000] via P2P/IPC/read
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO Channel 01 : 22[84000] -> 21[44000] via P2P/IPC/read
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Channel 03/0 : 37[44000] -> 40[3000] [send] via NET/IB/1
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO Channel 03 : 6[84000] -> 7[c4000] via P2P/IPC/read
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO Channel 00 : 26[84000] -> 25[44000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO Channel 01 : 23[c4000] -> 22[84000] via P2P/IPC/read
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO Channel 03/0 : 11[c4000] -> 12[3000] [send] via NET/IB/0
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 02 : 8[3000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Channel 02 : 9[44000] -> 10[84000] via P2P/IPC/read
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Channel 00 : 17[44000] -> 18[84000] via P2P/IPC/read
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Connected all rings
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO Channel 03 : 46[84000] -> 45[44000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 02 : 12[3000] -> 13[44000] via P2P/IPC/read
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO Channel 00 : 30[84000] -> 29[44000] via P2P/IPC/read
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO Channel 02 : 50[84000] -> 49[44000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO Channel 02 : 51[c4000] -> 50[84000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 03/0 : 48[3000] -> 52[3000] [receive] via NET/IB/1
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO Channel 02 : 22[84000] -> 21[44000] via P2P/IPC/read
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO Channel 00 : 18[84000] -> 19[c4000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 01 : 16[3000] -> 17[44000] via P2P/IPC/read
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO Channel 02 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Channel 03 : 9[44000] -> 10[84000] via P2P/IPC/read
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Channel 01/0 : 16[3000] -> 33[44000] [receive] via NET/IB/1
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Channel 02/0 : 45[44000] -> 52[3000] [send] via NET/IB/1
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Channel 02 : 13[44000] -> 14[84000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO Channel 01 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO Connected all rings
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO Channel 00 : 59[c4000] -> 58[84000] via P2P/IPC/read
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO Channel 01 : 59[c4000] -> 58[84000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Connected all rings
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO Channel 00 : 54[84000] -> 53[44000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO Channel 02 : 31[c4000] -> 30[84000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO Channel 03 : 51[c4000] -> 50[84000] via P2P/IPC/read
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO Connected all rings
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO Channel 00/0 : 15[c4000] -> 16[3000] [send] via NET/IB/0
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO Channel 01/0 : 15[c4000] -> 16[3000] [send] via NET/IB/0
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO Connected all rings
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO Channel 00 : 27[c4000] -> 26[84000] via P2P/IPC/read
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO Channel 01 : 26[84000] -> 25[44000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Connected all rings
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Connected all rings
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO Channel 00/0 : 19[c4000] -> 20[3000] [send] via NET/IB/0
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO Channel 01/0 : 19[c4000] -> 20[3000] [send] via NET/IB/0
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 03 : 8[3000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Channel 03/0 : 45[44000] -> 52[3000] [send] via NET/IB/1
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO Connected all trees
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Channel 01 : 17[44000] -> 18[84000] via P2P/IPC/read
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO Channel 00 : 58[84000] -> 57[44000] via P2P/IPC/read
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO Channel 01 : 30[84000] -> 29[44000] via P2P/IPC/read
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Channel 00/0 : 36[3000] -> 41[44000] [receive] via NET/IB/1
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO Channel 02 : 59[c4000] -> 58[84000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 03 : 12[3000] -> 13[44000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO Channel 02 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO Channel 03 : 55[c4000] -> 54[84000] via P2P/IPC/read
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Connected all rings
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Channel 02/0 : 5[44000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 02/0 : 53[44000] -> 56[3000] [receive] via NET/IB/1
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO Channel 03 : 50[84000] -> 49[44000] via P2P/IPC/read
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO Channel 03 : 22[84000] -> 21[44000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 02/0 : 21[44000] -> 24[3000] [receive] via NET/IB/1
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Connected all rings
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO Channel 03 : 10[84000] -> 11[c4000] via P2P/IPC/read
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO Channel 02/0 : 15[c4000] -> 16[3000] [send] via NET/IB/0
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO Channel 02 : 23[c4000] -> 22[84000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 02/0 : 32[3000] -> 36[3000] [send] via NET/IB/1
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO Connected all rings
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO Channel 00 : 35[c4000] -> 34[84000] via P2P/IPC/read
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO Channel 00 : 34[84000] -> 33[44000] via P2P/IPC/read
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO Channel 01 : 18[84000] -> 19[c4000] via P2P/IPC/read
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO Channel 02/0 : 19[c4000] -> 20[3000] [send] via NET/IB/0
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 02 : 16[3000] -> 17[44000] via P2P/IPC/read
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO Channel 01 : 58[84000] -> 57[44000] via P2P/IPC/read
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Channel 02 : 17[44000] -> 18[84000] via P2P/IPC/read
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Channel 03 : 13[44000] -> 14[84000] via P2P/IPC/read
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Channel 01/0 : 36[3000] -> 41[44000] [receive] via NET/IB/1
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 03/0 : 53[44000] -> 56[3000] [receive] via NET/IB/1
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Channel 03/0 : 5[44000] -> 8[3000] [send] via NET/IB/1
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO Channel 01 : 54[84000] -> 53[44000] via P2P/IPC/read
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO Channel 00 : 62[84000] -> 61[44000] via P2P/IPC/read
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO Connected all trees
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO Channel 00 : 38[84000] -> 37[44000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO Connected all rings
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO Channel 00 : 39[c4000] -> 38[84000] via P2P/IPC/read
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO Channel 01 : 27[c4000] -> 26[84000] via P2P/IPC/read
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO Channel 02 : 26[84000] -> 25[44000] via P2P/IPC/read
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO Channel 03/0 : 15[c4000] -> 16[3000] [send] via NET/IB/0
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 03/0 : 32[3000] -> 36[3000] [send] via NET/IB/1
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO Channel 03 : 23[c4000] -> 22[84000] via P2P/IPC/read
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO Channel 00 : 61[44000] -> 60[3000] via P2P/IPC/read
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO Connected all rings
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO Channel 03/0 : 19[c4000] -> 20[3000] [send] via NET/IB/0
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 03 : 16[3000] -> 17[44000] via P2P/IPC/read
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Channel 03 : 17[44000] -> 18[84000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO Channel 03 : 14[84000] -> 15[c4000] via P2P/IPC/read
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Connected all rings
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO Connected all rings
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO Channel 00 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO Channel 02 : 30[84000] -> 29[44000] via P2P/IPC/read
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO Connected all rings
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO Channel 00 : 43[c4000] -> 42[84000] via P2P/IPC/read
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO Channel 02 : 54[84000] -> 53[44000] via P2P/IPC/read
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO Channel 03 : 31[c4000] -> 30[84000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Connected all rings
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO Connected all rings
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO Channel 00 : 63[c4000] -> 62[84000] via P2P/IPC/read
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Connected all rings
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 00/0 : 48[3000] -> 56[3000] [send] via NET/IB/1
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO Channel 02 : 27[c4000] -> 26[84000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 03/0 : 21[44000] -> 24[3000] [receive] via NET/IB/1
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 00/0 : 24[3000] -> 28[3000] [receive] via NET/IB/1
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO Channel 01 : 35[c4000] -> 34[84000] via P2P/IPC/read
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO Channel 01 : 34[84000] -> 33[44000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Connected all rings
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO Channel 02 : 18[84000] -> 19[c4000] via P2P/IPC/read
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 02/0 : 0[3000] -> 4[3000] [send] via NET/IB/1
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO Channel 01 : 43[c4000] -> 42[84000] via P2P/IPC/read
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO Channel 03 : 59[c4000] -> 58[84000] via P2P/IPC/read
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO Channel 03 : 30[84000] -> 29[44000] via P2P/IPC/read
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO Channel 03 : 54[84000] -> 53[44000] via P2P/IPC/read
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO Channel 01 : 62[84000] -> 61[44000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO Channel 01 : 63[c4000] -> 62[84000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 01/0 : 48[3000] -> 56[3000] [send] via NET/IB/1
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Connected all rings
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO Channel 01 : 38[84000] -> 37[44000] via P2P/IPC/read
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO Channel 02 : 38[84000] -> 37[44000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO Channel 01 : 39[c4000] -> 38[84000] via P2P/IPC/read
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO Channel 03 : 27[c4000] -> 26[84000] via P2P/IPC/read
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO Channel 03 : 26[84000] -> 25[44000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 01/0 : 24[3000] -> 28[3000] [receive] via NET/IB/1
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO Channel 01 : 61[44000] -> 60[3000] via P2P/IPC/read
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO Channel 02 : 35[c4000] -> 34[84000] via P2P/IPC/read
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO Channel 02 : 34[84000] -> 33[44000] via P2P/IPC/read
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO Connected all trees
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 03/0 : 0[3000] -> 4[3000] [send] via NET/IB/1
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO Channel 00 : 2[84000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO Channel 01 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Channel 00/0 : 4[3000] -> 9[44000] [receive] via NET/IB/1
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Connected all rings
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO Channel 00 : 42[84000] -> 41[44000] via P2P/IPC/read
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO Channel 02 : 58[84000] -> 57[44000] via P2P/IPC/read
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Connected all rings
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO Connected all rings
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO Channel 02 : 62[84000] -> 61[44000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 00/0 : 56[3000] -> 60[3000] [receive] via NET/IB/1
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO Connected all trees
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO Channel 00 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 02/0 : 32[3000] -> 36[3000] [receive] via NET/IB/1
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO Channel 02 : 39[c4000] -> 38[84000] via P2P/IPC/read
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO Connected all rings
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO Channel 00 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO Channel 03 : 34[84000] -> 33[44000] via P2P/IPC/read
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO Channel 02 : 61[44000] -> 60[3000] via P2P/IPC/read
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO Channel 03 : 18[84000] -> 19[c4000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Connected all rings
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO Channel 03 : 58[84000] -> 57[44000] via P2P/IPC/read
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO Channel 02 : 43[c4000] -> 42[84000] via P2P/IPC/read
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Channel 02/0 : 13[44000] -> 20[3000] [send] via NET/IB/1
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Channel 02/0 : 56[3000] -> 53[44000] [receive] via NET/IB/1
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 00/0 : 52[3000] -> 57[44000] [send] via NET/IB/1
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 00/0 : 56[3000] -> 60[3000] [send] via NET/IB/1
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 01/0 : 56[3000] -> 60[3000] [receive] via NET/IB/1
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO Channel 01 : 1[44000] -> 0[3000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 02/0 : 0[3000] -> 4[3000] [receive] via NET/IB/1
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO Connected all trees
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO Channel 03 : 35[c4000] -> 34[84000] via P2P/IPC/read
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO Channel 03 : 61[44000] -> 60[3000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Channel 01/0 : 4[3000] -> 9[44000] [receive] via NET/IB/1
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO Channel 01 : 2[84000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO Channel 02 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 01/0 : 52[3000] -> 57[44000] [send] via NET/IB/1
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO Connected all trees
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 02/0 : 37[44000] -> 40[3000] [receive] via NET/IB/1
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO Channel 01 : 42[84000] -> 41[44000] via P2P/IPC/read
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Channel 03/0 : 13[44000] -> 20[3000] [send] via NET/IB/1
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO Channel 03 : 62[84000] -> 61[44000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO Channel 02 : 63[c4000] -> 62[84000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 03/0 : 0[3000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 03/0 : 32[3000] -> 36[3000] [receive] via NET/IB/1
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO Channel 03 : 38[84000] -> 37[44000] via P2P/IPC/read
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO Channel 00 : 6[84000] -> 5[44000] via P2P/IPC/read
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Connected all rings
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO Connected all rings
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 00/0 : 40[3000] -> 44[3000] [receive] via NET/IB/1
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO Channel 03 : 3[c4000] -> 2[84000] via P2P/IPC/read
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Channel 03/0 : 56[3000] -> 53[44000] [receive] via NET/IB/1
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO Connected all rings
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO Channel 00 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO Connected all trees
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 03/0 : 37[44000] -> 40[3000] [receive] via NET/IB/1
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO Channel 03 : 43[c4000] -> 42[84000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO Channel 03 : 39[c4000] -> 38[84000] via P2P/IPC/read
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO Channel 01 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO Channel 02 : 1[44000] -> 0[3000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Channel 02/0 : 24[3000] -> 21[44000] [receive] via NET/IB/1
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO Connected all trees
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 01/0 : 40[3000] -> 44[3000] [receive] via NET/IB/1
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Connected all rings
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 01/0 : 56[3000] -> 60[3000] [send] via NET/IB/1
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO Channel 02 : 42[84000] -> 41[44000] via P2P/IPC/read
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO Channel 03 : 63[c4000] -> 62[84000] via P2P/IPC/read
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO Connected all trees
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO Channel 01 : 6[84000] -> 5[44000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 00/0 : 24[3000] -> 28[3000] [send] via NET/IB/1
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Channel 03/0 : 24[3000] -> 21[44000] [receive] via NET/IB/1
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Channel 00/0 : 8[3000] -> 17[44000] [receive] via NET/IB/1
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO Channel 02 : 2[84000] -> 1[44000] via P2P/IPC/read
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO Channel 01 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Connected all rings
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO Connected all trees
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO Connected all trees
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO Channel 02 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO Channel 03 : 1[44000] -> 0[3000] via P2P/IPC/read
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO Channel 02 : 6[84000] -> 5[44000] via P2P/IPC/read
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO Channel 03 : 6[84000] -> 5[44000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 01/0 : 24[3000] -> 28[3000] [send] via NET/IB/1
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 00/0 : 32[3000] -> 48[3000] [send] via NET/IB/1
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO Channel 03 : 2[84000] -> 1[44000] via P2P/IPC/read
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO Channel 00 : 10[84000] -> 9[44000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 02/0 : 5[44000] -> 8[3000] [receive] via NET/IB/1
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO Channel 02 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 00/0 : 48[3000] -> 56[3000] [receive] via NET/IB/1
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO Connected all rings
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO Channel 00 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 02/0 : 45[44000] -> 52[3000] [receive] via NET/IB/1
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO Channel 03 : 42[84000] -> 41[44000] via P2P/IPC/read
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO Channel 00 : 14[84000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 00/0 : 4[3000] -> 9[44000] [send] via NET/IB/1
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 02/0 : 28[3000] -> 60[3000] [receive] via NET/IB/1
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 01/0 : 32[3000] -> 48[3000] [send] via NET/IB/1
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Channel 01/0 : 8[3000] -> 17[44000] [receive] via NET/IB/1
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 00/0 : 32[3000] -> 0[3000] [receive] via NET/IB/1
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO Connected all trees
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO Channel 03 : 11[c4000] -> 10[84000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 03/0 : 45[44000] -> 52[3000] [receive] via NET/IB/1
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Channel 00/0 : 57[44000] -> 52[3000] [send] via NET/IB/1
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO Connected all trees
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO Channel 03 : 7[c4000] -> 6[84000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 01/0 : 4[3000] -> 9[44000] [send] via NET/IB/1
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Channel 02/0 : 40[3000] -> 37[44000] [receive] via NET/IB/1
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 00/0 : 36[3000] -> 41[44000] [send] via NET/IB/1
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 01/0 : 36[3000] -> 41[44000] [send] via NET/IB/1
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO Connected all rings
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO Channel 00 : 19[c4000] -> 18[84000] via P2P/IPC/read
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 01/0 : 32[3000] -> 0[3000] [receive] via NET/IB/1
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO Connected all trees
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO Channel 01 : 10[84000] -> 9[44000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 03/0 : 5[44000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 00/0 : 40[3000] -> 44[3000] [send] via NET/IB/1
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Channel 01/0 : 57[44000] -> 52[3000] [send] via NET/IB/1
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO Channel 01 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 00/0 : 8[3000] -> 12[3000] [receive] via NET/IB/1
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 00/0 : 16[3000] -> 24[3000] [receive] via NET/IB/1
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 00/0 : 0[3000] -> 32[3000] [send] via NET/IB/1
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 01/0 : 48[3000] -> 56[3000] [receive] via NET/IB/1
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 01/0 : 40[3000] -> 44[3000] [send] via NET/IB/1
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO Channel 02 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Connected all rings
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO Channel 01 : 14[84000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 03/0 : 28[3000] -> 60[3000] [receive] via NET/IB/1
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Channel 03/0 : 40[3000] -> 37[44000] [receive] via NET/IB/1
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO Connected all trees
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO Channel 01 : 19[c4000] -> 18[84000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Connected all rings
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 01/0 : 0[3000] -> 32[3000] [send] via NET/IB/1
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO Channel 02 : 10[84000] -> 9[44000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 02/0 : 4[3000] -> 12[3000] [send] via NET/IB/1
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 02/0 : 16[3000] -> 20[3000] [receive] via NET/IB/1
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 02/0 : 36[3000] -> 44[3000] [send] via NET/IB/1
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 01/0 : 8[3000] -> 12[3000] [receive] via NET/IB/1
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO Channel 02 : 14[84000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 02/0 : 60[3000] -> 28[3000] [send] via NET/IB/1
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 01/0 : 16[3000] -> 24[3000] [receive] via NET/IB/1
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO Channel 00 : 18[84000] -> 17[44000] via P2P/IPC/read
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO Channel 02 : 19[c4000] -> 18[84000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 02/0 : 16[3000] -> 20[3000] [send] via NET/IB/1
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 03/0 : 16[3000] -> 20[3000] [send] via NET/IB/1
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Channel 00/0 : 41[44000] -> 36[3000] [send] via NET/IB/1
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 00/0 : 40[3000] -> 49[44000] [send] via NET/IB/1
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO Channel 03 : 15[c4000] -> 14[84000] via P2P/IPC/read
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 03/0 : 36[3000] -> 44[3000] [send] via NET/IB/1
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 03/0 : 4[3000] -> 12[3000] [send] via NET/IB/1
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 03/0 : 60[3000] -> 28[3000] [send] via NET/IB/1
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 02/0 : 12[3000] -> 28[3000] [receive] via NET/IB/1
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO Channel 01 : 18[84000] -> 17[44000] via P2P/IPC/read
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Channel 02/0 : 52[3000] -> 45[44000] [receive] via NET/IB/1
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 02/0 : 52[3000] -> 45[44000] [send] via NET/IB/1
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO Channel 03 : 10[84000] -> 9[44000] via P2P/IPC/read
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Channel 01/0 : 41[44000] -> 36[3000] [send] via NET/IB/1
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO Channel 03 : 14[84000] -> 13[44000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 03/0 : 16[3000] -> 20[3000] [receive] via NET/IB/1
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Channel 02/0 : 8[3000] -> 5[44000] [receive] via NET/IB/1
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 00/0 : 32[3000] -> 48[3000] [receive] via NET/IB/1
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Channel 03/0 : 52[3000] -> 45[44000] [receive] via NET/IB/1
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 03/0 : 52[3000] -> 45[44000] [send] via NET/IB/1
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Channel 00/0 : 9[44000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 00/0 : 8[3000] -> 12[3000] [send] via NET/IB/1
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 01/0 : 40[3000] -> 49[44000] [send] via NET/IB/1
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO Connected all trees
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 03/0 : 12[3000] -> 28[3000] [receive] via NET/IB/1
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO Channel 02 : 18[84000] -> 17[44000] via P2P/IPC/read
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO Channel 03 : 19[c4000] -> 18[84000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Channel 01/0 : 9[44000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 01/0 : 8[3000] -> 12[3000] [send] via NET/IB/1
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO Connected all trees
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 02/0 : 36[3000] -> 44[3000] [receive] via NET/IB/1
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 00/0 : 56[3000] -> 48[3000] [send] via NET/IB/1
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Channel 03/0 : 8[3000] -> 5[44000] [receive] via NET/IB/1
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 01/0 : 32[3000] -> 48[3000] [receive] via NET/IB/1
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 03/0 : 36[3000] -> 44[3000] [receive] via NET/IB/1
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 01/0 : 56[3000] -> 48[3000] [send] via NET/IB/1
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 00/0 : 20[3000] -> 25[44000] [send] via NET/IB/1
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO Channel 03 : 18[84000] -> 17[44000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 00/0 : 16[3000] -> 24[3000] [send] via NET/IB/1
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 01/0 : 16[3000] -> 24[3000] [send] via NET/IB/1
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 00/0 : 57[44000] -> 52[3000] [receive] via NET/IB/1
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 00/0 : 8[3000] -> 17[44000] [send] via NET/IB/1
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Channel 00/0 : 49[44000] -> 40[3000] [send] via NET/IB/1
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 01/0 : 8[3000] -> 17[44000] [send] via NET/IB/1
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO Connected all trees
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 00/0 : 49[44000] -> 40[3000] [receive] via NET/IB/1
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 01/0 : 20[3000] -> 25[44000] [send] via NET/IB/1
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Channel 01/0 : 49[44000] -> 40[3000] [send] via NET/IB/1
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 01/0 : 57[44000] -> 52[3000] [receive] via NET/IB/1
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 01/0 : 49[44000] -> 40[3000] [receive] via NET/IB/1
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 02/0 : 4[3000] -> 12[3000] [receive] via NET/IB/1
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 00/0 : 0[3000] -> 32[3000] [receive] via NET/IB/1
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 02/0 : 13[44000] -> 20[3000] [receive] via NET/IB/1
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 03/0 : 4[3000] -> 12[3000] [receive] via NET/IB/1
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 02/0 : 44[3000] -> 36[3000] [receive] via NET/IB/1
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 03/0 : 44[3000] -> 36[3000] [receive] via NET/IB/1
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Channel 00/0 : 17[44000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 00/0 : 16[3000] -> 33[44000] [send] via NET/IB/1
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 00/0 : 17[44000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 00/0 : 48[3000] -> 32[3000] [send] via NET/IB/1
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 01/0 : 0[3000] -> 32[3000] [receive] via NET/IB/1
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Channel 00/0 : 25[44000] -> 20[3000] [send] via NET/IB/1
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 00/0 : 24[3000] -> 16[3000] [send] via NET/IB/1
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Channel 01/0 : 17[44000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 01/0 : 16[3000] -> 33[44000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 02/0 : 29[44000] -> 44[3000] [receive] via NET/IB/1
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 01/0 : 48[3000] -> 32[3000] [send] via NET/IB/1
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Channel 01/0 : 25[44000] -> 20[3000] [send] via NET/IB/1
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 01/0 : 24[3000] -> 16[3000] [send] via NET/IB/1
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 01/0 : 17[44000] -> 8[3000] [receive] via NET/IB/1
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 00/0 : 32[3000] -> 0[3000] [send] via NET/IB/1
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 01/0 : 32[3000] -> 0[3000] [send] via NET/IB/1
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 02/0 : 52[3000] -> 48[3000] [send] via NET/IB/1
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Channel 03/0 : 52[3000] -> 48[3000] [send] via NET/IB/1
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Channel 00 : 45[44000] -> 44[3000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 03/0 : 29[44000] -> 44[3000] [receive] via NET/IB/1
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 02/0 : 12[3000] -> 28[3000] [send] via NET/IB/1
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 03/0 : 13[44000] -> 20[3000] [receive] via NET/IB/1
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 02/0 : 12[3000] -> 4[3000] [receive] via NET/IB/1
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Channel 01 : 45[44000] -> 44[3000] via P2P/IPC/read
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 00/0 : 44[3000] -> 40[3000] [receive] via NET/IB/1
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 03/0 : 12[3000] -> 28[3000] [send] via NET/IB/1
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 03/0 : 12[3000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 00/0 : 12[3000] -> 8[3000] [receive] via NET/IB/1
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Channel 00/0 : 33[44000] -> 16[3000] [send] via NET/IB/1
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 01/0 : 44[3000] -> 40[3000] [receive] via NET/IB/1
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 00/0 : 33[44000] -> 16[3000] [receive] via NET/IB/1
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Channel 00 : 57[44000] -> 56[3000] via P2P/IPC/read
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Channel 02 : 45[44000] -> 44[3000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 02/0 : 44[3000] -> 29[44000] [send] via NET/IB/1
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 01/0 : 33[44000] -> 16[3000] [receive] via NET/IB/1
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 02/0 : 60[3000] -> 28[3000] [receive] via NET/IB/1
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 01/0 : 12[3000] -> 8[3000] [receive] via NET/IB/1
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Channel 01/0 : 33[44000] -> 16[3000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 03/0 : 44[3000] -> 29[44000] [send] via NET/IB/1
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 02/0 : 4[3000] -> 0[3000] [receive] via NET/IB/1
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Channel 02/0 : 44[3000] -> 29[44000] [receive] via NET/IB/1
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Channel 03 : 45[44000] -> 44[3000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 00/0 : 48[3000] -> 32[3000] [receive] via NET/IB/1
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Channel 01 : 57[44000] -> 56[3000] via P2P/IPC/read
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Channel 00 : 49[44000] -> 48[3000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 02/0 : 28[3000] -> 12[3000] [receive] via NET/IB/1
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Channel 02/0 : 20[3000] -> 13[44000] [receive] via NET/IB/1
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 02/0 : 20[3000] -> 13[44000] [send] via NET/IB/1
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 03/0 : 20[3000] -> 13[44000] [send] via NET/IB/1
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Channel 03/0 : 44[3000] -> 29[44000] [receive] via NET/IB/1
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 03/0 : 60[3000] -> 28[3000] [receive] via NET/IB/1
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO Connected all trees
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Channel 03/0 : 4[3000] -> 0[3000] [receive] via NET/IB/1
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 03/0 : 28[3000] -> 12[3000] [receive] via NET/IB/1
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Channel 02 : 57[44000] -> 56[3000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 01/0 : 48[3000] -> 32[3000] [receive] via NET/IB/1
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Channel 01 : 49[44000] -> 48[3000] via P2P/IPC/read
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Channel 03/0 : 20[3000] -> 13[44000] [receive] via NET/IB/1
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 02/0 : 28[3000] -> 60[3000] [send] via NET/IB/1
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 03/0 : 28[3000] -> 60[3000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 02/0 : 44[3000] -> 36[3000] [send] via NET/IB/1
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Channel 00 : 17[44000] -> 16[3000] via P2P/IPC/read
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Channel 03 : 57[44000] -> 56[3000] via P2P/IPC/read
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 03/0 : 44[3000] -> 36[3000] [send] via NET/IB/1
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Channel 02 : 49[44000] -> 48[3000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 00/0 : 24[3000] -> 16[3000] [receive] via NET/IB/1
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Channel 01 : 17[44000] -> 16[3000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 01/0 : 24[3000] -> 16[3000] [receive] via NET/IB/1
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Channel 03 : 49[44000] -> 48[3000] via P2P/IPC/read
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO Connected all trees
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Channel 02 : 17[44000] -> 16[3000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 00/0 : 56[3000] -> 48[3000] [receive] via NET/IB/1
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 00/0 : 25[44000] -> 20[3000] [receive] via NET/IB/1
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 02/0 : 36[3000] -> 32[3000] [receive] via NET/IB/1
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 00/0 : 44[3000] -> 40[3000] [send] via NET/IB/1
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO Connected all trees
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 00/0 : 60[3000] -> 56[3000] [send] via NET/IB/1
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Channel 01/0 : 60[3000] -> 56[3000] [send] via NET/IB/1
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Channel 01/0 : 44[3000] -> 40[3000] [send] via NET/IB/1
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Channel 03 : 17[44000] -> 16[3000] via P2P/IPC/read
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Channel 00 : 33[44000] -> 32[3000] via P2P/IPC/read
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 01/0 : 56[3000] -> 48[3000] [receive] via NET/IB/1
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 01/0 : 25[44000] -> 20[3000] [receive] via NET/IB/1
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 00/0 : 41[44000] -> 36[3000] [receive] via NET/IB/1
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 00/0 : 28[3000] -> 24[3000] [receive] via NET/IB/1
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Channel 03/0 : 36[3000] -> 32[3000] [receive] via NET/IB/1
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 02/0 : 20[3000] -> 16[3000] [receive] via NET/IB/1
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Channel 00 : 29[44000] -> 28[3000] via P2P/IPC/read
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 02/0 : 28[3000] -> 12[3000] [send] via NET/IB/1
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Channel 01 : 33[44000] -> 32[3000] via P2P/IPC/read
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO Connected all trees
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 03/0 : 28[3000] -> 12[3000] [send] via NET/IB/1
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 01/0 : 41[44000] -> 36[3000] [receive] via NET/IB/1
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 01/0 : 28[3000] -> 24[3000] [receive] via NET/IB/1
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 02/0 : 40[3000] -> 37[44000] [send] via NET/IB/1
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Channel 00 : 13[44000] -> 12[3000] via P2P/IPC/read
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Channel 02 : 33[44000] -> 32[3000] via P2P/IPC/read
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Channel 03/0 : 20[3000] -> 16[3000] [receive] via NET/IB/1
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Channel 01 : 29[44000] -> 28[3000] via P2P/IPC/read
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Channel 03/0 : 40[3000] -> 37[44000] [send] via NET/IB/1
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 00/0 : 60[3000] -> 56[3000] [receive] via NET/IB/1
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 02/0 : 52[3000] -> 48[3000] [receive] via NET/IB/1
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Channel 03 : 33[44000] -> 32[3000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 01/0 : 60[3000] -> 56[3000] [receive] via NET/IB/1
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Channel 02 : 29[44000] -> 28[3000] via P2P/IPC/read
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Channel 01 : 13[44000] -> 12[3000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 02/0 : 20[3000] -> 16[3000] [send] via NET/IB/1
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 00/0 : 28[3000] -> 24[3000] [send] via NET/IB/1
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Channel 01/0 : 28[3000] -> 24[3000] [send] via NET/IB/1
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Channel 03 : 29[44000] -> 28[3000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 02/0 : 12[3000] -> 4[3000] [send] via NET/IB/1
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Channel 02 : 13[44000] -> 12[3000] via P2P/IPC/read
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Channel 03/0 : 20[3000] -> 16[3000] [send] via NET/IB/1
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Channel 03/0 : 52[3000] -> 48[3000] [receive] via NET/IB/1
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO Connected all trees
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 02/0 : 36[3000] -> 32[3000] [send] via NET/IB/1
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 03/0 : 12[3000] -> 4[3000] [send] via NET/IB/1
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Channel 03/0 : 36[3000] -> 32[3000] [send] via NET/IB/1
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO Connected all trees
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Channel 03 : 13[44000] -> 12[3000] via P2P/IPC/read
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO Connected all trees
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO Connected all trees
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 02/0 : 24[3000] -> 21[44000] [send] via NET/IB/1
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 02/0 : 56[3000] -> 53[44000] [send] via NET/IB/1
[default1]:n2gpu1222:147026:147233 [1] NCCL INFO comm 0x150b040090d0 rank 45 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1222:147027:147232 [2] NCCL INFO comm 0x14f9880090d0 rank 46 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1222:147028:147235 [3] NCCL INFO comm 0x15059c0090d0 rank 47 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1222:147025:147234 [0] NCCL INFO comm 0x154b4c0090d0 rank 44 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Channel 00 : 25[44000] -> 24[3000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Channel 03/0 : 24[3000] -> 21[44000] [send] via NET/IB/1
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 00/0 : 12[3000] -> 8[3000] [send] via NET/IB/1
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO Connected all trees
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Channel 00 : 41[44000] -> 40[3000] via P2P/IPC/read
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Channel 03/0 : 56[3000] -> 53[44000] [send] via NET/IB/1
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Channel 01 : 25[44000] -> 24[3000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Channel 01/0 : 12[3000] -> 8[3000] [send] via NET/IB/1
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 00/0 : 9[44000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO Connected all trees
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO Connected all trees
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Channel 01 : 41[44000] -> 40[3000] via P2P/IPC/read
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Channel 02 : 25[44000] -> 24[3000] via P2P/IPC/read
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Channel 00 : 37[44000] -> 36[3000] via P2P/IPC/read
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 01/0 : 9[44000] -> 4[3000] [receive] via NET/IB/1
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO Connected all trees
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1230:125964:126157 [2] NCCL INFO comm 0x14f1280090d0 rank 62 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1230:125962:126155 [0] NCCL INFO comm 0x1508940090d0 rank 60 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1230:125965:126158 [3] NCCL INFO comm 0x14d7f40090d0 rank 63 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1230:125963:126156 [1] NCCL INFO comm 0x1486340090d0 rank 61 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Channel 03 : 25[44000] -> 24[3000] via P2P/IPC/read
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Channel 02 : 41[44000] -> 40[3000] via P2P/IPC/read
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO Connected all trees
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Channel 01 : 37[44000] -> 36[3000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO Connected all trees
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO Connected all trees
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO Connected all trees
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1210:144011:144206 [0] NCCL INFO comm 0x1518e80090d0 rank 28 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO Connected all trees
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Channel 02 : 37[44000] -> 36[3000] via P2P/IPC/read
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 02/0 : 8[3000] -> 5[44000] [send] via NET/IB/1
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Channel 03/0 : 8[3000] -> 5[44000] [send] via NET/IB/1
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO Connected all trees
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1210:144013:144207 [2] NCCL INFO comm 0x151fc00090d0 rank 30 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1210:144012:144208 [1] NCCL INFO comm 0x14ed1c0090d0 rank 29 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1210:144014:144209 [3] NCCL INFO comm 0x1465940090d0 rank 31 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Channel 03 : 41[44000] -> 40[3000] via P2P/IPC/read
[default2]:n2gpu1224:124661:124854 [2] NCCL INFO comm 0x151bac0090d0 rank 50 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1224:124662:124853 [3] NCCL INFO comm 0x14c6c00090d0 rank 51 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1224:124660:124856 [1] NCCL INFO comm 0x14ef500090d0 rank 49 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Channel 03 : 37[44000] -> 36[3000] via P2P/IPC/read
[default0]:n2gpu1219:266888:267095 [0] NCCL INFO comm 0x14e1d00090d0 rank 32 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1219:266891:267094 [3] NCCL INFO comm 0x14f8f80090d0 rank 35 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO Connected all trees
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1224:124659:124855 [0] NCCL INFO comm 0x14915c0090d0 rank 48 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO Connected all trees
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO Connected all trees
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1219:266890:267096 [2] NCCL INFO comm 0x148da80090d0 rank 34 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1219:266889:267093 [1] NCCL INFO comm 0x1458400090d0 rank 33 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO Connected all trees
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO Connected all trees
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO Connected all trees
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO Connected all trees
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO Connected all trees
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO Connected all trees
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1206:143433:143626 [1] NCCL INFO comm 0x1484580090d0 rank 17 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1206:143434:143623 [2] NCCL INFO comm 0x14f63c0090d0 rank 18 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1206:143435:143625 [3] NCCL INFO comm 0x14643c0090d0 rank 19 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1206:143432:143624 [0] NCCL INFO comm 0x14d5a80090d0 rank 16 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO Connected all trees
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO Connected all trees
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO Connected all trees
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1221:160027:160243 [0] NCCL INFO comm 0x1450000090d0 rank 40 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1221:160028:160244 [1] NCCL INFO comm 0x148d000090d0 rank 41 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1221:160029:160245 [2] NCCL INFO comm 0x14c8240090d0 rank 42 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1221:160030:160242 [3] NCCL INFO comm 0x1483240090d0 rank 43 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Channel 00 : 21[44000] -> 20[3000] via P2P/IPC/read
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO Connected all trees
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 02/0 : 4[3000] -> 0[3000] [send] via NET/IB/1
[default1]:n2gpu1220:386661:386874 [1] NCCL INFO comm 0x14f9d00090d0 rank 37 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1220:386660:386871 [0] NCCL INFO comm 0x150f140090d0 rank 36 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1220:386662:386872 [2] NCCL INFO comm 0x1542a00090d0 rank 38 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1220:386663:386873 [3] NCCL INFO comm 0x14acec0090d0 rank 39 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1229:174606:174796 [2] NCCL INFO comm 0x147d7c0090d0 rank 58 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1229:174607:174797 [3] NCCL INFO comm 0x14bffc0090d0 rank 59 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1229:174605:174795 [1] NCCL INFO comm 0x15351c0090d0 rank 57 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1229:174604:174798 [0] NCCL INFO comm 0x1530e40090d0 rank 56 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1209:135998:136193 [1] NCCL INFO comm 0x152de40090d0 rank 25 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1209:136000:136194 [3] NCCL INFO comm 0x1510480090d0 rank 27 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1209:135999:136192 [2] NCCL INFO comm 0x1462540090d0 rank 26 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Channel 03/0 : 4[3000] -> 0[3000] [send] via NET/IB/1
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO Connected all trees
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Channel 00 : 53[44000] -> 52[3000] via P2P/IPC/read
[default0]:n2gpu1209:135997:136191 [0] NCCL INFO comm 0x14a7d00090d0 rank 24 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Channel 01 : 21[44000] -> 20[3000] via P2P/IPC/read
[default3]:n2gpu1205:143300:143490 [3] NCCL INFO comm 0x15242c0090d0 rank 15 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1205:143297:143489 [0] NCCL INFO comm 0x14dc880090d0 rank 12 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1205:143298:143491 [1] NCCL INFO comm 0x154c580090d0 rank 13 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1205:143299:143492 [2] NCCL INFO comm 0x14e0600090d0 rank 14 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Channel 01 : 53[44000] -> 52[3000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Channel 02 : 21[44000] -> 20[3000] via P2P/IPC/read
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Channel 02 : 53[44000] -> 52[3000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Channel 00 : 9[44000] -> 8[3000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Channel 03 : 21[44000] -> 20[3000] via P2P/IPC/read
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Channel 03 : 53[44000] -> 52[3000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Channel 01 : 9[44000] -> 8[3000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO Connected all trees
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO Connected all trees
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO Connected all trees
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO Connected all trees
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO Connected all trees
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Channel 02 : 9[44000] -> 8[3000] via P2P/IPC/read
[default1]:n2gpu1207:144619:144818 [1] NCCL INFO comm 0x1541700090d0 rank 21 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1207:144618:144816 [0] NCCL INFO comm 0x149a900090d0 rank 20 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1207:144621:144817 [3] NCCL INFO comm 0x1451200090d0 rank 23 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1207:144620:144815 [2] NCCL INFO comm 0x14dc0c0090d0 rank 22 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1227:190530:190725 [1] NCCL INFO comm 0x14ea640090d0 rank 53 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1227:190531:190723 [2] NCCL INFO comm 0x14992c0090d0 rank 54 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1227:190532:190722 [3] NCCL INFO comm 0x1478480090d0 rank 55 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Channel 00 : 5[44000] -> 4[3000] via P2P/IPC/read
[default0]:n2gpu1227:190529:190724 [0] NCCL INFO comm 0x14736c0090d0 rank 52 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Channel 03 : 9[44000] -> 8[3000] via P2P/IPC/read
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Channel 01 : 5[44000] -> 4[3000] via P2P/IPC/read
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO Connected all trees
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Channel 02 : 5[44000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO Connected all trees
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO Connected all trees
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO Connected all trees
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1201:986608:987028 [1] NCCL INFO comm 0x147ba80090d0 rank 1 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Channel 03 : 5[44000] -> 4[3000] via P2P/IPC/read
[default1]:n2gpu1204:138137:138339 [1] NCCL INFO comm 0x14fb340090d0 rank 9 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO Connected all trees
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default0]:n2gpu1201:986607:987026 [0] NCCL INFO comm 0x146c640090d0 rank 0 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1201:986607:986607 [0] NCCL INFO Launch mode Parallel
[default2]:n2gpu1201:986609:987027 [2] NCCL INFO comm 0x14a9cc0090d0 rank 2 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1201:986610:987029 [3] NCCL INFO comm 0x14e5c00090d0 rank 3 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1204:138138:138338 [2] NCCL INFO comm 0x148c900090d0 rank 10 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1204:138136:138340 [0] NCCL INFO comm 0x14e8a80090d0 rank 8 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1204:138139:138337 [3] NCCL INFO comm 0x1509a40090d0 rank 11 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO Connected all trees
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO Connected all trees
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO Connected all trees
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/512
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer
[default2]:n2gpu1202:1130095:1130290 [2] NCCL INFO comm 0x15272c0090d0 rank 6 nranks 64 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1202:1130096:1130289 [3] NCCL INFO comm 0x14d5cc0090d0 rank 7 nranks 64 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1202:1130093:1130288 [0] NCCL INFO comm 0x1533180090d0 rank 4 nranks 64 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1202:1130094:1130291 [1] NCCL INFO comm 0x148c540090d0 rank 5 nranks 64 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:[2023-04-24 08:06:52,294] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[default0]:[2023-04-24 08:06:52,328] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[default0]:[2023-04-24 08:06:52,328] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:[2023-04-24 08:06:52,436] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[default0]:[2023-04-24 08:06:52,436] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'apex.optimizers.fused_adam.FusedAdam'>
[default0]:[2023-04-24 08:06:52,436] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[default0]:[2023-04-24 08:06:52,436] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500000000
[default0]:[2023-04-24 08:06:52,436] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500000000
[default0]:[2023-04-24 08:06:52,436] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[default0]:[2023-04-24 08:06:52,436] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default1]:Building extension module utils...
[default1]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default1]:ninja: no work to do.
[default1]:Loading extension module utils...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Time to load utils op: 0.47046327590942383 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default1]:Building extension module utils...
[default1]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default1]:ninja: no work to do.
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.2341611385345459 seconds
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.24699664115905762 seconds
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.2866826057434082 seconds
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.28618621826171875 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default1]:Building extension module utils...
[default1]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:ninja: no work to do.
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.30658698081970215 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Emitting ninja build file /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117/utils/build.ninja...
[default0]:Building extension module utils...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.1899573802947998 seconds
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.25121021270751953 seconds
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.25387096405029297 seconds
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.2654097080230713 seconds
[default2]:Loading extension module utils...
[default3]:Loading extension module utils...
[default0]:Loading extension module utils...
[default1]:Loading extension module utils...
[default1]:Loading extension module utils...
[default0]:Loading extension module utils...
[default3]:Loading extension module utils...
[default2]:Loading extension module utils...
[default3]:Loading extension module utils...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 3.040494918823242 seconds
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 3.0675950050354004 seconds
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 3.0688164234161377 seconds
[default3]:Time to load utils op: 3.088107109069824 seconds
[default3]:Time to load utils op: 3.5234575271606445 seconds
[default2]:Time to load utils op: 3.535723924636841 seconds
[default1]:Time to load utils op: 3.5125327110290527 seconds
[default0]:Time to load utils op: 3.540778160095215 seconds
[default3]:Loading extension module utils...
[default1]:Loading extension module utils...
[default0]:Time to load utils op: 3.4584176540374756 seconds
[default3]:Time to load utils op: 3.4843850135803223 seconds
[default1]:Time to load utils op: 3.4875969886779785 seconds
[default2]:Time to load utils op: 3.4816482067108154 seconds
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 3.0704259872436523 seconds
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 3.086721420288086 seconds
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 3.700429677963257 seconds
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 3.710752010345459 seconds
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 3.744744300842285 seconds
[default3]:Time to load utils op: 3.078245162963867 seconds
[default1]:Time to load utils op: 3.0684866905212402 seconds
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 3.0580742359161377 seconds
[default1]:Loading extension module utils...
[default0]:Loading extension module utils...
[default3]:Loading extension module utils...
[default3]:Loading extension module utils...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 3.048921585083008 seconds
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 3.0420076847076416 seconds
[default1]:Loading extension module utils...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 3.076880931854248 seconds
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 3.08874249458313 seconds
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 3.058614492416382 seconds
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 3.0675013065338135 seconds
[default1]:Time to load utils op: 3.087080955505371 seconds
[default0]:Time to load utils op: 3.1161599159240723 seconds
[default3]:Time to load utils op: 3.0791430473327637 seconds
[default3]:Time to load utils op: 3.067265748977661 seconds
[default1]:Time to load utils op: 3.1012117862701416 seconds
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 3.0532052516937256 seconds
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 3.034970998764038 seconds
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 3.0673651695251465 seconds
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 3.064197063446045 seconds
[default2]:Loading extension module utils...
[default0]:Loading extension module utils...
[default1]:Loading extension module utils...
[default0]:Loading extension module utils...
[default2]:Loading extension module utils...
[default0]:Loading extension module utils...
[default1]:Loading extension module utils...
[default3]:Loading extension module utils...
[default2]:Loading extension module utils...
[default3]:Loading extension module utils...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 3.053074836730957 seconds
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 3.07812762260437 seconds
[default3]:Loading extension module utils...
[default2]:Loading extension module utils...
[default0]:Loading extension module utils...
[default1]:Loading extension module utils...
[default2]:Time to load utils op: 3.1083192825317383 seconds
[default0]:Time to load utils op: 3.0890166759490967 seconds
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 3.4974868297576904 seconds
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 3.5163700580596924 seconds
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 3.5064196586608887 seconds
[default0]:Time to load utils op: 3.5478827953338623 seconds
[default2]:Time to load utils op: 3.553959369659424 seconds
[default0]:Time to load utils op: 3.5801613330841064 seconds
[default1]:Time to load utils op: 3.5914361476898193 seconds
[default3]:Time to load utils op: 3.5891945362091064 seconds
[default1]:Time to load utils op: 3.5628247261047363 seconds
[default2]:Time to load utils op: 3.5666933059692383 seconds
[default0]:Time to load utils op: 3.5629091262817383 seconds
[default3]:Time to load utils op: 3.577826499938965 seconds
[default3]:Time to load utils op: 3.5693857669830322 seconds
[default1]:Time to load utils op: 3.5603389739990234 seconds
[default2]:Time to load utils op: 3.592404842376709 seconds
[default1]:Rank: 1 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 25 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 19 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 18 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 16 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 17 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 44 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 45 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 46 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 47 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 23 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 14 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 6 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 38 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 21 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 11 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 10 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 22 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 13 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 12 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 37 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 28 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 29 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 8 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 62 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 63 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 4 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 7 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 35 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 20 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 31 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 39 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 3 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 30 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 59 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 9 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 36 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 32 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 33 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 15 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 58 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 2 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 54 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 55 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 5 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 61 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 60 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 0 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 34 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 48 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 49 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 57 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 56 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 42 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 53 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 43 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 52 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 51 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 50 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 40 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default1]:Rank: 41 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default0]:Rank: 24 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Rank: 26 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default3]:Rank: 27 partition count [64, 64] and sizes[(160571392, False), (41728, False)] 
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.02174854278564453 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.05011606216430664 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.04482221603393555 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.028604507446289062 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.04520606994628906 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.050384521484375 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.04487490653991699 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.008160829544067383 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.024631738662719727 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.01766037940979004 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.013078689575195312 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.00922083854675293 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.021938800811767578 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.02684640884399414 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.0234982967376709 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.04681873321533203 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.028309345245361328 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.04678702354431152 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.041358232498168945 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.031037569046020508 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.03802776336669922 seconds
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.03360295295715332 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.036203622817993164 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.03537178039550781 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.021239280700683594 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.008727788925170898 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.029455900192260742 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.04152083396911621 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.04163622856140137 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.028151988983154297 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.05821871757507324 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.005243778228759766 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.03272509574890137 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.04197812080383301 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.03812408447265625 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.02455925941467285 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.06333255767822266 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.0334630012512207 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.0170745849609375 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.03798937797546387 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.029290199279785156 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.03457999229431152 seconds
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.032895565032958984 seconds
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.0486454963684082 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.01989889144897461 seconds
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.027706146240234375 seconds
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.007190704345703125 seconds
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.06445693969726562 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.06672906875610352 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.005501747131347656 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.06216144561767578 seconds
[default3]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.02790546417236328 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.011572122573852539 seconds
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.04462027549743652 seconds
[default0]:[2023-04-24 08:07:58,744] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[default0]:[2023-04-24 08:07:58,783] [INFO] [utils.py:786:see_memory_usage] MA 19.75 GB         Max_MA 19.75 GB         CA 19.76 GB         Max_CA 20 GB 
[default0]:[2023-04-24 08:07:58,783] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 16.84 GB, percent = 3.3%
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.03764963150024414 seconds
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.03740358352661133 seconds
[default1]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.03893709182739258 seconds
[default2]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.022301197052001953 seconds
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.03327775001525879 seconds
[default1]:No modifications detected for re-loaded extension module utils, skipping build step...
[default1]:Loading extension module utils...
[default1]:Time to load utils op: 0.038579463958740234 seconds
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.03372764587402344 seconds
[default2]:No modifications detected for re-loaded extension module utils, skipping build step...
[default2]:Loading extension module utils...
[default2]:Time to load utils op: 0.03300189971923828 seconds
[default3]:No modifications detected for re-loaded extension module utils, skipping build step...
[default3]:Loading extension module utils...
[default3]:Time to load utils op: 0.03814220428466797 seconds
[default0]:[2023-04-24 08:07:58,868] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[default0]:[2023-04-24 08:07:58,869] [INFO] [utils.py:786:see_memory_usage] MA 20.94 GB         Max_MA 21.54 GB         CA 21.56 GB         Max_CA 22 GB 
[default0]:[2023-04-24 08:07:58,869] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 16.84 GB, percent = 3.3%
[default0]:[2023-04-24 08:07:58,869] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[default0]:[2023-04-24 08:07:58,967] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[default0]:[2023-04-24 08:07:58,967] [INFO] [utils.py:786:see_memory_usage] MA 20.94 GB         Max_MA 20.94 GB         CA 21.56 GB         Max_CA 22 GB 
[default0]:[2023-04-24 08:07:58,967] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 16.84 GB, percent = 3.3%
[default0]:[2023-04-24 08:07:58,968] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[default0]:[2023-04-24 08:07:58,968] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[default0]:[2023-04-24 08:07:58,968] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x1471c6b3a380>
[default0]:[2023-04-24 08:07:58,969] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001, 0.0001], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-04-24 08:07:59,002] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   activation_checkpointing_config  {
[default0]:    "partition_activations": false, 
[default0]:    "contiguous_memory_optimization": false, 
[default0]:    "cpu_checkpointing": false, 
[default0]:    "number_checkpoints": null, 
[default0]:    "synchronize_checkpoint_boundary": false, 
[default0]:    "profile": false
[default0]:}
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   amp_enabled .................. False
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   amp_params ................... False
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   autotuning_config ............ {
[default0]:    "enabled": false, 
[default0]:    "start_step": null, 
[default0]:    "end_step": null, 
[default0]:    "metric_path": null, 
[default0]:    "arg_mappings": null, 
[default0]:    "metric": "throughput", 
[default0]:    "model_info": null, 
[default0]:    "results_dir": "autotuning_results", 
[default0]:    "exps_dir": "autotuning_exps", 
[default0]:    "overwrite": true, 
[default0]:    "fast": true, 
[default0]:    "start_profile_step": 3, 
[default0]:    "end_profile_step": 5, 
[default0]:    "tuner_type": "gridsearch", 
[default0]:    "tuner_early_stopping": 5, 
[default0]:    "tuner_num_trials": 50, 
[default0]:    "model_info_path": null, 
[default0]:    "mp_size": 1, 
[default0]:    "max_train_batch_size": null, 
[default0]:    "min_train_batch_size": 1, 
[default0]:    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[default0]:    "min_train_micro_batch_size_per_gpu": 1, 
[default0]:    "num_tuning_micro_batch_sizes": 3
[default0]:}
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1471c67255d0>
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   communication_data_type ...... None
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[default0]:[2023-04-24 08:07:59,003] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   disable_allgather ............ False
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   dump_state ................... False
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 500, 'delayed_shift': 2, 'min_scale': 1}
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[default0]:[2023-04-24 08:07:59,004] [INFO] [config.py:957:print]   flops_profiler_config ........ {
[default0]:    "enabled": false, 
[default0]:    "profile_step": 1, 
[default0]:    "module_depth": -1, 
[default0]:    "top_modules": 1, 
[default0]:    "detailed": true, 
[default0]:    "output_file": null
[default0]:}
[default0]:[2023-04-24 08:07:59,005] [INFO] [config.py:957:print]   fp16_auto_cast ............... False
[default0]:[2023-04-24 08:07:59,005] [INFO] [config.py:957:print]   fp16_enabled ................. True
[default0]:[2023-04-24 08:07:59,005] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[default0]:[2023-04-24 08:07:59,005] [INFO] [config.py:957:print]   global_rank .................. 0
[default0]:[2023-04-24 08:07:59,005] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[default0]:[2023-04-24 08:07:59,005] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[default0]:[2023-04-24 08:07:59,005] [INFO] [config.py:957:print]   gradient_clipping ............ 1
[default0]:[2023-04-24 08:07:59,005] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[default3]:[2023-04-24 08:07:59,128] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,128] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,129] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,129] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,139] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,150] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,139] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,149] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,128] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,138] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,161] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,128] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,150] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,161] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,129] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,150] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,139] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,139] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,150] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,128] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,159] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,156] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,128] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,139] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,149] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,167] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,128] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,172] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,160] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,128] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,150] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,114] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[default0]:[2023-04-24 08:07:59,114] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 4096
[default0]:[2023-04-24 08:07:59,114] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[default0]:[2023-04-24 08:07:59,114] [INFO] [config.py:957:print]   loss_scale ................... 0
[default0]:[2023-04-24 08:07:59,114] [INFO] [config.py:957:print]   memory_breakdown ............. False
[default0]:[2023-04-24 08:07:59,114] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[default0]:[2023-04-24 08:07:59,114] [INFO] [config.py:957:print]   nebula_config ................ {
[default0]:    "enabled": false, 
[default0]:    "persistent_storage_path": null, 
[default0]:    "persistent_time_interval": 100, 
[default0]:    "num_of_version_in_retention": 2, 
[default0]:    "enable_nebula_load": true, 
[default0]:    "load_path": null
[default0]:}
[default0]:[2023-04-24 08:07:59,114] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[default0]:[2023-04-24 08:07:59,114] [INFO] [config.py:957:print]   optimizer_name ............... None
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   optimizer_params ............. None
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   pld_enabled .................. False
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   pld_params ................... False
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   prescale_gradients ........... False
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   scheduler_name ............... None
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   scheduler_params ............. None
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   sparse_attention ............. None
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   steps_per_print .............. 2000
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   train_batch_size ............. 64
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  1
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   world_size ................... 64
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[default0]:[2023-04-24 08:07:59,115] [INFO] [config.py:957:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[default0]:[2023-04-24 08:07:59,116] [INFO] [config.py:957:print]   zero_enabled ................. True
[default0]:[2023-04-24 08:07:59,116] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[default0]:[2023-04-24 08:07:59,116] [INFO] [config.py:957:print]   zero_optimization_stage ...... 2
[default0]:[2023-04-24 08:07:59,116] [INFO] [config.py:943:print_user_config]   json = {
[default0]:    "train_micro_batch_size_per_gpu": 1, 
[default0]:    "train_batch_size": 64, 
[default0]:    "gradient_clipping": 1, 
[default0]:    "zero_optimization": {
[default0]:        "stage": 2, 
[default0]:        "contiguous_gradients": true, 
[default0]:        "overlap_comm": true, 
[default0]:        "reduce_scatter": true, 
[default0]:        "reduce_bucket_size": 5.000000e+08, 
[default0]:        "allgather_bucket_size": 5.000000e+08
[default0]:    }, 
[default0]:    "fp16": {
[default0]:        "enabled": true, 
[default0]:        "loss_scale": 0, 
[default0]:        "loss_scale_window": 500, 
[default0]:        "hysteresis": 2, 
[default0]:        "min_loss_scale": 1, 
[default0]:        "initial_scale_power": 12
[default0]:    }, 
[default0]:    "steps_per_print": 2.000000e+03, 
[default0]:    "wall_clock_breakdown": false
[default0]:}
[default0]:Using /pc2/users/n/nikit/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
[default0]:No modifications detected for re-loaded extension module utils, skipping build step...
[default0]:Loading extension module utils...
[default0]:Time to load utils op: 0.0010035037994384766 seconds
[default0]:[2023-04-24 08:07:59,139] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:WARNING: could not find the metadata file checkpoints/gpt2-10b-dist-2023-04-24_080429 
[default0]:    will not load any checkpoints and will start from random
[default3]:[2023-04-24 08:07:59,172] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,139] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,188] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,148] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,149] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,160] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,128] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,129] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,139] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,161] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,139] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,128] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,138] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,150] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,161] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,129] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,139] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,129] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,150] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,161] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,148] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,160] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,137] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,159] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,171] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,149] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,165] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:[2023-04-24 08:07:59,144] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:[2023-04-24 08:07:59,154] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default1]:[2023-04-24 08:07:59,148] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,159] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default2]:[2023-04-24 08:07:59,160] [WARNING] [engine.py:2535:load_checkpoint] Unable to find latest file at checkpoints/gpt2-10b-dist-2023-04-24_080429/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default3]:time (ms) | load-checkpoint: 75.33
[default0]:[after model, optimizer, and learning rate scheduler are built] datetime: 2023-04-24 08:07:59 
[default0]:> building train, validation, and test datasets ...
[default0]: > datasets target sizes (minimum size):
[default0]:    train:      1000000
[default0]:    validation: 200320
[default0]:    test:       640
[default0]:> building train, validation, and test datasets for GPT ...
[default0]: > building dataset index ...
[default0]:    reading sizes...
[default0]:    reading pointers...
[default0]:    reading document index...
[default0]:    creating numpy buffer of mmap...
[default0]:    creating memory view of numpy buffer...
[default0]: > finished creating indexed dataset in 0.099217 seconds
[default0]:    number of documents: 10000
[default0]: > dataset split:
[default0]:    train:
[default0]:     document indices in [0, 9690) total of 9690 documents
[default0]:    validation:
[default0]:     document indices in [9690, 9990) total of 300 documents
[default0]:    test:
[default0]:     document indices in [9990, 10000) total of 10 documents
[default3]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:NCCL version 2.12.12+cuda11.7
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Connected all rings
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO Connected all trees
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Channel 31/32 :    0
[default0]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 13/32 :    0
[default0]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default1]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default3]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:NCCL version 2.12.12+cuda11.7
[default0]:NCCL version 2.12.12+cuda11.7
[default2]:NCCL version 2.12.12+cuda11.7
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Connected all rings
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO Connected all trees
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Connected all rings
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO Connected all trees
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Connected all rings
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO Connected all trees
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Connected all rings
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO Connected all trees
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Connected all rings
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO Connected all trees
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Connected all rings
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO Connected all trees
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Connected all rings
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO Connected all trees
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Connected all rings
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO Connected all trees
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Connected all rings
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO Connected all trees
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Connected all rings
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO Connected all trees
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Connected all rings
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO Connected all trees
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Connected all rings
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO Connected all trees
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1221:160028:160277 [1] NCCL INFO comm 0x14910c0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Connected all rings
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO Connected all trees
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1221:160029:160281 [2] NCCL INFO comm 0x14cc2c0090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1219:266891:267127 [3] NCCL INFO comm 0x14fd000090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1219:266888:267133 [0] NCCL INFO comm 0x14e5e00090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1219:266889:267129 [1] NCCL INFO comm 0x145c4c0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1219:266890:267131 [2] NCCL INFO comm 0x1491ac0090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Connected all rings
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO Connected all trees
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Connected all rings
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO Connected all trees
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Connected all rings
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO Connected all trees
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Connected all rings
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO Connected all trees
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Connected all rings
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO Connected all trees
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Connected all rings
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO Connected all trees
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Connected all rings
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO Connected all trees
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Connected all rings
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO Connected all trees
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Connected all rings
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO Connected all trees
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1201:986609:987350 [2] NCCL INFO comm 0x14add00090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1201:986608:987346 [1] NCCL INFO comm 0x147fac0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Connected all rings
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO Connected all trees
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1201:986607:987352 [0] NCCL INFO comm 0x1470700090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_1000000ns_1024sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_1000000ns_1024sl_42s_sample_idx.npy
[default3]:n2gpu1201:986610:987348 [3] NCCL INFO comm 0x14e9c40090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Connected all rings
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO Connected all trees
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1224:124662:124898 [3] NCCL INFO comm 0x14cac40090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1224:124661:124892 [2] NCCL INFO comm 0x151fb00090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Connected all rings
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO Connected all trees
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1224:124659:124896 [0] NCCL INFO comm 0x14956c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1224:124660:124894 [1] NCCL INFO comm 0x14f35c0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Connected all rings
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO Connected all trees
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Connected all rings
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO Connected all trees
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Connected all rings
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO Connected all trees
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Connected all rings
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO Connected all trees
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Connected all rings
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO Connected all trees
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Connected all rings
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO Connected all trees
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Connected all rings
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO Connected all trees
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Connected all rings
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO Connected all trees
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Connected all rings
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO Connected all trees
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Connected all rings
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO Connected all trees
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1220:386661:386904 [1] NCCL INFO comm 0x14fdd40090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Connected all rings
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO Connected all trees
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1220:386662:386906 [2] NCCL INFO comm 0x1546a80090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1220:386660:386900 [0] NCCL INFO comm 0x1513240090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Connected all rings
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO Connected all trees
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1220:386663:386902 [3] NCCL INFO comm 0x14b0f00090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Connected all rings
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO Connected all trees
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1210:144013:144247 [2] NCCL INFO comm 0x1523c80090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Connected all rings
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO Connected all trees
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Connected all rings
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO Connected all trees
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Connected all rings
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO Connected all trees
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1209:136000:136237 [3] NCCL INFO comm 0x15144c0090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Connected all rings
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO Connected all trees
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1209:135998:136239 [1] NCCL INFO comm 0x1531f00090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1221:160027:160283 [0] NCCL INFO comm 0x1454100090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1221:160030:160279 [3] NCCL INFO comm 0x1487280090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1222:147026:147270 [1] NCCL INFO comm 0x150f080090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Connected all rings
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO Connected all trees
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1204:138139:138382 [3] NCCL INFO comm 0x150da80090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1204:138136:138376 [0] NCCL INFO comm 0x14ecb80090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1204:138138:138378 [2] NCCL INFO comm 0x1490940090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1204:138137:138380 [1] NCCL INFO comm 0x14ff400090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Connected all rings
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO Connected all trees
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1202:1130093:1130339 [0] NCCL INFO comm 0x1537280090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Connected all rings
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO Connected all trees
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1202:1130095:1130341 [2] NCCL INFO comm 0x152b300090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Connected all rings
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO Connected all trees
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1202:1130094:1130337 [1] NCCL INFO comm 0x1490580090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1202:1130096:1130335 [3] NCCL INFO comm 0x14d9d00090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1222:147027:147276 [2] NCCL INFO comm 0x14fd900090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Connected all rings
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO Connected all trees
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Connected all rings
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO Connected all trees
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Connected all rings
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO Connected all trees
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Connected all rings
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO Connected all trees
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1206:143434:143674 [2] NCCL INFO comm 0x14fa400090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1206:143435:143672 [3] NCCL INFO comm 0x1468400090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1206:143433:143676 [1] NCCL INFO comm 0x1488640090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1206:143432:143678 [0] NCCL INFO comm 0x14d9b80090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1222:147025:147272 [0] NCCL INFO comm 0x154f5c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1222:147028:147274 [3] NCCL INFO comm 0x1509a00090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1205:143297:143531 [0] NCCL INFO comm 0x14e0980090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_train_indexmap_1000000ns_1024sl_42s_shuffle_idx.npy
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1229:174604:174837 [0] NCCL INFO comm 0x1534f40090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Connected all rings
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO Connected all trees
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1229:174606:174841 [2] NCCL INFO comm 0x1481800090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1229:174605:174839 [1] NCCL INFO comm 0x1539280090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1205:143300:143533 [3] NCCL INFO comm 0x1528340090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1205:143298:143535 [1] NCCL INFO comm 0x15505c0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1205:143299:143529 [2] NCCL INFO comm 0x14e4640090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Connected all rings
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Connected all rings
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO Connected all trees
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Connected all rings
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO Connected all trees
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1229:174607:174843 [3] NCCL INFO comm 0x14c4000090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Connected all rings
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO Connected all trees
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1227:190532:190765 [3] NCCL INFO comm 0x147c500090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Connected all rings
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO Connected all trees
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Connected all rings
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO Connected all trees
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Connected all rings
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO Connected all trees
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Connected all rings
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO Connected all trees
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1209:135999:136241 [2] NCCL INFO comm 0x14665c0090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Connected all rings
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO Connected all trees
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Connected all rings
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO Connected all trees
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1210:144011:144249 [0] NCCL INFO comm 0x151cf80090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1209:135997:136243 [0] NCCL INFO comm 0x14abe00090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Connected all rings
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO Connected all trees
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1227:190529:190769 [0] NCCL INFO comm 0x14777c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1227:190531:190767 [2] NCCL INFO comm 0x149d340090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Connected all rings
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO Connected all trees
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1227:190530:190771 [1] NCCL INFO comm 0x14ee680090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1207:144619:144851 [1] NCCL INFO comm 0x1545740090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1207:144620:144853 [2] NCCL INFO comm 0x14e0100090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1207:144618:144855 [0] NCCL INFO comm 0x149ea00090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1207:144621:144857 [3] NCCL INFO comm 0x1455240090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1230:125963:126202 [1] NCCL INFO comm 0x148a380090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1230:125962:126206 [0] NCCL INFO comm 0x150c9c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1230:125965:126204 [3] NCCL INFO comm 0x14dbf80090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1230:125964:126208 [2] NCCL INFO comm 0x14f5300090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:    loaded indexed file in 0.172 seconds
[default0]:    total number of samples: 1014027
[default0]:    total number of epochs: 36
[default3]:n2gpu1210:144014:144251 [3] NCCL INFO comm 0x1469980090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1210:144012:144253 [1] NCCL INFO comm 0x14f1200090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_200320ns_1024sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_200320ns_1024sl_42s_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_valid_indexmap_200320ns_1024sl_42s_shuffle_idx.npy
[default0]:    loaded indexed file in 0.115 seconds
[default0]:    total number of samples: 200380
[default0]:    total number of epochs: 219
[default0]: > WARNING: could not find index map files, building the indices on rank 0 ...
[default0]: > last epoch number of samples (5) is smaller than 80% of number of samples per epoch (31), setting separate_last_epoch to True
[default0]: > elasped time to build and save doc-idx mapping (seconds): 0.033639
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default0]:    using:
[default0]:     number of documents:       10
[default0]:     number of epochs:          21
[default0]:     sequence length:           1024
[default0]:     total number of samples:   667
[default0]: > elasped time to build and save sample-idx mapping (seconds): 0.329423
[default0]: > building shuffle index with split [0, 635) and [635, 667) ...
[default0]: > elasped time to build and save shuffle-idx mapping (seconds): 0.001976
[default0]: > loading doc-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_640ns_1024sl_42s_doc_idx.npy
[default0]: > loading sample-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_640ns_1024sl_42s_sample_idx.npy
[default0]: > loading shuffle-idx mapping from data/meg-gpt2-oscar-en-10k_text_document_test_indexmap_640ns_1024sl_42s_shuffle_idx.npy
[default0]:    loaded indexed file in 0.004 seconds
[default0]:    total number of samples: 668
[default0]:    total number of epochs: 21
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default0]:> finished creating GPT datasets ...
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default1]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default1]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default3]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default3]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default0]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default0]:  warnings.warn(_create_warning_msg(
[default2]:/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[default2]:  warnings.warn(_create_warning_msg(
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Connected all rings
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO Connected all trees
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Connected all rings
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO Connected all trees
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Connected all rings
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO Connected all trees
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Connected all rings
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO Connected all trees
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Connected all rings
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO Connected all trees
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Connected all rings
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO Connected all trees
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Connected all rings
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO Connected all trees
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Connected all rings
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO Connected all trees
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Connected all rings
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO Connected all trees
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Connected all rings
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO Connected all trees
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Connected all rings
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO Connected all trees
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Connected all rings
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO Connected all trees
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Connected all rings
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO Connected all trees
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Connected all rings
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO Connected all trees
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Connected all rings
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO Connected all trees
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Connected all rings
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO Connected all trees
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Connected all rings
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO Connected all trees
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Connected all rings
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO Connected all trees
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Connected all rings
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO Connected all trees
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Connected all rings
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO Connected all trees
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Connected all rings
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO Connected all trees
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Connected all rings
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO Connected all trees
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Connected all rings
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO Connected all trees
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Connected all rings
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO Connected all trees
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Connected all rings
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO Connected all trees
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Connected all rings
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO Connected all trees
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Connected all rings
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO Connected all trees
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Connected all rings
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO Connected all trees
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Connected all rings
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO Connected all trees
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Connected all rings
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO Connected all trees
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Connected all rings
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO Connected all trees
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Connected all rings
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO Connected all trees
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Connected all rings
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO Connected all trees
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 00/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 01/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 02/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 03/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 04/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 05/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 06/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 07/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 08/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 09/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 10/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 12/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 13/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 14/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 15/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 16/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 17/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 18/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 19/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 20/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 21/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 22/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 23/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 24/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 25/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 26/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 27/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 28/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 29/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 30/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Channel 31/32 :    0
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Connected all rings
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO Connected all trees
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 00/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 01/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 02/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 03/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 04/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 05/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 06/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 07/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 08/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 09/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 10/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 11/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 12/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 14/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 15/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 16/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 17/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 18/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 19/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 20/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 21/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 22/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 23/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 24/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 25/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 26/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 27/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 28/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 29/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 30/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Channel 31/32 :    0
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Connected all rings
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO Connected all trees
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 00/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 01/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 02/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 03/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 04/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 05/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 06/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 07/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 09/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 10/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 11/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 12/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 13/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 14/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 15/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 16/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 17/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 18/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 19/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 20/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 21/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 22/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 23/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 24/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 25/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 26/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 28/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 29/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 30/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Channel 31/32 :    0
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Connected all rings
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO Connected all trees
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Connected all rings
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO Connected all trees
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Connected all rings
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO Connected all trees
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Connected all rings
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO Connected all trees
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Connected all rings
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO Connected all trees
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1221:160029:160293 [2] NCCL INFO comm 0x14cc240090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Connected all rings
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO Connected all trees
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1204:138139:138394 [3] NCCL INFO comm 0x150da00090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 11/32 :    0
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Connected all rings
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO Connected all trees
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Connected all rings
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO Connected all trees
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Connected all rings
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO Connected all trees
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1219:266890:267147 [2] NCCL INFO comm 0x1491a40090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 13/32 :    0
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Connected all rings
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO Connected all trees
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Connected all rings
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO Connected all trees
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1229:174604:174859 [0] NCCL INFO comm 0x1534f00090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Connected all rings
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO Connected all trees
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1229:174606:174857 [2] NCCL INFO comm 0x1481780090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Connected all rings
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO Connected all trees
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 27/32 :    0
[default1]:n2gpu1229:174605:174853 [1] NCCL INFO comm 0x1539200090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Connected all rings
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO Connected all trees
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1229:174607:174855 [3] NCCL INFO comm 0x14c3f80090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Connected all rings
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO Connected all trees
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Connected all rings
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO Connected all trees
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Connected all rings
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO Connected all trees
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Connected all rings
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO Connected all trees
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default2]:n2gpu1202:1130095:1130351 [2] NCCL INFO comm 0x152b280090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1204:138136:138398 [0] NCCL INFO comm 0x14ecb40090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1204:138138:138392 [2] NCCL INFO comm 0x14908c0090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1227:190530:190783 [1] NCCL INFO comm 0x14ee600090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1227:190531:190781 [2] NCCL INFO comm 0x149d380090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1227:190532:190785 [3] NCCL INFO comm 0x147c480090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Connected all rings
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Connected all rings
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO Connected all trees
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1230:125963:126218 [1] NCCL INFO comm 0x148a300090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1230:125964:126224 [2] NCCL INFO comm 0x14f5280090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1230:125965:126222 [3] NCCL INFO comm 0x14dbf00090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Connected all rings
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO Connected all trees
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1230:125962:126220 [0] NCCL INFO comm 0x150c940090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1224:124661:124912 [2] NCCL INFO comm 0x151fa80090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1224:124662:124908 [3] NCCL INFO comm 0x14cabc0090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Connected all rings
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO Connected all trees
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1224:124659:124914 [0] NCCL INFO comm 0x1495680090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1224:124660:124910 [1] NCCL INFO comm 0x14f3540090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Connected all rings
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO Connected all trees
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1207:144618:144873 [0] NCCL INFO comm 0x149e9c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Connected all rings
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO Connected all trees
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1207:144619:144867 [1] NCCL INFO comm 0x15456c0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1207:144620:144871 [2] NCCL INFO comm 0x14e0080090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1207:144621:144869 [3] NCCL INFO comm 0x14551c0090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1206:143434:143690 [2] NCCL INFO comm 0x14fa380090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1206:143435:143692 [3] NCCL INFO comm 0x1468380090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1206:143433:143688 [1] NCCL INFO comm 0x14885c0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 08/32 :    0
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Connected all rings
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO Connected all trees
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1220:386661:386918 [1] NCCL INFO comm 0x14fdcc0090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Connected all rings
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO Connected all trees
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default3]:n2gpu1220:386663:386920 [3] NCCL INFO comm 0x14b0e80090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default3]:n2gpu1222:147028:147290 [3] NCCL INFO comm 0x1509980090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1222:147025:147292 [0] NCCL INFO comm 0x154f580090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Connected all rings
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO Connected all trees
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1206:143432:143694 [0] NCCL INFO comm 0x14d9b40090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Connected all rings
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO Connected all trees
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default1]:n2gpu1205:143298:143549 [1] NCCL INFO comm 0x1550540090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1205:143297:143551 [0] NCCL INFO comm 0x14e0940090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1205:143300:143545 [3] NCCL INFO comm 0x15282c0090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1205:143299:143547 [2] NCCL INFO comm 0x14e45c0090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default3]:n2gpu1210:144014:144266 [3] NCCL INFO comm 0x1469900090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1210:144013:144264 [2] NCCL INFO comm 0x1523c00090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default1]:n2gpu1210:144012:144268 [1] NCCL INFO comm 0x14f1180090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Connected all rings
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO Connected all trees
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1210:144011:144270 [0] NCCL INFO comm 0x151cf40090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1209:136000:136255 [3] NCCL INFO comm 0x1514440090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default2]:n2gpu1209:135999:136253 [2] NCCL INFO comm 0x1466600090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1209:135997:136259 [0] NCCL INFO comm 0x14abdc0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1209:135998:136257 [1] NCCL INFO comm 0x1531e80090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1201:986608:987366 [1] NCCL INFO comm 0x147fa40090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1201:986609:987370 [2] NCCL INFO comm 0x14adc80090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1201:986607:987368 [0] NCCL INFO comm 0x1470680090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1201:986610:987364 [3] NCCL INFO comm 0x14e9bc0090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1221:160028:160295 [1] NCCL INFO comm 0x1491040090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default0]:n2gpu1221:160027:160299 [0] NCCL INFO comm 0x14540c0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1221:160030:160297 [3] NCCL INFO comm 0x1487200090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1202:1130093:1130357 [0] NCCL INFO comm 0x1537240090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default3]:n2gpu1202:1130096:1130355 [3] NCCL INFO comm 0x14d9c80090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default1]:n2gpu1202:1130094:1130353 [1] NCCL INFO comm 0x1490500090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1222:147026:147286 [1] NCCL INFO comm 0x150f000090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default1]:n2gpu1204:138137:138396 [1] NCCL INFO comm 0x14ff380090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default3]:n2gpu1219:266891:267145 [3] NCCL INFO comm 0x14fcf80090d0 rank 0 nranks 1 cudaDev 3 busId c4000 - Init COMPLETE
[default0]:n2gpu1219:266888:267149 [0] NCCL INFO comm 0x14e5dc0090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default1]:n2gpu1219:266889:267143 [1] NCCL INFO comm 0x145c440090d0 rank 0 nranks 1 cudaDev 1 busId 44000 - Init COMPLETE
[default2]:n2gpu1222:147027:147288 [2] NCCL INFO comm 0x14fd880090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:n2gpu1227:190529:190787 [0] NCCL INFO comm 0x1477780090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1220:386660:386922 [0] NCCL INFO comm 0x1513200090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default2]:n2gpu1220:386662:386916 [2] NCCL INFO comm 0x1546a00090d0 rank 0 nranks 1 cudaDev 2 busId 84000 - Init COMPLETE
[default0]:[after dataloaders are built] datetime: 2023-04-24 08:08:26 
[default0]:done with setup ...
[default0]:training ...
[default3]:time (ms) | model-and-optimizer-setup: 137566.75 | train/valid/test-data-iterators-setup: 26519.18
[default0]:[before the start of training step] datetime: 2023-04-24 08:08:26 
[default0]:[2023-04-24 08:08:26,629] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[default0]:[2023-04-24 08:08:26,629] [INFO] [checkpointing.py:530:forward] ----Partition Activations True, CPU CHECKPOINTING False
[default0]:[2023-04-24 08:08:26,629] [INFO] [checkpointing.py:531:forward] ----contiguous Memory Checkpointing False with 50 total layers
[default0]:[2023-04-24 08:08:26,629] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[default0]:[2023-04-24 08:08:26,629] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
[default0]:[Rank 0] (after 1 iterations) memory (MB) | allocated: 21445.1669921875 | max allocated: 24628.20068359375 | reserved: 26724.0 | max reserved: 26724.0
[default3]: iteration        1/   15625 | consumed samples:           64 | consumed tokens:        65536 | elapsed time per iteration (ms): 118103.3 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 1.167508E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.542 | TFLOPs: 0.74 |
[default3]:time (ms) | forward-compute: 5882.87 | backward-compute: 96444.91 | backward-embedding-all-reduce: 0.01 | optimizer: 15572.40 | batch-generator: 1.12
[default3]: iteration        2/   15625 | consumed samples:          128 | consumed tokens:       131072 | elapsed time per iteration (ms): 111219.7 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 2.418701E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.575 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 901.67 | backward-compute: 94939.29 | backward-embedding-all-reduce: 0.01 | optimizer: 15345.99 | batch-generator: 0.54
[default3]: iteration        3/   15625 | consumed samples:          192 | consumed tokens:       196608 | elapsed time per iteration (ms): 114039.9 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 2.008672E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.561 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 929.13 | backward-compute: 97123.32 | backward-embedding-all-reduce: 0.01 | optimizer: 15280.10 | batch-generator: 0.56
[default3]: iteration        4/   15625 | consumed samples:          256 | consumed tokens:       262144 | elapsed time per iteration (ms): 115998.5 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 1.484239E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.552 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 861.30 | backward-compute: 99241.22 | backward-embedding-all-reduce: 0.01 | optimizer: 15868.32 | batch-generator: 0.55
[default3]: iteration        5/   15625 | consumed samples:          320 | consumed tokens:       327680 | elapsed time per iteration (ms): 115562.4 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 1.382723E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.554 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 1017.99 | backward-compute: 98609.52 | backward-embedding-all-reduce: 0.01 | optimizer: 15650.61 | batch-generator: 0.52
[default3]: iteration        6/   15625 | consumed samples:          384 | consumed tokens:       393216 | elapsed time per iteration (ms): 114601.5 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 1.373531E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.558 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 978.50 | backward-compute: 98218.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15342.95 | batch-generator: 0.53
[default3]: iteration        7/   15625 | consumed samples:          448 | consumed tokens:       458752 | elapsed time per iteration (ms): 115580.6 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 1.247599E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.554 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 1625.02 | backward-compute: 97490.19 | backward-embedding-all-reduce: 0.01 | optimizer: 16401.81 | batch-generator: 0.52
[default3]: iteration        8/   15625 | consumed samples:          512 | consumed tokens:       524288 | elapsed time per iteration (ms): 113876.3 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 1.182641E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.562 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 925.45 | backward-compute: 96764.49 | backward-embedding-all-reduce: 0.01 | optimizer: 15589.22 | batch-generator: 0.53
[default3]: iteration        9/   15625 | consumed samples:          576 | consumed tokens:       589824 | elapsed time per iteration (ms): 112239.0 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 1.135963E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.570 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 825.17 | backward-compute: 96183.39 | backward-embedding-all-reduce: 0.01 | optimizer: 15106.74 | batch-generator: 0.56
[default3]: iteration       10/   15625 | consumed samples:          640 | consumed tokens:       655360 | elapsed time per iteration (ms): 116437.1 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 1.104672E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.550 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 982.98 | backward-compute: 99350.87 | backward-embedding-all-reduce: 0.01 | optimizer: 15681.10 | batch-generator: 0.52
[default3]: iteration       11/   15625 | consumed samples:          704 | consumed tokens:       720896 | elapsed time per iteration (ms): 115816.8 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 1.050697E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.553 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 1386.62 | backward-compute: 98861.73 | backward-embedding-all-reduce: 0.01 | optimizer: 15540.71 | batch-generator: 0.55
[default3]: iteration       12/   15625 | consumed samples:          768 | consumed tokens:       786432 | elapsed time per iteration (ms): 114572.5 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 1.008404E+01 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.559 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 2042.71 | backward-compute: 96502.26 | backward-embedding-all-reduce: 0.01 | optimizer: 15396.86 | batch-generator: 0.56
[default3]: iteration       13/   15625 | consumed samples:          832 | consumed tokens:       851968 | elapsed time per iteration (ms): 112967.7 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 9.610989E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.567 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 743.08 | backward-compute: 96564.32 | backward-embedding-all-reduce: 0.01 | optimizer: 15608.23 | batch-generator: 0.54
[default3]: iteration       14/   15625 | consumed samples:          896 | consumed tokens:       917504 | elapsed time per iteration (ms): 112899.6 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 9.238810E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.567 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 856.23 | backward-compute: 96486.29 | backward-embedding-all-reduce: 0.01 | optimizer: 15522.17 | batch-generator: 0.61
[default3]: iteration       15/   15625 | consumed samples:          960 | consumed tokens:       983040 | elapsed time per iteration (ms): 116229.1 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 8.795648E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.551 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 1154.95 | backward-compute: 99527.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15492.90 | batch-generator: 0.55
[default3]: iteration       16/   15625 | consumed samples:         1024 | consumed tokens:      1048576 | elapsed time per iteration (ms): 116785.1 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 8.585999E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.548 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 1230.24 | backward-compute: 99836.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15461.58 | batch-generator: 0.52
[default3]: iteration       17/   15625 | consumed samples:         1088 | consumed tokens:      1114112 | elapsed time per iteration (ms): 113710.7 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 8.812325E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.563 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1625.62 | backward-compute: 96595.34 | backward-embedding-all-reduce: 0.01 | optimizer: 15456.13 | batch-generator: 0.54
[default3]: iteration       18/   15625 | consumed samples:         1152 | consumed tokens:      1179648 | elapsed time per iteration (ms): 114104.2 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 8.485920E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.561 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1813.35 | backward-compute: 96651.28 | backward-embedding-all-reduce: 0.01 | optimizer: 15599.10 | batch-generator: 0.53
[default3]: iteration       19/   15625 | consumed samples:         1216 | consumed tokens:      1245184 | elapsed time per iteration (ms): 115898.4 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 8.137253E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.552 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 1433.47 | backward-compute: 98671.29 | backward-embedding-all-reduce: 0.01 | optimizer: 15752.01 | batch-generator: 0.54
[default3]: iteration       20/   15625 | consumed samples:         1280 | consumed tokens:      1310720 | elapsed time per iteration (ms): 113991.3 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 8.335059E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.561 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 867.57 | backward-compute: 97762.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15330.03 | batch-generator: 0.55
[default3]: iteration       21/   15625 | consumed samples:         1344 | consumed tokens:      1376256 | elapsed time per iteration (ms): 116245.7 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 8.144735E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.551 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 2057.20 | backward-compute: 98697.68 | backward-embedding-all-reduce: 0.01 | optimizer: 15444.15 | batch-generator: 0.55
[default3]: iteration       22/   15625 | consumed samples:         1408 | consumed tokens:      1441792 | elapsed time per iteration (ms): 112276.8 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 8.153654E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.570 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 1138.51 | backward-compute: 95795.27 | backward-embedding-all-reduce: 0.01 | optimizer: 15302.76 | batch-generator: 0.52
[default3]: iteration       23/   15625 | consumed samples:         1472 | consumed tokens:      1507328 | elapsed time per iteration (ms): 115562.9 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 8.140810E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.554 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 1012.85 | backward-compute: 98916.78 | backward-embedding-all-reduce: 0.01 | optimizer: 15513.19 | batch-generator: 0.55
[default3]: iteration       24/   15625 | consumed samples:         1536 | consumed tokens:      1572864 | elapsed time per iteration (ms): 117586.3 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 8.059458E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.544 | TFLOPs: 0.74 |
[default3]:time (ms) | forward-compute: 953.28 | backward-compute: 98073.10 | backward-embedding-all-reduce: 0.01 | optimizer: 15550.28 | batch-generator: 0.51
[default3]: iteration       25/   15625 | consumed samples:         1600 | consumed tokens:      1638400 | elapsed time per iteration (ms): 123840.4 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 8.131625E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.517 | TFLOPs: 0.70 |
[default3]:time (ms) | forward-compute: 2828.67 | backward-compute: 105408.36 | backward-embedding-all-reduce: 0.01 | optimizer: 15568.55 | batch-generator: 0.58
[default3]: iteration       26/   15625 | consumed samples:         1664 | consumed tokens:      1703936 | elapsed time per iteration (ms): 114064.8 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.969519E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.561 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 923.06 | backward-compute: 96784.58 | backward-embedding-all-reduce: 0.01 | optimizer: 15962.61 | batch-generator: 0.54
[default3]: iteration       27/   15625 | consumed samples:         1728 | consumed tokens:      1769472 | elapsed time per iteration (ms): 119981.3 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.931230E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.533 | TFLOPs: 0.73 |
[default3]:time (ms) | forward-compute: 782.37 | backward-compute: 101573.38 | backward-embedding-all-reduce: 0.01 | optimizer: 16143.68 | batch-generator: 0.55
[default3]: iteration       28/   15625 | consumed samples:         1792 | consumed tokens:      1835008 | elapsed time per iteration (ms): 113733.5 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.885029E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.563 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 849.87 | backward-compute: 96874.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15975.58 | batch-generator: 0.55
[default3]: iteration       29/   15625 | consumed samples:         1856 | consumed tokens:      1900544 | elapsed time per iteration (ms): 113250.7 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.832446E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.565 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1122.54 | backward-compute: 96368.41 | backward-embedding-all-reduce: 0.01 | optimizer: 15728.87 | batch-generator: 0.52
[default3]: iteration       30/   15625 | consumed samples:         1920 | consumed tokens:      1966080 | elapsed time per iteration (ms): 114657.4 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 8.041500E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.558 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1106.74 | backward-compute: 97988.42 | backward-embedding-all-reduce: 0.01 | optimizer: 15536.30 | batch-generator: 0.56
[default3]: iteration       31/   15625 | consumed samples:         1984 | consumed tokens:      2031616 | elapsed time per iteration (ms): 112625.6 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.986865E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.568 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1847.34 | backward-compute: 95198.08 | backward-embedding-all-reduce: 0.01 | optimizer: 15543.58 | batch-generator: 0.52
[default3]: iteration       32/   15625 | consumed samples:         2048 | consumed tokens:      2097152 | elapsed time per iteration (ms): 113806.1 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.834895E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.562 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 922.79 | backward-compute: 97501.49 | backward-embedding-all-reduce: 0.01 | optimizer: 15346.00 | batch-generator: 0.53
[default3]: iteration       33/   15625 | consumed samples:         2112 | consumed tokens:      2162688 | elapsed time per iteration (ms): 114106.7 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.928640E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.561 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1146.65 | backward-compute: 96398.25 | backward-embedding-all-reduce: 0.01 | optimizer: 15943.97 | batch-generator: 0.53
[default3]: iteration       34/   15625 | consumed samples:         2176 | consumed tokens:      2228224 | elapsed time per iteration (ms): 114619.4 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.944445E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.558 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 784.88 | backward-compute: 98365.66 | backward-embedding-all-reduce: 0.01 | optimizer: 15436.77 | batch-generator: 0.55
[default3]: iteration       35/   15625 | consumed samples:         2240 | consumed tokens:      2293760 | elapsed time per iteration (ms): 116456.3 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.930906E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.550 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 948.37 | backward-compute: 100075.28 | backward-embedding-all-reduce: 0.01 | optimizer: 15403.47 | batch-generator: 0.56
[default3]: iteration       36/   15625 | consumed samples:         2304 | consumed tokens:      2359296 | elapsed time per iteration (ms): 114030.0 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.845870E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.561 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1057.85 | backward-compute: 97521.40 | backward-embedding-all-reduce: 0.01 | optimizer: 15407.90 | batch-generator: 0.52
[default3]: iteration       37/   15625 | consumed samples:         2368 | consumed tokens:      2424832 | elapsed time per iteration (ms): 114287.8 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.889093E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.560 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 867.69 | backward-compute: 97692.38 | backward-embedding-all-reduce: 0.01 | optimizer: 15680.79 | batch-generator: 0.52
[default3]: iteration       38/   15625 | consumed samples:         2432 | consumed tokens:      2490368 | elapsed time per iteration (ms): 119824.1 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.720000E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.534 | TFLOPs: 0.73 |
[default3]:time (ms) | forward-compute: 1650.87 | backward-compute: 99185.29 | backward-embedding-all-reduce: 0.01 | optimizer: 15513.98 | batch-generator: 0.52
[default3]: iteration       39/   15625 | consumed samples:         2496 | consumed tokens:      2555904 | elapsed time per iteration (ms): 118323.7 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.805043E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.541 | TFLOPs: 0.74 |
[default3]:time (ms) | forward-compute: 888.24 | backward-compute: 101851.38 | backward-embedding-all-reduce: 0.01 | optimizer: 15547.72 | batch-generator: 0.59
[default3]: iteration       40/   15625 | consumed samples:         2560 | consumed tokens:      2621440 | elapsed time per iteration (ms): 111932.4 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.778379E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.572 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 871.59 | backward-compute: 95703.54 | backward-embedding-all-reduce: 0.01 | optimizer: 15304.59 | batch-generator: 0.53
[default3]: iteration       41/   15625 | consumed samples:         2624 | consumed tokens:      2686976 | elapsed time per iteration (ms): 113706.8 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.871145E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.563 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1176.06 | backward-compute: 96123.60 | backward-embedding-all-reduce: 0.01 | optimizer: 15371.79 | batch-generator: 0.52
[default3]: iteration       42/   15625 | consumed samples:         2688 | consumed tokens:      2752512 | elapsed time per iteration (ms): 114578.5 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.771821E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.559 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 857.34 | backward-compute: 98283.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15395.00 | batch-generator: 0.55
[default3]: iteration       43/   15625 | consumed samples:         2752 | consumed tokens:      2818048 | elapsed time per iteration (ms): 112964.1 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.848128E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.567 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 900.72 | backward-compute: 96355.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15650.99 | batch-generator: 0.52
[default3]: iteration       44/   15625 | consumed samples:         2816 | consumed tokens:      2883584 | elapsed time per iteration (ms): 112421.4 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.784802E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.569 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 884.43 | backward-compute: 96141.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15353.90 | batch-generator: 0.55
[default3]: iteration       45/   15625 | consumed samples:         2880 | consumed tokens:      2949120 | elapsed time per iteration (ms): 112594.5 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.768089E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.568 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1415.77 | backward-compute: 95638.28 | backward-embedding-all-reduce: 0.01 | optimizer: 15509.65 | batch-generator: 0.52
[default3]: iteration       46/   15625 | consumed samples:         2944 | consumed tokens:      3014656 | elapsed time per iteration (ms): 113536.1 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.809150E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.564 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 952.54 | backward-compute: 97123.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15429.47 | batch-generator: 0.52
[default3]: iteration       47/   15625 | consumed samples:         3008 | consumed tokens:      3080192 | elapsed time per iteration (ms): 115244.2 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.697958E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.555 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1021.61 | backward-compute: 98539.48 | backward-embedding-all-reduce: 0.01 | optimizer: 15626.96 | batch-generator: 0.55
[default3]: iteration       48/   15625 | consumed samples:         3072 | consumed tokens:      3145728 | elapsed time per iteration (ms): 113660.1 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.735729E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.563 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 2185.68 | backward-compute: 96151.26 | backward-embedding-all-reduce: 0.01 | optimizer: 15258.95 | batch-generator: 0.52
[default3]: iteration       49/   15625 | consumed samples:         3136 | consumed tokens:      3211264 | elapsed time per iteration (ms): 114311.6 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.743067E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.560 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 989.56 | backward-compute: 97669.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15623.71 | batch-generator: 0.52
[default3]: iteration       50/   15625 | consumed samples:         3200 | consumed tokens:      3276800 | elapsed time per iteration (ms): 114727.6 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.783722E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.558 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1093.48 | backward-compute: 97756.29 | backward-embedding-all-reduce: 0.01 | optimizer: 15828.05 | batch-generator: 0.56
[default3]:----------------------------------------------------------------------------------------------
[default3]: validation loss at iteration 50 | lm loss value: 7.902937E+00 | lm loss PPL: 2.705217E+03 | 
[default3]:----------------------------------------------------------------------------------------------
[default3]: iteration       51/   15625 | consumed samples:         3264 | consumed tokens:      3342336 | elapsed time per iteration (ms): 122891.6 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.763460E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.521 | TFLOPs: 0.71 |
[default3]:time (ms) | forward-compute: 8665.66 | backward-compute: 96254.28 | backward-embedding-all-reduce: 0.01 | optimizer: 16111.77 | batch-generator: 6.15
[default3]: iteration       52/   15625 | consumed samples:         3328 | consumed tokens:      3407872 | elapsed time per iteration (ms): 113137.3 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.835564E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.566 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 880.61 | backward-compute: 96049.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15699.16 | batch-generator: 0.58
[default3]: iteration       53/   15625 | consumed samples:         3392 | consumed tokens:      3473408 | elapsed time per iteration (ms): 113633.1 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.771498E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.563 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 812.67 | backward-compute: 96901.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15600.74 | batch-generator: 0.52
[default3]: iteration       54/   15625 | consumed samples:         3456 | consumed tokens:      3538944 | elapsed time per iteration (ms): 113576.3 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.717099E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.563 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 761.84 | backward-compute: 96306.78 | backward-embedding-all-reduce: 0.01 | optimizer: 15634.61 | batch-generator: 0.53
[default3]: iteration       55/   15625 | consumed samples:         3520 | consumed tokens:      3604480 | elapsed time per iteration (ms): 113367.7 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.718302E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.565 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 786.68 | backward-compute: 96100.17 | backward-embedding-all-reduce: 0.01 | optimizer: 16315.02 | batch-generator: 0.53
[default3]: iteration       56/   15625 | consumed samples:         3584 | consumed tokens:      3670016 | elapsed time per iteration (ms): 119872.8 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.712215E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.534 | TFLOPs: 0.73 |
[default3]:time (ms) | forward-compute: 885.28 | backward-compute: 103454.44 | backward-embedding-all-reduce: 0.01 | optimizer: 15493.65 | batch-generator: 0.52
[default3]: iteration       57/   15625 | consumed samples:         3648 | consumed tokens:      3735552 | elapsed time per iteration (ms): 112731.6 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.675525E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.568 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1017.33 | backward-compute: 96197.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15488.30 | batch-generator: 0.55
[default3]: iteration       58/   15625 | consumed samples:         3712 | consumed tokens:      3801088 | elapsed time per iteration (ms): 111915.0 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.673994E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.572 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 836.52 | backward-compute: 95256.65 | backward-embedding-all-reduce: 0.01 | optimizer: 15695.26 | batch-generator: 0.56
[default3]: iteration       59/   15625 | consumed samples:         3776 | consumed tokens:      3866624 | elapsed time per iteration (ms): 114390.3 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.735031E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.559 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1109.90 | backward-compute: 97267.11 | backward-embedding-all-reduce: 0.01 | optimizer: 15981.90 | batch-generator: 0.52
[default3]: iteration       60/   15625 | consumed samples:         3840 | consumed tokens:      3932160 | elapsed time per iteration (ms): 111800.1 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.677029E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.572 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 870.36 | backward-compute: 94936.33 | backward-embedding-all-reduce: 0.01 | optimizer: 15626.32 | batch-generator: 0.55
[default3]: iteration       61/   15625 | consumed samples:         3904 | consumed tokens:      3997696 | elapsed time per iteration (ms): 110504.2 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.792713E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.579 | TFLOPs: 0.79 |
[default3]:time (ms) | forward-compute: 754.41 | backward-compute: 94381.63 | backward-embedding-all-reduce: 0.01 | optimizer: 15328.33 | batch-generator: 0.54
[default3]: iteration       62/   15625 | consumed samples:         3968 | consumed tokens:      4063232 | elapsed time per iteration (ms): 113457.2 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.767366E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.564 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 973.08 | backward-compute: 96923.77 | backward-embedding-all-reduce: 0.01 | optimizer: 15532.17 | batch-generator: 0.52
[default3]: iteration       63/   15625 | consumed samples:         4032 | consumed tokens:      4128768 | elapsed time per iteration (ms): 111911.3 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.687562E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.572 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 946.75 | backward-compute: 95669.40 | backward-embedding-all-reduce: 0.01 | optimizer: 15259.67 | batch-generator: 0.52
[default3]: iteration       64/   15625 | consumed samples:         4096 | consumed tokens:      4194304 | elapsed time per iteration (ms): 113850.0 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.649479E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.562 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1342.32 | backward-compute: 96904.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15555.95 | batch-generator: 0.52
[default3]: iteration       65/   15625 | consumed samples:         4160 | consumed tokens:      4259840 | elapsed time per iteration (ms): 116695.3 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.732980E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.548 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 893.61 | backward-compute: 100226.75 | backward-embedding-all-reduce: 0.01 | optimizer: 15498.21 | batch-generator: 0.56
[default3]: iteration       66/   15625 | consumed samples:         4224 | consumed tokens:      4325376 | elapsed time per iteration (ms): 114628.2 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.719721E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.558 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1267.17 | backward-compute: 97729.26 | backward-embedding-all-reduce: 0.01 | optimizer: 15535.73 | batch-generator: 0.52
[default3]: iteration       67/   15625 | consumed samples:         4288 | consumed tokens:      4390912 | elapsed time per iteration (ms): 123466.4 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.822151E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.518 | TFLOPs: 0.71 |
[default3]:time (ms) | forward-compute: 697.58 | backward-compute: 107217.67 | backward-embedding-all-reduce: 0.01 | optimizer: 15522.62 | batch-generator: 0.52
[default3]: iteration       68/   15625 | consumed samples:         4352 | consumed tokens:      4456448 | elapsed time per iteration (ms): 114025.9 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.641360E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.561 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 863.51 | backward-compute: 97296.34 | backward-embedding-all-reduce: 0.01 | optimizer: 15355.14 | batch-generator: 0.52
[default3]: iteration       69/   15625 | consumed samples:         4416 | consumed tokens:      4521984 | elapsed time per iteration (ms): 110872.7 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.613778E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.577 | TFLOPs: 0.79 |
[default3]:time (ms) | forward-compute: 906.86 | backward-compute: 94628.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15284.03 | batch-generator: 0.53
[default3]: iteration       70/   15625 | consumed samples:         4480 | consumed tokens:      4587520 | elapsed time per iteration (ms): 117681.3 | learning rate: 1.000E-04 | global batch size:    64 | lm loss: 7.659916E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.544 | TFLOPs: 0.74 |
[default3]:time (ms) | forward-compute: 901.16 | backward-compute: 100855.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15690.45 | batch-generator: 0.52
[default3]: iteration       71/   15625 | consumed samples:         4544 | consumed tokens:      4653056 | elapsed time per iteration (ms): 128807.3 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.726373E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.497 | TFLOPs: 0.68 |
[default3]:time (ms) | forward-compute: 692.75 | backward-compute: 111899.37 | backward-embedding-all-reduce: 0.01 | optimizer: 15491.59 | batch-generator: 0.52
[default3]: iteration       72/   15625 | consumed samples:         4608 | consumed tokens:      4718592 | elapsed time per iteration (ms): 118019.1 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.685398E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.542 | TFLOPs: 0.74 |
[default3]:time (ms) | forward-compute: 812.66 | backward-compute: 101132.43 | backward-embedding-all-reduce: 0.01 | optimizer: 15769.98 | batch-generator: 0.55
[default3]: iteration       73/   15625 | consumed samples:         4672 | consumed tokens:      4784128 | elapsed time per iteration (ms): 122309.9 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.791553E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.523 | TFLOPs: 0.71 |
[default3]:time (ms) | forward-compute: 810.36 | backward-compute: 106202.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15232.21 | batch-generator: 0.53
[default3]: iteration       74/   15625 | consumed samples:         4736 | consumed tokens:      4849664 | elapsed time per iteration (ms): 116329.0 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.669135E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.550 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 2014.06 | backward-compute: 98486.27 | backward-embedding-all-reduce: 0.01 | optimizer: 15474.15 | batch-generator: 0.51
[default3]: iteration       75/   15625 | consumed samples:         4800 | consumed tokens:      4915200 | elapsed time per iteration (ms): 115498.9 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.587955E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.554 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 724.38 | backward-compute: 99149.76 | backward-embedding-all-reduce: 0.01 | optimizer: 15455.38 | batch-generator: 0.54
[default3]: iteration       76/   15625 | consumed samples:         4864 | consumed tokens:      4980736 | elapsed time per iteration (ms): 116938.1 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.602394E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.547 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 5382.54 | backward-compute: 95460.28 | backward-embedding-all-reduce: 0.01 | optimizer: 15436.76 | batch-generator: 0.55
[default3]: iteration       77/   15625 | consumed samples:         4928 | consumed tokens:      5046272 | elapsed time per iteration (ms): 120903.0 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.484888E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.529 | TFLOPs: 0.72 |
[default3]:time (ms) | forward-compute: 794.51 | backward-compute: 103944.63 | backward-embedding-all-reduce: 0.01 | optimizer: 15538.26 | batch-generator: 0.54
[default3]: iteration       78/   15625 | consumed samples:         4992 | consumed tokens:      5111808 | elapsed time per iteration (ms): 115730.1 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.621478E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.553 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 1016.19 | backward-compute: 98694.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15129.74 | batch-generator: 0.53
[default3]: iteration       79/   15625 | consumed samples:         5056 | consumed tokens:      5177344 | elapsed time per iteration (ms): 112913.4 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.485848E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.567 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 808.40 | backward-compute: 95381.30 | backward-embedding-all-reduce: 0.01 | optimizer: 16142.76 | batch-generator: 0.55
[default3]: iteration       80/   15625 | consumed samples:         5120 | consumed tokens:      5242880 | elapsed time per iteration (ms): 111285.4 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.576918E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.575 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 813.60 | backward-compute: 94606.40 | backward-embedding-all-reduce: 0.01 | optimizer: 15825.72 | batch-generator: 0.54
[default3]: iteration       81/   15625 | consumed samples:         5184 | consumed tokens:      5308416 | elapsed time per iteration (ms): 113832.9 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.428493E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.562 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 886.92 | backward-compute: 96364.91 | backward-embedding-all-reduce: 0.01 | optimizer: 15533.49 | batch-generator: 0.55
[default3]: iteration       82/   15625 | consumed samples:         5248 | consumed tokens:      5373952 | elapsed time per iteration (ms): 111338.1 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.620929E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.575 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 807.31 | backward-compute: 94864.96 | backward-embedding-all-reduce: 0.01 | optimizer: 15635.36 | batch-generator: 0.55
[default3]: iteration       83/   15625 | consumed samples:         5312 | consumed tokens:      5439488 | elapsed time per iteration (ms): 111982.2 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.552079E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.572 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 835.30 | backward-compute: 94838.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15416.20 | batch-generator: 0.55
[default3]: iteration       84/   15625 | consumed samples:         5376 | consumed tokens:      5505024 | elapsed time per iteration (ms): 115161.3 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.541941E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.556 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 811.44 | backward-compute: 96035.65 | backward-embedding-all-reduce: 0.01 | optimizer: 15534.88 | batch-generator: 0.54
[default3]: iteration       85/   15625 | consumed samples:         5440 | consumed tokens:      5570560 | elapsed time per iteration (ms): 117009.5 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.554217E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.547 | TFLOPs: 0.74 |
[default3]:time (ms) | forward-compute: 4216.79 | backward-compute: 97279.24 | backward-embedding-all-reduce: 0.01 | optimizer: 15478.91 | batch-generator: 0.58
[default3]: iteration       86/   15625 | consumed samples:         5504 | consumed tokens:      5636096 | elapsed time per iteration (ms): 112529.6 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.607065E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.569 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1031.35 | backward-compute: 96108.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15014.34 | batch-generator: 0.55
[default3]: iteration       87/   15625 | consumed samples:         5568 | consumed tokens:      5701632 | elapsed time per iteration (ms): 112996.0 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.499819E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.566 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 989.75 | backward-compute: 96469.97 | backward-embedding-all-reduce: 0.01 | optimizer: 15508.00 | batch-generator: 0.52
[default3]: iteration       88/   15625 | consumed samples:         5632 | consumed tokens:      5767168 | elapsed time per iteration (ms): 112632.5 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.449973E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.568 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1017.39 | backward-compute: 96252.29 | backward-embedding-all-reduce: 0.01 | optimizer: 15290.96 | batch-generator: 0.56
[default3]: iteration       89/   15625 | consumed samples:         5696 | consumed tokens:      5832704 | elapsed time per iteration (ms): 119293.5 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.542825E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.536 | TFLOPs: 0.73 |
[default3]:time (ms) | forward-compute: 984.79 | backward-compute: 101226.30 | backward-embedding-all-reduce: 0.01 | optimizer: 16990.54 | batch-generator: 0.51
[default3]: iteration       90/   15625 | consumed samples:         5760 | consumed tokens:      5898240 | elapsed time per iteration (ms): 113935.6 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.471747E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.562 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 926.76 | backward-compute: 97703.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15255.10 | batch-generator: 0.54
[default3]: iteration       91/   15625 | consumed samples:         5824 | consumed tokens:      5963776 | elapsed time per iteration (ms): 115885.6 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.459175E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.552 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 1925.11 | backward-compute: 98378.55 | backward-embedding-all-reduce: 0.01 | optimizer: 15459.76 | batch-generator: 0.52
[default3]: iteration       92/   15625 | consumed samples:         5888 | consumed tokens:      6029312 | elapsed time per iteration (ms): 114518.5 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.344447E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.559 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1116.05 | backward-compute: 97923.35 | backward-embedding-all-reduce: 0.01 | optimizer: 15440.12 | batch-generator: 0.52
[default3]: iteration       93/   15625 | consumed samples:         5952 | consumed tokens:      6094848 | elapsed time per iteration (ms): 113946.2 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.488817E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.562 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1330.01 | backward-compute: 97156.32 | backward-embedding-all-reduce: 0.01 | optimizer: 15419.76 | batch-generator: 0.51
[default3]: iteration       94/   15625 | consumed samples:         6016 | consumed tokens:      6160384 | elapsed time per iteration (ms): 113107.0 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.494571E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.566 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 973.80 | backward-compute: 96317.32 | backward-embedding-all-reduce: 0.01 | optimizer: 15772.76 | batch-generator: 0.54
[default3]: iteration       95/   15625 | consumed samples:         6080 | consumed tokens:      6225920 | elapsed time per iteration (ms): 114645.5 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.411776E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.558 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1129.69 | backward-compute: 97701.62 | backward-embedding-all-reduce: 0.01 | optimizer: 15780.12 | batch-generator: 0.55
[default3]: iteration       96/   15625 | consumed samples:         6144 | consumed tokens:      6291456 | elapsed time per iteration (ms): 112157.0 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.379367E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.571 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 1030.36 | backward-compute: 95456.29 | backward-embedding-all-reduce: 0.01 | optimizer: 15453.07 | batch-generator: 0.54
[default3]: iteration       97/   15625 | consumed samples:         6208 | consumed tokens:      6356992 | elapsed time per iteration (ms): 118597.6 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.365941E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.540 | TFLOPs: 0.73 |
[default3]:time (ms) | forward-compute: 1652.35 | backward-compute: 101045.27 | backward-embedding-all-reduce: 0.01 | optimizer: 15853.76 | batch-generator: 0.53
[default3]: iteration       98/   15625 | consumed samples:         6272 | consumed tokens:      6422528 | elapsed time per iteration (ms): 115846.5 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.484891E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.552 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 830.67 | backward-compute: 98943.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15485.22 | batch-generator: 0.55
[default3]: iteration       99/   15625 | consumed samples:         6336 | consumed tokens:      6488064 | elapsed time per iteration (ms): 112566.8 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.285951E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.569 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 822.37 | backward-compute: 96091.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15610.62 | batch-generator: 0.57
[default3]: iteration      100/   15625 | consumed samples:         6400 | consumed tokens:      6553600 | elapsed time per iteration (ms): 113997.8 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.470642E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.561 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1154.52 | backward-compute: 97321.49 | backward-embedding-all-reduce: 0.01 | optimizer: 15263.57 | batch-generator: 0.52
[default3]:-----------------------------------------------------------------------------------------------
[default3]: validation loss at iteration 100 | lm loss value: 7.493259E+00 | lm loss PPL: 1.795896E+03 | 
[default3]:-----------------------------------------------------------------------------------------------
[default3]: iteration      101/   15625 | consumed samples:         6464 | consumed tokens:      6619136 | elapsed time per iteration (ms): 123642.1 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.368232E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.518 | TFLOPs: 0.70 |
[default3]:time (ms) | forward-compute: 9744.36 | backward-compute: 97736.43 | backward-embedding-all-reduce: 0.01 | optimizer: 16107.60 | batch-generator: 5.22
[default3]: iteration      102/   15625 | consumed samples:         6528 | consumed tokens:      6684672 | elapsed time per iteration (ms): 114199.2 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.366112E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.560 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 908.70 | backward-compute: 96655.29 | backward-embedding-all-reduce: 0.01 | optimizer: 15729.62 | batch-generator: 0.51
[default3]: iteration      103/   15625 | consumed samples:         6592 | consumed tokens:      6750208 | elapsed time per iteration (ms): 113273.7 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.286267E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.565 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 881.19 | backward-compute: 96813.83 | backward-embedding-all-reduce: 0.01 | optimizer: 15544.84 | batch-generator: 0.54
[default3]: iteration      104/   15625 | consumed samples:         6656 | consumed tokens:      6815744 | elapsed time per iteration (ms): 114152.6 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.417598E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.561 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1408.62 | backward-compute: 97337.42 | backward-embedding-all-reduce: 0.01 | optimizer: 15375.70 | batch-generator: 0.55
[default3]: iteration      105/   15625 | consumed samples:         6720 | consumed tokens:      6881280 | elapsed time per iteration (ms): 111755.0 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.227704E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.573 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 914.19 | backward-compute: 95388.09 | backward-embedding-all-reduce: 0.01 | optimizer: 15415.85 | batch-generator: 0.55
[default3]: iteration      106/   15625 | consumed samples:         6784 | consumed tokens:      6946816 | elapsed time per iteration (ms): 115651.0 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.413510E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.553 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 1141.97 | backward-compute: 98665.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15751.73 | batch-generator: 0.52
[default3]: iteration      107/   15625 | consumed samples:         6848 | consumed tokens:      7012352 | elapsed time per iteration (ms): 113847.6 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.244789E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.562 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1406.55 | backward-compute: 95817.28 | backward-embedding-all-reduce: 0.01 | optimizer: 16410.78 | batch-generator: 0.54
[default3]: iteration      108/   15625 | consumed samples:         6912 | consumed tokens:      7077888 | elapsed time per iteration (ms): 112873.7 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.252671E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.567 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 699.25 | backward-compute: 95490.35 | backward-embedding-all-reduce: 0.01 | optimizer: 16011.13 | batch-generator: 0.54
[default3]: iteration      109/   15625 | consumed samples:         6976 | consumed tokens:      7143424 | elapsed time per iteration (ms): 115875.1 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.393675E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.552 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 816.35 | backward-compute: 98891.52 | backward-embedding-all-reduce: 0.01 | optimizer: 15925.36 | batch-generator: 0.54
[default3]: iteration      110/   15625 | consumed samples:         7040 | consumed tokens:      7208960 | elapsed time per iteration (ms): 112195.2 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.266897E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.570 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 979.35 | backward-compute: 95972.28 | backward-embedding-all-reduce: 0.01 | optimizer: 15221.20 | batch-generator: 0.54
[default3]: iteration      111/   15625 | consumed samples:         7104 | consumed tokens:      7274496 | elapsed time per iteration (ms): 113789.0 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.379925E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.562 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 988.64 | backward-compute: 96631.32 | backward-embedding-all-reduce: 0.01 | optimizer: 15536.77 | batch-generator: 0.55
[default3]: iteration      112/   15625 | consumed samples:         7168 | consumed tokens:      7340032 | elapsed time per iteration (ms): 112663.4 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.320632E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.568 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 794.18 | backward-compute: 96270.32 | backward-embedding-all-reduce: 0.01 | optimizer: 15563.05 | batch-generator: 0.54
[default3]: iteration      113/   15625 | consumed samples:         7232 | consumed tokens:      7405568 | elapsed time per iteration (ms): 116167.0 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.266013E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.551 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 940.66 | backward-compute: 98941.69 | backward-embedding-all-reduce: 0.01 | optimizer: 16215.95 | batch-generator: 0.55
[default3]: iteration      114/   15625 | consumed samples:         7296 | consumed tokens:      7471104 | elapsed time per iteration (ms): 112802.5 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.262071E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.567 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 845.69 | backward-compute: 96495.09 | backward-embedding-all-reduce: 0.01 | optimizer: 15312.76 | batch-generator: 0.53
[default3]: iteration      115/   15625 | consumed samples:         7360 | consumed tokens:      7536640 | elapsed time per iteration (ms): 112001.3 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.342309E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.571 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 818.96 | backward-compute: 95804.32 | backward-embedding-all-reduce: 0.01 | optimizer: 15322.77 | batch-generator: 0.52
[default3]: iteration      116/   15625 | consumed samples:         7424 | consumed tokens:      7602176 | elapsed time per iteration (ms): 112687.3 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.255300E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.568 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 893.92 | backward-compute: 95529.51 | backward-embedding-all-reduce: 0.01 | optimizer: 16227.24 | batch-generator: 0.52
[default3]: iteration      117/   15625 | consumed samples:         7488 | consumed tokens:      7667712 | elapsed time per iteration (ms): 113337.7 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.204754E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.565 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1033.36 | backward-compute: 96833.27 | backward-embedding-all-reduce: 0.01 | optimizer: 15434.54 | batch-generator: 0.56
[default3]: iteration      118/   15625 | consumed samples:         7552 | consumed tokens:      7733248 | elapsed time per iteration (ms): 112617.9 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.200636E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.568 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 845.12 | backward-compute: 95041.41 | backward-embedding-all-reduce: 0.01 | optimizer: 15980.97 | batch-generator: 1.29
[default3]: iteration      119/   15625 | consumed samples:         7616 | consumed tokens:      7798784 | elapsed time per iteration (ms): 112267.0 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.391841E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.570 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 758.19 | backward-compute: 95860.95 | backward-embedding-all-reduce: 0.01 | optimizer: 15466.42 | batch-generator: 0.53
[default3]: iteration      120/   15625 | consumed samples:         7680 | consumed tokens:      7864320 | elapsed time per iteration (ms): 112765.0 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.330871E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.568 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1208.66 | backward-compute: 95915.28 | backward-embedding-all-reduce: 0.01 | optimizer: 15462.12 | batch-generator: 0.54
[default3]: iteration      121/   15625 | consumed samples:         7744 | consumed tokens:      7929856 | elapsed time per iteration (ms): 114955.4 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.173278E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.557 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 829.82 | backward-compute: 98350.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15612.35 | batch-generator: 0.52
[default3]: iteration      122/   15625 | consumed samples:         7808 | consumed tokens:      7995392 | elapsed time per iteration (ms): 112366.2 | learning rate: 9.999E-05 | global batch size:    64 | lm loss: 7.291867E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.570 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 713.88 | backward-compute: 96131.71 | backward-embedding-all-reduce: 0.01 | optimizer: 15395.47 | batch-generator: 0.55
[default3]: iteration      123/   15625 | consumed samples:         7872 | consumed tokens:      8060928 | elapsed time per iteration (ms): 111179.2 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.151535E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.576 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 767.94 | backward-compute: 94879.32 | backward-embedding-all-reduce: 0.01 | optimizer: 15486.64 | batch-generator: 0.53
[default3]: iteration      124/   15625 | consumed samples:         7936 | consumed tokens:      8126464 | elapsed time per iteration (ms): 111937.8 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.287385E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.572 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 837.06 | backward-compute: 95307.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15413.77 | batch-generator: 0.55
[default3]: iteration      125/   15625 | consumed samples:         8000 | consumed tokens:      8192000 | elapsed time per iteration (ms): 116931.0 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.267257E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.547 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 826.12 | backward-compute: 97500.82 | backward-embedding-all-reduce: 0.01 | optimizer: 15566.83 | batch-generator: 0.54
[default3]: iteration      126/   15625 | consumed samples:         8064 | consumed tokens:      8257536 | elapsed time per iteration (ms): 114229.5 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.255930E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.560 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 937.98 | backward-compute: 97468.20 | backward-embedding-all-reduce: 0.01 | optimizer: 15701.61 | batch-generator: 0.58
[default3]: iteration      127/   15625 | consumed samples:         8128 | consumed tokens:      8323072 | elapsed time per iteration (ms): 113510.0 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.351635E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.564 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 754.71 | backward-compute: 95582.32 | backward-embedding-all-reduce: 0.01 | optimizer: 15255.76 | batch-generator: 0.52
[default3]: iteration      128/   15625 | consumed samples:         8192 | consumed tokens:      8388608 | elapsed time per iteration (ms): 112816.3 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.136163E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.567 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 920.77 | backward-compute: 96548.27 | backward-embedding-all-reduce: 0.01 | optimizer: 15297.77 | batch-generator: 0.57
[default3]: iteration      129/   15625 | consumed samples:         8256 | consumed tokens:      8454144 | elapsed time per iteration (ms): 112806.8 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.232438E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.567 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 847.84 | backward-compute: 96325.73 | backward-embedding-all-reduce: 0.01 | optimizer: 15599.83 | batch-generator: 0.51
[default3]: iteration      130/   15625 | consumed samples:         8320 | consumed tokens:      8519680 | elapsed time per iteration (ms): 112007.4 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.315905E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.571 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 847.42 | backward-compute: 95725.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15378.01 | batch-generator: 0.53
[default3]: iteration      131/   15625 | consumed samples:         8384 | consumed tokens:      8585216 | elapsed time per iteration (ms): 111997.3 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.164182E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.571 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 1240.73 | backward-compute: 94815.76 | backward-embedding-all-reduce: 0.01 | optimizer: 15848.60 | batch-generator: 0.51
[default3]: iteration      132/   15625 | consumed samples:         8448 | consumed tokens:      8650752 | elapsed time per iteration (ms): 112587.1 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.224665E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.568 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 767.25 | backward-compute: 96501.49 | backward-embedding-all-reduce: 0.01 | optimizer: 15285.55 | batch-generator: 0.53
[default3]: iteration      133/   15625 | consumed samples:         8512 | consumed tokens:      8716288 | elapsed time per iteration (ms): 114852.2 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.186281E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.557 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1466.83 | backward-compute: 97544.25 | backward-embedding-all-reduce: 0.01 | optimizer: 15521.70 | batch-generator: 0.55
[default3]: iteration      134/   15625 | consumed samples:         8576 | consumed tokens:      8781824 | elapsed time per iteration (ms): 117042.0 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.222041E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.547 | TFLOPs: 0.74 |
[default3]:time (ms) | forward-compute: 730.42 | backward-compute: 100629.40 | backward-embedding-all-reduce: 0.01 | optimizer: 15589.62 | batch-generator: 0.53
[default3]: iteration      135/   15625 | consumed samples:         8640 | consumed tokens:      8847360 | elapsed time per iteration (ms): 115552.0 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.237171E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.554 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 822.10 | backward-compute: 98679.39 | backward-embedding-all-reduce: 0.01 | optimizer: 15625.08 | batch-generator: 0.55
[default3]: iteration      136/   15625 | consumed samples:         8704 | consumed tokens:      8912896 | elapsed time per iteration (ms): 113547.3 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.165676E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.564 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 903.56 | backward-compute: 97043.85 | backward-embedding-all-reduce: 0.01 | optimizer: 15535.80 | batch-generator: 0.52
[default3]: iteration      137/   15625 | consumed samples:         8768 | consumed tokens:      8978432 | elapsed time per iteration (ms): 112642.4 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.106143E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.568 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 878.00 | backward-compute: 96194.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15491.24 | batch-generator: 0.52
[default3]: iteration      138/   15625 | consumed samples:         8832 | consumed tokens:      9043968 | elapsed time per iteration (ms): 114643.9 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.223156E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.558 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1034.62 | backward-compute: 96342.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15929.99 | batch-generator: 0.52
[default3]: iteration      139/   15625 | consumed samples:         8896 | consumed tokens:      9109504 | elapsed time per iteration (ms): 113486.5 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.054863E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.564 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 840.68 | backward-compute: 97070.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15420.83 | batch-generator: 0.56
[default3]: iteration      140/   15625 | consumed samples:         8960 | consumed tokens:      9175040 | elapsed time per iteration (ms): 112339.6 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.095900E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.570 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 785.38 | backward-compute: 95887.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15619.33 | batch-generator: 0.53
[default3]: iteration      141/   15625 | consumed samples:         9024 | consumed tokens:      9240576 | elapsed time per iteration (ms): 111885.4 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.059242E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.572 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 860.63 | backward-compute: 95277.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15567.88 | batch-generator: 0.52
[default3]: iteration      142/   15625 | consumed samples:         9088 | consumed tokens:      9306112 | elapsed time per iteration (ms): 111820.3 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.064609E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.572 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 722.89 | backward-compute: 95552.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15489.50 | batch-generator: 0.52
[default3]: iteration      143/   15625 | consumed samples:         9152 | consumed tokens:      9371648 | elapsed time per iteration (ms): 110978.9 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.174379E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.577 | TFLOPs: 0.79 |
[default3]:time (ms) | forward-compute: 729.01 | backward-compute: 94821.19 | backward-embedding-all-reduce: 0.01 | optimizer: 15364.81 | batch-generator: 0.55
[default3]: iteration      144/   15625 | consumed samples:         9216 | consumed tokens:      9437184 | elapsed time per iteration (ms): 114417.1 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.085986E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.559 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1116.27 | backward-compute: 97866.84 | backward-embedding-all-reduce: 0.01 | optimizer: 15363.63 | batch-generator: 0.52
[default3]: iteration      145/   15625 | consumed samples:         9280 | consumed tokens:      9502720 | elapsed time per iteration (ms): 113117.0 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.046940E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.566 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 965.95 | backward-compute: 96577.61 | backward-embedding-all-reduce: 0.01 | optimizer: 15536.43 | batch-generator: 0.51
[default3]: iteration      146/   15625 | consumed samples:         9344 | consumed tokens:      9568256 | elapsed time per iteration (ms): 113031.4 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.136883E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.566 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1050.79 | backward-compute: 96640.19 | backward-embedding-all-reduce: 0.01 | optimizer: 15305.69 | batch-generator: 0.51
[default3]: iteration      147/   15625 | consumed samples:         9408 | consumed tokens:      9633792 | elapsed time per iteration (ms): 113057.3 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 6.986432E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.566 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1058.27 | backward-compute: 96254.29 | backward-embedding-all-reduce: 0.01 | optimizer: 15715.29 | batch-generator: 0.56
[default3]: iteration      148/   15625 | consumed samples:         9472 | consumed tokens:      9699328 | elapsed time per iteration (ms): 115305.8 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.019723E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.555 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1100.27 | backward-compute: 98655.96 | backward-embedding-all-reduce: 0.01 | optimizer: 15504.10 | batch-generator: 0.55
[default3]: iteration      149/   15625 | consumed samples:         9536 | consumed tokens:      9764864 | elapsed time per iteration (ms): 113622.9 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.050249E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.563 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 859.39 | backward-compute: 97439.03 | backward-embedding-all-reduce: 0.01 | optimizer: 15288.18 | batch-generator: 0.56
[default3]: iteration      150/   15625 | consumed samples:         9600 | consumed tokens:      9830400 | elapsed time per iteration (ms): 115535.2 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 6.979506E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.554 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 932.67 | backward-compute: 99177.74 | backward-embedding-all-reduce: 0.02 | optimizer: 15121.94 | batch-generator: 0.51
[default3]:-----------------------------------------------------------------------------------------------
[default3]: validation loss at iteration 150 | lm loss value: 7.206332E+00 | lm loss PPL: 1.347939E+03 | 
[default3]:-----------------------------------------------------------------------------------------------
[default3]: iteration      151/   15625 | consumed samples:         9664 | consumed tokens:      9895936 | elapsed time per iteration (ms): 120905.9 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 6.964537E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.529 | TFLOPs: 0.72 |
[default3]:time (ms) | forward-compute: 8655.63 | backward-compute: 96803.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15407.05 | batch-generator: 5.15
[default3]: iteration      152/   15625 | consumed samples:         9728 | consumed tokens:      9961472 | elapsed time per iteration (ms): 111825.6 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 6.745039E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.572 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 1133.31 | backward-compute: 95318.20 | backward-embedding-all-reduce: 0.01 | optimizer: 15339.14 | batch-generator: 0.55
[default3]: iteration      153/   15625 | consumed samples:         9792 | consumed tokens:     10027008 | elapsed time per iteration (ms): 112728.7 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.092988E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.568 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 888.25 | backward-compute: 96004.64 | backward-embedding-all-reduce: 0.01 | optimizer: 15193.17 | batch-generator: 0.55
[default3]: iteration      154/   15625 | consumed samples:         9856 | consumed tokens:     10092544 | elapsed time per iteration (ms): 112155.8 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 6.953460E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.571 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 796.83 | backward-compute: 96003.26 | backward-embedding-all-reduce: 0.01 | optimizer: 15316.81 | batch-generator: 0.56
[default3]: iteration      155/   15625 | consumed samples:         9920 | consumed tokens:     10158080 | elapsed time per iteration (ms): 113320.5 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 6.928834E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.565 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 862.33 | backward-compute: 96829.11 | backward-embedding-all-reduce: 0.01 | optimizer: 15525.37 | batch-generator: 0.56
[default3]: iteration      156/   15625 | consumed samples:         9984 | consumed tokens:     10223616 | elapsed time per iteration (ms): 113827.3 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 7.132743E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.562 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1142.91 | backward-compute: 97023.41 | backward-embedding-all-reduce: 0.01 | optimizer: 15614.76 | batch-generator: 0.52
[default3]: iteration      157/   15625 | consumed samples:        10048 | consumed tokens:     10289152 | elapsed time per iteration (ms): 113531.8 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 6.893569E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.564 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 845.24 | backward-compute: 96927.41 | backward-embedding-all-reduce: 0.01 | optimizer: 15380.64 | batch-generator: 0.52
[default3]: iteration      158/   15625 | consumed samples:        10112 | consumed tokens:     10354688 | elapsed time per iteration (ms): 112437.5 | learning rate: 9.998E-05 | global batch size:    64 | lm loss: 6.932440E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.569 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 785.53 | backward-compute: 95639.50 | backward-embedding-all-reduce: 0.01 | optimizer: 15943.87 | batch-generator: 0.54
[default3]: iteration      159/   15625 | consumed samples:        10176 | consumed tokens:     10420224 | elapsed time per iteration (ms): 115056.7 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.938956E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.556 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1284.82 | backward-compute: 98111.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15590.47 | batch-generator: 0.51
[default3]: iteration      160/   15625 | consumed samples:        10240 | consumed tokens:     10485760 | elapsed time per iteration (ms): 116916.2 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.975653E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.547 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 936.71 | backward-compute: 100132.56 | backward-embedding-all-reduce: 0.01 | optimizer: 15810.04 | batch-generator: 0.54
[default3]: iteration      161/   15625 | consumed samples:        10304 | consumed tokens:     10551296 | elapsed time per iteration (ms): 113174.9 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.953517E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.565 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 948.94 | backward-compute: 96805.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15373.22 | batch-generator: 0.52
[default3]: iteration      162/   15625 | consumed samples:        10368 | consumed tokens:     10616832 | elapsed time per iteration (ms): 116947.5 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 7.025791E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.547 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 2141.36 | backward-compute: 98782.25 | backward-embedding-all-reduce: 0.01 | optimizer: 15999.54 | batch-generator: 0.55
[default3]: iteration      163/   15625 | consumed samples:        10432 | consumed tokens:     10682368 | elapsed time per iteration (ms): 112941.5 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.871834E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.567 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1010.79 | backward-compute: 96316.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15491.94 | batch-generator: 0.54
[default3]: iteration      164/   15625 | consumed samples:        10496 | consumed tokens:     10747904 | elapsed time per iteration (ms): 112845.9 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 7.057896E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.567 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 939.49 | backward-compute: 96028.55 | backward-embedding-all-reduce: 0.01 | optimizer: 15822.55 | batch-generator: 0.52
[default3]: iteration      165/   15625 | consumed samples:        10560 | consumed tokens:     10813440 | elapsed time per iteration (ms): 114018.0 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.952416E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.561 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1131.20 | backward-compute: 97113.29 | backward-embedding-all-reduce: 0.01 | optimizer: 15733.77 | batch-generator: 0.53
[default3]: iteration      166/   15625 | consumed samples:        10624 | consumed tokens:     10878976 | elapsed time per iteration (ms): 113098.6 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.951563E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.566 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1220.56 | backward-compute: 95882.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15523.85 | batch-generator: 0.51
[default3]: iteration      167/   15625 | consumed samples:        10688 | consumed tokens:     10944512 | elapsed time per iteration (ms): 112149.7 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.902575E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.571 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 809.75 | backward-compute: 95579.31 | backward-embedding-all-reduce: 0.01 | optimizer: 15262.73 | batch-generator: 0.53
[default3]: iteration      168/   15625 | consumed samples:        10752 | consumed tokens:     11010048 | elapsed time per iteration (ms): 117732.0 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.900473E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.544 | TFLOPs: 0.74 |
[default3]:time (ms) | forward-compute: 792.99 | backward-compute: 97178.19 | backward-embedding-all-reduce: 0.01 | optimizer: 15562.90 | batch-generator: 0.53
[default3]: iteration      169/   15625 | consumed samples:        10816 | consumed tokens:     11075584 | elapsed time per iteration (ms): 115150.1 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.836535E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.556 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 940.49 | backward-compute: 97662.47 | backward-embedding-all-reduce: 0.01 | optimizer: 15334.63 | batch-generator: 0.59
[default3]: iteration      170/   15625 | consumed samples:        10880 | consumed tokens:     11141120 | elapsed time per iteration (ms): 113903.4 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 7.021996E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.562 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 839.25 | backward-compute: 97475.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15523.77 | batch-generator: 0.54
[default3]: iteration      171/   15625 | consumed samples:        10944 | consumed tokens:     11206656 | elapsed time per iteration (ms): 112827.1 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.992019E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.567 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 883.45 | backward-compute: 96397.00 | backward-embedding-all-reduce: 0.01 | optimizer: 15490.30 | batch-generator: 0.52
[default3]: iteration      172/   15625 | consumed samples:        11008 | consumed tokens:     11272192 | elapsed time per iteration (ms): 112839.7 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.972888E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.567 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1015.51 | backward-compute: 96085.22 | backward-embedding-all-reduce: 0.01 | optimizer: 15686.06 | batch-generator: 0.52
[default3]: iteration      173/   15625 | consumed samples:        11072 | consumed tokens:     11337728 | elapsed time per iteration (ms): 113589.0 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.770165E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.563 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 891.91 | backward-compute: 97288.29 | backward-embedding-all-reduce: 0.01 | optimizer: 15370.38 | batch-generator: 0.52
[default3]: iteration      174/   15625 | consumed samples:        11136 | consumed tokens:     11403264 | elapsed time per iteration (ms): 115638.6 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.995382E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.553 | TFLOPs: 0.75 |
[default3]:time (ms) | forward-compute: 1056.05 | backward-compute: 98905.28 | backward-embedding-all-reduce: 0.01 | optimizer: 15618.77 | batch-generator: 0.51
[default3]: iteration      175/   15625 | consumed samples:        11200 | consumed tokens:     11468800 | elapsed time per iteration (ms): 114788.0 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.862311E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.558 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 842.24 | backward-compute: 97684.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15833.14 | batch-generator: 0.54
[default3]: iteration      176/   15625 | consumed samples:        11264 | consumed tokens:     11534336 | elapsed time per iteration (ms): 113922.1 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.880239E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.562 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1567.95 | backward-compute: 96888.70 | backward-embedding-all-reduce: 0.01 | optimizer: 15429.42 | batch-generator: 0.55
[default3]: iteration      177/   15625 | consumed samples:        11328 | consumed tokens:     11599872 | elapsed time per iteration (ms): 114664.9 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.927305E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.558 | TFLOPs: 0.76 |
[default3]:time (ms) | forward-compute: 1130.16 | backward-compute: 98026.07 | backward-embedding-all-reduce: 0.01 | optimizer: 15474.64 | batch-generator: 0.55
[default3]: iteration      178/   15625 | consumed samples:        11392 | consumed tokens:     11665408 | elapsed time per iteration (ms): 113903.9 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.826238E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.562 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 880.71 | backward-compute: 97242.59 | backward-embedding-all-reduce: 0.01 | optimizer: 15750.51 | batch-generator: 1.20
[default3]: iteration      179/   15625 | consumed samples:        11456 | consumed tokens:     11730944 | elapsed time per iteration (ms): 113407.8 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.786202E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.564 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 1418.79 | backward-compute: 96442.30 | backward-embedding-all-reduce: 0.01 | optimizer: 15476.28 | batch-generator: 0.53
[default3]: iteration      180/   15625 | consumed samples:        11520 | consumed tokens:     11796480 | elapsed time per iteration (ms): 113200.7 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.999478E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.565 | TFLOPs: 0.77 |
[default3]:time (ms) | forward-compute: 940.57 | backward-compute: 96486.03 | backward-embedding-all-reduce: 0.01 | optimizer: 15743.50 | batch-generator: 0.52
[default3]: iteration      181/   15625 | consumed samples:        11584 | consumed tokens:     11862016 | elapsed time per iteration (ms): 111950.5 | learning rate: 9.997E-05 | global batch size:    64 | lm loss: 6.911802E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.572 | TFLOPs: 0.78 |
[default3]:time (ms) | forward-compute: 1059.65 | backward-compute: 95324.40 | backward-embedding-all-reduce: 0.01 | optimizer: 15508.65 | batch-generator: 0.55
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 3411401 ON n2gpu1201 CANCELLED AT 2023-04-24T13:55:26 ***
