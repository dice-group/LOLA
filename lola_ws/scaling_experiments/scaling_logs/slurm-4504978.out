cpu-bind=MASK - n2gpu1227, task  0  0 [3528378]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||--------|--------||B-------|--------||--------|--------||--------|--------|  set
Total estimated parameters in the Dense GPT-2 model: 125226240 (0.13B)
Total Estimated Parameters in the Sparse(MoE) GPT-2 model: 3752054016 (3.75B)
LAUNCHER: python -u -m torch.distributed.run --nproc_per_node 1 --nnodes 1 --rdzv_id=10 --rdzv_endpoint n2gpu1227:6005 --rdzv_backend c10d --max_restarts 0 --tee 3
CMD: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/pretrain_gpt.py --override-opt_param-scheduler --adam-beta1 0.9 --adam-beta2 0.95 --tensor-model-parallel-size 1 --moe-expert-parallel-size 1 --num-experts 128 --moe-loss-coeff 0.01 --moe-train-capacity-factor 1.0 --moe-eval-capacity-factor 1.0 --moe-min-capacity 4 --init-method-std 0.01 --lr-decay-tokens 300000000000 --lr-warmup-tokens 375000000 --micro-batch-size 1 --exit-duration-in-mins 30000000 --global-batch-size 1 --num-layers 12 --hidden-size 768 --num-attention-heads 12 --seq-length 2048 --max-position-embeddings 2048 --train-tokens 300000000000 --train-iters 439453125 --lr 2.0e-4 --min-lr 2e-06 --lr-decay-style cosine --split 98,2,0 --log-interval 5 --eval-interval 100 --eval-iters 50 --save-interval 1000000 --weight-decay 0.1 --clip-grad 1.0 --hysteresis 2 --num-workers 0 --fp16 --load /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/scaling_experiments/output/GPT_0.35B_MoE128_1BATCH_1GPU_1Node/checkpoint/gpt-0.35B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-128-mlc-0.01-cap-1.0-drop-true --save /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/scaling_experiments/output/GPT_0.35B_MoE128_1BATCH_1GPU_1Node/checkpoint/gpt-0.35B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-128-mlc-0.01-cap-1.0-drop-true --tensorboard-queue-size 1 --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --tensorboard-dir /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/scaling_experiments/output/GPT_0.35B_MoE128_1BATCH_1GPU_1Node/tensorboard/gpt-0.35B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-128-mlc-0.01-cap-1.0-drop-true_n2gpu1227_2023.07.30-22.21.10 --checkpoint-activations --create-moe-param-group --vocab-file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/gpt2-vocab.json --merge-file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/gpt2-merges.txt --data-path /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/meg-gpt2-oscar-en-10k_text_document --data-impl mmap --deepspeed --deepspeed_config /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/scaling_experiments/output/GPT_0.35B_MoE128_1BATCH_1GPU_1Node/ds_config_gpt_gpt-0.35B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-128-mlc-0.01-cap-1.0-drop-true.json --pipeline-model-parallel-size 1 --no-pipeline-parallel --deepspeed-activation-checkpointing
cpu-bind=MASK - n2gpu1227, task  0  0 [3528618]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||--------|--------||B-------|--------||--------|--------||--------|--------|  set
[default0]:[2023-07-30 22:21:13,896] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.10.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:**** Git info for Megatron: git_hash=6e47d55 git_branch=main ****
[default0]:using world size: 1, data-parallel-size: 1, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
[default0]:using torch.float16 for parameters ...
[default0]:------------------------ arguments ------------------------
[default0]:  accumulate_allreduce_grads_in_fp32 .............. False
[default0]:  adam_beta1 ...................................... 0.9
[default0]:  adam_beta2 ...................................... 0.95
[default0]:  adam_eps ........................................ 1e-08
[default0]:  add_bias_linear ................................. True
[default0]:  add_position_embedding .......................... True
[default0]:  adlr_autoresume ................................. False
[default0]:  adlr_autoresume_interval ........................ 1000
[default0]:  aml_data_download_path .......................... None
[default0]:  apply_layernorm_1p .............................. False
[default0]:  apply_query_key_layer_scaling ................... True
[default0]:  apply_residual_connection_post_layernorm ........ False
[default0]:  async_tensor_model_parallel_allreduce ........... False
[default0]:  attention_dropout ............................... 0.1
[default0]:  attention_softmax_in_fp32 ....................... False
[default0]:  barrier_with_L1_time ............................ True
[default0]:  bert_binary_head ................................ True
[default0]:  bert_embedder_type .............................. megatron
[default0]:  bert_load ....................................... None
[default0]:  bf16 ............................................ False
[default0]:  bias_dropout_fusion ............................. True
[default0]:  bias_gelu_fusion ................................ True
[default0]:  biencoder_projection_dim ........................ 0
[default0]:  biencoder_shared_query_context_model ............ False
[default0]:  block_data_path ................................. None
[default0]:  checkpoint_activations .......................... True
[default0]:  checkpoint_in_cpu ............................... False
[default0]:  checkpoint_num_layers ........................... 1
[default0]:  classes_fraction ................................ 1.0
[default0]:  clip_grad ....................................... 1.0
[default0]:  compression_training ............................ False
[default0]:  consumed_train_samples .......................... 0
[default0]:  consumed_train_tokens ........................... 0
[default0]:  consumed_valid_samples .......................... 0
[default0]:  contigious_checkpointing ........................ False
[default0]:  cpu_optimizer ................................... False
[default0]:  cpu_torch_adam .................................. False
[default0]:  create_moe_param_group .......................... True
[default0]:  curriculum_learning_legacy ...................... False
[default0]:  data_cache_path ................................. None
[default0]:  data_efficiency_curriculum_learning ............. False
[default0]:  data_impl ....................................... mmap
[default0]:  data_parallel_random_init ....................... False
[default0]:  data_parallel_size .............................. 1
[default0]:  data_path ....................................... ['/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/meg-gpt2-oscar-en-10k_text_document']
[default0]:  data_per_class_fraction ......................... 1.0
[default0]:  data_sharding ................................... True
[default0]:  dataloader_type ................................. single
[default0]:  DDP_impl ........................................ local
[default0]:  decoder_num_layers .............................. None
[default0]:  decoder_seq_length .............................. None
[default0]:  deepscale ....................................... False
[default0]:  deepscale_config ................................ None
[default0]:  deepspeed ....................................... True
[default0]:  deepspeed_activation_checkpointing .............. True
[default0]:  deepspeed_config ................................ /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/scaling_experiments/output/GPT_0.35B_MoE128_1BATCH_1GPU_1Node/ds_config_gpt_gpt-0.35B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-128-mlc-0.01-cap-1.0-drop-true.json
[default0]:  deepspeed_mpi ................................... False
[default0]:  dino_bottleneck_size ............................ 256
[default0]:  dino_freeze_last_layer .......................... 1
[default0]:  dino_head_hidden_size ........................... 2048
[default0]:  dino_local_crops_number ......................... 10
[default0]:  dino_local_img_size ............................. 96
[default0]:  dino_norm_last_layer ............................ False
[default0]:  dino_teacher_temp ............................... 0.07
[default0]:  dino_warmup_teacher_temp ........................ 0.04
[default0]:  dino_warmup_teacher_temp_epochs ................. 30
[default0]:  distribute_checkpointed_activations ............. False
[default0]:  distribute_saved_activations .................... False
[default0]:  distributed_backend ............................. nccl
[default0]:  distributed_timeout_minutes ..................... 10
[default0]:  ds_inference .................................... False
[default0]:  ds_pipeline_enabled ............................. False
[default0]:  embedding_path .................................. None
[default0]:  embedding_weights_in_fp32 ....................... False
[default0]:  empty_unused_memory_level ....................... 0
[default0]:  enable_expert_tensor_parallelism ................ False
[default0]:  encoder_num_layers .............................. 12
[default0]:  encoder_seq_length .............................. 2048
[default0]:  end_weight_decay ................................ 0.1
[default0]:  eod_mask_loss ................................... False
[default0]:  eval_interval ................................... 100
[default0]:  eval_iters ...................................... 50
[default0]:  evidence_data_path .............................. None
[default0]:  exit_duration_in_mins ........................... 30000000
[default0]:  exit_interval ................................... None
[default0]:  exit_on_missing_checkpoint ...................... False
[default0]:  exit_signal_handler ............................. False
[default0]:  expert_interval ................................. 2
[default0]:  ffn_hidden_size ................................. 3072
[default0]:  finetune ........................................ False
[default0]:  fp16 ............................................ True
[default0]:  fp16_lm_cross_entropy ........................... False
[default0]:  fp32_residual_connection ........................ False
[default0]:  fp8_amax_compute_algo ........................... most_recent
[default0]:  fp8_amax_history_len ............................ 1
[default0]:  fp8_e4m3 ........................................ False
[default0]:  fp8_hybrid ...................................... False
[default0]:  fp8_interval .................................... 1
[default0]:  fp8_margin ...................................... 0
[default0]:  fp8_wgrad ....................................... True
[default0]:  global_batch_size ............................... 1
[default0]:  gradient_accumulation_fusion .................... True
[default0]:  head_lr_mult .................................... 1.0
[default0]:  hidden_dropout .................................. 0.1
[default0]:  hidden_size ..................................... 768
[default0]:  hidden_size_teacher ............................. None
[default0]:  hysteresis ...................................... 2
[default0]:  ict_head_size ................................... None
[default0]:  ict_load ........................................ None
[default0]:  img_h ........................................... 224
[default0]:  img_w ........................................... 224
[default0]:  indexer_batch_size .............................. 128
[default0]:  indexer_log_interval ............................ 1000
[default0]:  inference ....................................... False
[default0]:  inference_batch_times_seqlen_threshold .......... 512
[default0]:  init_method_std ................................. 0.01
[default0]:  init_method_xavier_uniform ...................... False
[default0]:  initial_loss_scale .............................. 4294967296
[default0]:  iter_per_epoch .................................. 1250
[default0]:  kd .............................................. False
[default0]:  kd_alpha_ce ..................................... 1
[default0]:  kd_beta_ce ...................................... 1
[default0]:  kd_temp ......................................... 1.0
[default0]:  kv_channels ..................................... 64
[default0]:  layernorm_epsilon ............................... 1e-05
[default0]:  lazy_mpu_init ................................... None
[default0]:  load ............................................ /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/scaling_experiments/output/GPT_0.35B_MoE128_1BATCH_1GPU_1Node/checkpoint/gpt-0.35B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-128-mlc-0.01-cap-1.0-drop-true
[default0]:  load_teacher .................................... None
[default0]:  local_rank ...................................... None
[default0]:  log_batch_size_to_tensorboard ................... True
[default0]:  log_interval .................................... 5
[default0]:  log_learning_rate_to_tensorboard ................ True
[default0]:  log_loss_scale_to_tensorboard ................... True
[default0]:  log_memory_to_tensorboard ....................... False
[default0]:  log_num_zeros_in_grad ........................... False
[default0]:  log_optimizer_states_to_tensorboard ............. False
[default0]:  log_params_norm ................................. False
[default0]:  log_timers_to_tensorboard ....................... True
[default0]:  log_validation_ppl_to_tensorboard ............... True
[default0]:  log_world_size_to_tensorboard ................... False
[default0]:  loss_scale ...................................... None
[default0]:  loss_scale_window ............................... 1000
[default0]:  lr .............................................. 0.0002
[default0]:  lr_decay_iters .................................. None
[default0]:  lr_decay_samples ................................ None
[default0]:  lr_decay_style .................................. cosine
[default0]:  lr_decay_tokens ................................. 300000000000
[default0]:  lr_warmup_fraction .............................. None
[default0]:  lr_warmup_iters ................................. 0
[default0]:  lr_warmup_samples ............................... 0
[default0]:  lr_warmup_tokens ................................ 375000000
[default0]:  make_vocab_size_divisible_by .................... 128
[default0]:  mask_factor ..................................... 1.0
[default0]:  mask_prob ....................................... 0.15
[default0]:  mask_type ....................................... random
[default0]:  masked_softmax_fusion ........................... True
[default0]:  max_position_embeddings ......................... 2048
[default0]:  max_tokens_to_oom ............................... 12000
[default0]:  memory_centric_tiled_linear ..................... False
[default0]:  merge_file ...................................... /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/gpt2-merges.txt
[default0]:  micro_batch_size ................................ 1
[default0]:  min_loss_scale .................................. 1.0
[default0]:  min_lr .......................................... 2e-06
[default0]:  mlp_type ........................................ standard
[default0]:  mmap_warmup ..................................... False
[default0]:  moe_eval_capacity_factor ........................ 1.0
[default0]:  moe_expert_parallel_size ........................ 1
[default0]:  moe_loss_coeff .................................. 0.01
[default0]:  moe_min_capacity ................................ 4
[default0]:  moe_token_dropping .............................. True
[default0]:  moe_train_capacity_factor ....................... 1.0
[default0]:  mos ............................................. False
[default0]:  no_load_lr_state ................................ False
[default0]:  no_load_optim ................................... None
[default0]:  no_load_rng ..................................... None
[default0]:  no_persist_layer_norm ........................... False
[default0]:  no_pipeline_parallel ............................ True
[default0]:  no_save_optim ................................... None
[default0]:  no_save_rng ..................................... None
[default0]:  normalization ................................... layernorm
[default0]:  num_attention_heads ............................. 12
[default0]:  num_attention_heads_teacher ..................... None
[default0]:  num_channels .................................... 3
[default0]:  num_classes ..................................... 1000
[default0]:  num_experts ..................................... [128]
[default0]:  num_experts_switch .............................. None
[default0]:  num_experts_teacher ............................. [1]
[default0]:  num_layers ...................................... 12
[default0]:  num_layers_per_virtual_pipeline_stage ........... None
[default0]:  num_layers_teacher .............................. None
[default0]:  num_workers ..................................... 0
[default0]:  onnx_safe ....................................... None
[default0]:  openai_gelu ..................................... False
[default0]:  optimizer ....................................... adam
[default0]:  output_bert_embeddings .......................... False
[default0]:  overlap_p2p_comm ................................ False
[default0]:  override_opt_param_scheduler .................... True
[default0]:  params_dtype .................................... torch.float16
[default0]:  partition_activations ........................... False
[default0]:  patch_dim ....................................... 16
[default0]:  perform_initialization .......................... True
[default0]:  pipeline_model_parallel_size .................... 1
[default0]:  pipeline_model_parallel_split_rank .............. None
[default0]:  profile_backward ................................ False
[default0]:  query_in_block_prob ............................. 0.1
[default0]:  rampup_batch_size ............................... None
[default0]:  random_ltd ...................................... False
[default0]:  rank ............................................ 0
[default0]:  recompute_granularity ........................... None
[default0]:  recompute_method ................................ None
[default0]:  recompute_num_layers ............................ 1
[default0]:  remote_device ................................... none
[default0]:  reset_attention_mask ............................ False
[default0]:  reset_iteration ................................. False
[default0]:  reset_position_ids .............................. False
[default0]:  retriever_report_topk_accuracies ................ []
[default0]:  retriever_score_scaling ......................... False
[default0]:  retriever_seq_length ............................ 256
[default0]:  retro_add_retriever ............................. False
[default0]:  retro_cyclic_train_iters ........................ None
[default0]:  retro_encoder_attention_dropout ................. 0.1
[default0]:  retro_encoder_hidden_dropout .................... 0.1
[default0]:  retro_encoder_layers ............................ 2
[default0]:  retro_num_neighbors ............................. 2
[default0]:  retro_num_retrieved_chunks ...................... 2
[default0]:  retro_return_doc_ids ............................ False
[default0]:  retro_workdir ................................... None
[default0]:  return_data_index ............................... False
[default0]:  rotary_percent .................................. 1.0
[default0]:  sample_rate ..................................... 1.0
[default0]:  save ............................................ /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/scaling_experiments/output/GPT_0.35B_MoE128_1BATCH_1GPU_1Node/checkpoint/gpt-0.35B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-128-mlc-0.01-cap-1.0-drop-true
[default0]:  save_interval ................................... 1000000
[default0]:  scatter_gather_tensors_in_pipeline .............. True
[default0]:  scattered_embeddings ............................ False
[default0]:  seed ............................................ 1234
[default0]:  seq_length ...................................... 2048
[default0]:  sequence_parallel ............................... False
[default0]:  sgd_momentum .................................... 0.9
[default0]:  short_seq_prob .................................. 0.1
[default0]:  skip_train ...................................... False
[default0]:  split ........................................... 98,2,0
[default0]:  split_transformers .............................. False
[default0]:  squared_relu .................................... False
[default0]:  standalone_embedding_stage ...................... False
[default0]:  start_weight_decay .............................. 0.1
[default0]:  swiglu .......................................... False
[default0]:  swin_backbone_type .............................. tiny
[default0]:  synchronize_each_layer .......................... False
[default0]:  tensor_model_parallel_size ...................... 1
[default0]:  tensorboard_dir ................................. /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/scaling_experiments/output/GPT_0.35B_MoE128_1BATCH_1GPU_1Node/tensorboard/gpt-0.35B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-128-mlc-0.01-cap-1.0-drop-true_n2gpu1227_2023.07.30-22.21.10
[default0]:  tensorboard_log_interval ........................ 1
[default0]:  tensorboard_queue_size .......................... 1
[default0]:  test_data_path .................................. None
[default0]:  tile_factor ..................................... 1
[default0]:  timing_log_level ................................ 0
[default0]:  timing_log_option ............................... minmax
[default0]:  titles_data_path ................................ None
[default0]:  tokenizer_model ................................. None
[default0]:  tokenizer_type .................................. GPT2BPETokenizer
[default0]:  topk ............................................ 1
[default0]:  train_data_exact_num_epochs ..................... None
[default0]:  train_data_path ................................. None
[default0]:  train_desc_path ................................. None
[default0]:  train_doc_idx_path .............................. None
[default0]:  train_idx_path .................................. None
[default0]:  train_iters ..................................... 439453125
[default0]:  train_sample_idx_path ........................... None
[default0]:  train_samples ................................... None
[default0]:  train_shuffle_idx_path .......................... None
[default0]:  train_tokens .................................... 300000000000
[default0]:  transformer_impl ................................ local
[default0]:  transformer_pipeline_model_parallel_size ........ 1
[default0]:  untie_embeddings_and_output_weights ............. False
[default0]:  use_checkpoint_args ............................. False
[default0]:  use_checkpoint_opt_param_scheduler .............. False
[default0]:  use_contiguous_buffers_in_local_ddp ............. True
[default0]:  use_cpu_initialization .......................... None
[default0]:  use_distributed_optimizer ....................... False
[default0]:  use_flash_attn .................................. False
[default0]:  use_one_sent_docs ............................... False
[default0]:  use_pin_memory .................................. False
[default0]:  use_ring_exchange_p2p ........................... False
[default0]:  use_rotary_position_embeddings .................. False
[default0]:  use_tutel ....................................... False
[default0]:  valid_data_path ................................. None
[default0]:  variable_seq_lengths ............................ False
[default0]:  virtual_pipeline_model_parallel_size ............ None
[default0]:  vision_backbone_type ............................ vit
[default0]:  vision_pretraining .............................. False
[default0]:  vision_pretraining_type ......................... classify
[default0]:  vocab_extra_ids ................................. 0
[default0]:  vocab_file ...................................... /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/gpt2-vocab.json
[default0]:  vocab_size ...................................... None
[default0]:  weight_decay .................................... 0.1
[default0]:  weight_decay_incr_style ......................... constant
[default0]:  world_size ...................................... 1
[default0]:  zero_allgather_bucket_size ...................... 0.0
[default0]:  zero_contigious_gradients ....................... False
[default0]:  zero_reduce_bucket_size ......................... 0.0
[default0]:  zero_reduce_scatter ............................. False
[default0]:  zero_stage ...................................... 1.0
[default0]:-------------------- end of arguments ---------------------
[default0]:setting number of micro-batches to constant 1
[default0]:> building GPT2BPETokenizer tokenizer ...
[default0]: > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
[default0]:> setting tensorboard ...
[default0]:> initializing torch distributed ...
[default0]:[2023-07-30 22:21:34,080] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[default0]:[2023-07-30 22:21:34,080] [INFO] [comm.py:616:init_distributed] cdb=None
[default0]:[2023-07-30 22:21:34,080] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[default0]:> initialized tensor model parallel with size 1
[default0]:> initialized pipeline model parallel with size 1
[default0]:> setting random seeds to 1234 ...
[default0]:> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
[default0]:> compiling dataset index builder ...
[default0]:make: Entering directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/data'
[default0]:make: Nothing to be done for 'default'.
[default0]:make: Leaving directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/data'
[default0]:>>> done with dataset index builder. Compilation time: 0.089 seconds
[default0]:> compiling and loading fused kernels ...
[default0]:Loading extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Loading extension module scaled_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:ninja: no work to do.
[default0]:Loading extension module scaled_softmax_cuda...
[default0]:n2gpu1227:3528640:3528640 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.95<0>
[default0]:n2gpu1227:3528640:3528640 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1227:3528640:3528640 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.95<0>
[default0]:n2gpu1227:3528640:3528640 [0] NCCL INFO Using network IB
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Connected all rings
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1227:3528640:3528840 [0] NCCL INFO comm 0x14a6300090d0 rank 0 nranks 1 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:>>> done with compiling and loading fused kernels. Compilation time: 2.242 seconds
[default0]:time to initialize megatron (seconds): 5.623
[default0]:[after megatron is initialized] datetime: 2023-07-30 22:21:37 
[default0]:building GPT model ...
[default0]:[2023-07-30 22:21:37,167] [INFO] [utils.py:785:see_memory_usage] Before Building Model
[default0]:[2023-07-30 22:21:37,168] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.2 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-07-30 22:21:37,168] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 26.97 GB, percent = 5.4%
[default0]:[2023-07-30 22:21:37,292] [INFO] [utils.py:785:see_memory_usage] After Building Model
[default0]:[2023-07-30 22:21:37,293] [INFO] [utils.py:786:see_memory_usage] MA 0.24 GB         Max_MA 0.24 GB         CA 0.25 GB         Max_CA 0 GB 
[default0]:[2023-07-30 22:21:37,293] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 26.98 GB, percent = 5.4%
[default0]: > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 125262336
[default0]:param_group keyset: dict_keys(['name', 'params', 'wd_mult', 'lr_mult'])
[default0]:> learning rate decay style: cosine
[default0]:DeepSpeed is enabled.
[default0]:[2023-07-30 22:21:37,295] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Connected all rings
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1227:3528640:3528975 [0] NCCL INFO comm 0x14a5680090d0 rank 0 nranks 1 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:[2023-07-30 22:21:37,680] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[default0]:[2023-07-30 22:21:37,681] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[default0]:[2023-07-30 22:21:37,681] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[default0]:[2023-07-30 22:21:37,683] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[default0]:[2023-07-30 22:21:37,683] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'apex.optimizers.fused_adam.FusedAdam'>
[default0]:[2023-07-30 22:21:37,684] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[default0]:[2023-07-30 22:21:37,684] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000
[default0]:[2023-07-30 22:21:37,684] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000
[default0]:[2023-07-30 22:21:37,684] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[default0]:[2023-07-30 22:21:37,684] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
[default0]:Rank: 0 partition count [1, 1] and sizes[(125140992, False), (121344, False)] 
[default0]:[2023-07-30 22:21:37,981] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[default0]:[2023-07-30 22:21:37,982] [INFO] [utils.py:786:see_memory_usage] MA 0.7 GB         Max_MA 0.7 GB         CA 0.7 GB         Max_CA 1 GB 
[default0]:[2023-07-30 22:21:37,982] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 27.22 GB, percent = 5.4%
[default0]:[2023-07-30 22:21:38,032] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[default0]:[2023-07-30 22:21:38,032] [INFO] [utils.py:786:see_memory_usage] MA 1.64 GB         Max_MA 2.1 GB         CA 2.11 GB         Max_CA 2 GB 
[default0]:[2023-07-30 22:21:38,033] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 27.22 GB, percent = 5.4%
[default0]:[2023-07-30 22:21:38,033] [INFO] [stage_1_and_2.py:493:__init__] optimizer state initialized
[default0]:[2023-07-30 22:21:38,074] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[default0]:[2023-07-30 22:21:38,075] [INFO] [utils.py:786:see_memory_usage] MA 1.64 GB         Max_MA 1.64 GB         CA 2.11 GB         Max_CA 2 GB 
[default0]:[2023-07-30 22:21:38,075] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 27.22 GB, percent = 5.4%
[default0]:[2023-07-30 22:21:38,078] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[default0]:[2023-07-30 22:21:38,078] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[default0]:[2023-07-30 22:21:38,078] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.optimizer_param_scheduler.OptimizerParamScheduler object at 0x14a6c3757700>
[default0]:[2023-07-30 22:21:38,078] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:38,079] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[default0]:[2023-07-30 22:21:38,079] [INFO] [config.py:964:print]   activation_checkpointing_config  {
[default0]:    "partition_activations": false, 
[default0]:    "contiguous_memory_optimization": false, 
[default0]:    "cpu_checkpointing": false, 
[default0]:    "number_checkpoints": null, 
[default0]:    "synchronize_checkpoint_boundary": false, 
[default0]:    "profile": false
[default0]:}
[default0]:[2023-07-30 22:21:38,079] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[default0]:[2023-07-30 22:21:38,079] [INFO] [config.py:964:print]   amp_enabled .................. False
[default0]:[2023-07-30 22:21:38,079] [INFO] [config.py:964:print]   amp_params ................... False
[default0]:[2023-07-30 22:21:38,079] [INFO] [config.py:964:print]   autotuning_config ............ {
[default0]:    "enabled": false, 
[default0]:    "start_step": null, 
[default0]:    "end_step": null, 
[default0]:    "metric_path": null, 
[default0]:    "arg_mappings": null, 
[default0]:    "metric": "throughput", 
[default0]:    "model_info": null, 
[default0]:    "results_dir": "autotuning_results", 
[default0]:    "exps_dir": "autotuning_exps", 
[default0]:    "overwrite": true, 
[default0]:    "fast": true, 
[default0]:    "start_profile_step": 3, 
[default0]:    "end_profile_step": 5, 
[default0]:    "tuner_type": "gridsearch", 
[default0]:    "tuner_early_stopping": 5, 
[default0]:    "tuner_num_trials": 50, 
[default0]:    "model_info_path": null, 
[default0]:    "mp_size": 1, 
[default0]:    "max_train_batch_size": null, 
[default0]:    "min_train_batch_size": 1, 
[default0]:    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[default0]:    "min_train_micro_batch_size_per_gpu": 1, 
[default0]:    "num_tuning_micro_batch_sizes": 3
[default0]:}
[default0]:[2023-07-30 22:21:38,079] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[default0]:[2023-07-30 22:21:38,079] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x14a6c37b5c30>
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   communication_data_type ...... None
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   curriculum_params_legacy ..... {'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 56390977, 'difficulty_step': 8}}
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   disable_allgather ............ False
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   dump_state ................... False
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 500, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[default0]:[2023-07-30 22:21:38,080] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   flops_profiler_config ........ {
[default0]:    "enabled": false, 
[default0]:    "recompute_fwd_factor": 0.0, 
[default0]:    "profile_step": 1, 
[default0]:    "module_depth": -1, 
[default0]:    "top_modules": 1, 
[default0]:    "detailed": true, 
[default0]:    "output_file": null
[default0]:}
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   fp16_enabled ................. True
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   global_rank .................. 0
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   gradient_clipping ............ 1
[default0]:[2023-07-30 22:21:38,081] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[default0]:[2023-07-30 22:21:38,082] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[default0]:[2023-07-30 22:21:38,082] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[default0]:[2023-07-30 22:21:38,082] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[default0]:[2023-07-30 22:21:38,082] [INFO] [config.py:964:print]   loss_scale ................... 0
[default0]:[2023-07-30 22:21:38,082] [INFO] [config.py:964:print]   memory_breakdown ............. False
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   nebula_config ................ {
[default0]:    "enabled": false, 
[default0]:    "persistent_storage_path": null, 
[default0]:    "persistent_time_interval": 100, 
[default0]:    "num_of_version_in_retention": 2, 
[default0]:    "enable_nebula_load": true, 
[default0]:    "load_path": null
[default0]:}
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   optimizer_name ............... None
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   optimizer_params ............. None
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   pld_enabled .................. False
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   pld_params ................... False
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   prescale_gradients ........... False
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   scheduler_name ............... None
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   scheduler_params ............. None
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   sparse_attention ............. None
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[default0]:[2023-07-30 22:21:38,083] [INFO] [config.py:964:print]   steps_per_print .............. 5
[default0]:[2023-07-30 22:21:38,084] [INFO] [config.py:964:print]   train_batch_size ............. 1
[default0]:[2023-07-30 22:21:38,084] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[default0]:[2023-07-30 22:21:38,084] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[default0]:[2023-07-30 22:21:38,084] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[default0]:[2023-07-30 22:21:38,084] [INFO] [config.py:964:print]   world_size ................... 1
[default0]:[2023-07-30 22:21:38,084] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  False
[default0]:[2023-07-30 22:21:38,084] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[default0]:[2023-07-30 22:21:38,084] [INFO] [config.py:964:print]   zero_enabled ................. True
[default0]:[2023-07-30 22:21:38,084] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[default0]:[2023-07-30 22:21:38,084] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2
[default0]:[2023-07-30 22:21:38,084] [INFO] [config.py:950:print_user_config]   json = {
[default0]:    "train_batch_size": 1, 
[default0]:    "train_micro_batch_size_per_gpu": 1, 
[default0]:    "steps_per_print": 5, 
[default0]:    "zero_optimization": {
[default0]:        "stage": 2
[default0]:    }, 
[default0]:    "gradient_clipping": 1, 
[default0]:    "prescale_gradients": false, 
[default0]:    "fp16": {
[default0]:        "enabled": true, 
[default0]:        "loss_scale": 0, 
[default0]:        "loss_scale_window": 500, 
[default0]:        "hysteresis": 2, 
[default0]:        "min_loss_scale": 1, 
[default0]:        "initial_scale_power": 11
[default0]:    }, 
[default0]:    "bf16": {
[default0]:        "enabled": false
[default0]:    }, 
[default0]:    "curriculum_learning": {
[default0]:        "enabled": false, 
[default0]:        "curriculum_type": "seqlen", 
[default0]:        "min_difficulty": 80, 
[default0]:        "max_difficulty": 2.048000e+03, 
[default0]:        "schedule_type": "fixed_linear", 
[default0]:        "schedule_config": {
[default0]:            "total_curriculum_step": 5.639098e+07, 
[default0]:            "difficulty_step": 8
[default0]:        }
[default0]:    }, 
[default0]:    "wall_clock_breakdown": false
[default0]:}
[default0]:[2023-07-30 22:21:38,085] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/scaling_experiments/output/GPT_0.35B_MoE128_1BATCH_1GPU_1Node/checkpoint/gpt-0.35B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-128-mlc-0.01-cap-1.0-drop-true/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:WARNING: could not find the metadata file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/scaling_experiments/output/GPT_0.35B_MoE128_1BATCH_1GPU_1Node/checkpoint/gpt-0.35B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-128-mlc-0.01-cap-1.0-drop-true 
[default0]:    will not load any checkpoints and will start from random
[default0]:(min, max) time across ranks (ms):
[default0]:    load-checkpoint ................................: (0.69, 0.69)
[default0]:[after model, optimizer, and learning rate scheduler are built] datetime: 2023-07-30 22:21:38 
[default0]:> building train, validation, and test datasets ...
[default0]: > datasets target sizes (minimum size):
[default0]:    train:      439453125
[default0]:    validation: 219726600
[default0]:    test:       50
[default0]:> building train, validation, and test datasets for GPT ...
[default0]:Single data path provided for train, valid & test
[default0]: > building dataset index ...
[default0]:    reading sizes...
[default0]:    reading pointers...
[default0]:    reading document index...
[default0]:    creating numpy buffer of mmap...
[default0]:    creating memory view of numpy buffer...
[default0]: > finished creating indexed dataset in 0.002864 seconds
[default0]:    number of documents: 10000
[default0]: > dataset split:
[default0]:    train:
[default0]:     document indices in [0, 9800) total of 9800 documents
[default0]:    validation:
[default0]:     document indices in [9800, 10000) total of 200 documents
[default0]:    test:
[default0]:     document indices in [10000, 10000) total of 0 documents
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Connected all rings
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1227:3528640:3528981 [0] NCCL INFO comm 0x14a4800090d0 rank 0 nranks 1 cudaDev 0 busId 44000 - Init COMPLETE
[default0]: > loading doc-idx mapping from /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/index-cache/153ec6eb4421dfd1cf9815ea8f6e40e4_doc_idx.npy
[default0]: > loading sample-idx mapping from /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/index-cache/153ec6eb4421dfd1cf9815ea8f6e40e4_sample_idx.npy
[default0]: > loading shuffle-idx mapping from /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/index-cache/153ec6eb4421dfd1cf9815ea8f6e40e4_shuffle_idx.npy
[default0]:    loaded indexed file in 0.019 seconds
[default0]:    total number of samples: 439466004
[default0]:    total number of epochs: 30909
[default0]: > loading doc-idx mapping from /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/index-cache/de3819301120d9a35080a0a129b3870d_doc_idx.npy
[default0]: > loading sample-idx mapping from /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/index-cache/de3819301120d9a35080a0a129b3870d_sample_idx.npy
[default0]: > loading shuffle-idx mapping from /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/index-cache/de3819301120d9a35080a0a129b3870d_shuffle_idx.npy
[default0]:    loaded indexed file in 0.062 seconds
[default0]:    total number of samples: 219726809
[default0]:    total number of epochs: 648115
[default0]:> finished creating GPT datasets ...
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Connected all rings
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO Connected all trees
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1227:3528640:3528991 [0] NCCL INFO comm 0x14a4802cf4b0 rank 0 nranks 1 cudaDev 0 busId 44000 - Init COMPLETE
[default0]:[after dataloaders are built] datetime: 2023-07-30 22:21:39 
[default0]:done with setup ...
[default0]:(min, max) time across ranks (ms):
[default0]:    model-and-optimizer-setup ......................: (964.93, 964.93)
[default0]:    train/valid/test-data-iterators-setup ..........: (1124.16, 1124.16)
[default0]:training ...
[default0]:[before the start of training step] datetime: 2023-07-30 22:21:39 
[default0]:[2023-07-30 22:21:41,183] [INFO] [logging.py:96:log_dist] [Rank 0] step=5, skipped=0, lr=[4.369066666666667e-09, 4.369066666666667e-09], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:41,183] [INFO] [timer.py:215:stop] epoch=0/micro_step=5/global_step=5, RunningAvgSamplesPerSec=7.630210825236448, CurrSamplesPerSec=7.79939491197959, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration        5/439453125 | consumed samples:            5 | consumed tokens:        10240 | elapsed time per iteration (ms): 359.3 | learning rate: 4.369E-09 | global batch size:     1 | lm loss: 1.085262E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.783 | TFLOPs: 6.92 |
[default0]:[Rank 0] (after 5 iterations) memory (MB) | allocated: 1770.31103515625 | max allocated: 3362.361328125 | reserved: 3994.0 | max reserved: 3994.0
[default0]:[2023-07-30 22:21:42,059] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[9.830400000000001e-09, 9.830400000000001e-09], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:42,060] [INFO] [timer.py:215:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=7.7508219290414155, CurrSamplesPerSec=7.6925125402342065, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       10/439453125 | consumed samples:           10 | consumed tokens:        20480 | elapsed time per iteration (ms): 175.4 | learning rate: 9.830E-09 | global batch size:     1 | lm loss: 1.084972E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.702 | TFLOPs: 14.17 |
[default0]:[2023-07-30 22:21:42,832] [INFO] [logging.py:96:log_dist] [Rank 0] step=15, skipped=0, lr=[1.5291733333333332e-08, 1.5291733333333332e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:42,833] [INFO] [timer.py:215:stop] epoch=0/micro_step=15/global_step=15, RunningAvgSamplesPerSec=7.773708827685296, CurrSamplesPerSec=7.822742125602423, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       15/439453125 | consumed samples:           15 | consumed tokens:        30720 | elapsed time per iteration (ms): 154.2 | learning rate: 1.529E-08 | global batch size:     1 | lm loss: 1.084826E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.485 | TFLOPs: 16.11 |
[default0]:[2023-07-30 22:21:43,593] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[2.0753066666666666e-08, 2.0753066666666666e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:43,593] [INFO] [timer.py:215:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=7.779128815558614, CurrSamplesPerSec=7.864383898119172, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       20/439453125 | consumed samples:           20 | consumed tokens:        40960 | elapsed time per iteration (ms): 152.2 | learning rate: 2.075E-08 | global batch size:     1 | lm loss: 1.085709E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.572 | TFLOPs: 16.33 |
[default0]:[2023-07-30 22:21:44,351] [INFO] [logging.py:96:log_dist] [Rank 0] step=25, skipped=0, lr=[2.62144e-08, 2.62144e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:44,353] [INFO] [timer.py:215:stop] epoch=0/micro_step=25/global_step=25, RunningAvgSamplesPerSec=7.762780718747501, CurrSamplesPerSec=7.700152743508401, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       25/439453125 | consumed samples:           25 | consumed tokens:        51200 | elapsed time per iteration (ms): 152.0 | learning rate: 2.621E-08 | global batch size:     1 | lm loss: 1.085252E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.579 | TFLOPs: 16.35 |
[default0]:[2023-07-30 22:21:45,117] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[3.1675733333333335e-08, 3.1675733333333335e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:45,117] [INFO] [timer.py:215:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=7.77602651677046, CurrSamplesPerSec=7.748117606201, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       30/439453125 | consumed samples:           30 | consumed tokens:        61440 | elapsed time per iteration (ms): 153.0 | learning rate: 3.168E-08 | global batch size:     1 | lm loss: 1.085226E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.536 | TFLOPs: 16.24 |
[default0]:[2023-07-30 22:21:45,842] [INFO] [logging.py:96:log_dist] [Rank 0] step=35, skipped=0, lr=[3.713706666666667e-08, 3.713706666666667e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:45,843] [INFO] [timer.py:215:stop] epoch=0/micro_step=35/global_step=35, RunningAvgSamplesPerSec=7.7887987452570675, CurrSamplesPerSec=7.820670880647387, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       35/439453125 | consumed samples:           35 | consumed tokens:        71680 | elapsed time per iteration (ms): 145.0 | learning rate: 3.714E-08 | global batch size:     1 | lm loss: 1.084700E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.895 | TFLOPs: 17.13 |
[default0]:[2023-07-30 22:21:46,609] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[4.2598400000000004e-08, 4.2598400000000004e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:46,609] [INFO] [timer.py:215:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=7.797149862302995, CurrSamplesPerSec=7.8579010770576785, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       40/439453125 | consumed samples:           40 | consumed tokens:        81920 | elapsed time per iteration (ms): 153.1 | learning rate: 4.260E-08 | global batch size:     1 | lm loss: 1.084694E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.533 | TFLOPs: 16.23 |
[default0]:[2023-07-30 22:21:47,388] [INFO] [logging.py:96:log_dist] [Rank 0] step=45, skipped=0, lr=[4.805973333333334e-08, 4.805973333333334e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:47,389] [INFO] [timer.py:215:stop] epoch=0/micro_step=45/global_step=45, RunningAvgSamplesPerSec=7.803608493046807, CurrSamplesPerSec=7.849695036934312, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       45/439453125 | consumed samples:           45 | consumed tokens:        92160 | elapsed time per iteration (ms): 156.3 | learning rate: 4.806E-08 | global batch size:     1 | lm loss: 1.083223E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.397 | TFLOPs: 15.89 |
[default0]:[2023-07-30 22:21:48,120] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[5.3521066666666666e-08, 5.3521066666666666e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:48,120] [INFO] [timer.py:215:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=7.8053545103310356, CurrSamplesPerSec=7.718659251598276, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       50/439453125 | consumed samples:           50 | consumed tokens:       102400 | elapsed time per iteration (ms): 146.0 | learning rate: 5.352E-08 | global batch size:     1 | lm loss: 1.083442E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.851 | TFLOPs: 17.02 |
[default0]:[2023-07-30 22:21:48,849] [INFO] [logging.py:96:log_dist] [Rank 0] step=55, skipped=0, lr=[5.89824e-08, 5.89824e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:48,851] [INFO] [timer.py:215:stop] epoch=0/micro_step=55/global_step=55, RunningAvgSamplesPerSec=7.807623030288215, CurrSamplesPerSec=7.775768575491234, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       55/439453125 | consumed samples:           55 | consumed tokens:       112640 | elapsed time per iteration (ms): 146.4 | learning rate: 5.898E-08 | global batch size:     1 | lm loss: 1.082107E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.831 | TFLOPs: 16.97 |
[default0]:[2023-07-30 22:21:49,636] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[6.444373333333333e-08, 6.444373333333333e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:49,637] [INFO] [timer.py:215:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=7.812304280639897, CurrSamplesPerSec=7.914423245659553, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       60/439453125 | consumed samples:           60 | consumed tokens:       122880 | elapsed time per iteration (ms): 157.4 | learning rate: 6.444E-08 | global batch size:     1 | lm loss: 1.081043E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.353 | TFLOPs: 15.79 |
[default0]:[2023-07-30 22:21:50,376] [INFO] [logging.py:96:log_dist] [Rank 0] step=65, skipped=0, lr=[6.990506666666667e-08, 6.990506666666667e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:50,376] [INFO] [timer.py:215:stop] epoch=0/micro_step=65/global_step=65, RunningAvgSamplesPerSec=7.814726720872275, CurrSamplesPerSec=7.86407424767976, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       65/439453125 | consumed samples:           65 | consumed tokens:       133120 | elapsed time per iteration (ms): 147.9 | learning rate: 6.991E-08 | global batch size:     1 | lm loss: 1.080054E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.764 | TFLOPs: 16.81 |
[default0]:[2023-07-30 22:21:51,166] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[7.536640000000001e-08, 7.536640000000001e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:51,166] [INFO] [timer.py:215:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=7.818048006219074, CurrSamplesPerSec=7.791976369395394, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       70/439453125 | consumed samples:           70 | consumed tokens:       143360 | elapsed time per iteration (ms): 158.1 | learning rate: 7.537E-08 | global batch size:     1 | lm loss: 1.079340E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.324 | TFLOPs: 15.71 |
[default0]:[2023-07-30 22:21:51,913] [INFO] [logging.py:96:log_dist] [Rank 0] step=75, skipped=0, lr=[8.082773333333334e-08, 8.082773333333334e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:51,914] [INFO] [timer.py:215:stop] epoch=0/micro_step=75/global_step=75, RunningAvgSamplesPerSec=7.8204982931175, CurrSamplesPerSec=7.802630452981118, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       75/439453125 | consumed samples:           75 | consumed tokens:       153600 | elapsed time per iteration (ms): 149.6 | learning rate: 8.083E-08 | global batch size:     1 | lm loss: 1.078534E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.687 | TFLOPs: 16.61 |
[default0]:[2023-07-30 22:21:52,662] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[8.628906666666668e-08, 8.628906666666668e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:52,663] [INFO] [timer.py:215:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=7.820232499353105, CurrSamplesPerSec=7.790818496744773, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       80/439453125 | consumed samples:           80 | consumed tokens:       163840 | elapsed time per iteration (ms): 149.5 | learning rate: 8.629E-08 | global batch size:     1 | lm loss: 1.078796E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.691 | TFLOPs: 16.63 |
[default0]:[2023-07-30 22:21:53,423] [INFO] [logging.py:96:log_dist] [Rank 0] step=85, skipped=0, lr=[9.175040000000002e-08, 9.175040000000002e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:53,424] [INFO] [timer.py:215:stop] epoch=0/micro_step=85/global_step=85, RunningAvgSamplesPerSec=7.8161145256569995, CurrSamplesPerSec=7.8069293109032225, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       85/439453125 | consumed samples:           85 | consumed tokens:       174080 | elapsed time per iteration (ms): 152.4 | learning rate: 9.175E-08 | global batch size:     1 | lm loss: 1.077242E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.562 | TFLOPs: 16.30 |
[default0]:[2023-07-30 22:21:54,177] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[9.721173333333333e-08, 9.721173333333333e-08], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:54,179] [INFO] [timer.py:215:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=7.8150592063137925, CurrSamplesPerSec=7.6877468689456965, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       90/439453125 | consumed samples:           90 | consumed tokens:       184320 | elapsed time per iteration (ms): 151.0 | learning rate: 9.721E-08 | global batch size:     1 | lm loss: 1.074635E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.623 | TFLOPs: 16.46 |
[default0]:[2023-07-30 22:21:54,910] [INFO] [logging.py:96:log_dist] [Rank 0] step=95, skipped=0, lr=[1.0267306666666667e-07, 1.0267306666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:54,911] [INFO] [timer.py:215:stop] epoch=0/micro_step=95/global_step=95, RunningAvgSamplesPerSec=7.815511500396837, CurrSamplesPerSec=7.815351935528952, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration       95/439453125 | consumed samples:           95 | consumed tokens:       194560 | elapsed time per iteration (ms): 146.2 | learning rate: 1.027E-07 | global batch size:     1 | lm loss: 1.071906E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.841 | TFLOPs: 17.00 |
[default0]:[2023-07-30 22:21:55,649] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[1.081344e-07, 1.081344e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:55,649] [INFO] [timer.py:215:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=7.817333686541995, CurrSamplesPerSec=7.7991628687087315, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      100/439453125 | consumed samples:          100 | consumed tokens:       204800 | elapsed time per iteration (ms): 147.7 | learning rate: 1.081E-07 | global batch size:     1 | lm loss: 1.071692E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.769 | TFLOPs: 16.82 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 100 | lm loss value: 1.068772E+01 | lm loss PPL: 4.381451E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:21:59,296] [INFO] [logging.py:96:log_dist] [Rank 0] step=105, skipped=0, lr=[1.1359573333333334e-07, 1.1359573333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:21:59,296] [INFO] [timer.py:215:stop] epoch=0/micro_step=105/global_step=105, RunningAvgSamplesPerSec=7.803682592462435, CurrSamplesPerSec=7.874246471958713, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      105/439453125 | consumed samples:          105 | consumed tokens:       215040 | elapsed time per iteration (ms): 729.4 | learning rate: 1.136E-07 | global batch size:     1 | lm loss: 1.070442E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.371 | TFLOPs: 3.41 |
[default0]:[2023-07-30 22:22:00,063] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=0, lr=[1.1905706666666667e-07, 1.1905706666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:00,064] [INFO] [timer.py:215:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=7.808799839847014, CurrSamplesPerSec=7.879897572513663, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      110/439453125 | consumed samples:          110 | consumed tokens:       225280 | elapsed time per iteration (ms): 153.7 | learning rate: 1.191E-07 | global batch size:     1 | lm loss: 1.069241E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.508 | TFLOPs: 16.17 |
[default0]:[2023-07-30 22:22:00,794] [INFO] [logging.py:96:log_dist] [Rank 0] step=115, skipped=0, lr=[1.245184e-07, 1.245184e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:00,795] [INFO] [timer.py:215:stop] epoch=0/micro_step=115/global_step=115, RunningAvgSamplesPerSec=7.811029381651471, CurrSamplesPerSec=7.886668847847588, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      115/439453125 | consumed samples:          115 | consumed tokens:       235520 | elapsed time per iteration (ms): 146.0 | learning rate: 1.245E-07 | global batch size:     1 | lm loss: 1.067580E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.849 | TFLOPs: 17.02 |
[default0]:[2023-07-30 22:22:01,545] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=0, lr=[1.2997973333333334e-07, 1.2997973333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:01,548] [INFO] [timer.py:215:stop] epoch=0/micro_step=120/global_step=120, RunningAvgSamplesPerSec=7.814027215660342, CurrSamplesPerSec=7.7541050887941525, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      120/439453125 | consumed samples:          120 | consumed tokens:       245760 | elapsed time per iteration (ms): 150.7 | learning rate: 1.300E-07 | global batch size:     1 | lm loss: 1.068065E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.636 | TFLOPs: 16.49 |
[default0]:[2023-07-30 22:22:02,286] [INFO] [logging.py:96:log_dist] [Rank 0] step=125, skipped=0, lr=[1.3544106666666668e-07, 1.3544106666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:02,287] [INFO] [timer.py:215:stop] epoch=0/micro_step=125/global_step=125, RunningAvgSamplesPerSec=7.817074838965644, CurrSamplesPerSec=7.780326512592493, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      125/439453125 | consumed samples:          125 | consumed tokens:       256000 | elapsed time per iteration (ms): 147.8 | learning rate: 1.354E-07 | global batch size:     1 | lm loss: 1.063595E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.768 | TFLOPs: 16.82 |
[default0]:[2023-07-30 22:22:03,065] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=0, lr=[1.409024e-07, 1.409024e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:03,066] [INFO] [timer.py:215:stop] epoch=0/micro_step=130/global_step=130, RunningAvgSamplesPerSec=7.817377677656984, CurrSamplesPerSec=7.7516688721159746, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      130/439453125 | consumed samples:          130 | consumed tokens:       266240 | elapsed time per iteration (ms): 155.8 | learning rate: 1.409E-07 | global batch size:     1 | lm loss: 1.063173E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.420 | TFLOPs: 15.95 |
[default0]:[2023-07-30 22:22:03,804] [INFO] [logging.py:96:log_dist] [Rank 0] step=135, skipped=0, lr=[1.4636373333333334e-07, 1.4636373333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:03,805] [INFO] [timer.py:215:stop] epoch=0/micro_step=135/global_step=135, RunningAvgSamplesPerSec=7.818714372315088, CurrSamplesPerSec=7.786783107209957, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      135/439453125 | consumed samples:          135 | consumed tokens:       276480 | elapsed time per iteration (ms): 148.2 | learning rate: 1.464E-07 | global batch size:     1 | lm loss: 1.061077E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.746 | TFLOPs: 16.76 |
[default0]:[2023-07-30 22:22:04,567] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=0, lr=[1.5182506666666668e-07, 1.5182506666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:04,569] [INFO] [timer.py:215:stop] epoch=0/micro_step=140/global_step=140, RunningAvgSamplesPerSec=7.815766990001798, CurrSamplesPerSec=7.60216412161856, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      140/439453125 | consumed samples:          140 | consumed tokens:       286720 | elapsed time per iteration (ms): 152.4 | learning rate: 1.518E-07 | global batch size:     1 | lm loss: 1.058713E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.561 | TFLOPs: 16.30 |
[default0]:[2023-07-30 22:22:05,355] [INFO] [logging.py:96:log_dist] [Rank 0] step=145, skipped=0, lr=[1.5728640000000002e-07, 1.5728640000000002e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:05,356] [INFO] [timer.py:215:stop] epoch=0/micro_step=145/global_step=145, RunningAvgSamplesPerSec=7.8160188142567275, CurrSamplesPerSec=7.798640821828662, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      145/439453125 | consumed samples:          145 | consumed tokens:       296960 | elapsed time per iteration (ms): 157.3 | learning rate: 1.573E-07 | global batch size:     1 | lm loss: 1.057580E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.356 | TFLOPs: 15.79 |
[default0]:[2023-07-30 22:22:06,096] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=0, lr=[1.6274773333333333e-07, 1.6274773333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:06,097] [INFO] [timer.py:215:stop] epoch=0/micro_step=150/global_step=150, RunningAvgSamplesPerSec=7.816904532108976, CurrSamplesPerSec=7.785352199471733, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      150/439453125 | consumed samples:          150 | consumed tokens:       307200 | elapsed time per iteration (ms): 148.2 | learning rate: 1.627E-07 | global batch size:     1 | lm loss: 1.057622E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.750 | TFLOPs: 16.77 |
[default0]:[2023-07-30 22:22:06,864] [INFO] [logging.py:96:log_dist] [Rank 0] step=155, skipped=0, lr=[1.6820906666666667e-07, 1.6820906666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:06,864] [INFO] [timer.py:215:stop] epoch=0/micro_step=155/global_step=155, RunningAvgSamplesPerSec=7.817030509901967, CurrSamplesPerSec=7.77860944715417, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      155/439453125 | consumed samples:          155 | consumed tokens:       317440 | elapsed time per iteration (ms): 153.7 | learning rate: 1.682E-07 | global batch size:     1 | lm loss: 1.057441E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.508 | TFLOPs: 16.17 |
[default0]:[2023-07-30 22:22:07,596] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=0, lr=[1.7367040000000001e-07, 1.7367040000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:07,597] [INFO] [timer.py:215:stop] epoch=0/micro_step=160/global_step=160, RunningAvgSamplesPerSec=7.818528044127878, CurrSamplesPerSec=7.873832573978437, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      160/439453125 | consumed samples:          160 | consumed tokens:       327680 | elapsed time per iteration (ms): 146.3 | learning rate: 1.737E-07 | global batch size:     1 | lm loss: 1.058430E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.837 | TFLOPs: 16.99 |
[default0]:[2023-07-30 22:22:08,381] [INFO] [logging.py:96:log_dist] [Rank 0] step=165, skipped=0, lr=[1.7913173333333336e-07, 1.7913173333333336e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:08,382] [INFO] [timer.py:215:stop] epoch=0/micro_step=165/global_step=165, RunningAvgSamplesPerSec=7.819406265859347, CurrSamplesPerSec=7.805737936784433, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      165/439453125 | consumed samples:          165 | consumed tokens:       337920 | elapsed time per iteration (ms): 157.3 | learning rate: 1.791E-07 | global batch size:     1 | lm loss: 1.053336E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.355 | TFLOPs: 15.79 |
[default0]:[2023-07-30 22:22:09,120] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=0, lr=[1.845930666666667e-07, 1.845930666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:09,120] [INFO] [timer.py:215:stop] epoch=0/micro_step=170/global_step=170, RunningAvgSamplesPerSec=7.819281462389236, CurrSamplesPerSec=7.795278195432826, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      170/439453125 | consumed samples:          170 | consumed tokens:       348160 | elapsed time per iteration (ms): 147.5 | learning rate: 1.846E-07 | global batch size:     1 | lm loss: 1.047976E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.780 | TFLOPs: 16.85 |
[default0]:[2023-07-30 22:22:09,858] [INFO] [logging.py:96:log_dist] [Rank 0] step=175, skipped=0, lr=[1.9005440000000004e-07, 1.9005440000000004e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:09,859] [INFO] [timer.py:215:stop] epoch=0/micro_step=175/global_step=175, RunningAvgSamplesPerSec=7.820811902294803, CurrSamplesPerSec=7.770798440765389, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      175/439453125 | consumed samples:          175 | consumed tokens:       358400 | elapsed time per iteration (ms): 147.8 | learning rate: 1.901E-07 | global batch size:     1 | lm loss: 1.052437E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.766 | TFLOPs: 16.81 |
[default0]:[2023-07-30 22:22:10,608] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=0, lr=[1.9551573333333333e-07, 1.9551573333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:10,609] [INFO] [timer.py:215:stop] epoch=0/micro_step=180/global_step=180, RunningAvgSamplesPerSec=7.821449804241687, CurrSamplesPerSec=7.8278812129537005, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      180/439453125 | consumed samples:          180 | consumed tokens:       368640 | elapsed time per iteration (ms): 150.0 | learning rate: 1.955E-07 | global batch size:     1 | lm loss: 1.039689E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.665 | TFLOPs: 16.56 |
[default0]:[2023-07-30 22:22:11,361] [INFO] [logging.py:96:log_dist] [Rank 0] step=185, skipped=0, lr=[2.0097706666666667e-07, 2.0097706666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:11,362] [INFO] [timer.py:215:stop] epoch=0/micro_step=185/global_step=185, RunningAvgSamplesPerSec=7.821890093076255, CurrSamplesPerSec=7.890170170019527, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      185/439453125 | consumed samples:          185 | consumed tokens:       378880 | elapsed time per iteration (ms): 150.3 | learning rate: 2.010E-07 | global batch size:     1 | lm loss: 1.044905E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.652 | TFLOPs: 16.53 |
[default0]:[2023-07-30 22:22:12,116] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=0, lr=[2.064384e-07, 2.064384e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:12,116] [INFO] [timer.py:215:stop] epoch=0/micro_step=190/global_step=190, RunningAvgSamplesPerSec=7.822025646824128, CurrSamplesPerSec=7.645022528762449, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      190/439453125 | consumed samples:          190 | consumed tokens:       389120 | elapsed time per iteration (ms): 151.0 | learning rate: 2.064E-07 | global batch size:     1 | lm loss: 1.044585E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.621 | TFLOPs: 16.45 |
[default0]:[2023-07-30 22:22:12,850] [INFO] [logging.py:96:log_dist] [Rank 0] step=195, skipped=0, lr=[2.1189973333333335e-07, 2.1189973333333335e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:12,851] [INFO] [timer.py:215:stop] epoch=0/micro_step=195/global_step=195, RunningAvgSamplesPerSec=7.821638499048626, CurrSamplesPerSec=7.734016326184404, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      195/439453125 | consumed samples:          195 | consumed tokens:       399360 | elapsed time per iteration (ms): 147.0 | learning rate: 2.119E-07 | global batch size:     1 | lm loss: 1.042636E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.801 | TFLOPs: 16.90 |
[default0]:[2023-07-30 22:22:13,718] [INFO] [logging.py:96:log_dist] [Rank 0] step=200, skipped=0, lr=[2.173610666666667e-07, 2.173610666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:13,719] [INFO] [timer.py:215:stop] epoch=0/micro_step=200/global_step=200, RunningAvgSamplesPerSec=7.822280280566379, CurrSamplesPerSec=7.92468130692972, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      200/439453125 | consumed samples:          200 | consumed tokens:       409600 | elapsed time per iteration (ms): 173.6 | learning rate: 2.174E-07 | global batch size:     1 | lm loss: 1.043415E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.762 | TFLOPs: 14.32 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 200 | lm loss value: 1.039569E+01 | lm loss PPL: 3.271837E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:22:16,960] [INFO] [logging.py:96:log_dist] [Rank 0] step=205, skipped=0, lr=[2.228224e-07, 2.228224e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:16,960] [INFO] [timer.py:215:stop] epoch=0/micro_step=205/global_step=205, RunningAvgSamplesPerSec=7.816918978268952, CurrSamplesPerSec=7.805156910617519, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      205/439453125 | consumed samples:          205 | consumed tokens:       419840 | elapsed time per iteration (ms): 648.5 | learning rate: 2.228E-07 | global batch size:     1 | lm loss: 1.041765E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.542 | TFLOPs: 3.83 |
[default0]:[2023-07-30 22:22:17,721] [INFO] [logging.py:96:log_dist] [Rank 0] step=210, skipped=0, lr=[2.2828373333333334e-07, 2.2828373333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:17,721] [INFO] [timer.py:215:stop] epoch=0/micro_step=210/global_step=210, RunningAvgSamplesPerSec=7.819477692030929, CurrSamplesPerSec=7.980182271352195, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      210/439453125 | consumed samples:          210 | consumed tokens:       430080 | elapsed time per iteration (ms): 151.8 | learning rate: 2.283E-07 | global batch size:     1 | lm loss: 1.040592E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.587 | TFLOPs: 16.37 |
[default0]:[2023-07-30 22:22:18,475] [INFO] [logging.py:96:log_dist] [Rank 0] step=215, skipped=0, lr=[2.3374506666666669e-07, 2.3374506666666669e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:18,475] [INFO] [timer.py:215:stop] epoch=0/micro_step=215/global_step=215, RunningAvgSamplesPerSec=7.820572159932949, CurrSamplesPerSec=7.89563606654895, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      215/439453125 | consumed samples:          215 | consumed tokens:       440320 | elapsed time per iteration (ms): 150.9 | learning rate: 2.337E-07 | global batch size:     1 | lm loss: 1.039074E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.628 | TFLOPs: 16.47 |
[default0]:[2023-07-30 22:22:19,222] [INFO] [logging.py:96:log_dist] [Rank 0] step=220, skipped=0, lr=[2.392064e-07, 2.392064e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:19,223] [INFO] [timer.py:215:stop] epoch=0/micro_step=220/global_step=220, RunningAvgSamplesPerSec=7.821115868926623, CurrSamplesPerSec=7.813590265203168, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      220/439453125 | consumed samples:          220 | consumed tokens:       450560 | elapsed time per iteration (ms): 149.7 | learning rate: 2.392E-07 | global batch size:     1 | lm loss: 1.032823E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.678 | TFLOPs: 16.59 |
[default0]:[2023-07-30 22:22:19,993] [INFO] [logging.py:96:log_dist] [Rank 0] step=225, skipped=0, lr=[2.446677333333333e-07, 2.446677333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:19,994] [INFO] [timer.py:215:stop] epoch=0/micro_step=225/global_step=225, RunningAvgSamplesPerSec=7.823277415897784, CurrSamplesPerSec=7.960447377361248, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      225/439453125 | consumed samples:          225 | consumed tokens:       460800 | elapsed time per iteration (ms): 154.1 | learning rate: 2.447E-07 | global batch size:     1 | lm loss: 1.037936E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.491 | TFLOPs: 16.13 |
[default0]:[2023-07-30 22:22:20,746] [INFO] [logging.py:96:log_dist] [Rank 0] step=230, skipped=0, lr=[2.501290666666667e-07, 2.501290666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:20,747] [INFO] [timer.py:215:stop] epoch=0/micro_step=230/global_step=230, RunningAvgSamplesPerSec=7.823949066235092, CurrSamplesPerSec=7.857017884004054, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      230/439453125 | consumed samples:          230 | consumed tokens:       471040 | elapsed time per iteration (ms): 150.4 | learning rate: 2.501E-07 | global batch size:     1 | lm loss: 1.036609E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.647 | TFLOPs: 16.52 |
[default0]:[2023-07-30 22:22:21,523] [INFO] [logging.py:96:log_dist] [Rank 0] step=235, skipped=0, lr=[2.555904e-07, 2.555904e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:21,524] [INFO] [timer.py:215:stop] epoch=0/micro_step=235/global_step=235, RunningAvgSamplesPerSec=7.825095031947422, CurrSamplesPerSec=7.936122064377455, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      235/439453125 | consumed samples:          235 | consumed tokens:       481280 | elapsed time per iteration (ms): 155.4 | learning rate: 2.556E-07 | global batch size:     1 | lm loss: 1.031868E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.436 | TFLOPs: 15.99 |
[default0]:[2023-07-30 22:22:22,257] [INFO] [logging.py:96:log_dist] [Rank 0] step=240, skipped=0, lr=[2.6105173333333336e-07, 2.6105173333333336e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:22,258] [INFO] [timer.py:215:stop] epoch=0/micro_step=240/global_step=240, RunningAvgSamplesPerSec=7.827304312031258, CurrSamplesPerSec=7.896007665763668, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      240/439453125 | consumed samples:          240 | consumed tokens:       491520 | elapsed time per iteration (ms): 146.7 | learning rate: 2.611E-07 | global batch size:     1 | lm loss: 1.034946E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.817 | TFLOPs: 16.94 |
[default0]:[2023-07-30 22:22:23,022] [INFO] [logging.py:96:log_dist] [Rank 0] step=245, skipped=0, lr=[2.665130666666667e-07, 2.665130666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:23,023] [INFO] [timer.py:215:stop] epoch=0/micro_step=245/global_step=245, RunningAvgSamplesPerSec=7.828323904914843, CurrSamplesPerSec=7.734544019532273, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      245/439453125 | consumed samples:          245 | consumed tokens:       501760 | elapsed time per iteration (ms): 153.5 | learning rate: 2.665E-07 | global batch size:     1 | lm loss: 1.037611E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.517 | TFLOPs: 16.19 |
[default0]:[2023-07-30 22:22:23,796] [INFO] [logging.py:96:log_dist] [Rank 0] step=250, skipped=0, lr=[2.7197440000000005e-07, 2.7197440000000005e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:23,797] [INFO] [timer.py:215:stop] epoch=0/micro_step=250/global_step=250, RunningAvgSamplesPerSec=7.829577492978191, CurrSamplesPerSec=7.925250315078614, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      250/439453125 | consumed samples:          250 | consumed tokens:       512000 | elapsed time per iteration (ms): 155.4 | learning rate: 2.720E-07 | global batch size:     1 | lm loss: 1.037167E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.436 | TFLOPs: 15.99 |
[default0]:[2023-07-30 22:22:24,580] [INFO] [logging.py:96:log_dist] [Rank 0] step=255, skipped=0, lr=[2.7743573333333336e-07, 2.7743573333333336e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:24,582] [INFO] [timer.py:215:stop] epoch=0/micro_step=255/global_step=255, RunningAvgSamplesPerSec=7.830014401232025, CurrSamplesPerSec=7.799873544835794, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      255/439453125 | consumed samples:          255 | consumed tokens:       522240 | elapsed time per iteration (ms): 156.1 | learning rate: 2.774E-07 | global batch size:     1 | lm loss: 1.033210E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.405 | TFLOPs: 15.92 |
[default0]:[2023-07-30 22:22:25,390] [INFO] [logging.py:96:log_dist] [Rank 0] step=260, skipped=0, lr=[2.828970666666667e-07, 2.828970666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:25,391] [INFO] [timer.py:215:stop] epoch=0/micro_step=260/global_step=260, RunningAvgSamplesPerSec=7.8312647210664235, CurrSamplesPerSec=7.884963820903603, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      260/439453125 | consumed samples:          260 | consumed tokens:       532480 | elapsed time per iteration (ms): 161.7 | learning rate: 2.829E-07 | global batch size:     1 | lm loss: 1.029224E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.184 | TFLOPs: 15.37 |
[default0]:[2023-07-30 22:22:26,144] [INFO] [logging.py:96:log_dist] [Rank 0] step=265, skipped=0, lr=[2.883584e-07, 2.883584e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:26,144] [INFO] [timer.py:215:stop] epoch=0/micro_step=265/global_step=265, RunningAvgSamplesPerSec=7.833193925309567, CurrSamplesPerSec=7.897672859695602, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      265/439453125 | consumed samples:          265 | consumed tokens:       542720 | elapsed time per iteration (ms): 150.6 | learning rate: 2.884E-07 | global batch size:     1 | lm loss: 1.031771E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.642 | TFLOPs: 16.50 |
[default0]:[2023-07-30 22:22:26,909] [INFO] [logging.py:96:log_dist] [Rank 0] step=270, skipped=0, lr=[2.9381973333333336e-07, 2.9381973333333336e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:26,910] [INFO] [timer.py:215:stop] epoch=0/micro_step=270/global_step=270, RunningAvgSamplesPerSec=7.834029345526634, CurrSamplesPerSec=7.843324400994089, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      270/439453125 | consumed samples:          270 | consumed tokens:       552960 | elapsed time per iteration (ms): 153.1 | learning rate: 2.938E-07 | global batch size:     1 | lm loss: 1.029493E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.532 | TFLOPs: 16.23 |
[default0]:[2023-07-30 22:22:27,679] [INFO] [logging.py:96:log_dist] [Rank 0] step=275, skipped=0, lr=[2.9928106666666667e-07, 2.9928106666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:27,679] [INFO] [timer.py:215:stop] epoch=0/micro_step=275/global_step=275, RunningAvgSamplesPerSec=7.834411756465282, CurrSamplesPerSec=7.889665550581242, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      275/439453125 | consumed samples:          275 | consumed tokens:       563200 | elapsed time per iteration (ms): 153.9 | learning rate: 2.993E-07 | global batch size:     1 | lm loss: 1.029575E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.498 | TFLOPs: 16.14 |
[default0]:[2023-07-30 22:22:28,509] [INFO] [logging.py:96:log_dist] [Rank 0] step=280, skipped=0, lr=[3.0474240000000004e-07, 3.0474240000000004e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:28,510] [INFO] [timer.py:215:stop] epoch=0/micro_step=280/global_step=280, RunningAvgSamplesPerSec=7.835390480596357, CurrSamplesPerSec=7.754348794687344, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      280/439453125 | consumed samples:          280 | consumed tokens:       573440 | elapsed time per iteration (ms): 166.3 | learning rate: 3.047E-07 | global batch size:     1 | lm loss: 1.025232E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.012 | TFLOPs: 14.94 |
[default0]:[2023-07-30 22:22:29,308] [INFO] [logging.py:96:log_dist] [Rank 0] step=285, skipped=0, lr=[3.1020373333333335e-07, 3.1020373333333335e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:29,308] [INFO] [timer.py:215:stop] epoch=0/micro_step=285/global_step=285, RunningAvgSamplesPerSec=7.835690191219109, CurrSamplesPerSec=7.837974607849366, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      285/439453125 | consumed samples:          285 | consumed tokens:       583680 | elapsed time per iteration (ms): 159.9 | learning rate: 3.102E-07 | global batch size:     1 | lm loss: 1.027010E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.253 | TFLOPs: 15.54 |
[default0]:[2023-07-30 22:22:30,046] [INFO] [logging.py:96:log_dist] [Rank 0] step=290, skipped=0, lr=[3.1566506666666667e-07, 3.1566506666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:30,046] [INFO] [timer.py:215:stop] epoch=0/micro_step=290/global_step=290, RunningAvgSamplesPerSec=7.836524876846478, CurrSamplesPerSec=7.932804896270112, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      290/439453125 | consumed samples:          290 | consumed tokens:       593920 | elapsed time per iteration (ms): 147.0 | learning rate: 3.157E-07 | global batch size:     1 | lm loss: 1.026299E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.803 | TFLOPs: 16.90 |
[default0]:[2023-07-30 22:22:30,850] [INFO] [logging.py:96:log_dist] [Rank 0] step=295, skipped=0, lr=[3.2112640000000003e-07, 3.2112640000000003e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:30,850] [INFO] [timer.py:215:stop] epoch=0/micro_step=295/global_step=295, RunningAvgSamplesPerSec=7.8375100314913375, CurrSamplesPerSec=7.885734698290044, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      295/439453125 | consumed samples:          295 | consumed tokens:       604160 | elapsed time per iteration (ms): 161.0 | learning rate: 3.211E-07 | global batch size:     1 | lm loss: 1.028481E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.210 | TFLOPs: 15.43 |
[default0]:[2023-07-30 22:22:31,596] [INFO] [logging.py:96:log_dist] [Rank 0] step=300, skipped=0, lr=[3.2658773333333335e-07, 3.2658773333333335e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:31,597] [INFO] [timer.py:215:stop] epoch=0/micro_step=300/global_step=300, RunningAvgSamplesPerSec=7.8378027308970095, CurrSamplesPerSec=7.926643232414862, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      300/439453125 | consumed samples:          300 | consumed tokens:       614400 | elapsed time per iteration (ms): 149.3 | learning rate: 3.266E-07 | global batch size:     1 | lm loss: 1.029668E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.700 | TFLOPs: 16.65 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 300 | lm loss value: 1.023531E+01 | lm loss PPL: 2.787018E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:22:34,373] [INFO] [logging.py:96:log_dist] [Rank 0] step=305, skipped=0, lr=[3.3204906666666666e-07, 3.3204906666666666e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:34,374] [INFO] [timer.py:215:stop] epoch=0/micro_step=305/global_step=305, RunningAvgSamplesPerSec=7.837503274455191, CurrSamplesPerSec=7.871483049575113, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      305/439453125 | consumed samples:          305 | consumed tokens:       624640 | elapsed time per iteration (ms): 555.5 | learning rate: 3.320E-07 | global batch size:     1 | lm loss: 1.027720E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.800 | TFLOPs: 4.47 |
[default0]:[2023-07-30 22:22:35,244] [INFO] [logging.py:96:log_dist] [Rank 0] step=310, skipped=0, lr=[3.375104e-07, 3.375104e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:35,246] [INFO] [timer.py:215:stop] epoch=0/micro_step=310/global_step=310, RunningAvgSamplesPerSec=7.836850709172628, CurrSamplesPerSec=7.752929781366221, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      310/439453125 | consumed samples:          310 | consumed tokens:       634880 | elapsed time per iteration (ms): 174.3 | learning rate: 3.375E-07 | global batch size:     1 | lm loss: 1.024414E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.739 | TFLOPs: 14.26 |
[default0]:[2023-07-30 22:22:36,005] [INFO] [logging.py:96:log_dist] [Rank 0] step=315, skipped=0, lr=[3.429717333333334e-07, 3.429717333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:36,006] [INFO] [timer.py:215:stop] epoch=0/micro_step=315/global_step=315, RunningAvgSamplesPerSec=7.838132077642132, CurrSamplesPerSec=7.934890936264401, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      315/439453125 | consumed samples:          315 | consumed tokens:       645120 | elapsed time per iteration (ms): 152.0 | learning rate: 3.430E-07 | global batch size:     1 | lm loss: 1.026155E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.577 | TFLOPs: 16.34 |
[default0]:[2023-07-30 22:22:36,755] [INFO] [logging.py:96:log_dist] [Rank 0] step=320, skipped=0, lr=[3.484330666666667e-07, 3.484330666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:36,756] [INFO] [timer.py:215:stop] epoch=0/micro_step=320/global_step=320, RunningAvgSamplesPerSec=7.839426354596699, CurrSamplesPerSec=7.83405118473498, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      320/439453125 | consumed samples:          320 | consumed tokens:       655360 | elapsed time per iteration (ms): 150.0 | learning rate: 3.484E-07 | global batch size:     1 | lm loss: 1.024005E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.668 | TFLOPs: 16.57 |
[default0]:[2023-07-30 22:22:37,507] [INFO] [logging.py:96:log_dist] [Rank 0] step=325, skipped=0, lr=[3.538944e-07, 3.538944e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:37,507] [INFO] [timer.py:215:stop] epoch=0/micro_step=325/global_step=325, RunningAvgSamplesPerSec=7.83957027337636, CurrSamplesPerSec=7.849724418659056, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      325/439453125 | consumed samples:          325 | consumed tokens:       665600 | elapsed time per iteration (ms): 150.2 | learning rate: 3.539E-07 | global batch size:     1 | lm loss: 1.026312E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.658 | TFLOPs: 16.54 |
[default0]:[2023-07-30 22:22:38,268] [INFO] [logging.py:96:log_dist] [Rank 0] step=330, skipped=0, lr=[3.5935573333333334e-07, 3.5935573333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:38,268] [INFO] [timer.py:215:stop] epoch=0/micro_step=330/global_step=330, RunningAvgSamplesPerSec=7.839923317891675, CurrSamplesPerSec=7.918532251426328, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      330/439453125 | consumed samples:          330 | consumed tokens:       675840 | elapsed time per iteration (ms): 152.2 | learning rate: 3.594E-07 | global batch size:     1 | lm loss: 1.020862E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.568 | TFLOPs: 16.32 |
[default0]:[2023-07-30 22:22:39,022] [INFO] [logging.py:96:log_dist] [Rank 0] step=335, skipped=0, lr=[3.6481706666666666e-07, 3.6481706666666666e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:39,023] [INFO] [timer.py:215:stop] epoch=0/micro_step=335/global_step=335, RunningAvgSamplesPerSec=7.840493332331797, CurrSamplesPerSec=7.806711349435758, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      335/439453125 | consumed samples:          335 | consumed tokens:       686080 | elapsed time per iteration (ms): 151.0 | learning rate: 3.648E-07 | global batch size:     1 | lm loss: 1.024681E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.621 | TFLOPs: 16.45 |
[default0]:[2023-07-30 22:22:39,769] [INFO] [logging.py:96:log_dist] [Rank 0] step=340, skipped=0, lr=[3.7027839999999997e-07, 3.7027839999999997e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:39,770] [INFO] [timer.py:215:stop] epoch=0/micro_step=340/global_step=340, RunningAvgSamplesPerSec=7.840952323710674, CurrSamplesPerSec=7.869193982022615, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      340/439453125 | consumed samples:          340 | consumed tokens:       696320 | elapsed time per iteration (ms): 149.3 | learning rate: 3.703E-07 | global batch size:     1 | lm loss: 1.024169E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.698 | TFLOPs: 16.64 |
[default0]:[2023-07-30 22:22:40,523] [INFO] [logging.py:96:log_dist] [Rank 0] step=345, skipped=0, lr=[3.7573973333333334e-07, 3.7573973333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:40,524] [INFO] [timer.py:215:stop] epoch=0/micro_step=345/global_step=345, RunningAvgSamplesPerSec=7.841246645952765, CurrSamplesPerSec=7.735442690130741, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      345/439453125 | consumed samples:          345 | consumed tokens:       706560 | elapsed time per iteration (ms): 151.2 | learning rate: 3.757E-07 | global batch size:     1 | lm loss: 1.027893E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.615 | TFLOPs: 16.44 |
[default0]:[2023-07-30 22:22:41,275] [INFO] [logging.py:96:log_dist] [Rank 0] step=350, skipped=0, lr=[3.8120106666666665e-07, 3.8120106666666665e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:41,276] [INFO] [timer.py:215:stop] epoch=0/micro_step=350/global_step=350, RunningAvgSamplesPerSec=7.840731901591742, CurrSamplesPerSec=7.795654897208525, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      350/439453125 | consumed samples:          350 | consumed tokens:       716800 | elapsed time per iteration (ms): 150.1 | learning rate: 3.812E-07 | global batch size:     1 | lm loss: 1.032542E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.664 | TFLOPs: 16.56 |
[default0]:[2023-07-30 22:22:42,081] [INFO] [logging.py:96:log_dist] [Rank 0] step=355, skipped=0, lr=[3.866624e-07, 3.866624e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:42,082] [INFO] [timer.py:215:stop] epoch=0/micro_step=355/global_step=355, RunningAvgSamplesPerSec=7.841095031919196, CurrSamplesPerSec=7.682100574375806, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      355/439453125 | consumed samples:          355 | consumed tokens:       727040 | elapsed time per iteration (ms): 161.2 | learning rate: 3.867E-07 | global batch size:     1 | lm loss: 1.024712E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.204 | TFLOPs: 15.42 |
[default0]:[2023-07-30 22:22:42,874] [INFO] [logging.py:96:log_dist] [Rank 0] step=360, skipped=0, lr=[3.9212373333333333e-07, 3.9212373333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:42,874] [INFO] [timer.py:215:stop] epoch=0/micro_step=360/global_step=360, RunningAvgSamplesPerSec=7.841827508488545, CurrSamplesPerSec=7.919504094468267, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      360/439453125 | consumed samples:          360 | consumed tokens:       737280 | elapsed time per iteration (ms): 158.4 | learning rate: 3.921E-07 | global batch size:     1 | lm loss: 1.023561E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.312 | TFLOPs: 15.68 |
[default0]:[2023-07-30 22:22:43,705] [INFO] [logging.py:96:log_dist] [Rank 0] step=365, skipped=0, lr=[3.975850666666667e-07, 3.975850666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:43,706] [INFO] [timer.py:215:stop] epoch=0/micro_step=365/global_step=365, RunningAvgSamplesPerSec=7.84113736955367, CurrSamplesPerSec=7.826230713396737, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      365/439453125 | consumed samples:          365 | consumed tokens:       747520 | elapsed time per iteration (ms): 166.4 | learning rate: 3.976E-07 | global batch size:     1 | lm loss: 1.029010E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.010 | TFLOPs: 14.93 |
[default0]:[2023-07-30 22:22:44,464] [INFO] [logging.py:96:log_dist] [Rank 0] step=370, skipped=0, lr=[4.030464e-07, 4.030464e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:44,465] [INFO] [timer.py:215:stop] epoch=0/micro_step=370/global_step=370, RunningAvgSamplesPerSec=7.840634134065039, CurrSamplesPerSec=7.878624627839922, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      370/439453125 | consumed samples:          370 | consumed tokens:       757760 | elapsed time per iteration (ms): 151.9 | learning rate: 4.030E-07 | global batch size:     1 | lm loss: 1.022966E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.584 | TFLOPs: 16.36 |
[default0]:[2023-07-30 22:22:45,239] [INFO] [logging.py:96:log_dist] [Rank 0] step=375, skipped=0, lr=[4.085077333333334e-07, 4.085077333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:45,239] [INFO] [timer.py:215:stop] epoch=0/micro_step=375/global_step=375, RunningAvgSamplesPerSec=7.841500222630434, CurrSamplesPerSec=7.867496501712567, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      375/439453125 | consumed samples:          375 | consumed tokens:       768000 | elapsed time per iteration (ms): 154.8 | learning rate: 4.085E-07 | global batch size:     1 | lm loss: 1.018875E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.458 | TFLOPs: 16.05 |
[default0]:[2023-07-30 22:22:45,980] [INFO] [logging.py:96:log_dist] [Rank 0] step=380, skipped=0, lr=[4.139690666666667e-07, 4.139690666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:45,981] [INFO] [timer.py:215:stop] epoch=0/micro_step=380/global_step=380, RunningAvgSamplesPerSec=7.842633794890714, CurrSamplesPerSec=7.927886787245987, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      380/439453125 | consumed samples:          380 | consumed tokens:       778240 | elapsed time per iteration (ms): 148.1 | learning rate: 4.140E-07 | global batch size:     1 | lm loss: 1.023664E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.750 | TFLOPs: 16.77 |
[default0]:[2023-07-30 22:22:46,706] [INFO] [logging.py:96:log_dist] [Rank 0] step=385, skipped=0, lr=[4.194304e-07, 4.194304e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:46,706] [INFO] [timer.py:215:stop] epoch=0/micro_step=385/global_step=385, RunningAvgSamplesPerSec=7.844056362667933, CurrSamplesPerSec=7.9345156683030185, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      385/439453125 | consumed samples:          385 | consumed tokens:       788480 | elapsed time per iteration (ms): 145.1 | learning rate: 4.194E-07 | global batch size:     1 | lm loss: 1.017905E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.892 | TFLOPs: 17.12 |
[default0]:[2023-07-30 22:22:47,480] [INFO] [logging.py:96:log_dist] [Rank 0] step=390, skipped=0, lr=[4.248917333333334e-07, 4.248917333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:47,480] [INFO] [timer.py:215:stop] epoch=0/micro_step=390/global_step=390, RunningAvgSamplesPerSec=7.844956176388908, CurrSamplesPerSec=7.890734232844447, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      390/439453125 | consumed samples:          390 | consumed tokens:       798720 | elapsed time per iteration (ms): 155.2 | learning rate: 4.249E-07 | global batch size:     1 | lm loss: 1.022088E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.441 | TFLOPs: 16.01 |
[default0]:[2023-07-30 22:22:48,225] [INFO] [logging.py:96:log_dist] [Rank 0] step=395, skipped=0, lr=[4.303530666666667e-07, 4.303530666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:48,226] [INFO] [timer.py:215:stop] epoch=0/micro_step=395/global_step=395, RunningAvgSamplesPerSec=7.845725256822377, CurrSamplesPerSec=7.961565547180341, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      395/439453125 | consumed samples:          395 | consumed tokens:       808960 | elapsed time per iteration (ms): 148.5 | learning rate: 4.304E-07 | global batch size:     1 | lm loss: 1.021951E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.734 | TFLOPs: 16.73 |
[default0]:[2023-07-30 22:22:49,057] [INFO] [logging.py:96:log_dist] [Rank 0] step=400, skipped=0, lr=[4.3581440000000006e-07, 4.3581440000000006e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:49,058] [INFO] [timer.py:215:stop] epoch=0/micro_step=400/global_step=400, RunningAvgSamplesPerSec=7.846708550613014, CurrSamplesPerSec=7.863174925151525, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      400/439453125 | consumed samples:          400 | consumed tokens:       819200 | elapsed time per iteration (ms): 166.6 | learning rate: 4.358E-07 | global batch size:     1 | lm loss: 1.022145E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.004 | TFLOPs: 14.92 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 400 | lm loss value: 1.020686E+01 | lm loss PPL: 2.708839E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:22:52,454] [INFO] [logging.py:96:log_dist] [Rank 0] step=405, skipped=0, lr=[4.412757333333334e-07, 4.412757333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:52,455] [INFO] [timer.py:215:stop] epoch=0/micro_step=405/global_step=405, RunningAvgSamplesPerSec=7.844675887729125, CurrSamplesPerSec=7.925235340133098, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      405/439453125 | consumed samples:          405 | consumed tokens:       829440 | elapsed time per iteration (ms): 679.6 | learning rate: 4.413E-07 | global batch size:     1 | lm loss: 1.020019E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.471 | TFLOPs: 3.66 |
[default0]:[2023-07-30 22:22:53,221] [INFO] [logging.py:96:log_dist] [Rank 0] step=410, skipped=0, lr=[4.4673706666666664e-07, 4.4673706666666664e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:53,222] [INFO] [timer.py:215:stop] epoch=0/micro_step=410/global_step=410, RunningAvgSamplesPerSec=7.845061707457105, CurrSamplesPerSec=7.891461696070924, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      410/439453125 | consumed samples:          410 | consumed tokens:       839680 | elapsed time per iteration (ms): 153.2 | learning rate: 4.467E-07 | global batch size:     1 | lm loss: 1.021405E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.529 | TFLOPs: 16.22 |
[default0]:[2023-07-30 22:22:53,980] [INFO] [logging.py:96:log_dist] [Rank 0] step=415, skipped=0, lr=[4.521984e-07, 4.521984e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:53,980] [INFO] [timer.py:215:stop] epoch=0/micro_step=415/global_step=415, RunningAvgSamplesPerSec=7.8453372756588164, CurrSamplesPerSec=7.930030212851238, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      415/439453125 | consumed samples:          415 | consumed tokens:       849920 | elapsed time per iteration (ms): 151.8 | learning rate: 4.522E-07 | global batch size:     1 | lm loss: 1.026295E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.588 | TFLOPs: 16.37 |
[default0]:[2023-07-30 22:22:54,757] [INFO] [logging.py:96:log_dist] [Rank 0] step=420, skipped=0, lr=[4.576597333333333e-07, 4.576597333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:54,759] [INFO] [timer.py:215:stop] epoch=0/micro_step=420/global_step=420, RunningAvgSamplesPerSec=7.844074558504588, CurrSamplesPerSec=7.78178444869107, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      420/439453125 | consumed samples:          420 | consumed tokens:       860160 | elapsed time per iteration (ms): 156.0 | learning rate: 4.577E-07 | global batch size:     1 | lm loss: 1.020610E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.408 | TFLOPs: 15.92 |
[default0]:[2023-07-30 22:22:55,535] [INFO] [logging.py:96:log_dist] [Rank 0] step=425, skipped=0, lr=[4.631210666666667e-07, 4.631210666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:55,536] [INFO] [timer.py:215:stop] epoch=0/micro_step=425/global_step=425, RunningAvgSamplesPerSec=7.844405190179929, CurrSamplesPerSec=7.82548602559797, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      425/439453125 | consumed samples:          425 | consumed tokens:       870400 | elapsed time per iteration (ms): 155.0 | learning rate: 4.631E-07 | global batch size:     1 | lm loss: 1.018607E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.452 | TFLOPs: 16.03 |
[default0]:[2023-07-30 22:22:56,311] [INFO] [logging.py:96:log_dist] [Rank 0] step=430, skipped=0, lr=[4.685824e-07, 4.685824e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:56,312] [INFO] [timer.py:215:stop] epoch=0/micro_step=430/global_step=430, RunningAvgSamplesPerSec=7.8448873959806695, CurrSamplesPerSec=7.886223987124238, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      430/439453125 | consumed samples:          430 | consumed tokens:       880640 | elapsed time per iteration (ms): 155.0 | learning rate: 4.686E-07 | global batch size:     1 | lm loss: 1.022016E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.450 | TFLOPs: 16.03 |
[default0]:[2023-07-30 22:22:57,057] [INFO] [logging.py:96:log_dist] [Rank 0] step=435, skipped=0, lr=[4.7404373333333337e-07, 4.7404373333333337e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:57,057] [INFO] [timer.py:215:stop] epoch=0/micro_step=435/global_step=435, RunningAvgSamplesPerSec=7.845056434483516, CurrSamplesPerSec=7.862202119304112, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      435/439453125 | consumed samples:          435 | consumed tokens:       890880 | elapsed time per iteration (ms): 149.4 | learning rate: 4.740E-07 | global batch size:     1 | lm loss: 1.025060E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.694 | TFLOPs: 16.63 |
[default0]:[2023-07-30 22:22:57,833] [INFO] [logging.py:96:log_dist] [Rank 0] step=440, skipped=0, lr=[4.795050666666667e-07, 4.795050666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:57,834] [INFO] [timer.py:215:stop] epoch=0/micro_step=440/global_step=440, RunningAvgSamplesPerSec=7.845207650205178, CurrSamplesPerSec=7.858666671663072, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      440/439453125 | consumed samples:          440 | consumed tokens:       901120 | elapsed time per iteration (ms): 154.9 | learning rate: 4.795E-07 | global batch size:     1 | lm loss: 1.018014E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.456 | TFLOPs: 16.04 |
[default0]:[2023-07-30 22:22:58,568] [INFO] [logging.py:96:log_dist] [Rank 0] step=445, skipped=0, lr=[4.849664e-07, 4.849664e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:58,569] [INFO] [timer.py:215:stop] epoch=0/micro_step=445/global_step=445, RunningAvgSamplesPerSec=7.845367184535381, CurrSamplesPerSec=7.837710971252598, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      445/439453125 | consumed samples:          445 | consumed tokens:       911360 | elapsed time per iteration (ms): 147.2 | learning rate: 4.850E-07 | global batch size:     1 | lm loss: 1.020998E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.794 | TFLOPs: 16.88 |
[default0]:[2023-07-30 22:22:59,318] [INFO] [logging.py:96:log_dist] [Rank 0] step=450, skipped=0, lr=[4.904277333333333e-07, 4.904277333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:22:59,319] [INFO] [timer.py:215:stop] epoch=0/micro_step=450/global_step=450, RunningAvgSamplesPerSec=7.845721906671631, CurrSamplesPerSec=7.845877284707634, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      450/439453125 | consumed samples:          450 | consumed tokens:       921600 | elapsed time per iteration (ms): 150.0 | learning rate: 4.904E-07 | global batch size:     1 | lm loss: 1.017945E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.665 | TFLOPs: 16.56 |
[default0]:[2023-07-30 22:23:00,068] [INFO] [logging.py:96:log_dist] [Rank 0] step=455, skipped=0, lr=[4.958890666666667e-07, 4.958890666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:00,069] [INFO] [timer.py:215:stop] epoch=0/micro_step=455/global_step=455, RunningAvgSamplesPerSec=7.845817121152794, CurrSamplesPerSec=7.813925067020882, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      455/439453125 | consumed samples:          455 | consumed tokens:       931840 | elapsed time per iteration (ms): 150.1 | learning rate: 4.959E-07 | global batch size:     1 | lm loss: 1.020834E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.660 | TFLOPs: 16.55 |
[default0]:[2023-07-30 22:23:00,865] [INFO] [logging.py:96:log_dist] [Rank 0] step=460, skipped=0, lr=[5.013504e-07, 5.013504e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:00,866] [INFO] [timer.py:215:stop] epoch=0/micro_step=460/global_step=460, RunningAvgSamplesPerSec=7.846295139179186, CurrSamplesPerSec=7.892590271779731, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      460/439453125 | consumed samples:          460 | consumed tokens:       942080 | elapsed time per iteration (ms): 159.4 | learning rate: 5.014E-07 | global batch size:     1 | lm loss: 1.023412E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.273 | TFLOPs: 15.59 |
[default0]:[2023-07-30 22:23:01,667] [INFO] [logging.py:96:log_dist] [Rank 0] step=465, skipped=0, lr=[5.068117333333334e-07, 5.068117333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:01,667] [INFO] [timer.py:215:stop] epoch=0/micro_step=465/global_step=465, RunningAvgSamplesPerSec=7.84625597624357, CurrSamplesPerSec=7.814318131853801, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      465/439453125 | consumed samples:          465 | consumed tokens:       952320 | elapsed time per iteration (ms): 160.3 | learning rate: 5.068E-07 | global batch size:     1 | lm loss: 1.025486E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.237 | TFLOPs: 15.50 |
[default0]:[2023-07-30 22:23:02,425] [INFO] [logging.py:96:log_dist] [Rank 0] step=470, skipped=0, lr=[5.122730666666667e-07, 5.122730666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:02,425] [INFO] [timer.py:215:stop] epoch=0/micro_step=470/global_step=470, RunningAvgSamplesPerSec=7.846655060610206, CurrSamplesPerSec=7.8663013246461455, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      470/439453125 | consumed samples:          470 | consumed tokens:       962560 | elapsed time per iteration (ms): 151.0 | learning rate: 5.123E-07 | global batch size:     1 | lm loss: 1.017570E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.622 | TFLOPs: 16.46 |
[default0]:[2023-07-30 22:23:03,168] [INFO] [logging.py:96:log_dist] [Rank 0] step=475, skipped=0, lr=[5.177344000000001e-07, 5.177344000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:03,168] [INFO] [timer.py:215:stop] epoch=0/micro_step=475/global_step=475, RunningAvgSamplesPerSec=7.846619962136837, CurrSamplesPerSec=7.768941674183755, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      475/439453125 | consumed samples:          475 | consumed tokens:       972800 | elapsed time per iteration (ms): 148.8 | learning rate: 5.177E-07 | global batch size:     1 | lm loss: 1.017668E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.719 | TFLOPs: 16.69 |
[default0]:[2023-07-30 22:23:03,937] [INFO] [logging.py:96:log_dist] [Rank 0] step=480, skipped=0, lr=[5.231957333333334e-07, 5.231957333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:03,938] [INFO] [timer.py:215:stop] epoch=0/micro_step=480/global_step=480, RunningAvgSamplesPerSec=7.846843659187774, CurrSamplesPerSec=7.891149909692956, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      480/439453125 | consumed samples:          480 | consumed tokens:       983040 | elapsed time per iteration (ms): 154.1 | learning rate: 5.232E-07 | global batch size:     1 | lm loss: 1.017325E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.490 | TFLOPs: 16.13 |
[default0]:[2023-07-30 22:23:04,726] [INFO] [logging.py:96:log_dist] [Rank 0] step=485, skipped=0, lr=[5.286570666666667e-07, 5.286570666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:04,728] [INFO] [timer.py:215:stop] epoch=0/micro_step=485/global_step=485, RunningAvgSamplesPerSec=7.84630195444122, CurrSamplesPerSec=7.805273108930938, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      485/439453125 | consumed samples:          485 | consumed tokens:       993280 | elapsed time per iteration (ms): 158.1 | learning rate: 5.287E-07 | global batch size:     1 | lm loss: 1.011024E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.325 | TFLOPs: 15.72 |
[default0]:[2023-07-30 22:23:05,488] [INFO] [logging.py:96:log_dist] [Rank 0] step=490, skipped=0, lr=[5.341184e-07, 5.341184e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:05,488] [INFO] [timer.py:215:stop] epoch=0/micro_step=490/global_step=490, RunningAvgSamplesPerSec=7.846570540897394, CurrSamplesPerSec=7.896527963430843, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      490/439453125 | consumed samples:          490 | consumed tokens:      1003520 | elapsed time per iteration (ms): 152.0 | learning rate: 5.341E-07 | global batch size:     1 | lm loss: 1.017121E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.580 | TFLOPs: 16.35 |
[default0]:[2023-07-30 22:23:06,253] [INFO] [logging.py:96:log_dist] [Rank 0] step=495, skipped=0, lr=[5.395797333333334e-07, 5.395797333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:06,254] [INFO] [timer.py:215:stop] epoch=0/micro_step=495/global_step=495, RunningAvgSamplesPerSec=7.847099764395197, CurrSamplesPerSec=7.9526591317175095, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      495/439453125 | consumed samples:          495 | consumed tokens:      1013760 | elapsed time per iteration (ms): 152.9 | learning rate: 5.396E-07 | global batch size:     1 | lm loss: 1.013131E+01 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.540 | TFLOPs: 16.25 |
[default0]:[2023-07-30 22:23:06,988] [INFO] [logging.py:96:log_dist] [Rank 0] step=500, skipped=0, lr=[5.450410666666667e-07, 5.450410666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:06,989] [INFO] [timer.py:215:stop] epoch=0/micro_step=500/global_step=500, RunningAvgSamplesPerSec=7.847468801688471, CurrSamplesPerSec=7.84473268308193, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      500/439453125 | consumed samples:          500 | consumed tokens:      1024000 | elapsed time per iteration (ms): 146.8 | learning rate: 5.450E-07 | global batch size:     1 | lm loss: 1.015133E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.810 | TFLOPs: 16.92 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 500 | lm loss value: 1.010547E+01 | lm loss PPL: 2.447645E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:23:09,325] [INFO] [logging.py:96:log_dist] [Rank 0] step=505, skipped=0, lr=[5.505024e-07, 5.505024e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:09,326] [INFO] [timer.py:215:stop] epoch=0/micro_step=505/global_step=505, RunningAvgSamplesPerSec=7.8478063646215, CurrSamplesPerSec=7.848578694356132, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      505/439453125 | consumed samples:          505 | consumed tokens:      1034240 | elapsed time per iteration (ms): 467.8 | learning rate: 5.505E-07 | global batch size:     1 | lm loss: 1.018436E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.138 | TFLOPs: 5.31 |
[default0]:[2023-07-30 22:23:10,068] [INFO] [logging.py:96:log_dist] [Rank 0] step=510, skipped=0, lr=[5.559637333333333e-07, 5.559637333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:10,069] [INFO] [timer.py:215:stop] epoch=0/micro_step=510/global_step=510, RunningAvgSamplesPerSec=7.848249357625657, CurrSamplesPerSec=7.889502305170316, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      510/439453125 | consumed samples:          510 | consumed tokens:      1044480 | elapsed time per iteration (ms): 148.7 | learning rate: 5.560E-07 | global batch size:     1 | lm loss: 1.006624E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.726 | TFLOPs: 16.71 |
[default0]:[2023-07-30 22:23:10,822] [INFO] [logging.py:96:log_dist] [Rank 0] step=515, skipped=0, lr=[5.614250666666667e-07, 5.614250666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:10,822] [INFO] [timer.py:215:stop] epoch=0/micro_step=515/global_step=515, RunningAvgSamplesPerSec=7.8490845424815054, CurrSamplesPerSec=7.898148758400826, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      515/439453125 | consumed samples:          515 | consumed tokens:      1054720 | elapsed time per iteration (ms): 150.5 | learning rate: 5.614E-07 | global batch size:     1 | lm loss: 1.014043E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.645 | TFLOPs: 16.51 |
[default0]:[2023-07-30 22:23:11,620] [INFO] [logging.py:96:log_dist] [Rank 0] step=520, skipped=0, lr=[5.668864e-07, 5.668864e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:11,621] [INFO] [timer.py:215:stop] epoch=0/micro_step=520/global_step=520, RunningAvgSamplesPerSec=7.849054507609975, CurrSamplesPerSec=7.870685416830862, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      520/439453125 | consumed samples:          520 | consumed tokens:      1064960 | elapsed time per iteration (ms): 159.8 | learning rate: 5.669E-07 | global batch size:     1 | lm loss: 1.013668E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.258 | TFLOPs: 15.55 |
[default0]:[2023-07-30 22:23:12,403] [INFO] [logging.py:96:log_dist] [Rank 0] step=525, skipped=0, lr=[5.723477333333333e-07, 5.723477333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:12,404] [INFO] [timer.py:215:stop] epoch=0/micro_step=525/global_step=525, RunningAvgSamplesPerSec=7.848882576129747, CurrSamplesPerSec=7.885764350430452, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      525/439453125 | consumed samples:          525 | consumed tokens:      1075200 | elapsed time per iteration (ms): 156.8 | learning rate: 5.723E-07 | global batch size:     1 | lm loss: 1.008132E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.377 | TFLOPs: 15.84 |
[default0]:[2023-07-30 22:23:13,214] [INFO] [logging.py:96:log_dist] [Rank 0] step=530, skipped=0, lr=[5.778090666666667e-07, 5.778090666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:13,214] [INFO] [timer.py:215:stop] epoch=0/micro_step=530/global_step=530, RunningAvgSamplesPerSec=7.848944541990102, CurrSamplesPerSec=7.786985500250636, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      530/439453125 | consumed samples:          530 | consumed tokens:      1085440 | elapsed time per iteration (ms): 161.7 | learning rate: 5.778E-07 | global batch size:     1 | lm loss: 1.011224E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.185 | TFLOPs: 15.37 |
[default0]:[2023-07-30 22:23:14,008] [INFO] [logging.py:96:log_dist] [Rank 0] step=535, skipped=0, lr=[5.832704000000001e-07, 5.832704000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:14,009] [INFO] [timer.py:215:stop] epoch=0/micro_step=535/global_step=535, RunningAvgSamplesPerSec=7.848928350904003, CurrSamplesPerSec=7.832529719998954, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      535/439453125 | consumed samples:          535 | consumed tokens:      1095680 | elapsed time per iteration (ms): 158.9 | learning rate: 5.833E-07 | global batch size:     1 | lm loss: 1.006126E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.295 | TFLOPs: 15.64 |
[default0]:[2023-07-30 22:23:14,780] [INFO] [logging.py:96:log_dist] [Rank 0] step=540, skipped=0, lr=[5.887317333333334e-07, 5.887317333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:14,783] [INFO] [timer.py:215:stop] epoch=0/micro_step=540/global_step=540, RunningAvgSamplesPerSec=7.848794331663258, CurrSamplesPerSec=7.808280943702168, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      540/439453125 | consumed samples:          540 | consumed tokens:      1105920 | elapsed time per iteration (ms): 155.0 | learning rate: 5.887E-07 | global batch size:     1 | lm loss: 1.016928E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.452 | TFLOPs: 16.03 |
[default0]:[2023-07-30 22:23:15,556] [INFO] [logging.py:96:log_dist] [Rank 0] step=545, skipped=0, lr=[5.941930666666667e-07, 5.941930666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:15,557] [INFO] [timer.py:215:stop] epoch=0/micro_step=545/global_step=545, RunningAvgSamplesPerSec=7.849054780986927, CurrSamplesPerSec=7.909796385594427, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      545/439453125 | consumed samples:          545 | consumed tokens:      1116160 | elapsed time per iteration (ms): 154.5 | learning rate: 5.942E-07 | global batch size:     1 | lm loss: 1.015199E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.472 | TFLOPs: 16.08 |
[default0]:[2023-07-30 22:23:16,304] [INFO] [logging.py:96:log_dist] [Rank 0] step=550, skipped=0, lr=[5.996544e-07, 5.996544e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:16,305] [INFO] [timer.py:215:stop] epoch=0/micro_step=550/global_step=550, RunningAvgSamplesPerSec=7.849070057183253, CurrSamplesPerSec=7.822596227372253, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      550/439453125 | consumed samples:          550 | consumed tokens:      1126400 | elapsed time per iteration (ms): 149.9 | learning rate: 5.997E-07 | global batch size:     1 | lm loss: 1.011604E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.670 | TFLOPs: 16.57 |
[default0]:[2023-07-30 22:23:17,071] [INFO] [logging.py:96:log_dist] [Rank 0] step=555, skipped=0, lr=[6.051157333333333e-07, 6.051157333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:17,071] [INFO] [timer.py:215:stop] epoch=0/micro_step=555/global_step=555, RunningAvgSamplesPerSec=7.8492335389386065, CurrSamplesPerSec=7.886920957869896, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      555/439453125 | consumed samples:          555 | consumed tokens:      1136640 | elapsed time per iteration (ms): 153.5 | learning rate: 6.051E-07 | global batch size:     1 | lm loss: 1.009828E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.514 | TFLOPs: 16.19 |
[default0]:[2023-07-30 22:23:17,898] [INFO] [logging.py:96:log_dist] [Rank 0] step=560, skipped=0, lr=[6.105770666666668e-07, 6.105770666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:17,899] [INFO] [timer.py:215:stop] epoch=0/micro_step=560/global_step=560, RunningAvgSamplesPerSec=7.8494132362945015, CurrSamplesPerSec=7.904087439932159, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      560/439453125 | consumed samples:          560 | consumed tokens:      1146880 | elapsed time per iteration (ms): 165.1 | learning rate: 6.106E-07 | global batch size:     1 | lm loss: 1.006620E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.056 | TFLOPs: 15.05 |
[default0]:[2023-07-30 22:23:18,667] [INFO] [logging.py:96:log_dist] [Rank 0] step=565, skipped=0, lr=[6.160384000000001e-07, 6.160384000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:18,668] [INFO] [timer.py:215:stop] epoch=0/micro_step=565/global_step=565, RunningAvgSamplesPerSec=7.849653365362653, CurrSamplesPerSec=7.914871293593269, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      565/439453125 | consumed samples:          565 | consumed tokens:      1157120 | elapsed time per iteration (ms): 153.8 | learning rate: 6.160E-07 | global batch size:     1 | lm loss: 1.023057E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.504 | TFLOPs: 16.16 |
[default0]:[2023-07-30 22:23:19,498] [INFO] [logging.py:96:log_dist] [Rank 0] step=570, skipped=0, lr=[6.214997333333334e-07, 6.214997333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:19,499] [INFO] [timer.py:215:stop] epoch=0/micro_step=570/global_step=570, RunningAvgSamplesPerSec=7.8494458959907485, CurrSamplesPerSec=7.821472993258804, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      570/439453125 | consumed samples:          570 | consumed tokens:      1167360 | elapsed time per iteration (ms): 166.2 | learning rate: 6.215E-07 | global batch size:     1 | lm loss: 1.000329E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.017 | TFLOPs: 14.95 |
[default0]:[2023-07-30 22:23:20,245] [INFO] [logging.py:96:log_dist] [Rank 0] step=575, skipped=0, lr=[6.269610666666667e-07, 6.269610666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:20,245] [INFO] [timer.py:215:stop] epoch=0/micro_step=575/global_step=575, RunningAvgSamplesPerSec=7.8499038673172805, CurrSamplesPerSec=7.910243909798826, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      575/439453125 | consumed samples:          575 | consumed tokens:      1177600 | elapsed time per iteration (ms): 149.6 | learning rate: 6.270E-07 | global batch size:     1 | lm loss: 1.023075E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.683 | TFLOPs: 16.61 |
[default0]:[2023-07-30 22:23:21,038] [INFO] [logging.py:96:log_dist] [Rank 0] step=580, skipped=0, lr=[6.324224e-07, 6.324224e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:21,041] [INFO] [timer.py:215:stop] epoch=0/micro_step=580/global_step=580, RunningAvgSamplesPerSec=7.849804634937583, CurrSamplesPerSec=7.741953584870137, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      580/439453125 | consumed samples:          580 | consumed tokens:      1187840 | elapsed time per iteration (ms): 158.8 | learning rate: 6.324E-07 | global batch size:     1 | lm loss: 1.007869E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.296 | TFLOPs: 15.64 |
[default0]:[2023-07-30 22:23:21,814] [INFO] [logging.py:96:log_dist] [Rank 0] step=585, skipped=0, lr=[6.378837333333333e-07, 6.378837333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:21,815] [INFO] [timer.py:215:stop] epoch=0/micro_step=585/global_step=585, RunningAvgSamplesPerSec=7.849541605411655, CurrSamplesPerSec=7.783560693083822, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      585/439453125 | consumed samples:          585 | consumed tokens:      1198080 | elapsed time per iteration (ms): 154.8 | learning rate: 6.379E-07 | global batch size:     1 | lm loss: 1.012955E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.459 | TFLOPs: 16.05 |
[default0]:[2023-07-30 22:23:22,557] [INFO] [logging.py:96:log_dist] [Rank 0] step=590, skipped=0, lr=[6.433450666666666e-07, 6.433450666666666e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:22,558] [INFO] [timer.py:215:stop] epoch=0/micro_step=590/global_step=590, RunningAvgSamplesPerSec=7.849888445679115, CurrSamplesPerSec=7.824478732354692, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      590/439453125 | consumed samples:          590 | consumed tokens:      1208320 | elapsed time per iteration (ms): 148.6 | learning rate: 6.433E-07 | global batch size:     1 | lm loss: 1.012305E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.731 | TFLOPs: 16.73 |
[default0]:[2023-07-30 22:23:23,318] [INFO] [logging.py:96:log_dist] [Rank 0] step=595, skipped=0, lr=[6.488064000000001e-07, 6.488064000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:23,319] [INFO] [timer.py:215:stop] epoch=0/micro_step=595/global_step=595, RunningAvgSamplesPerSec=7.8498046868866656, CurrSamplesPerSec=7.7367839520405814, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      595/439453125 | consumed samples:          595 | consumed tokens:      1218560 | elapsed time per iteration (ms): 152.5 | learning rate: 6.488E-07 | global batch size:     1 | lm loss: 1.008318E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.558 | TFLOPs: 16.29 |
[default0]:[2023-07-30 22:23:24,091] [INFO] [logging.py:96:log_dist] [Rank 0] step=600, skipped=0, lr=[6.542677333333334e-07, 6.542677333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:24,092] [INFO] [timer.py:215:stop] epoch=0/micro_step=600/global_step=600, RunningAvgSamplesPerSec=7.849631262643134, CurrSamplesPerSec=7.85276661711457, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      600/439453125 | consumed samples:          600 | consumed tokens:      1228800 | elapsed time per iteration (ms): 154.1 | learning rate: 6.543E-07 | global batch size:     1 | lm loss: 1.011614E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.489 | TFLOPs: 16.12 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 600 | lm loss value: 1.007959E+01 | lm loss PPL: 2.385125E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:23:27,470] [INFO] [logging.py:96:log_dist] [Rank 0] step=605, skipped=0, lr=[6.597290666666667e-07, 6.597290666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:27,471] [INFO] [timer.py:215:stop] epoch=0/micro_step=605/global_step=605, RunningAvgSamplesPerSec=7.847012579279316, CurrSamplesPerSec=7.794727696782167, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      605/439453125 | consumed samples:          605 | consumed tokens:      1239040 | elapsed time per iteration (ms): 676.0 | learning rate: 6.597E-07 | global batch size:     1 | lm loss: 1.001168E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.479 | TFLOPs: 3.68 |
[default0]:[2023-07-30 22:23:28,318] [INFO] [logging.py:96:log_dist] [Rank 0] step=610, skipped=0, lr=[6.651904e-07, 6.651904e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:28,319] [INFO] [timer.py:215:stop] epoch=0/micro_step=610/global_step=610, RunningAvgSamplesPerSec=7.8472562509889325, CurrSamplesPerSec=7.948123022114419, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      610/439453125 | consumed samples:          610 | consumed tokens:      1249280 | elapsed time per iteration (ms): 169.4 | learning rate: 6.652E-07 | global batch size:     1 | lm loss: 1.009221E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.903 | TFLOPs: 14.67 |
[default0]:[2023-07-30 22:23:29,055] [INFO] [logging.py:96:log_dist] [Rank 0] step=615, skipped=0, lr=[6.706517333333333e-07, 6.706517333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:29,055] [INFO] [timer.py:215:stop] epoch=0/micro_step=615/global_step=615, RunningAvgSamplesPerSec=7.8475420942228125, CurrSamplesPerSec=7.853531211498204, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      615/439453125 | consumed samples:          615 | consumed tokens:      1259520 | elapsed time per iteration (ms): 147.3 | learning rate: 6.707E-07 | global batch size:     1 | lm loss: 1.019914E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.788 | TFLOPs: 16.87 |
[default0]:[2023-07-30 22:23:29,848] [INFO] [logging.py:96:log_dist] [Rank 0] step=620, skipped=0, lr=[6.761130666666667e-07, 6.761130666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:29,849] [INFO] [timer.py:215:stop] epoch=0/micro_step=620/global_step=620, RunningAvgSamplesPerSec=7.84758818485002, CurrSamplesPerSec=7.848975253379643, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      620/439453125 | consumed samples:          620 | consumed tokens:      1269760 | elapsed time per iteration (ms): 158.7 | learning rate: 6.761E-07 | global batch size:     1 | lm loss: 1.009737E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.300 | TFLOPs: 15.65 |
[default0]:[2023-07-30 22:23:30,689] [INFO] [logging.py:96:log_dist] [Rank 0] step=625, skipped=0, lr=[6.815744000000001e-07, 6.815744000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:30,690] [INFO] [timer.py:215:stop] epoch=0/micro_step=625/global_step=625, RunningAvgSamplesPerSec=7.847964143588309, CurrSamplesPerSec=7.903327862581755, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      625/439453125 | consumed samples:          625 | consumed tokens:      1280000 | elapsed time per iteration (ms): 168.4 | learning rate: 6.816E-07 | global batch size:     1 | lm loss: 1.003159E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.940 | TFLOPs: 14.76 |
[default0]:[2023-07-30 22:23:31,526] [INFO] [logging.py:96:log_dist] [Rank 0] step=630, skipped=0, lr=[6.870357333333333e-07, 6.870357333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:31,526] [INFO] [timer.py:215:stop] epoch=0/micro_step=630/global_step=630, RunningAvgSamplesPerSec=7.8482946306174615, CurrSamplesPerSec=7.857488895591395, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      630/439453125 | consumed samples:          630 | consumed tokens:      1290240 | elapsed time per iteration (ms): 167.1 | learning rate: 6.870E-07 | global batch size:     1 | lm loss: 1.006168E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.985 | TFLOPs: 14.87 |
[default0]:[2023-07-30 22:23:32,255] [INFO] [logging.py:96:log_dist] [Rank 0] step=635, skipped=0, lr=[6.924970666666667e-07, 6.924970666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:32,255] [INFO] [timer.py:215:stop] epoch=0/micro_step=635/global_step=635, RunningAvgSamplesPerSec=7.848962073546519, CurrSamplesPerSec=7.986442691811157, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      635/439453125 | consumed samples:          635 | consumed tokens:      1300480 | elapsed time per iteration (ms): 145.9 | learning rate: 6.925E-07 | global batch size:     1 | lm loss: 1.010215E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.856 | TFLOPs: 17.04 |
[default0]:[2023-07-30 22:23:33,154] [INFO] [logging.py:96:log_dist] [Rank 0] step=640, skipped=0, lr=[6.979584e-07, 6.979584e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:33,154] [INFO] [timer.py:215:stop] epoch=0/micro_step=640/global_step=640, RunningAvgSamplesPerSec=7.8496690402781875, CurrSamplesPerSec=7.797162068459103, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      640/439453125 | consumed samples:          640 | consumed tokens:      1310720 | elapsed time per iteration (ms): 179.6 | learning rate: 6.980E-07 | global batch size:     1 | lm loss: 1.006947E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.568 | TFLOPs: 13.83 |
[default0]:[2023-07-30 22:23:33,897] [INFO] [logging.py:96:log_dist] [Rank 0] step=645, skipped=0, lr=[7.034197333333333e-07, 7.034197333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:33,897] [INFO] [timer.py:215:stop] epoch=0/micro_step=645/global_step=645, RunningAvgSamplesPerSec=7.849938802239571, CurrSamplesPerSec=7.940644482182175, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      645/439453125 | consumed samples:          645 | consumed tokens:      1320960 | elapsed time per iteration (ms): 148.6 | learning rate: 7.034E-07 | global batch size:     1 | lm loss: 9.930136E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.729 | TFLOPs: 16.72 |
[default0]:[2023-07-30 22:23:34,651] [INFO] [logging.py:96:log_dist] [Rank 0] step=650, skipped=0, lr=[7.088810666666666e-07, 7.088810666666666e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:34,653] [INFO] [timer.py:215:stop] epoch=0/micro_step=650/global_step=650, RunningAvgSamplesPerSec=7.850385565621023, CurrSamplesPerSec=7.909289252707425, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      650/439453125 | consumed samples:          650 | consumed tokens:      1331200 | elapsed time per iteration (ms): 151.1 | learning rate: 7.089E-07 | global batch size:     1 | lm loss: 1.007694E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.618 | TFLOPs: 16.45 |
[default0]:[2023-07-30 22:23:35,424] [INFO] [logging.py:96:log_dist] [Rank 0] step=655, skipped=0, lr=[7.143424e-07, 7.143424e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:35,425] [INFO] [timer.py:215:stop] epoch=0/micro_step=655/global_step=655, RunningAvgSamplesPerSec=7.850747831832833, CurrSamplesPerSec=7.867201362499015, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      655/439453125 | consumed samples:          655 | consumed tokens:      1341440 | elapsed time per iteration (ms): 154.4 | learning rate: 7.143E-07 | global batch size:     1 | lm loss: 1.012750E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.477 | TFLOPs: 16.09 |
[default0]:[2023-07-30 22:23:36,196] [INFO] [logging.py:96:log_dist] [Rank 0] step=660, skipped=0, lr=[7.198037333333334e-07, 7.198037333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:36,196] [INFO] [timer.py:215:stop] epoch=0/micro_step=660/global_step=660, RunningAvgSamplesPerSec=7.850829295415435, CurrSamplesPerSec=7.869666454647626, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      660/439453125 | consumed samples:          660 | consumed tokens:      1351680 | elapsed time per iteration (ms): 154.2 | learning rate: 7.198E-07 | global batch size:     1 | lm loss: 1.000904E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.485 | TFLOPs: 16.11 |
[default0]:[2023-07-30 22:23:36,934] [INFO] [logging.py:96:log_dist] [Rank 0] step=665, skipped=0, lr=[7.252650666666667e-07, 7.252650666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:36,935] [INFO] [timer.py:215:stop] epoch=0/micro_step=665/global_step=665, RunningAvgSamplesPerSec=7.851150228375401, CurrSamplesPerSec=7.901615625753557, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      665/439453125 | consumed samples:          665 | consumed tokens:      1361920 | elapsed time per iteration (ms): 147.9 | learning rate: 7.253E-07 | global batch size:     1 | lm loss: 1.011956E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.761 | TFLOPs: 16.80 |
[default0]:[2023-07-30 22:23:37,685] [INFO] [logging.py:96:log_dist] [Rank 0] step=670, skipped=0, lr=[7.307264e-07, 7.307264e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:37,685] [INFO] [timer.py:215:stop] epoch=0/micro_step=670/global_step=670, RunningAvgSamplesPerSec=7.850700364374514, CurrSamplesPerSec=7.7154503848248055, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      670/439453125 | consumed samples:          670 | consumed tokens:      1372160 | elapsed time per iteration (ms): 150.1 | learning rate: 7.307E-07 | global batch size:     1 | lm loss: 9.925035E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.662 | TFLOPs: 16.55 |
[default0]:[2023-07-30 22:23:38,461] [INFO] [logging.py:96:log_dist] [Rank 0] step=675, skipped=0, lr=[7.361877333333333e-07, 7.361877333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:38,461] [INFO] [timer.py:215:stop] epoch=0/micro_step=675/global_step=675, RunningAvgSamplesPerSec=7.850817286899929, CurrSamplesPerSec=7.926523392321241, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      675/439453125 | consumed samples:          675 | consumed tokens:      1382400 | elapsed time per iteration (ms): 154.9 | learning rate: 7.362E-07 | global batch size:     1 | lm loss: 1.000581E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.454 | TFLOPs: 16.04 |
[default0]:[2023-07-30 22:23:39,208] [INFO] [logging.py:96:log_dist] [Rank 0] step=680, skipped=0, lr=[7.416490666666667e-07, 7.416490666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:39,209] [INFO] [timer.py:215:stop] epoch=0/micro_step=680/global_step=680, RunningAvgSamplesPerSec=7.850904809829351, CurrSamplesPerSec=7.764641415824355, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      680/439453125 | consumed samples:          680 | consumed tokens:      1392640 | elapsed time per iteration (ms): 149.6 | learning rate: 7.416E-07 | global batch size:     1 | lm loss: 1.003903E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.684 | TFLOPs: 16.61 |
[default0]:[2023-07-30 22:23:39,951] [INFO] [logging.py:96:log_dist] [Rank 0] step=685, skipped=0, lr=[7.471104e-07, 7.471104e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:39,952] [INFO] [timer.py:215:stop] epoch=0/micro_step=685/global_step=685, RunningAvgSamplesPerSec=7.850628842381683, CurrSamplesPerSec=7.792150079978004, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      685/439453125 | consumed samples:          685 | consumed tokens:      1402880 | elapsed time per iteration (ms): 148.9 | learning rate: 7.471E-07 | global batch size:     1 | lm loss: 9.930054E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.715 | TFLOPs: 16.69 |
[default0]:[2023-07-30 22:23:40,715] [INFO] [logging.py:96:log_dist] [Rank 0] step=690, skipped=0, lr=[7.525717333333334e-07, 7.525717333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:40,716] [INFO] [timer.py:215:stop] epoch=0/micro_step=690/global_step=690, RunningAvgSamplesPerSec=7.851129788138966, CurrSamplesPerSec=7.865224500817594, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      690/439453125 | consumed samples:          690 | consumed tokens:      1413120 | elapsed time per iteration (ms): 152.4 | learning rate: 7.526E-07 | global batch size:     1 | lm loss: 9.962751E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.561 | TFLOPs: 16.30 |
[default0]:[2023-07-30 22:23:41,468] [INFO] [logging.py:96:log_dist] [Rank 0] step=695, skipped=0, lr=[7.580330666666667e-07, 7.580330666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:41,469] [INFO] [timer.py:215:stop] epoch=0/micro_step=695/global_step=695, RunningAvgSamplesPerSec=7.850861698567946, CurrSamplesPerSec=7.831389009216245, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      695/439453125 | consumed samples:          695 | consumed tokens:      1423360 | elapsed time per iteration (ms): 150.7 | learning rate: 7.580E-07 | global batch size:     1 | lm loss: 9.997604E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.635 | TFLOPs: 16.49 |
[default0]:[2023-07-30 22:23:42,262] [INFO] [logging.py:96:log_dist] [Rank 0] step=700, skipped=0, lr=[7.634944e-07, 7.634944e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:42,262] [INFO] [timer.py:215:stop] epoch=0/micro_step=700/global_step=700, RunningAvgSamplesPerSec=7.85065816066665, CurrSamplesPerSec=7.840743863296051, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      700/439453125 | consumed samples:          700 | consumed tokens:      1433600 | elapsed time per iteration (ms): 158.6 | learning rate: 7.635E-07 | global batch size:     1 | lm loss: 9.919152E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.307 | TFLOPs: 15.67 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 700 | lm loss value: 9.980741E+00 | lm loss PPL: 2.160631E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:23:45,755] [INFO] [logging.py:96:log_dist] [Rank 0] step=705, skipped=0, lr=[7.689557333333334e-07, 7.689557333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:45,755] [INFO] [timer.py:215:stop] epoch=0/micro_step=705/global_step=705, RunningAvgSamplesPerSec=7.848906890522948, CurrSamplesPerSec=7.816051000042861, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      705/439453125 | consumed samples:          705 | consumed tokens:      1443840 | elapsed time per iteration (ms): 699.0 | learning rate: 7.690E-07 | global batch size:     1 | lm loss: 9.889054E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.431 | TFLOPs: 3.55 |
[default0]:[2023-07-30 22:23:46,484] [INFO] [logging.py:96:log_dist] [Rank 0] step=710, skipped=0, lr=[7.744170666666667e-07, 7.744170666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:46,484] [INFO] [timer.py:215:stop] epoch=0/micro_step=710/global_step=710, RunningAvgSamplesPerSec=7.849044898060422, CurrSamplesPerSec=7.8904521913512315, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      710/439453125 | consumed samples:          710 | consumed tokens:      1454080 | elapsed time per iteration (ms): 145.7 | learning rate: 7.744E-07 | global batch size:     1 | lm loss: 9.963757E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.864 | TFLOPs: 17.06 |
[default0]:[2023-07-30 22:23:47,270] [INFO] [logging.py:96:log_dist] [Rank 0] step=715, skipped=0, lr=[7.798784e-07, 7.798784e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:47,270] [INFO] [timer.py:215:stop] epoch=0/micro_step=715/global_step=715, RunningAvgSamplesPerSec=7.849561379648433, CurrSamplesPerSec=7.8513113584928975, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      715/439453125 | consumed samples:          715 | consumed tokens:      1464320 | elapsed time per iteration (ms): 157.2 | learning rate: 7.799E-07 | global batch size:     1 | lm loss: 9.911429E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.363 | TFLOPs: 15.81 |
[default0]:[2023-07-30 22:23:48,042] [INFO] [logging.py:96:log_dist] [Rank 0] step=720, skipped=0, lr=[7.853397333333334e-07, 7.853397333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:48,043] [INFO] [timer.py:215:stop] epoch=0/micro_step=720/global_step=720, RunningAvgSamplesPerSec=7.849597788267963, CurrSamplesPerSec=7.838765624065546, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      720/439453125 | consumed samples:          720 | consumed tokens:      1474560 | elapsed time per iteration (ms): 154.6 | learning rate: 7.853E-07 | global batch size:     1 | lm loss: 9.959122E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.467 | TFLOPs: 16.07 |
[default0]:[2023-07-30 22:23:48,786] [INFO] [logging.py:96:log_dist] [Rank 0] step=725, skipped=0, lr=[7.908010666666668e-07, 7.908010666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:48,786] [INFO] [timer.py:215:stop] epoch=0/micro_step=725/global_step=725, RunningAvgSamplesPerSec=7.849742868706519, CurrSamplesPerSec=7.950126711361564, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      725/439453125 | consumed samples:          725 | consumed tokens:      1484800 | elapsed time per iteration (ms): 148.4 | learning rate: 7.908E-07 | global batch size:     1 | lm loss: 9.943606E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.740 | TFLOPs: 16.75 |
[default0]:[2023-07-30 22:23:49,576] [INFO] [logging.py:96:log_dist] [Rank 0] step=730, skipped=0, lr=[7.962624000000001e-07, 7.962624000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:49,577] [INFO] [timer.py:215:stop] epoch=0/micro_step=730/global_step=730, RunningAvgSamplesPerSec=7.849885013043914, CurrSamplesPerSec=7.82713621103744, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      730/439453125 | consumed samples:          730 | consumed tokens:      1495040 | elapsed time per iteration (ms): 158.4 | learning rate: 7.963E-07 | global batch size:     1 | lm loss: 9.928918E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.312 | TFLOPs: 15.68 |
[default0]:[2023-07-30 22:23:50,331] [INFO] [logging.py:96:log_dist] [Rank 0] step=735, skipped=0, lr=[8.017237333333334e-07, 8.017237333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:50,332] [INFO] [timer.py:215:stop] epoch=0/micro_step=735/global_step=735, RunningAvgSamplesPerSec=7.849935087658458, CurrSamplesPerSec=7.849812565153027, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      735/439453125 | consumed samples:          735 | consumed tokens:      1505280 | elapsed time per iteration (ms): 150.8 | learning rate: 8.017E-07 | global batch size:     1 | lm loss: 1.003717E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.630 | TFLOPs: 16.48 |
[default0]:[2023-07-30 22:23:51,097] [INFO] [logging.py:96:log_dist] [Rank 0] step=740, skipped=0, lr=[8.071850666666667e-07, 8.071850666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:51,098] [INFO] [timer.py:215:stop] epoch=0/micro_step=740/global_step=740, RunningAvgSamplesPerSec=7.850265710783129, CurrSamplesPerSec=7.958091183172722, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      740/439453125 | consumed samples:          740 | consumed tokens:      1515520 | elapsed time per iteration (ms): 153.1 | learning rate: 8.072E-07 | global batch size:     1 | lm loss: 9.943643E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.532 | TFLOPs: 16.23 |
[default0]:[2023-07-30 22:23:51,919] [INFO] [logging.py:96:log_dist] [Rank 0] step=745, skipped=0, lr=[8.126464000000001e-07, 8.126464000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:51,919] [INFO] [timer.py:215:stop] epoch=0/micro_step=745/global_step=745, RunningAvgSamplesPerSec=7.8501608007303, CurrSamplesPerSec=7.829254725398621, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      745/439453125 | consumed samples:          745 | consumed tokens:      1525760 | elapsed time per iteration (ms): 164.3 | learning rate: 8.126E-07 | global batch size:     1 | lm loss: 9.942279E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.085 | TFLOPs: 15.12 |
[default0]:[2023-07-30 22:23:52,671] [INFO] [logging.py:96:log_dist] [Rank 0] step=750, skipped=0, lr=[8.181077333333335e-07, 8.181077333333335e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:52,671] [INFO] [timer.py:215:stop] epoch=0/micro_step=750/global_step=750, RunningAvgSamplesPerSec=7.850366531045508, CurrSamplesPerSec=7.857798027637061, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      750/439453125 | consumed samples:          750 | consumed tokens:      1536000 | elapsed time per iteration (ms): 151.0 | learning rate: 8.181E-07 | global batch size:     1 | lm loss: 1.000499E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.624 | TFLOPs: 16.46 |
[default0]:[2023-07-30 22:23:53,449] [INFO] [logging.py:96:log_dist] [Rank 0] step=755, skipped=0, lr=[8.235690666666668e-07, 8.235690666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:53,450] [INFO] [timer.py:215:stop] epoch=0/micro_step=755/global_step=755, RunningAvgSamplesPerSec=7.850710238621642, CurrSamplesPerSec=7.848108750362532, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      755/439453125 | consumed samples:          755 | consumed tokens:      1546240 | elapsed time per iteration (ms): 156.3 | learning rate: 8.236E-07 | global batch size:     1 | lm loss: 9.864136E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.399 | TFLOPs: 15.90 |
[default0]:[2023-07-30 22:23:54,274] [INFO] [logging.py:96:log_dist] [Rank 0] step=760, skipped=0, lr=[8.290304000000001e-07, 8.290304000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:54,275] [INFO] [timer.py:215:stop] epoch=0/micro_step=760/global_step=760, RunningAvgSamplesPerSec=7.849711452686128, CurrSamplesPerSec=7.178622468452463, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      760/439453125 | consumed samples:          760 | consumed tokens:      1556480 | elapsed time per iteration (ms): 164.5 | learning rate: 8.290E-07 | global batch size:     1 | lm loss: 9.876118E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.080 | TFLOPs: 15.11 |
[default0]:[2023-07-30 22:23:55,061] [INFO] [logging.py:96:log_dist] [Rank 0] step=765, skipped=0, lr=[8.344917333333334e-07, 8.344917333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:55,061] [INFO] [timer.py:215:stop] epoch=0/micro_step=765/global_step=765, RunningAvgSamplesPerSec=7.850101972214232, CurrSamplesPerSec=7.91923494482049, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      765/439453125 | consumed samples:          765 | consumed tokens:      1566720 | elapsed time per iteration (ms): 156.8 | learning rate: 8.345E-07 | global batch size:     1 | lm loss: 9.890326E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.377 | TFLOPs: 15.84 |
[default0]:[2023-07-30 22:23:55,819] [INFO] [logging.py:96:log_dist] [Rank 0] step=770, skipped=0, lr=[8.399530666666668e-07, 8.399530666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:55,820] [INFO] [timer.py:215:stop] epoch=0/micro_step=770/global_step=770, RunningAvgSamplesPerSec=7.8501706615117515, CurrSamplesPerSec=7.867998289200201, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      770/439453125 | consumed samples:          770 | consumed tokens:      1576960 | elapsed time per iteration (ms): 151.5 | learning rate: 8.400E-07 | global batch size:     1 | lm loss: 1.005895E+01 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.602 | TFLOPs: 16.40 |
[default0]:[2023-07-30 22:23:56,579] [INFO] [logging.py:96:log_dist] [Rank 0] step=775, skipped=0, lr=[8.454144000000001e-07, 8.454144000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:56,580] [INFO] [timer.py:215:stop] epoch=0/micro_step=775/global_step=775, RunningAvgSamplesPerSec=7.8505784282592765, CurrSamplesPerSec=7.966555806484086, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      775/439453125 | consumed samples:          775 | consumed tokens:      1587200 | elapsed time per iteration (ms): 152.0 | learning rate: 8.454E-07 | global batch size:     1 | lm loss: 9.931982E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.580 | TFLOPs: 16.35 |
[default0]:[2023-07-30 22:23:57,346] [INFO] [logging.py:96:log_dist] [Rank 0] step=780, skipped=0, lr=[8.508757333333333e-07, 8.508757333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:57,347] [INFO] [timer.py:215:stop] epoch=0/micro_step=780/global_step=780, RunningAvgSamplesPerSec=7.85124733889723, CurrSamplesPerSec=7.894580915471617, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      780/439453125 | consumed samples:          780 | consumed tokens:      1597440 | elapsed time per iteration (ms): 153.5 | learning rate: 8.509E-07 | global batch size:     1 | lm loss: 9.797679E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.515 | TFLOPs: 16.19 |
[default0]:[2023-07-30 22:23:58,139] [INFO] [logging.py:96:log_dist] [Rank 0] step=785, skipped=0, lr=[8.563370666666667e-07, 8.563370666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:58,140] [INFO] [timer.py:215:stop] epoch=0/micro_step=785/global_step=785, RunningAvgSamplesPerSec=7.851511582479658, CurrSamplesPerSec=7.867304658704896, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      785/439453125 | consumed samples:          785 | consumed tokens:      1607680 | elapsed time per iteration (ms): 158.7 | learning rate: 8.563E-07 | global batch size:     1 | lm loss: 9.858833E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.303 | TFLOPs: 15.66 |
[default0]:[2023-07-30 22:23:58,902] [INFO] [logging.py:96:log_dist] [Rank 0] step=790, skipped=0, lr=[8.617984e-07, 8.617984e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:58,902] [INFO] [timer.py:215:stop] epoch=0/micro_step=790/global_step=790, RunningAvgSamplesPerSec=7.851988554111406, CurrSamplesPerSec=7.885838481757094, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      790/439453125 | consumed samples:          790 | consumed tokens:      1617920 | elapsed time per iteration (ms): 152.9 | learning rate: 8.618E-07 | global batch size:     1 | lm loss: 9.958147E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.539 | TFLOPs: 16.25 |
[default0]:[2023-07-30 22:23:59,639] [INFO] [logging.py:96:log_dist] [Rank 0] step=795, skipped=0, lr=[8.672597333333333e-07, 8.672597333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:23:59,641] [INFO] [timer.py:215:stop] epoch=0/micro_step=795/global_step=795, RunningAvgSamplesPerSec=7.852036519877643, CurrSamplesPerSec=7.7154929629282165, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      795/439453125 | consumed samples:          795 | consumed tokens:      1628160 | elapsed time per iteration (ms): 146.9 | learning rate: 8.673E-07 | global batch size:     1 | lm loss: 9.872131E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.807 | TFLOPs: 16.91 |
[default0]:[2023-07-30 22:24:00,388] [INFO] [logging.py:96:log_dist] [Rank 0] step=800, skipped=0, lr=[8.727210666666667e-07, 8.727210666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:00,389] [INFO] [timer.py:215:stop] epoch=0/micro_step=800/global_step=800, RunningAvgSamplesPerSec=7.852133953033875, CurrSamplesPerSec=7.8908233027681725, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      800/439453125 | consumed samples:          800 | consumed tokens:      1638400 | elapsed time per iteration (ms): 149.8 | learning rate: 8.727E-07 | global batch size:     1 | lm loss: 9.910513E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.674 | TFLOPs: 16.58 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 800 | lm loss value: 9.872047E+00 | lm loss PPL: 1.938098E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:24:04,028] [INFO] [logging.py:96:log_dist] [Rank 0] step=805, skipped=0, lr=[8.781824e-07, 8.781824e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:04,029] [INFO] [timer.py:215:stop] epoch=0/micro_step=805/global_step=805, RunningAvgSamplesPerSec=7.850075168548524, CurrSamplesPerSec=7.6779661637481285, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      805/439453125 | consumed samples:          805 | consumed tokens:      1648640 | elapsed time per iteration (ms): 728.0 | learning rate: 8.782E-07 | global batch size:     1 | lm loss: 9.931628E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.374 | TFLOPs: 3.41 |
[default0]:[2023-07-30 22:24:04,806] [INFO] [logging.py:96:log_dist] [Rank 0] step=810, skipped=0, lr=[8.836437333333333e-07, 8.836437333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:04,808] [INFO] [timer.py:215:stop] epoch=0/micro_step=810/global_step=810, RunningAvgSamplesPerSec=7.84945862750941, CurrSamplesPerSec=7.754592515900015, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      810/439453125 | consumed samples:          810 | consumed tokens:      1658880 | elapsed time per iteration (ms): 156.1 | learning rate: 8.836E-07 | global batch size:     1 | lm loss: 9.904102E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.406 | TFLOPs: 15.92 |
[default0]:[2023-07-30 22:24:05,616] [INFO] [logging.py:96:log_dist] [Rank 0] step=815, skipped=0, lr=[8.891050666666666e-07, 8.891050666666666e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:05,617] [INFO] [timer.py:215:stop] epoch=0/micro_step=815/global_step=815, RunningAvgSamplesPerSec=7.8495973524122915, CurrSamplesPerSec=7.835207307846781, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      815/439453125 | consumed samples:          815 | consumed tokens:      1669120 | elapsed time per iteration (ms): 161.3 | learning rate: 8.891E-07 | global batch size:     1 | lm loss: 9.811765E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.198 | TFLOPs: 15.40 |
[default0]:[2023-07-30 22:24:06,403] [INFO] [logging.py:96:log_dist] [Rank 0] step=820, skipped=0, lr=[8.945664e-07, 8.945664e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:06,404] [INFO] [timer.py:215:stop] epoch=0/micro_step=820/global_step=820, RunningAvgSamplesPerSec=7.8496966173637865, CurrSamplesPerSec=7.836671244266323, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      820/439453125 | consumed samples:          820 | consumed tokens:      1679360 | elapsed time per iteration (ms): 157.7 | learning rate: 8.946E-07 | global batch size:     1 | lm loss: 9.874854E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.342 | TFLOPs: 15.76 |
[default0]:[2023-07-30 22:24:07,140] [INFO] [logging.py:96:log_dist] [Rank 0] step=825, skipped=0, lr=[9.000277333333334e-07, 9.000277333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:07,141] [INFO] [timer.py:215:stop] epoch=0/micro_step=825/global_step=825, RunningAvgSamplesPerSec=7.850064359430097, CurrSamplesPerSec=7.915797420097572, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      825/439453125 | consumed samples:          825 | consumed tokens:      1689600 | elapsed time per iteration (ms): 147.2 | learning rate: 9.000E-07 | global batch size:     1 | lm loss: 9.901663E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.792 | TFLOPs: 16.88 |
[default0]:[2023-07-30 22:24:07,906] [INFO] [logging.py:96:log_dist] [Rank 0] step=830, skipped=0, lr=[9.054890666666667e-07, 9.054890666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:07,907] [INFO] [timer.py:215:stop] epoch=0/micro_step=830/global_step=830, RunningAvgSamplesPerSec=7.850190705555299, CurrSamplesPerSec=7.742353733836654, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      830/439453125 | consumed samples:          830 | consumed tokens:      1699840 | elapsed time per iteration (ms): 153.5 | learning rate: 9.055E-07 | global batch size:     1 | lm loss: 9.802018E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.515 | TFLOPs: 16.19 |
[default0]:[2023-07-30 22:24:08,666] [INFO] [logging.py:96:log_dist] [Rank 0] step=835, skipped=0, lr=[9.109504e-07, 9.109504e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:08,667] [INFO] [timer.py:215:stop] epoch=0/micro_step=835/global_step=835, RunningAvgSamplesPerSec=7.850195702658071, CurrSamplesPerSec=7.896884778605775, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      835/439453125 | consumed samples:          835 | consumed tokens:      1710080 | elapsed time per iteration (ms): 151.9 | learning rate: 9.110E-07 | global batch size:     1 | lm loss: 9.854002E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.584 | TFLOPs: 16.36 |
[default0]:[2023-07-30 22:24:09,415] [INFO] [logging.py:96:log_dist] [Rank 0] step=840, skipped=0, lr=[9.164117333333333e-07, 9.164117333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:09,415] [INFO] [timer.py:215:stop] epoch=0/micro_step=840/global_step=840, RunningAvgSamplesPerSec=7.850452896301015, CurrSamplesPerSec=7.841227584762874, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      840/439453125 | consumed samples:          840 | consumed tokens:      1720320 | elapsed time per iteration (ms): 149.5 | learning rate: 9.164E-07 | global batch size:     1 | lm loss: 9.867091E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.687 | TFLOPs: 16.62 |
[default0]:[2023-07-30 22:24:10,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=845, skipped=0, lr=[9.218730666666667e-07, 9.218730666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:10,184] [INFO] [timer.py:215:stop] epoch=0/micro_step=845/global_step=845, RunningAvgSamplesPerSec=7.850395064919267, CurrSamplesPerSec=7.934725813988244, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      845/439453125 | consumed samples:          845 | consumed tokens:      1730560 | elapsed time per iteration (ms): 153.6 | learning rate: 9.219E-07 | global batch size:     1 | lm loss: 9.745409E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.511 | TFLOPs: 16.18 |
[default0]:[2023-07-30 22:24:10,944] [INFO] [logging.py:96:log_dist] [Rank 0] step=850, skipped=0, lr=[9.273344000000001e-07, 9.273344000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:10,945] [INFO] [timer.py:215:stop] epoch=0/micro_step=850/global_step=850, RunningAvgSamplesPerSec=7.850661405631146, CurrSamplesPerSec=7.869622157928904, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      850/439453125 | consumed samples:          850 | consumed tokens:      1740800 | elapsed time per iteration (ms): 152.3 | learning rate: 9.273E-07 | global batch size:     1 | lm loss: 9.997500E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.566 | TFLOPs: 16.31 |
[default0]:[2023-07-30 22:24:11,751] [INFO] [logging.py:96:log_dist] [Rank 0] step=855, skipped=0, lr=[9.327957333333334e-07, 9.327957333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:11,751] [INFO] [timer.py:215:stop] epoch=0/micro_step=855/global_step=855, RunningAvgSamplesPerSec=7.8509514484243486, CurrSamplesPerSec=7.939922953876442, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      855/439453125 | consumed samples:          855 | consumed tokens:      1751040 | elapsed time per iteration (ms): 161.2 | learning rate: 9.328E-07 | global batch size:     1 | lm loss: 9.898074E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.205 | TFLOPs: 15.42 |
[default0]:[2023-07-30 22:24:12,491] [INFO] [logging.py:96:log_dist] [Rank 0] step=860, skipped=0, lr=[9.382570666666667e-07, 9.382570666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:12,491] [INFO] [timer.py:215:stop] epoch=0/micro_step=860/global_step=860, RunningAvgSamplesPerSec=7.851024163617422, CurrSamplesPerSec=7.9098560525625965, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      860/439453125 | consumed samples:          860 | consumed tokens:      1761280 | elapsed time per iteration (ms): 147.9 | learning rate: 9.383E-07 | global batch size:     1 | lm loss: 9.830493E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.759 | TFLOPs: 16.80 |
[default0]:[2023-07-30 22:24:13,291] [INFO] [logging.py:96:log_dist] [Rank 0] step=865, skipped=0, lr=[9.437184e-07, 9.437184e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:13,293] [INFO] [timer.py:215:stop] epoch=0/micro_step=865/global_step=865, RunningAvgSamplesPerSec=7.851136822283696, CurrSamplesPerSec=7.716117495773368, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      865/439453125 | consumed samples:          865 | consumed tokens:      1771520 | elapsed time per iteration (ms): 160.5 | learning rate: 9.437E-07 | global batch size:     1 | lm loss: 9.737599E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.230 | TFLOPs: 15.48 |
[default0]:[2023-07-30 22:24:14,243] [INFO] [logging.py:96:log_dist] [Rank 0] step=870, skipped=0, lr=[9.491797333333334e-07, 9.491797333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:14,243] [INFO] [timer.py:215:stop] epoch=0/micro_step=870/global_step=870, RunningAvgSamplesPerSec=7.851469251299795, CurrSamplesPerSec=7.859299872206628, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      870/439453125 | consumed samples:          870 | consumed tokens:      1781760 | elapsed time per iteration (ms): 190.7 | learning rate: 9.492E-07 | global batch size:     1 | lm loss: 9.780677E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.244 | TFLOPs: 13.03 |
[default0]:[2023-07-30 22:24:15,170] [INFO] [logging.py:96:log_dist] [Rank 0] step=875, skipped=0, lr=[9.546410666666666e-07, 9.546410666666666e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:15,171] [INFO] [timer.py:215:stop] epoch=0/micro_step=875/global_step=875, RunningAvgSamplesPerSec=7.844609928950231, CurrSamplesPerSec=7.837491287636011, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      875/439453125 | consumed samples:          875 | consumed tokens:      1792000 | elapsed time per iteration (ms): 184.8 | learning rate: 9.546E-07 | global batch size:     1 | lm loss: 9.836132E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.410 | TFLOPs: 13.44 |
[default0]:[2023-07-30 22:24:15,983] [INFO] [logging.py:96:log_dist] [Rank 0] step=880, skipped=0, lr=[9.601024000000002e-07, 9.601024000000002e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:15,983] [INFO] [timer.py:215:stop] epoch=0/micro_step=880/global_step=880, RunningAvgSamplesPerSec=7.845073768980681, CurrSamplesPerSec=7.944871061474525, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      880/439453125 | consumed samples:          880 | consumed tokens:      1802240 | elapsed time per iteration (ms): 162.4 | learning rate: 9.601E-07 | global batch size:     1 | lm loss: 9.758636E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.159 | TFLOPs: 15.30 |
[default0]:[2023-07-30 22:24:16,727] [INFO] [logging.py:96:log_dist] [Rank 0] step=885, skipped=0, lr=[9.655637333333335e-07, 9.655637333333335e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:16,727] [INFO] [timer.py:215:stop] epoch=0/micro_step=885/global_step=885, RunningAvgSamplesPerSec=7.845340307062496, CurrSamplesPerSec=7.913572094322037, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      885/439453125 | consumed samples:          885 | consumed tokens:      1812480 | elapsed time per iteration (ms): 148.7 | learning rate: 9.656E-07 | global batch size:     1 | lm loss: 9.736404E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.723 | TFLOPs: 16.71 |
[default0]:[2023-07-30 22:24:17,522] [INFO] [logging.py:96:log_dist] [Rank 0] step=890, skipped=0, lr=[9.710250666666668e-07, 9.710250666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:17,522] [INFO] [timer.py:215:stop] epoch=0/micro_step=890/global_step=890, RunningAvgSamplesPerSec=7.8455870374945835, CurrSamplesPerSec=7.977586774218704, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      890/439453125 | consumed samples:          890 | consumed tokens:      1822720 | elapsed time per iteration (ms): 159.0 | learning rate: 9.710E-07 | global batch size:     1 | lm loss: 9.814253E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.290 | TFLOPs: 15.63 |
[default0]:[2023-07-30 22:24:18,280] [INFO] [logging.py:96:log_dist] [Rank 0] step=895, skipped=0, lr=[9.764864e-07, 9.764864e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:18,280] [INFO] [timer.py:215:stop] epoch=0/micro_step=895/global_step=895, RunningAvgSamplesPerSec=7.845668416915079, CurrSamplesPerSec=7.878565431120144, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      895/439453125 | consumed samples:          895 | consumed tokens:      1832960 | elapsed time per iteration (ms): 152.2 | learning rate: 9.765E-07 | global batch size:     1 | lm loss: 9.768087E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.569 | TFLOPs: 16.32 |
[default0]:[2023-07-30 22:24:19,055] [INFO] [logging.py:96:log_dist] [Rank 0] step=900, skipped=0, lr=[9.819477333333334e-07, 9.819477333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:19,055] [INFO] [timer.py:215:stop] epoch=0/micro_step=900/global_step=900, RunningAvgSamplesPerSec=7.846118523136672, CurrSamplesPerSec=7.936467449407268, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      900/439453125 | consumed samples:          900 | consumed tokens:      1843200 | elapsed time per iteration (ms): 154.5 | learning rate: 9.819E-07 | global batch size:     1 | lm loss: 9.913692E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.472 | TFLOPs: 16.08 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 900 | lm loss value: 9.811135E+00 | lm loss PPL: 1.823568E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:24:22,659] [INFO] [logging.py:96:log_dist] [Rank 0] step=905, skipped=0, lr=[9.874090666666667e-07, 9.874090666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:22,659] [INFO] [timer.py:215:stop] epoch=0/micro_step=905/global_step=905, RunningAvgSamplesPerSec=7.844528788129477, CurrSamplesPerSec=7.798379824595654, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      905/439453125 | consumed samples:          905 | consumed tokens:      1853440 | elapsed time per iteration (ms): 720.7 | learning rate: 9.874E-07 | global batch size:     1 | lm loss: 9.801039E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.387 | TFLOPs: 3.45 |
[default0]:[2023-07-30 22:24:23,435] [INFO] [logging.py:96:log_dist] [Rank 0] step=910, skipped=0, lr=[9.928704e-07, 9.928704e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:23,435] [INFO] [timer.py:215:stop] epoch=0/micro_step=910/global_step=910, RunningAvgSamplesPerSec=7.844955746239062, CurrSamplesPerSec=7.89171411261341, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      910/439453125 | consumed samples:          910 | consumed tokens:      1863680 | elapsed time per iteration (ms): 155.2 | learning rate: 9.929E-07 | global batch size:     1 | lm loss: 9.779812E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.442 | TFLOPs: 16.01 |
[default0]:[2023-07-30 22:24:24,202] [INFO] [logging.py:96:log_dist] [Rank 0] step=915, skipped=0, lr=[9.983317333333334e-07, 9.983317333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:24,202] [INFO] [timer.py:215:stop] epoch=0/micro_step=915/global_step=915, RunningAvgSamplesPerSec=7.845493029450519, CurrSamplesPerSec=7.89098660285101, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      915/439453125 | consumed samples:          915 | consumed tokens:      1873920 | elapsed time per iteration (ms): 153.5 | learning rate: 9.983E-07 | global batch size:     1 | lm loss: 9.783710E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.514 | TFLOPs: 16.19 |
[default0]:[2023-07-30 22:24:24,958] [INFO] [logging.py:96:log_dist] [Rank 0] step=920, skipped=0, lr=[1.0037930666666667e-06, 1.0037930666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:24,961] [INFO] [timer.py:215:stop] epoch=0/micro_step=920/global_step=920, RunningAvgSamplesPerSec=7.845240122845598, CurrSamplesPerSec=7.737911542562808, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      920/439453125 | consumed samples:          920 | consumed tokens:      1884160 | elapsed time per iteration (ms): 151.6 | learning rate: 1.004E-06 | global batch size:     1 | lm loss: 9.744514E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.597 | TFLOPs: 16.39 |
[default0]:[2023-07-30 22:24:25,693] [INFO] [logging.py:96:log_dist] [Rank 0] step=925, skipped=0, lr=[1.0092544000000002e-06, 1.0092544000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:25,694] [INFO] [timer.py:215:stop] epoch=0/micro_step=925/global_step=925, RunningAvgSamplesPerSec=7.845431973774428, CurrSamplesPerSec=7.869666454647626, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      925/439453125 | consumed samples:          925 | consumed tokens:      1894400 | elapsed time per iteration (ms): 146.5 | learning rate: 1.009E-06 | global batch size:     1 | lm loss: 9.762318E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.827 | TFLOPs: 16.96 |
[default0]:[2023-07-30 22:24:26,456] [INFO] [logging.py:96:log_dist] [Rank 0] step=930, skipped=0, lr=[1.0147157333333335e-06, 1.0147157333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:26,457] [INFO] [timer.py:215:stop] epoch=0/micro_step=930/global_step=930, RunningAvgSamplesPerSec=7.84590254168969, CurrSamplesPerSec=7.9220020776277265, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      930/439453125 | consumed samples:          930 | consumed tokens:      1904640 | elapsed time per iteration (ms): 152.7 | learning rate: 1.015E-06 | global batch size:     1 | lm loss: 9.749189E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.548 | TFLOPs: 16.27 |
[default0]:[2023-07-30 22:24:27,226] [INFO] [logging.py:96:log_dist] [Rank 0] step=935, skipped=0, lr=[1.0201770666666668e-06, 1.0201770666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:27,227] [INFO] [timer.py:215:stop] epoch=0/micro_step=935/global_step=935, RunningAvgSamplesPerSec=7.84615438657961, CurrSamplesPerSec=7.910497529327449, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      935/439453125 | consumed samples:          935 | consumed tokens:      1914880 | elapsed time per iteration (ms): 153.9 | learning rate: 1.020E-06 | global batch size:     1 | lm loss: 9.861264E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.499 | TFLOPs: 16.15 |
[default0]:[2023-07-30 22:24:27,974] [INFO] [logging.py:96:log_dist] [Rank 0] step=940, skipped=0, lr=[1.0256384000000001e-06, 1.0256384000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:27,975] [INFO] [timer.py:215:stop] epoch=0/micro_step=940/global_step=940, RunningAvgSamplesPerSec=7.84639763161019, CurrSamplesPerSec=7.926163893781228, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      940/439453125 | consumed samples:          940 | consumed tokens:      1925120 | elapsed time per iteration (ms): 149.5 | learning rate: 1.026E-06 | global batch size:     1 | lm loss: 9.737851E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.687 | TFLOPs: 16.62 |
[default0]:[2023-07-30 22:24:28,732] [INFO] [logging.py:96:log_dist] [Rank 0] step=945, skipped=0, lr=[1.0310997333333332e-06, 1.0310997333333332e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:28,734] [INFO] [timer.py:215:stop] epoch=0/micro_step=945/global_step=945, RunningAvgSamplesPerSec=7.846649551154147, CurrSamplesPerSec=7.872369497811512, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      945/439453125 | consumed samples:          945 | consumed tokens:      1935360 | elapsed time per iteration (ms): 152.1 | learning rate: 1.031E-06 | global batch size:     1 | lm loss: 9.719653E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.575 | TFLOPs: 16.34 |
[default0]:[2023-07-30 22:24:29,521] [INFO] [logging.py:96:log_dist] [Rank 0] step=950, skipped=0, lr=[1.0365610666666666e-06, 1.0365610666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:29,522] [INFO] [timer.py:215:stop] epoch=0/micro_step=950/global_step=950, RunningAvgSamplesPerSec=7.846811584375143, CurrSamplesPerSec=7.798263831432869, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      950/439453125 | consumed samples:          950 | consumed tokens:      1945600 | elapsed time per iteration (ms): 157.6 | learning rate: 1.037E-06 | global batch size:     1 | lm loss: 9.791174E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.344 | TFLOPs: 15.76 |
[default0]:[2023-07-30 22:24:30,266] [INFO] [logging.py:96:log_dist] [Rank 0] step=955, skipped=0, lr=[1.0420224e-06, 1.0420224e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:30,266] [INFO] [timer.py:215:stop] epoch=0/micro_step=955/global_step=955, RunningAvgSamplesPerSec=7.8470770773823, CurrSamplesPerSec=7.887158252615229, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      955/439453125 | consumed samples:          955 | consumed tokens:      1955840 | elapsed time per iteration (ms): 148.7 | learning rate: 1.042E-06 | global batch size:     1 | lm loss: 9.819888E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.724 | TFLOPs: 16.71 |
[default0]:[2023-07-30 22:24:31,040] [INFO] [logging.py:96:log_dist] [Rank 0] step=960, skipped=0, lr=[1.0474837333333334e-06, 1.0474837333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:31,040] [INFO] [timer.py:215:stop] epoch=0/micro_step=960/global_step=960, RunningAvgSamplesPerSec=7.847475236717644, CurrSamplesPerSec=7.905800748301243, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      960/439453125 | consumed samples:          960 | consumed tokens:      1966080 | elapsed time per iteration (ms): 154.6 | learning rate: 1.047E-06 | global batch size:     1 | lm loss: 9.743535E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.466 | TFLOPs: 16.07 |
[default0]:[2023-07-30 22:24:31,851] [INFO] [logging.py:96:log_dist] [Rank 0] step=965, skipped=0, lr=[1.0529450666666667e-06, 1.0529450666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:31,851] [INFO] [timer.py:215:stop] epoch=0/micro_step=965/global_step=965, RunningAvgSamplesPerSec=7.847748232768006, CurrSamplesPerSec=7.871896700574303, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      965/439453125 | consumed samples:          965 | consumed tokens:      1976320 | elapsed time per iteration (ms): 162.1 | learning rate: 1.053E-06 | global batch size:     1 | lm loss: 9.794370E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.167 | TFLOPs: 15.32 |
[default0]:[2023-07-30 22:24:32,607] [INFO] [logging.py:96:log_dist] [Rank 0] step=970, skipped=0, lr=[1.0584064e-06, 1.0584064e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:32,609] [INFO] [timer.py:215:stop] epoch=0/micro_step=970/global_step=970, RunningAvgSamplesPerSec=7.848027863046056, CurrSamplesPerSec=7.843441738522271, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      970/439453125 | consumed samples:          970 | consumed tokens:      1986560 | elapsed time per iteration (ms): 151.8 | learning rate: 1.058E-06 | global batch size:     1 | lm loss: 9.759853E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.589 | TFLOPs: 16.37 |
[default0]:[2023-07-30 22:24:33,383] [INFO] [logging.py:96:log_dist] [Rank 0] step=975, skipped=0, lr=[1.0638677333333333e-06, 1.0638677333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:33,383] [INFO] [timer.py:215:stop] epoch=0/micro_step=975/global_step=975, RunningAvgSamplesPerSec=7.8482295213201825, CurrSamplesPerSec=7.8735073989461455, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      975/439453125 | consumed samples:          975 | consumed tokens:      1996800 | elapsed time per iteration (ms): 154.8 | learning rate: 1.064E-06 | global batch size:     1 | lm loss: 9.704410E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.461 | TFLOPs: 16.06 |
[default0]:[2023-07-30 22:24:34,140] [INFO] [logging.py:96:log_dist] [Rank 0] step=980, skipped=0, lr=[1.0693290666666667e-06, 1.0693290666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:34,141] [INFO] [timer.py:215:stop] epoch=0/micro_step=980/global_step=980, RunningAvgSamplesPerSec=7.8485340490594195, CurrSamplesPerSec=7.959042555210195, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      980/439453125 | consumed samples:          980 | consumed tokens:      2007040 | elapsed time per iteration (ms): 151.4 | learning rate: 1.069E-06 | global batch size:     1 | lm loss: 9.770877E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.603 | TFLOPs: 16.41 |
[default0]:[2023-07-30 22:24:34,909] [INFO] [logging.py:96:log_dist] [Rank 0] step=985, skipped=0, lr=[1.0747904e-06, 1.0747904e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:34,911] [INFO] [timer.py:215:stop] epoch=0/micro_step=985/global_step=985, RunningAvgSamplesPerSec=7.84840582025323, CurrSamplesPerSec=7.846185503754447, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      985/439453125 | consumed samples:          985 | consumed tokens:      2017280 | elapsed time per iteration (ms): 154.0 | learning rate: 1.075E-06 | global batch size:     1 | lm loss: 9.689235E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.493 | TFLOPs: 16.13 |
[default0]:[2023-07-30 22:24:35,668] [INFO] [logging.py:96:log_dist] [Rank 0] step=990, skipped=0, lr=[1.0802517333333333e-06, 1.0802517333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:35,669] [INFO] [timer.py:215:stop] epoch=0/micro_step=990/global_step=990, RunningAvgSamplesPerSec=7.848697928407021, CurrSamplesPerSec=7.910243909798826, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      990/439453125 | consumed samples:          990 | consumed tokens:      2027520 | elapsed time per iteration (ms): 151.9 | learning rate: 1.080E-06 | global batch size:     1 | lm loss: 9.601843E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.583 | TFLOPs: 16.36 |
[default0]:[2023-07-30 22:24:36,449] [INFO] [logging.py:96:log_dist] [Rank 0] step=995, skipped=0, lr=[1.0857130666666666e-06, 1.0857130666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:36,451] [INFO] [timer.py:215:stop] epoch=0/micro_step=995/global_step=995, RunningAvgSamplesPerSec=7.84894530039273, CurrSamplesPerSec=7.8836596024622905, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration      995/439453125 | consumed samples:          995 | consumed tokens:      2037760 | elapsed time per iteration (ms): 156.2 | learning rate: 1.086E-06 | global batch size:     1 | lm loss: 9.811799E+00 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.403 | TFLOPs: 15.91 |
[default0]:[2023-07-30 22:24:37,192] [INFO] [logging.py:96:log_dist] [Rank 0] step=1000, skipped=0, lr=[1.0911744000000001e-06, 1.0911744000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:37,192] [INFO] [timer.py:215:stop] epoch=0/micro_step=1000/global_step=1000, RunningAvgSamplesPerSec=7.849172679540113, CurrSamplesPerSec=7.879394266155439, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1000/439453125 | consumed samples:         1000 | consumed tokens:      2048000 | elapsed time per iteration (ms): 148.7 | learning rate: 1.091E-06 | global batch size:     1 | lm loss: 9.795808E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.727 | TFLOPs: 16.71 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1000 | lm loss value: 9.769706E+00 | lm loss PPL: 1.749562E+04 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:24:41,043] [INFO] [logging.py:96:log_dist] [Rank 0] step=1005, skipped=0, lr=[1.0966357333333334e-06, 1.0966357333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:41,044] [INFO] [timer.py:215:stop] epoch=0/micro_step=1005/global_step=1005, RunningAvgSamplesPerSec=7.848164342434462, CurrSamplesPerSec=7.730937174560166, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1005/439453125 | consumed samples:         1005 | consumed tokens:      2058240 | elapsed time per iteration (ms): 769.7 | learning rate: 1.097E-06 | global batch size:     1 | lm loss: 9.607436E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.299 | TFLOPs: 3.23 |
[default0]:[2023-07-30 22:24:41,776] [INFO] [logging.py:96:log_dist] [Rank 0] step=1010, skipped=0, lr=[1.1020970666666668e-06, 1.1020970666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:41,776] [INFO] [timer.py:215:stop] epoch=0/micro_step=1010/global_step=1010, RunningAvgSamplesPerSec=7.848406334229441, CurrSamplesPerSec=7.93009018547579, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1010/439453125 | consumed samples:         1010 | consumed tokens:      2068480 | elapsed time per iteration (ms): 146.8 | learning rate: 1.102E-06 | global batch size:     1 | lm loss: 9.682712E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.813 | TFLOPs: 16.93 |
[default0]:[2023-07-30 22:24:42,511] [INFO] [logging.py:96:log_dist] [Rank 0] step=1015, skipped=0, lr=[1.1075584e-06, 1.1075584e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:42,511] [INFO] [timer.py:215:stop] epoch=0/micro_step=1015/global_step=1015, RunningAvgSamplesPerSec=7.848795027262566, CurrSamplesPerSec=7.954242713880418, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1015/439453125 | consumed samples:         1015 | consumed tokens:      2078720 | elapsed time per iteration (ms): 146.7 | learning rate: 1.108E-06 | global batch size:     1 | lm loss: 9.799925E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.815 | TFLOPs: 16.93 |
[default0]:[2023-07-30 22:24:43,290] [INFO] [logging.py:96:log_dist] [Rank 0] step=1020, skipped=0, lr=[1.1130197333333334e-06, 1.1130197333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:43,291] [INFO] [timer.py:215:stop] epoch=0/micro_step=1020/global_step=1020, RunningAvgSamplesPerSec=7.8488724379330925, CurrSamplesPerSec=7.7379971957789095, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1020/439453125 | consumed samples:         1020 | consumed tokens:      2088960 | elapsed time per iteration (ms): 156.2 | learning rate: 1.113E-06 | global batch size:     1 | lm loss: 9.831714E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.403 | TFLOPs: 15.91 |
[default0]:[2023-07-30 22:24:44,043] [INFO] [logging.py:96:log_dist] [Rank 0] step=1025, skipped=0, lr=[1.1184810666666667e-06, 1.1184810666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:44,043] [INFO] [timer.py:215:stop] epoch=0/micro_step=1025/global_step=1025, RunningAvgSamplesPerSec=7.849257281032287, CurrSamplesPerSec=7.954001365394826, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1025/439453125 | consumed samples:         1025 | consumed tokens:      2099200 | elapsed time per iteration (ms): 150.3 | learning rate: 1.118E-06 | global batch size:     1 | lm loss: 9.671022E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.652 | TFLOPs: 16.53 |
[default0]:[2023-07-30 22:24:44,819] [INFO] [logging.py:96:log_dist] [Rank 0] step=1030, skipped=0, lr=[1.1239424e-06, 1.1239424e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:44,821] [INFO] [timer.py:215:stop] epoch=0/micro_step=1030/global_step=1030, RunningAvgSamplesPerSec=7.848978753952963, CurrSamplesPerSec=7.854604835643913, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1030/439453125 | consumed samples:         1030 | consumed tokens:      2109440 | elapsed time per iteration (ms): 155.7 | learning rate: 1.124E-06 | global batch size:     1 | lm loss: 9.624341E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.425 | TFLOPs: 15.96 |
[default0]:[2023-07-30 22:24:45,572] [INFO] [logging.py:96:log_dist] [Rank 0] step=1035, skipped=0, lr=[1.1294037333333333e-06, 1.1294037333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:45,573] [INFO] [timer.py:215:stop] epoch=0/micro_step=1035/global_step=1035, RunningAvgSamplesPerSec=7.849190305763555, CurrSamplesPerSec=7.849606893079784, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1035/439453125 | consumed samples:         1035 | consumed tokens:      2119680 | elapsed time per iteration (ms): 150.1 | learning rate: 1.129E-06 | global batch size:     1 | lm loss: 9.629288E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.662 | TFLOPs: 16.55 |
[default0]:[2023-07-30 22:24:46,321] [INFO] [logging.py:96:log_dist] [Rank 0] step=1040, skipped=0, lr=[1.1348650666666666e-06, 1.1348650666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:46,322] [INFO] [timer.py:215:stop] epoch=0/micro_step=1040/global_step=1040, RunningAvgSamplesPerSec=7.849397849473028, CurrSamplesPerSec=7.85541392446314, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1040/439453125 | consumed samples:         1040 | consumed tokens:      2129920 | elapsed time per iteration (ms): 149.8 | learning rate: 1.135E-06 | global batch size:     1 | lm loss: 9.682350E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.673 | TFLOPs: 16.58 |
[default0]:[2023-07-30 22:24:47,079] [INFO] [logging.py:96:log_dist] [Rank 0] step=1045, skipped=0, lr=[1.1403264000000002e-06, 1.1403264000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:47,079] [INFO] [timer.py:215:stop] epoch=0/micro_step=1045/global_step=1045, RunningAvgSamplesPerSec=7.849765209759497, CurrSamplesPerSec=7.81303717722797, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1045/439453125 | consumed samples:         1045 | consumed tokens:      2140160 | elapsed time per iteration (ms): 151.5 | learning rate: 1.140E-06 | global batch size:     1 | lm loss: 9.702592E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.602 | TFLOPs: 16.41 |
[default0]:[2023-07-30 22:24:47,830] [INFO] [logging.py:96:log_dist] [Rank 0] step=1050, skipped=0, lr=[1.1457877333333335e-06, 1.1457877333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:47,831] [INFO] [timer.py:215:stop] epoch=0/micro_step=1050/global_step=1050, RunningAvgSamplesPerSec=7.849910484659183, CurrSamplesPerSec=7.878091889384129, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1050/439453125 | consumed samples:         1050 | consumed tokens:      2150400 | elapsed time per iteration (ms): 150.3 | learning rate: 1.146E-06 | global batch size:     1 | lm loss: 9.649478E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.656 | TFLOPs: 16.54 |
[default0]:[2023-07-30 22:24:48,592] [INFO] [logging.py:96:log_dist] [Rank 0] step=1055, skipped=0, lr=[1.1512490666666668e-06, 1.1512490666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:48,592] [INFO] [timer.py:215:stop] epoch=0/micro_step=1055/global_step=1055, RunningAvgSamplesPerSec=7.849931757205619, CurrSamplesPerSec=7.955676022222685, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1055/439453125 | consumed samples:         1055 | consumed tokens:      2160640 | elapsed time per iteration (ms): 152.3 | learning rate: 1.151E-06 | global batch size:     1 | lm loss: 9.660510E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.567 | TFLOPs: 16.32 |
[default0]:[2023-07-30 22:24:49,366] [INFO] [logging.py:96:log_dist] [Rank 0] step=1060, skipped=0, lr=[1.1567104000000001e-06, 1.1567104000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:49,367] [INFO] [timer.py:215:stop] epoch=0/micro_step=1060/global_step=1060, RunningAvgSamplesPerSec=7.850148923035817, CurrSamplesPerSec=7.894655212654626, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1060/439453125 | consumed samples:         1060 | consumed tokens:      2170880 | elapsed time per iteration (ms): 155.0 | learning rate: 1.157E-06 | global batch size:     1 | lm loss: 9.677159E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.453 | TFLOPs: 16.04 |
[default0]:[2023-07-30 22:24:50,156] [INFO] [logging.py:96:log_dist] [Rank 0] step=1065, skipped=0, lr=[1.1621717333333334e-06, 1.1621717333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:50,157] [INFO] [timer.py:215:stop] epoch=0/micro_step=1065/global_step=1065, RunningAvgSamplesPerSec=7.85031233432703, CurrSamplesPerSec=7.828640968784764, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1065/439453125 | consumed samples:         1065 | consumed tokens:      2181120 | elapsed time per iteration (ms): 157.9 | learning rate: 1.162E-06 | global batch size:     1 | lm loss: 9.690426E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.332 | TFLOPs: 15.73 |
[default0]:[2023-07-30 22:24:50,882] [INFO] [logging.py:96:log_dist] [Rank 0] step=1070, skipped=0, lr=[1.1676330666666667e-06, 1.1676330666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:50,883] [INFO] [timer.py:215:stop] epoch=0/micro_step=1070/global_step=1070, RunningAvgSamplesPerSec=7.850606688140299, CurrSamplesPerSec=7.874216906374199, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1070/439453125 | consumed samples:         1070 | consumed tokens:      2191360 | elapsed time per iteration (ms): 145.4 | learning rate: 1.168E-06 | global batch size:     1 | lm loss: 9.736201E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.878 | TFLOPs: 17.09 |
[default0]:[2023-07-30 22:24:51,668] [INFO] [logging.py:96:log_dist] [Rank 0] step=1075, skipped=0, lr=[1.1730944e-06, 1.1730944e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:51,669] [INFO] [timer.py:215:stop] epoch=0/micro_step=1075/global_step=1075, RunningAvgSamplesPerSec=7.850792578621855, CurrSamplesPerSec=7.897702601684495, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1075/439453125 | consumed samples:         1075 | consumed tokens:      2201600 | elapsed time per iteration (ms): 157.2 | learning rate: 1.173E-06 | global batch size:     1 | lm loss: 9.713103E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.360 | TFLOPs: 15.80 |
[default0]:[2023-07-30 22:24:52,427] [INFO] [logging.py:96:log_dist] [Rank 0] step=1080, skipped=0, lr=[1.1785557333333334e-06, 1.1785557333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:52,427] [INFO] [timer.py:215:stop] epoch=0/micro_step=1080/global_step=1080, RunningAvgSamplesPerSec=7.85108218690595, CurrSamplesPerSec=7.883822606172018, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1080/439453125 | consumed samples:         1080 | consumed tokens:      2211840 | elapsed time per iteration (ms): 151.8 | learning rate: 1.179E-06 | global batch size:     1 | lm loss: 9.716170E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.588 | TFLOPs: 16.37 |
[default0]:[2023-07-30 22:24:53,169] [INFO] [logging.py:96:log_dist] [Rank 0] step=1085, skipped=0, lr=[1.1840170666666667e-06, 1.1840170666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:53,169] [INFO] [timer.py:215:stop] epoch=0/micro_step=1085/global_step=1085, RunningAvgSamplesPerSec=7.851331972145552, CurrSamplesPerSec=7.87349261890102, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1085/439453125 | consumed samples:         1085 | consumed tokens:      2222080 | elapsed time per iteration (ms): 148.2 | learning rate: 1.184E-06 | global batch size:     1 | lm loss: 9.725075E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.746 | TFLOPs: 16.76 |
[default0]:[2023-07-30 22:24:53,915] [INFO] [logging.py:96:log_dist] [Rank 0] step=1090, skipped=0, lr=[1.1894784000000002e-06, 1.1894784000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:53,915] [INFO] [timer.py:215:stop] epoch=0/micro_step=1090/global_step=1090, RunningAvgSamplesPerSec=7.85150394879018, CurrSamplesPerSec=7.9184425548624855, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1090/439453125 | consumed samples:         1090 | consumed tokens:      2232320 | elapsed time per iteration (ms): 149.0 | learning rate: 1.189E-06 | global batch size:     1 | lm loss: 9.757466E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.712 | TFLOPs: 16.68 |
[default0]:[2023-07-30 22:24:54,737] [INFO] [logging.py:96:log_dist] [Rank 0] step=1095, skipped=0, lr=[1.1949397333333335e-06, 1.1949397333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:54,740] [INFO] [timer.py:215:stop] epoch=0/micro_step=1095/global_step=1095, RunningAvgSamplesPerSec=7.850943187867958, CurrSamplesPerSec=7.5955697532071484, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1095/439453125 | consumed samples:         1095 | consumed tokens:      2242560 | elapsed time per iteration (ms): 165.2 | learning rate: 1.195E-06 | global batch size:     1 | lm loss: 9.636685E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.052 | TFLOPs: 15.04 |
[default0]:[2023-07-30 22:24:55,491] [INFO] [logging.py:96:log_dist] [Rank 0] step=1100, skipped=0, lr=[1.2004010666666668e-06, 1.2004010666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:55,491] [INFO] [timer.py:215:stop] epoch=0/micro_step=1100/global_step=1100, RunningAvgSamplesPerSec=7.8511849648723535, CurrSamplesPerSec=7.873536959202867, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1100/439453125 | consumed samples:         1100 | consumed tokens:      2252800 | elapsed time per iteration (ms): 150.2 | learning rate: 1.200E-06 | global batch size:     1 | lm loss: 9.695177E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.659 | TFLOPs: 16.55 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1100 | lm loss value: 9.680403E+00 | lm loss PPL: 1.600094E+04 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:24:59,033] [INFO] [logging.py:96:log_dist] [Rank 0] step=1105, skipped=0, lr=[1.2058624000000002e-06, 1.2058624000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:59,034] [INFO] [timer.py:215:stop] epoch=0/micro_step=1105/global_step=1105, RunningAvgSamplesPerSec=7.850017142440269, CurrSamplesPerSec=7.900588639724234, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1105/439453125 | consumed samples:         1105 | consumed tokens:      2263040 | elapsed time per iteration (ms): 708.2 | learning rate: 1.206E-06 | global batch size:     1 | lm loss: 9.621945E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.412 | TFLOPs: 3.51 |
[default0]:[2023-07-30 22:24:59,812] [INFO] [logging.py:96:log_dist] [Rank 0] step=1110, skipped=0, lr=[1.2113237333333333e-06, 1.2113237333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:24:59,813] [INFO] [timer.py:215:stop] epoch=0/micro_step=1110/global_step=1110, RunningAvgSamplesPerSec=7.85006700511883, CurrSamplesPerSec=7.789429503715218, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1110/439453125 | consumed samples:         1110 | consumed tokens:      2273280 | elapsed time per iteration (ms): 156.1 | learning rate: 1.211E-06 | global batch size:     1 | lm loss: 9.674413E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.406 | TFLOPs: 15.92 |
[default0]:[2023-07-30 22:25:00,672] [INFO] [logging.py:96:log_dist] [Rank 0] step=1115, skipped=0, lr=[1.2167850666666666e-06, 1.2167850666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:00,673] [INFO] [timer.py:215:stop] epoch=0/micro_step=1115/global_step=1115, RunningAvgSamplesPerSec=7.850351466009967, CurrSamplesPerSec=7.888671342349916, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1115/439453125 | consumed samples:         1115 | consumed tokens:      2283520 | elapsed time per iteration (ms): 172.0 | learning rate: 1.217E-06 | global batch size:     1 | lm loss: 9.519359E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.814 | TFLOPs: 14.45 |
[default0]:[2023-07-30 22:25:01,415] [INFO] [logging.py:96:log_dist] [Rank 0] step=1120, skipped=0, lr=[1.2222464e-06, 1.2222464e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:01,415] [INFO] [timer.py:215:stop] epoch=0/micro_step=1120/global_step=1120, RunningAvgSamplesPerSec=7.850536892077679, CurrSamplesPerSec=7.913572094322037, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1120/439453125 | consumed samples:         1120 | consumed tokens:      2293760 | elapsed time per iteration (ms): 148.3 | learning rate: 1.222E-06 | global batch size:     1 | lm loss: 9.519894E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.742 | TFLOPs: 16.75 |
[default0]:[2023-07-30 22:25:02,154] [INFO] [logging.py:96:log_dist] [Rank 0] step=1125, skipped=0, lr=[1.2277077333333334e-06, 1.2277077333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:02,155] [INFO] [timer.py:215:stop] epoch=0/micro_step=1125/global_step=1125, RunningAvgSamplesPerSec=7.850692895902413, CurrSamplesPerSec=7.837447352390491, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1125/439453125 | consumed samples:         1125 | consumed tokens:      2304000 | elapsed time per iteration (ms): 147.9 | learning rate: 1.228E-06 | global batch size:     1 | lm loss: 9.631856E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.761 | TFLOPs: 16.80 |
[default0]:[2023-07-30 22:25:02,900] [INFO] [logging.py:96:log_dist] [Rank 0] step=1130, skipped=0, lr=[1.2331690666666667e-06, 1.2331690666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:02,901] [INFO] [timer.py:215:stop] epoch=0/micro_step=1130/global_step=1130, RunningAvgSamplesPerSec=7.850860185670443, CurrSamplesPerSec=7.821152128470921, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1130/439453125 | consumed samples:         1130 | consumed tokens:      2314240 | elapsed time per iteration (ms): 149.0 | learning rate: 1.233E-06 | global batch size:     1 | lm loss: 9.588791E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.711 | TFLOPs: 16.68 |
[default0]:[2023-07-30 22:25:03,673] [INFO] [logging.py:96:log_dist] [Rank 0] step=1135, skipped=0, lr=[1.2386304e-06, 1.2386304e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:03,674] [INFO] [timer.py:215:stop] epoch=0/micro_step=1135/global_step=1135, RunningAvgSamplesPerSec=7.851040079175432, CurrSamplesPerSec=7.876597646581609, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1135/439453125 | consumed samples:         1135 | consumed tokens:      2324480 | elapsed time per iteration (ms): 154.7 | learning rate: 1.239E-06 | global batch size:     1 | lm loss: 9.600816E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.462 | TFLOPs: 16.06 |
[default0]:[2023-07-30 22:25:04,446] [INFO] [logging.py:96:log_dist] [Rank 0] step=1140, skipped=0, lr=[1.2440917333333334e-06, 1.2440917333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:04,447] [INFO] [timer.py:215:stop] epoch=0/micro_step=1140/global_step=1140, RunningAvgSamplesPerSec=7.850910056632546, CurrSamplesPerSec=7.490243209891976, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1140/439453125 | consumed samples:         1140 | consumed tokens:      2334720 | elapsed time per iteration (ms): 155.4 | learning rate: 1.244E-06 | global batch size:     1 | lm loss: 9.586108E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.434 | TFLOPs: 15.99 |
[default0]:[2023-07-30 22:25:05,200] [INFO] [logging.py:96:log_dist] [Rank 0] step=1145, skipped=0, lr=[1.2495530666666667e-06, 1.2495530666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:05,201] [INFO] [timer.py:215:stop] epoch=0/micro_step=1145/global_step=1145, RunningAvgSamplesPerSec=7.851085858850241, CurrSamplesPerSec=7.947866984255117, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1145/439453125 | consumed samples:         1145 | consumed tokens:      2344960 | elapsed time per iteration (ms): 157.5 | learning rate: 1.250E-06 | global batch size:     1 | lm loss: 9.617787E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.349 | TFLOPs: 15.78 |
[default0]:[2023-07-30 22:25:05,988] [INFO] [logging.py:96:log_dist] [Rank 0] step=1150, skipped=0, lr=[1.2550144e-06, 1.2550144e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:05,989] [INFO] [timer.py:215:stop] epoch=0/micro_step=1150/global_step=1150, RunningAvgSamplesPerSec=7.851357920156072, CurrSamplesPerSec=7.904832265359969, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1150/439453125 | consumed samples:         1150 | consumed tokens:      2355200 | elapsed time per iteration (ms): 150.3 | learning rate: 1.255E-06 | global batch size:     1 | lm loss: 9.600581E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.654 | TFLOPs: 16.53 |
[default0]:[2023-07-30 22:25:06,755] [INFO] [logging.py:96:log_dist] [Rank 0] step=1155, skipped=0, lr=[1.2604757333333333e-06, 1.2604757333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:06,755] [INFO] [timer.py:215:stop] epoch=0/micro_step=1155/global_step=1155, RunningAvgSamplesPerSec=7.851548223413341, CurrSamplesPerSec=7.927587099798328, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1155/439453125 | consumed samples:         1155 | consumed tokens:      2365440 | elapsed time per iteration (ms): 152.9 | learning rate: 1.260E-06 | global batch size:     1 | lm loss: 9.841383E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.539 | TFLOPs: 16.25 |
[default0]:[2023-07-30 22:25:07,513] [INFO] [logging.py:96:log_dist] [Rank 0] step=1160, skipped=0, lr=[1.2659370666666666e-06, 1.2659370666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:07,514] [INFO] [timer.py:215:stop] epoch=0/micro_step=1160/global_step=1160, RunningAvgSamplesPerSec=7.85193163266563, CurrSamplesPerSec=7.931919786379418, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1160/439453125 | consumed samples:         1160 | consumed tokens:      2375680 | elapsed time per iteration (ms): 151.6 | learning rate: 1.266E-06 | global batch size:     1 | lm loss: 9.519770E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.596 | TFLOPs: 16.39 |
[default0]:[2023-07-30 22:25:08,281] [INFO] [logging.py:96:log_dist] [Rank 0] step=1165, skipped=0, lr=[1.2713984000000001e-06, 1.2713984000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:08,282] [INFO] [timer.py:215:stop] epoch=0/micro_step=1165/global_step=1165, RunningAvgSamplesPerSec=7.851984249181905, CurrSamplesPerSec=7.823763565616734, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1165/439453125 | consumed samples:         1165 | consumed tokens:      2385920 | elapsed time per iteration (ms): 154.0 | learning rate: 1.271E-06 | global batch size:     1 | lm loss: 9.573074E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.492 | TFLOPs: 16.13 |
[default0]:[2023-07-30 22:25:09,050] [INFO] [logging.py:96:log_dist] [Rank 0] step=1170, skipped=0, lr=[1.2768597333333335e-06, 1.2768597333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:09,050] [INFO] [timer.py:215:stop] epoch=0/micro_step=1170/global_step=1170, RunningAvgSamplesPerSec=7.85175048943227, CurrSamplesPerSec=7.732376657805373, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1170/439453125 | consumed samples:         1170 | consumed tokens:      2396160 | elapsed time per iteration (ms): 153.4 | learning rate: 1.277E-06 | global batch size:     1 | lm loss: 9.601042E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.521 | TFLOPs: 16.20 |
[default0]:[2023-07-30 22:25:09,786] [INFO] [logging.py:96:log_dist] [Rank 0] step=1175, skipped=0, lr=[1.2823210666666668e-06, 1.2823210666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:09,788] [INFO] [timer.py:215:stop] epoch=0/micro_step=1175/global_step=1175, RunningAvgSamplesPerSec=7.85186920214549, CurrSamplesPerSec=7.822829667152838, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1175/439453125 | consumed samples:         1175 | consumed tokens:      2406400 | elapsed time per iteration (ms): 147.4 | learning rate: 1.282E-06 | global batch size:     1 | lm loss: 9.518557E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.784 | TFLOPs: 16.86 |
[default0]:[2023-07-30 22:25:10,540] [INFO] [logging.py:96:log_dist] [Rank 0] step=1180, skipped=0, lr=[1.2877824e-06, 1.2877824e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:10,541] [INFO] [timer.py:215:stop] epoch=0/micro_step=1180/global_step=1180, RunningAvgSamplesPerSec=7.852074409170584, CurrSamplesPerSec=7.904847163300346, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1180/439453125 | consumed samples:         1180 | consumed tokens:      2416640 | elapsed time per iteration (ms): 150.7 | learning rate: 1.288E-06 | global batch size:     1 | lm loss: 9.591044E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.636 | TFLOPs: 16.49 |
[default0]:[2023-07-30 22:25:11,286] [INFO] [logging.py:96:log_dist] [Rank 0] step=1185, skipped=0, lr=[1.2932437333333334e-06, 1.2932437333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:11,286] [INFO] [timer.py:215:stop] epoch=0/micro_step=1185/global_step=1185, RunningAvgSamplesPerSec=7.852321658314026, CurrSamplesPerSec=7.965254712054313, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1185/439453125 | consumed samples:         1185 | consumed tokens:      2426880 | elapsed time per iteration (ms): 150.1 | learning rate: 1.293E-06 | global batch size:     1 | lm loss: 9.599500E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.662 | TFLOPs: 16.55 |
[default0]:[2023-07-30 22:25:12,021] [INFO] [logging.py:96:log_dist] [Rank 0] step=1190, skipped=0, lr=[1.2987050666666667e-06, 1.2987050666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:12,022] [INFO] [timer.py:215:stop] epoch=0/micro_step=1190/global_step=1190, RunningAvgSamplesPerSec=7.852461939719427, CurrSamplesPerSec=7.866404597218263, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1190/439453125 | consumed samples:         1190 | consumed tokens:      2437120 | elapsed time per iteration (ms): 146.2 | learning rate: 1.299E-06 | global batch size:     1 | lm loss: 9.577744E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.839 | TFLOPs: 16.99 |
[default0]:[2023-07-30 22:25:12,790] [INFO] [logging.py:96:log_dist] [Rank 0] step=1195, skipped=0, lr=[1.3041664e-06, 1.3041664e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:12,790] [INFO] [timer.py:215:stop] epoch=0/micro_step=1195/global_step=1195, RunningAvgSamplesPerSec=7.852576132587142, CurrSamplesPerSec=7.953654452604851, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1195/439453125 | consumed samples:         1195 | consumed tokens:      2447360 | elapsed time per iteration (ms): 153.7 | learning rate: 1.304E-06 | global batch size:     1 | lm loss: 9.558528E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.507 | TFLOPs: 16.17 |
[default0]:[2023-07-30 22:25:13,536] [INFO] [logging.py:96:log_dist] [Rank 0] step=1200, skipped=0, lr=[1.3096277333333333e-06, 1.3096277333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:13,537] [INFO] [timer.py:215:stop] epoch=0/micro_step=1200/global_step=1200, RunningAvgSamplesPerSec=7.852710017323679, CurrSamplesPerSec=7.901779372839367, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1200/439453125 | consumed samples:         1200 | consumed tokens:      2457600 | elapsed time per iteration (ms): 149.2 | learning rate: 1.310E-06 | global batch size:     1 | lm loss: 9.582971E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.701 | TFLOPs: 16.65 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1200 | lm loss value: 9.604535E+00 | lm loss PPL: 1.483189E+04 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:25:16,832] [INFO] [logging.py:96:log_dist] [Rank 0] step=1205, skipped=0, lr=[1.3150890666666667e-06, 1.3150890666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:16,832] [INFO] [timer.py:215:stop] epoch=0/micro_step=1205/global_step=1205, RunningAvgSamplesPerSec=7.851706739763249, CurrSamplesPerSec=7.90612859628322, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1205/439453125 | consumed samples:         1205 | consumed tokens:      2467840 | elapsed time per iteration (ms): 659.0 | learning rate: 1.315E-06 | global batch size:     1 | lm loss: 9.429263E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.518 | TFLOPs: 3.77 |
[default0]:[2023-07-30 22:25:17,659] [INFO] [logging.py:96:log_dist] [Rank 0] step=1210, skipped=0, lr=[1.3205504000000002e-06, 1.3205504000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:17,661] [INFO] [timer.py:215:stop] epoch=0/micro_step=1210/global_step=1210, RunningAvgSamplesPerSec=7.851835735552242, CurrSamplesPerSec=7.735242967506588, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1210/439453125 | consumed samples:         1210 | consumed tokens:      2478080 | elapsed time per iteration (ms): 165.8 | learning rate: 1.321E-06 | global batch size:     1 | lm loss: 9.520001E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.031 | TFLOPs: 14.99 |
[default0]:[2023-07-30 22:25:18,406] [INFO] [logging.py:96:log_dist] [Rank 0] step=1215, skipped=0, lr=[1.3260117333333335e-06, 1.3260117333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:18,408] [INFO] [timer.py:215:stop] epoch=0/micro_step=1215/global_step=1215, RunningAvgSamplesPerSec=7.8516027499638525, CurrSamplesPerSec=7.716344623694488, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1215/439453125 | consumed samples:         1215 | consumed tokens:      2488320 | elapsed time per iteration (ms): 149.8 | learning rate: 1.326E-06 | global batch size:     1 | lm loss: 9.619214E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.674 | TFLOPs: 16.58 |
[default0]:[2023-07-30 22:25:19,170] [INFO] [logging.py:96:log_dist] [Rank 0] step=1220, skipped=0, lr=[1.3314730666666668e-06, 1.3314730666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:19,170] [INFO] [timer.py:215:stop] epoch=0/micro_step=1220/global_step=1220, RunningAvgSamplesPerSec=7.851652284895104, CurrSamplesPerSec=7.852354974108203, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1220/439453125 | consumed samples:         1220 | consumed tokens:      2498560 | elapsed time per iteration (ms): 152.2 | learning rate: 1.331E-06 | global batch size:     1 | lm loss: 9.525919E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.568 | TFLOPs: 16.32 |
[default0]:[2023-07-30 22:25:19,949] [INFO] [logging.py:96:log_dist] [Rank 0] step=1225, skipped=0, lr=[1.3369344000000001e-06, 1.3369344000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:19,949] [INFO] [timer.py:215:stop] epoch=0/micro_step=1225/global_step=1225, RunningAvgSamplesPerSec=7.851812970385874, CurrSamplesPerSec=7.8556640401857205, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1225/439453125 | consumed samples:         1225 | consumed tokens:      2508800 | elapsed time per iteration (ms): 155.4 | learning rate: 1.337E-06 | global batch size:     1 | lm loss: 9.483328E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.433 | TFLOPs: 15.99 |
[default0]:[2023-07-30 22:25:20,729] [INFO] [logging.py:96:log_dist] [Rank 0] step=1230, skipped=0, lr=[1.3423957333333334e-06, 1.3423957333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:20,730] [INFO] [timer.py:215:stop] epoch=0/micro_step=1230/global_step=1230, RunningAvgSamplesPerSec=7.851960395707541, CurrSamplesPerSec=7.89802977834771, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1230/439453125 | consumed samples:         1230 | consumed tokens:      2519040 | elapsed time per iteration (ms): 156.1 | learning rate: 1.342E-06 | global batch size:     1 | lm loss: 9.624290E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.405 | TFLOPs: 15.91 |
[default0]:[2023-07-30 22:25:21,486] [INFO] [logging.py:96:log_dist] [Rank 0] step=1235, skipped=0, lr=[1.3478570666666668e-06, 1.3478570666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:21,487] [INFO] [timer.py:215:stop] epoch=0/micro_step=1235/global_step=1235, RunningAvgSamplesPerSec=7.852155570981071, CurrSamplesPerSec=7.859756428923457, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1235/439453125 | consumed samples:         1235 | consumed tokens:      2529280 | elapsed time per iteration (ms): 151.4 | learning rate: 1.348E-06 | global batch size:     1 | lm loss: 9.476939E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.606 | TFLOPs: 16.41 |
[default0]:[2023-07-30 22:25:22,250] [INFO] [logging.py:96:log_dist] [Rank 0] step=1240, skipped=0, lr=[1.3533184e-06, 1.3533184e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:22,250] [INFO] [timer.py:215:stop] epoch=0/micro_step=1240/global_step=1240, RunningAvgSamplesPerSec=7.852321274113997, CurrSamplesPerSec=7.936257211461138, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1240/439453125 | consumed samples:         1240 | consumed tokens:      2539520 | elapsed time per iteration (ms): 152.7 | learning rate: 1.353E-06 | global batch size:     1 | lm loss: 9.615855E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.549 | TFLOPs: 16.27 |
[default0]:[2023-07-30 22:25:23,087] [INFO] [logging.py:96:log_dist] [Rank 0] step=1245, skipped=0, lr=[1.3587797333333334e-06, 1.3587797333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:23,087] [INFO] [timer.py:215:stop] epoch=0/micro_step=1245/global_step=1245, RunningAvgSamplesPerSec=7.852539891145972, CurrSamplesPerSec=7.940524218358055, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1245/439453125 | consumed samples:         1245 | consumed tokens:      2549760 | elapsed time per iteration (ms): 167.4 | learning rate: 1.359E-06 | global batch size:     1 | lm loss: 9.621194E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.975 | TFLOPs: 14.85 |
[default0]:[2023-07-30 22:25:23,831] [INFO] [logging.py:96:log_dist] [Rank 0] step=1250, skipped=0, lr=[1.3642410666666667e-06, 1.3642410666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:23,832] [INFO] [timer.py:215:stop] epoch=0/micro_step=1250/global_step=1250, RunningAvgSamplesPerSec=7.852642886430628, CurrSamplesPerSec=7.838985379127831, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1250/439453125 | consumed samples:         1250 | consumed tokens:      2560000 | elapsed time per iteration (ms): 148.9 | learning rate: 1.364E-06 | global batch size:     1 | lm loss: 9.369075E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.714 | TFLOPs: 16.68 |
[default0]:[2023-07-30 22:25:24,598] [INFO] [logging.py:96:log_dist] [Rank 0] step=1255, skipped=0, lr=[1.3697024000000002e-06, 1.3697024000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:24,599] [INFO] [timer.py:215:stop] epoch=0/micro_step=1255/global_step=1255, RunningAvgSamplesPerSec=7.8526121227307435, CurrSamplesPerSec=7.670426012453937, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1255/439453125 | consumed samples:         1255 | consumed tokens:      2570240 | elapsed time per iteration (ms): 153.4 | learning rate: 1.370E-06 | global batch size:     1 | lm loss: 9.596246E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.519 | TFLOPs: 16.20 |
[default0]:[2023-07-30 22:25:25,350] [INFO] [logging.py:96:log_dist] [Rank 0] step=1260, skipped=0, lr=[1.3751637333333335e-06, 1.3751637333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:25,351] [INFO] [timer.py:215:stop] epoch=0/micro_step=1260/global_step=1260, RunningAvgSamplesPerSec=7.852813856447575, CurrSamplesPerSec=7.907097396917322, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1260/439453125 | consumed samples:         1260 | consumed tokens:      2580480 | elapsed time per iteration (ms): 150.9 | learning rate: 1.375E-06 | global batch size:     1 | lm loss: 9.433363E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.628 | TFLOPs: 16.47 |
[default0]:[2023-07-30 22:25:26,105] [INFO] [logging.py:96:log_dist] [Rank 0] step=1265, skipped=0, lr=[1.3806250666666669e-06, 1.3806250666666669e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:26,108] [INFO] [timer.py:215:stop] epoch=0/micro_step=1265/global_step=1265, RunningAvgSamplesPerSec=7.852854447790969, CurrSamplesPerSec=7.745427685034717, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1265/439453125 | consumed samples:         1265 | consumed tokens:      2590720 | elapsed time per iteration (ms): 151.1 | learning rate: 1.381E-06 | global batch size:     1 | lm loss: 9.443529E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.620 | TFLOPs: 16.45 |
[default0]:[2023-07-30 22:25:26,841] [INFO] [logging.py:96:log_dist] [Rank 0] step=1270, skipped=0, lr=[1.3860864000000002e-06, 1.3860864000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:26,841] [INFO] [timer.py:215:stop] epoch=0/micro_step=1270/global_step=1270, RunningAvgSamplesPerSec=7.85310144511795, CurrSamplesPerSec=7.968054104371284, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1270/439453125 | consumed samples:         1270 | consumed tokens:      2600960 | elapsed time per iteration (ms): 146.5 | learning rate: 1.386E-06 | global batch size:     1 | lm loss: 9.493402E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.828 | TFLOPs: 16.97 |
[default0]:[2023-07-30 22:25:27,597] [INFO] [logging.py:96:log_dist] [Rank 0] step=1275, skipped=0, lr=[1.3915477333333335e-06, 1.3915477333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:27,598] [INFO] [timer.py:215:stop] epoch=0/micro_step=1275/global_step=1275, RunningAvgSamplesPerSec=7.853472079371418, CurrSamplesPerSec=7.933375071639199, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1275/439453125 | consumed samples:         1275 | consumed tokens:      2611200 | elapsed time per iteration (ms): 151.2 | learning rate: 1.392E-06 | global batch size:     1 | lm loss: 9.569147E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.612 | TFLOPs: 16.43 |
[default0]:[2023-07-30 22:25:28,328] [INFO] [logging.py:96:log_dist] [Rank 0] step=1280, skipped=0, lr=[1.3970090666666668e-06, 1.3970090666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:28,329] [INFO] [timer.py:215:stop] epoch=0/micro_step=1280/global_step=1280, RunningAvgSamplesPerSec=7.853852057351405, CurrSamplesPerSec=7.912736053728753, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1280/439453125 | consumed samples:         1280 | consumed tokens:      2621440 | elapsed time per iteration (ms): 146.2 | learning rate: 1.397E-06 | global batch size:     1 | lm loss: 9.585212E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.840 | TFLOPs: 17.00 |
[default0]:[2023-07-30 22:25:29,099] [INFO] [logging.py:96:log_dist] [Rank 0] step=1285, skipped=0, lr=[1.4024704000000001e-06, 1.4024704000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:29,100] [INFO] [timer.py:215:stop] epoch=0/micro_step=1285/global_step=1285, RunningAvgSamplesPerSec=7.854262045063532, CurrSamplesPerSec=7.968099516135467, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1285/439453125 | consumed samples:         1285 | consumed tokens:      2631680 | elapsed time per iteration (ms): 154.2 | learning rate: 1.402E-06 | global batch size:     1 | lm loss: 9.369808E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.484 | TFLOPs: 16.11 |
[default0]:[2023-07-30 22:25:29,842] [INFO] [logging.py:96:log_dist] [Rank 0] step=1290, skipped=0, lr=[1.4079317333333334e-06, 1.4079317333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:29,843] [INFO] [timer.py:215:stop] epoch=0/micro_step=1290/global_step=1290, RunningAvgSamplesPerSec=7.854537114565939, CurrSamplesPerSec=7.928965849693281, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1290/439453125 | consumed samples:         1290 | consumed tokens:      2641920 | elapsed time per iteration (ms): 148.7 | learning rate: 1.408E-06 | global batch size:     1 | lm loss: 9.491286E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.725 | TFLOPs: 16.71 |
[default0]:[2023-07-30 22:25:30,588] [INFO] [logging.py:96:log_dist] [Rank 0] step=1295, skipped=0, lr=[1.4133930666666667e-06, 1.4133930666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:30,588] [INFO] [timer.py:215:stop] epoch=0/micro_step=1295/global_step=1295, RunningAvgSamplesPerSec=7.854716424584941, CurrSamplesPerSec=7.869489270764734, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1295/439453125 | consumed samples:         1295 | consumed tokens:      2652160 | elapsed time per iteration (ms): 149.1 | learning rate: 1.413E-06 | global batch size:     1 | lm loss: 9.423442E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.707 | TFLOPs: 16.67 |
[default0]:[2023-07-30 22:25:31,332] [INFO] [logging.py:96:log_dist] [Rank 0] step=1300, skipped=0, lr=[1.4188544000000003e-06, 1.4188544000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:31,334] [INFO] [timer.py:215:stop] epoch=0/micro_step=1300/global_step=1300, RunningAvgSamplesPerSec=7.854966179341502, CurrSamplesPerSec=7.802296618319745, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1300/439453125 | consumed samples:         1300 | consumed tokens:      2662400 | elapsed time per iteration (ms): 149.3 | learning rate: 1.419E-06 | global batch size:     1 | lm loss: 9.510842E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.698 | TFLOPs: 16.64 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1300 | lm loss value: 9.428749E+00 | lm loss PPL: 1.244095E+04 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:25:34,925] [INFO] [logging.py:96:log_dist] [Rank 0] step=1305, skipped=0, lr=[1.4243157333333336e-06, 1.4243157333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:34,927] [INFO] [timer.py:215:stop] epoch=0/micro_step=1305/global_step=1305, RunningAvgSamplesPerSec=7.854117329046124, CurrSamplesPerSec=7.763247371255856, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1305/439453125 | consumed samples:         1305 | consumed tokens:      2672640 | elapsed time per iteration (ms): 718.4 | learning rate: 1.424E-06 | global batch size:     1 | lm loss: 9.484054E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.392 | TFLOPs: 3.46 |
[default0]:[2023-07-30 22:25:35,680] [INFO] [logging.py:96:log_dist] [Rank 0] step=1310, skipped=0, lr=[1.429777066666667e-06, 1.429777066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:35,681] [INFO] [timer.py:215:stop] epoch=0/micro_step=1310/global_step=1310, RunningAvgSamplesPerSec=7.854252797965452, CurrSamplesPerSec=7.88017885995566, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1310/439453125 | consumed samples:         1310 | consumed tokens:      2682880 | elapsed time per iteration (ms): 150.9 | learning rate: 1.430E-06 | global batch size:     1 | lm loss: 9.437302E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.629 | TFLOPs: 16.47 |
[default0]:[2023-07-30 22:25:36,409] [INFO] [logging.py:96:log_dist] [Rank 0] step=1315, skipped=0, lr=[1.4352384000000002e-06, 1.4352384000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:36,410] [INFO] [timer.py:215:stop] epoch=0/micro_step=1315/global_step=1315, RunningAvgSamplesPerSec=7.854437380735998, CurrSamplesPerSec=7.858637222958149, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1315/439453125 | consumed samples:         1315 | consumed tokens:      2693120 | elapsed time per iteration (ms): 146.0 | learning rate: 1.435E-06 | global batch size:     1 | lm loss: 9.440078E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.849 | TFLOPs: 17.02 |
[default0]:[2023-07-30 22:25:37,190] [INFO] [logging.py:96:log_dist] [Rank 0] step=1320, skipped=0, lr=[1.4406997333333335e-06, 1.4406997333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:37,191] [INFO] [timer.py:215:stop] epoch=0/micro_step=1320/global_step=1320, RunningAvgSamplesPerSec=7.8546450684996465, CurrSamplesPerSec=7.843617751397406, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1320/439453125 | consumed samples:         1320 | consumed tokens:      2703360 | elapsed time per iteration (ms): 156.1 | learning rate: 1.441E-06 | global batch size:     1 | lm loss: 9.545397E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.408 | TFLOPs: 15.92 |
[default0]:[2023-07-30 22:25:37,941] [INFO] [logging.py:96:log_dist] [Rank 0] step=1325, skipped=0, lr=[1.4461610666666668e-06, 1.4461610666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:37,941] [INFO] [timer.py:215:stop] epoch=0/micro_step=1325/global_step=1325, RunningAvgSamplesPerSec=7.854813449305296, CurrSamplesPerSec=7.862835889725814, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1325/439453125 | consumed samples:         1325 | consumed tokens:      2713600 | elapsed time per iteration (ms): 150.0 | learning rate: 1.446E-06 | global batch size:     1 | lm loss: 9.312747E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.666 | TFLOPs: 16.56 |
[default0]:[2023-07-30 22:25:38,704] [INFO] [logging.py:96:log_dist] [Rank 0] step=1330, skipped=0, lr=[1.4516224000000002e-06, 1.4516224000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:38,705] [INFO] [timer.py:215:stop] epoch=0/micro_step=1330/global_step=1330, RunningAvgSamplesPerSec=7.854977999398302, CurrSamplesPerSec=7.7958577517067305, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1330/439453125 | consumed samples:         1330 | consumed tokens:      2723840 | elapsed time per iteration (ms): 152.7 | learning rate: 1.452E-06 | global batch size:     1 | lm loss: 9.509346E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.550 | TFLOPs: 16.27 |
[default0]:[2023-07-30 22:25:39,448] [INFO] [logging.py:96:log_dist] [Rank 0] step=1335, skipped=0, lr=[1.4570837333333335e-06, 1.4570837333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:39,449] [INFO] [timer.py:215:stop] epoch=0/micro_step=1335/global_step=1335, RunningAvgSamplesPerSec=7.85526319606957, CurrSamplesPerSec=7.865032768594654, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1335/439453125 | consumed samples:         1335 | consumed tokens:      2734080 | elapsed time per iteration (ms): 148.8 | learning rate: 1.457E-06 | global batch size:     1 | lm loss: 9.377974E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.722 | TFLOPs: 16.70 |
[default0]:[2023-07-30 22:25:40,203] [INFO] [logging.py:96:log_dist] [Rank 0] step=1340, skipped=0, lr=[1.4625450666666668e-06, 1.4625450666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:40,204] [INFO] [timer.py:215:stop] epoch=0/micro_step=1340/global_step=1340, RunningAvgSamplesPerSec=7.855463031481302, CurrSamplesPerSec=7.915767541666116, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1340/439453125 | consumed samples:         1340 | consumed tokens:      2744320 | elapsed time per iteration (ms): 151.1 | learning rate: 1.463E-06 | global batch size:     1 | lm loss: 9.369008E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.620 | TFLOPs: 16.45 |
[default0]:[2023-07-30 22:25:40,980] [INFO] [logging.py:96:log_dist] [Rank 0] step=1345, skipped=0, lr=[1.4680064000000003e-06, 1.4680064000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:40,981] [INFO] [timer.py:215:stop] epoch=0/micro_step=1345/global_step=1345, RunningAvgSamplesPerSec=7.855611925495955, CurrSamplesPerSec=7.765230801701043, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1345/439453125 | consumed samples:         1345 | consumed tokens:      2754560 | elapsed time per iteration (ms): 155.4 | learning rate: 1.468E-06 | global batch size:     1 | lm loss: 9.361609E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.434 | TFLOPs: 15.99 |
[default0]:[2023-07-30 22:25:41,751] [INFO] [logging.py:96:log_dist] [Rank 0] step=1350, skipped=0, lr=[1.4734677333333336e-06, 1.4734677333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:41,751] [INFO] [timer.py:215:stop] epoch=0/micro_step=1350/global_step=1350, RunningAvgSamplesPerSec=7.855935970151588, CurrSamplesPerSec=7.892382352000332, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1350/439453125 | consumed samples:         1350 | consumed tokens:      2764800 | elapsed time per iteration (ms): 154.0 | learning rate: 1.473E-06 | global batch size:     1 | lm loss: 9.537492E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.494 | TFLOPs: 16.14 |
[default0]:[2023-07-30 22:25:42,499] [INFO] [logging.py:96:log_dist] [Rank 0] step=1355, skipped=0, lr=[1.478929066666667e-06, 1.478929066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:42,499] [INFO] [timer.py:215:stop] epoch=0/micro_step=1355/global_step=1355, RunningAvgSamplesPerSec=7.856158533465213, CurrSamplesPerSec=7.898371855662726, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1355/439453125 | consumed samples:         1355 | consumed tokens:      2775040 | elapsed time per iteration (ms): 150.0 | learning rate: 1.479E-06 | global batch size:     1 | lm loss: 9.436815E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.665 | TFLOPs: 16.56 |
[default0]:[2023-07-30 22:25:43,242] [INFO] [logging.py:96:log_dist] [Rank 0] step=1360, skipped=0, lr=[1.4843903999999998e-06, 1.4843903999999998e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:43,243] [INFO] [timer.py:215:stop] epoch=0/micro_step=1360/global_step=1360, RunningAvgSamplesPerSec=7.856298360691482, CurrSamplesPerSec=7.857768585441888, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1360/439453125 | consumed samples:         1360 | consumed tokens:      2785280 | elapsed time per iteration (ms): 148.5 | learning rate: 1.484E-06 | global batch size:     1 | lm loss: 9.376174E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.736 | TFLOPs: 16.74 |
[default0]:[2023-07-30 22:25:44,003] [INFO] [logging.py:96:log_dist] [Rank 0] step=1365, skipped=0, lr=[1.4898517333333334e-06, 1.4898517333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:44,005] [INFO] [timer.py:215:stop] epoch=0/micro_step=1365/global_step=1365, RunningAvgSamplesPerSec=7.856407205924309, CurrSamplesPerSec=7.787867478447516, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1365/439453125 | consumed samples:         1365 | consumed tokens:      2795520 | elapsed time per iteration (ms): 152.4 | learning rate: 1.490E-06 | global batch size:     1 | lm loss: 9.299203E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.563 | TFLOPs: 16.31 |
[default0]:[2023-07-30 22:25:44,795] [INFO] [logging.py:96:log_dist] [Rank 0] step=1370, skipped=0, lr=[1.4953130666666667e-06, 1.4953130666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:44,797] [INFO] [timer.py:215:stop] epoch=0/micro_step=1370/global_step=1370, RunningAvgSamplesPerSec=7.856203989965804, CurrSamplesPerSec=7.756571525792337, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1370/439453125 | consumed samples:         1370 | consumed tokens:      2805760 | elapsed time per iteration (ms): 159.8 | learning rate: 1.495E-06 | global batch size:     1 | lm loss: 9.282669E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.259 | TFLOPs: 15.55 |
[default0]:[2023-07-30 22:25:45,544] [INFO] [logging.py:96:log_dist] [Rank 0] step=1375, skipped=0, lr=[1.5007744e-06, 1.5007744e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:45,545] [INFO] [timer.py:215:stop] epoch=0/micro_step=1375/global_step=1375, RunningAvgSamplesPerSec=7.856246104979348, CurrSamplesPerSec=7.888715853777808, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1375/439453125 | consumed samples:         1375 | consumed tokens:      2816000 | elapsed time per iteration (ms): 148.0 | learning rate: 1.501E-06 | global batch size:     1 | lm loss: 9.415743E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.756 | TFLOPs: 16.79 |
[default0]:[2023-07-30 22:25:46,277] [INFO] [logging.py:96:log_dist] [Rank 0] step=1380, skipped=0, lr=[1.5062357333333333e-06, 1.5062357333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:46,277] [INFO] [timer.py:215:stop] epoch=0/micro_step=1380/global_step=1380, RunningAvgSamplesPerSec=7.856321233058663, CurrSamplesPerSec=7.867437472098319, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1380/439453125 | consumed samples:         1380 | consumed tokens:      2826240 | elapsed time per iteration (ms): 146.3 | learning rate: 1.506E-06 | global batch size:     1 | lm loss: 9.449396E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.837 | TFLOPs: 16.99 |
[default0]:[2023-07-30 22:25:47,019] [INFO] [logging.py:96:log_dist] [Rank 0] step=1385, skipped=0, lr=[1.5116970666666666e-06, 1.5116970666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:47,019] [INFO] [timer.py:215:stop] epoch=0/micro_step=1385/global_step=1385, RunningAvgSamplesPerSec=7.8564957142139855, CurrSamplesPerSec=7.869356388088376, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1385/439453125 | consumed samples:         1385 | consumed tokens:      2836480 | elapsed time per iteration (ms): 148.6 | learning rate: 1.512E-06 | global batch size:     1 | lm loss: 9.364145E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.729 | TFLOPs: 16.72 |
[default0]:[2023-07-30 22:25:47,757] [INFO] [logging.py:96:log_dist] [Rank 0] step=1390, skipped=0, lr=[1.5171584e-06, 1.5171584e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:47,757] [INFO] [timer.py:215:stop] epoch=0/micro_step=1390/global_step=1390, RunningAvgSamplesPerSec=7.856733020238074, CurrSamplesPerSec=7.880889570321601, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1390/439453125 | consumed samples:         1390 | consumed tokens:      2846720 | elapsed time per iteration (ms): 147.5 | learning rate: 1.517E-06 | global batch size:     1 | lm loss: 9.559016E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.781 | TFLOPs: 16.85 |
[default0]:[2023-07-30 22:25:48,511] [INFO] [logging.py:96:log_dist] [Rank 0] step=1395, skipped=0, lr=[1.5226197333333332e-06, 1.5226197333333332e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:48,511] [INFO] [timer.py:215:stop] epoch=0/micro_step=1395/global_step=1395, RunningAvgSamplesPerSec=7.856740529653001, CurrSamplesPerSec=7.817886639540281, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1395/439453125 | consumed samples:         1395 | consumed tokens:      2856960 | elapsed time per iteration (ms): 150.9 | learning rate: 1.523E-06 | global batch size:     1 | lm loss: 9.313913E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.625 | TFLOPs: 16.46 |
[default0]:[2023-07-30 22:25:49,262] [INFO] [logging.py:96:log_dist] [Rank 0] step=1400, skipped=0, lr=[1.5280810666666666e-06, 1.5280810666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:49,263] [INFO] [timer.py:215:stop] epoch=0/micro_step=1400/global_step=1400, RunningAvgSamplesPerSec=7.856978372388477, CurrSamplesPerSec=7.930839919827553, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1400/439453125 | consumed samples:         1400 | consumed tokens:      2867200 | elapsed time per iteration (ms): 150.2 | learning rate: 1.528E-06 | global batch size:     1 | lm loss: 9.328457E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.658 | TFLOPs: 16.54 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1400 | lm loss value: 9.310205E+00 | lm loss PPL: 1.105021E+04 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:25:52,683] [INFO] [logging.py:96:log_dist] [Rank 0] step=1405, skipped=0, lr=[1.5335423999999999e-06, 1.5335423999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:52,683] [INFO] [timer.py:215:stop] epoch=0/micro_step=1405/global_step=1405, RunningAvgSamplesPerSec=7.8563405681301415, CurrSamplesPerSec=7.981427494919202, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1405/439453125 | consumed samples:         1405 | consumed tokens:      2877440 | elapsed time per iteration (ms): 684.1 | learning rate: 1.534E-06 | global batch size:     1 | lm loss: 9.405412E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.462 | TFLOPs: 3.63 |
[default0]:[2023-07-30 22:25:53,443] [INFO] [logging.py:96:log_dist] [Rank 0] step=1410, skipped=0, lr=[1.5390037333333334e-06, 1.5390037333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:53,444] [INFO] [timer.py:215:stop] epoch=0/micro_step=1410/global_step=1410, RunningAvgSamplesPerSec=7.856572379670095, CurrSamplesPerSec=7.811320192493929, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1410/439453125 | consumed samples:         1410 | consumed tokens:      2887680 | elapsed time per iteration (ms): 152.3 | learning rate: 1.539E-06 | global batch size:     1 | lm loss: 9.413969E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.566 | TFLOPs: 16.32 |
[default0]:[2023-07-30 22:25:54,247] [INFO] [logging.py:96:log_dist] [Rank 0] step=1415, skipped=0, lr=[1.5444650666666667e-06, 1.5444650666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:54,249] [INFO] [timer.py:215:stop] epoch=0/micro_step=1415/global_step=1415, RunningAvgSamplesPerSec=7.856758276758371, CurrSamplesPerSec=7.788547171703292, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1415/439453125 | consumed samples:         1415 | consumed tokens:      2897920 | elapsed time per iteration (ms): 161.3 | learning rate: 1.544E-06 | global batch size:     1 | lm loss: 9.370911E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.201 | TFLOPs: 15.41 |
[default0]:[2023-07-30 22:25:55,011] [INFO] [logging.py:96:log_dist] [Rank 0] step=1420, skipped=0, lr=[1.5499264e-06, 1.5499264e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:55,013] [INFO] [timer.py:215:stop] epoch=0/micro_step=1420/global_step=1420, RunningAvgSamplesPerSec=7.856754708451277, CurrSamplesPerSec=7.843441738522271, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1420/439453125 | consumed samples:         1420 | consumed tokens:      2908160 | elapsed time per iteration (ms): 152.3 | learning rate: 1.550E-06 | global batch size:     1 | lm loss: 9.277417E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.565 | TFLOPs: 16.31 |
[default0]:[2023-07-30 22:25:55,770] [INFO] [logging.py:96:log_dist] [Rank 0] step=1425, skipped=0, lr=[1.5553877333333333e-06, 1.5553877333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:55,771] [INFO] [timer.py:215:stop] epoch=0/micro_step=1425/global_step=1425, RunningAvgSamplesPerSec=7.856854218215897, CurrSamplesPerSec=7.972719081816143, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1425/439453125 | consumed samples:         1425 | consumed tokens:      2918400 | elapsed time per iteration (ms): 151.7 | learning rate: 1.555E-06 | global batch size:     1 | lm loss: 9.435241E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.590 | TFLOPs: 16.37 |
[default0]:[2023-07-30 22:25:56,533] [INFO] [logging.py:96:log_dist] [Rank 0] step=1430, skipped=0, lr=[1.5608490666666667e-06, 1.5608490666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:56,534] [INFO] [timer.py:215:stop] epoch=0/micro_step=1430/global_step=1430, RunningAvgSamplesPerSec=7.857052515285586, CurrSamplesPerSec=7.9672216470856405, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1430/439453125 | consumed samples:         1430 | consumed tokens:      2928640 | elapsed time per iteration (ms): 152.7 | learning rate: 1.561E-06 | global batch size:     1 | lm loss: 9.384865E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.547 | TFLOPs: 16.27 |
[default0]:[2023-07-30 22:25:57,280] [INFO] [logging.py:96:log_dist] [Rank 0] step=1435, skipped=0, lr=[1.5663104e-06, 1.5663104e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:57,281] [INFO] [timer.py:215:stop] epoch=0/micro_step=1435/global_step=1435, RunningAvgSamplesPerSec=7.857172998515069, CurrSamplesPerSec=7.900335655167997, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1435/439453125 | consumed samples:         1435 | consumed tokens:      2938880 | elapsed time per iteration (ms): 149.3 | learning rate: 1.566E-06 | global batch size:     1 | lm loss: 9.346560E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.699 | TFLOPs: 16.64 |
[default0]:[2023-07-30 22:25:58,038] [INFO] [logging.py:96:log_dist] [Rank 0] step=1440, skipped=0, lr=[1.5717717333333333e-06, 1.5717717333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:58,039] [INFO] [timer.py:215:stop] epoch=0/micro_step=1440/global_step=1440, RunningAvgSamplesPerSec=7.857335423709153, CurrSamplesPerSec=7.909125194225286, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1440/439453125 | consumed samples:         1440 | consumed tokens:      2949120 | elapsed time per iteration (ms): 152.0 | learning rate: 1.572E-06 | global batch size:     1 | lm loss: 9.288557E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.579 | TFLOPs: 16.35 |
[default0]:[2023-07-30 22:25:58,784] [INFO] [logging.py:96:log_dist] [Rank 0] step=1445, skipped=0, lr=[1.5772330666666666e-06, 1.5772330666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:58,785] [INFO] [timer.py:215:stop] epoch=0/micro_step=1445/global_step=1445, RunningAvgSamplesPerSec=7.857416683614052, CurrSamplesPerSec=7.910572126401554, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1445/439453125 | consumed samples:         1445 | consumed tokens:      2959360 | elapsed time per iteration (ms): 148.6 | learning rate: 1.577E-06 | global batch size:     1 | lm loss: 9.164298E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.728 | TFLOPs: 16.72 |
[default0]:[2023-07-30 22:25:59,558] [INFO] [logging.py:96:log_dist] [Rank 0] step=1450, skipped=0, lr=[1.5826944e-06, 1.5826944e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:25:59,558] [INFO] [timer.py:215:stop] epoch=0/micro_step=1450/global_step=1450, RunningAvgSamplesPerSec=7.857589639386738, CurrSamplesPerSec=7.930330085045397, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1450/439453125 | consumed samples:         1450 | consumed tokens:      2969600 | elapsed time per iteration (ms): 154.7 | learning rate: 1.583E-06 | global batch size:     1 | lm loss: 9.330409E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.466 | TFLOPs: 16.07 |
[default0]:[2023-07-30 22:26:00,316] [INFO] [logging.py:96:log_dist] [Rank 0] step=1455, skipped=0, lr=[1.5881557333333334e-06, 1.5881557333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:00,316] [INFO] [timer.py:215:stop] epoch=0/micro_step=1455/global_step=1455, RunningAvgSamplesPerSec=7.857777440366582, CurrSamplesPerSec=7.873197029650932, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1455/439453125 | consumed samples:         1455 | consumed tokens:      2979840 | elapsed time per iteration (ms): 151.5 | learning rate: 1.588E-06 | global batch size:     1 | lm loss: 9.379578E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.600 | TFLOPs: 16.40 |
[default0]:[2023-07-30 22:26:01,074] [INFO] [logging.py:96:log_dist] [Rank 0] step=1460, skipped=0, lr=[1.5936170666666668e-06, 1.5936170666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:01,075] [INFO] [timer.py:215:stop] epoch=0/micro_step=1460/global_step=1460, RunningAvgSamplesPerSec=7.857954622224042, CurrSamplesPerSec=7.898223122754423, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1460/439453125 | consumed samples:         1460 | consumed tokens:      2990080 | elapsed time per iteration (ms): 151.7 | learning rate: 1.594E-06 | global batch size:     1 | lm loss: 9.316434E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.593 | TFLOPs: 16.38 |
[default0]:[2023-07-30 22:26:01,828] [INFO] [logging.py:96:log_dist] [Rank 0] step=1465, skipped=0, lr=[1.5990784e-06, 1.5990784e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:01,828] [INFO] [timer.py:215:stop] epoch=0/micro_step=1465/global_step=1465, RunningAvgSamplesPerSec=7.858117065981481, CurrSamplesPerSec=7.878521034164081, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1465/439453125 | consumed samples:         1465 | consumed tokens:      3000320 | elapsed time per iteration (ms): 150.7 | learning rate: 1.599E-06 | global batch size:     1 | lm loss: 9.202296E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.634 | TFLOPs: 16.48 |
[default0]:[2023-07-30 22:26:02,554] [INFO] [logging.py:96:log_dist] [Rank 0] step=1470, skipped=0, lr=[1.6045397333333334e-06, 1.6045397333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:02,554] [INFO] [timer.py:215:stop] epoch=0/micro_step=1470/global_step=1470, RunningAvgSamplesPerSec=7.858265772975253, CurrSamplesPerSec=7.783791808867386, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1470/439453125 | consumed samples:         1470 | consumed tokens:      3010560 | elapsed time per iteration (ms): 145.2 | learning rate: 1.605E-06 | global batch size:     1 | lm loss: 9.195959E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.887 | TFLOPs: 17.11 |
[default0]:[2023-07-30 22:26:03,336] [INFO] [logging.py:96:log_dist] [Rank 0] step=1475, skipped=0, lr=[1.6100010666666667e-06, 1.6100010666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:03,337] [INFO] [timer.py:215:stop] epoch=0/micro_step=1475/global_step=1475, RunningAvgSamplesPerSec=7.858101427018503, CurrSamplesPerSec=7.758264523957501, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1475/439453125 | consumed samples:         1475 | consumed tokens:      3020800 | elapsed time per iteration (ms): 156.9 | learning rate: 1.610E-06 | global batch size:     1 | lm loss: 9.313547E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.372 | TFLOPs: 15.83 |
[default0]:[2023-07-30 22:26:04,118] [INFO] [logging.py:96:log_dist] [Rank 0] step=1480, skipped=0, lr=[1.6154624e-06, 1.6154624e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:04,119] [INFO] [timer.py:215:stop] epoch=0/micro_step=1480/global_step=1480, RunningAvgSamplesPerSec=7.858240533753102, CurrSamplesPerSec=7.98574322574749, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1480/439453125 | consumed samples:         1480 | consumed tokens:      3031040 | elapsed time per iteration (ms): 156.0 | learning rate: 1.615E-06 | global batch size:     1 | lm loss: 9.486185E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.410 | TFLOPs: 15.93 |
[default0]:[2023-07-30 22:26:04,897] [INFO] [logging.py:96:log_dist] [Rank 0] step=1485, skipped=0, lr=[1.6209237333333333e-06, 1.6209237333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:04,898] [INFO] [timer.py:215:stop] epoch=0/micro_step=1485/global_step=1485, RunningAvgSamplesPerSec=7.858142704349774, CurrSamplesPerSec=7.846288248818185, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1485/439453125 | consumed samples:         1485 | consumed tokens:      3041280 | elapsed time per iteration (ms): 155.9 | learning rate: 1.621E-06 | global batch size:     1 | lm loss: 9.235775E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.413 | TFLOPs: 15.93 |
[default0]:[2023-07-30 22:26:05,649] [INFO] [logging.py:96:log_dist] [Rank 0] step=1490, skipped=0, lr=[1.6263850666666666e-06, 1.6263850666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:05,650] [INFO] [timer.py:215:stop] epoch=0/micro_step=1490/global_step=1490, RunningAvgSamplesPerSec=7.858276068772212, CurrSamplesPerSec=7.777960334164727, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1490/439453125 | consumed samples:         1490 | consumed tokens:      3051520 | elapsed time per iteration (ms): 150.3 | learning rate: 1.626E-06 | global batch size:     1 | lm loss: 9.223341E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.653 | TFLOPs: 16.53 |
[default0]:[2023-07-30 22:26:06,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=1495, skipped=0, lr=[1.6318464e-06, 1.6318464e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:06,398] [INFO] [timer.py:215:stop] epoch=0/micro_step=1495/global_step=1495, RunningAvgSamplesPerSec=7.858262022778312, CurrSamplesPerSec=7.935566508055133, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1495/439453125 | consumed samples:         1495 | consumed tokens:      3061760 | elapsed time per iteration (ms): 149.6 | learning rate: 1.632E-06 | global batch size:     1 | lm loss: 9.214912E+00 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.686 | TFLOPs: 16.61 |
[default0]:[2023-07-30 22:26:07,148] [INFO] [logging.py:96:log_dist] [Rank 0] step=1500, skipped=0, lr=[1.6373077333333335e-06, 1.6373077333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:07,148] [INFO] [timer.py:215:stop] epoch=0/micro_step=1500/global_step=1500, RunningAvgSamplesPerSec=7.858417888162785, CurrSamplesPerSec=7.84970972776919, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1500/439453125 | consumed samples:         1500 | consumed tokens:      3072000 | elapsed time per iteration (ms): 150.0 | learning rate: 1.637E-06 | global batch size:     1 | lm loss: 9.333271E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.668 | TFLOPs: 16.57 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1500 | lm loss value: 9.233184E+00 | lm loss PPL: 1.023106E+04 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:26:10,565] [INFO] [logging.py:96:log_dist] [Rank 0] step=1505, skipped=0, lr=[1.6427690666666668e-06, 1.6427690666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:10,565] [INFO] [timer.py:215:stop] epoch=0/micro_step=1505/global_step=1505, RunningAvgSamplesPerSec=7.8577322580340745, CurrSamplesPerSec=7.903953386261234, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1505/439453125 | consumed samples:         1505 | consumed tokens:      3082240 | elapsed time per iteration (ms): 683.5 | learning rate: 1.643E-06 | global batch size:     1 | lm loss: 9.152213E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.463 | TFLOPs: 3.64 |
[default0]:[2023-07-30 22:26:11,374] [INFO] [logging.py:96:log_dist] [Rank 0] step=1510, skipped=0, lr=[1.6482304000000001e-06, 1.6482304000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:11,374] [INFO] [timer.py:215:stop] epoch=0/micro_step=1510/global_step=1510, RunningAvgSamplesPerSec=7.857759741112028, CurrSamplesPerSec=7.897063198285893, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1510/439453125 | consumed samples:         1510 | consumed tokens:      3092480 | elapsed time per iteration (ms): 161.7 | learning rate: 1.648E-06 | global batch size:     1 | lm loss: 9.324871E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.184 | TFLOPs: 15.37 |
[default0]:[2023-07-30 22:26:12,113] [INFO] [logging.py:96:log_dist] [Rank 0] step=1515, skipped=0, lr=[1.6536917333333334e-06, 1.6536917333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:12,113] [INFO] [timer.py:215:stop] epoch=0/micro_step=1515/global_step=1515, RunningAvgSamplesPerSec=7.857775036241056, CurrSamplesPerSec=7.66287265645268, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1515/439453125 | consumed samples:         1515 | consumed tokens:      3102720 | elapsed time per iteration (ms): 147.9 | learning rate: 1.654E-06 | global batch size:     1 | lm loss: 9.184940E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.761 | TFLOPs: 16.80 |
[default0]:[2023-07-30 22:26:12,847] [INFO] [logging.py:96:log_dist] [Rank 0] step=1520, skipped=0, lr=[1.6591530666666667e-06, 1.6591530666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:12,848] [INFO] [timer.py:215:stop] epoch=0/micro_step=1520/global_step=1520, RunningAvgSamplesPerSec=7.858026716441954, CurrSamplesPerSec=7.920521047155221, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1520/439453125 | consumed samples:         1520 | consumed tokens:      3112960 | elapsed time per iteration (ms): 147.3 | learning rate: 1.659E-06 | global batch size:     1 | lm loss: 9.265594E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.789 | TFLOPs: 16.87 |
[default0]:[2023-07-30 22:26:13,629] [INFO] [logging.py:96:log_dist] [Rank 0] step=1525, skipped=0, lr=[1.6646144e-06, 1.6646144e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:13,629] [INFO] [timer.py:215:stop] epoch=0/micro_step=1525/global_step=1525, RunningAvgSamplesPerSec=7.858232050136876, CurrSamplesPerSec=7.952478191046621, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1525/439453125 | consumed samples:         1525 | consumed tokens:      3123200 | elapsed time per iteration (ms): 155.9 | learning rate: 1.665E-06 | global batch size:     1 | lm loss: 9.450186E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.415 | TFLOPs: 15.94 |
[default0]:[2023-07-30 22:26:14,397] [INFO] [logging.py:96:log_dist] [Rank 0] step=1530, skipped=0, lr=[1.6700757333333334e-06, 1.6700757333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:14,399] [INFO] [timer.py:215:stop] epoch=0/micro_step=1530/global_step=1530, RunningAvgSamplesPerSec=7.858447632931935, CurrSamplesPerSec=7.95843848311089, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1530/439453125 | consumed samples:         1530 | consumed tokens:      3133440 | elapsed time per iteration (ms): 153.8 | learning rate: 1.670E-06 | global batch size:     1 | lm loss: 9.432709E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.501 | TFLOPs: 16.15 |
[default0]:[2023-07-30 22:26:15,143] [INFO] [logging.py:96:log_dist] [Rank 0] step=1535, skipped=0, lr=[1.6755370666666667e-06, 1.6755370666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:15,144] [INFO] [timer.py:215:stop] epoch=0/micro_step=1535/global_step=1535, RunningAvgSamplesPerSec=7.85838501623027, CurrSamplesPerSec=7.905085537983689, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1535/439453125 | consumed samples:         1535 | consumed tokens:      3143680 | elapsed time per iteration (ms): 149.9 | learning rate: 1.676E-06 | global batch size:     1 | lm loss: 9.231630E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.669 | TFLOPs: 16.57 |
[default0]:[2023-07-30 22:26:15,957] [INFO] [logging.py:96:log_dist] [Rank 0] step=1540, skipped=0, lr=[1.6809984e-06, 1.6809984e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:15,957] [INFO] [timer.py:215:stop] epoch=0/micro_step=1540/global_step=1540, RunningAvgSamplesPerSec=7.858476455685121, CurrSamplesPerSec=7.911750946926826, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1540/439453125 | consumed samples:         1540 | consumed tokens:      3153920 | elapsed time per iteration (ms): 161.9 | learning rate: 1.681E-06 | global batch size:     1 | lm loss: 9.273776E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.178 | TFLOPs: 15.35 |
[default0]:[2023-07-30 22:26:16,688] [INFO] [logging.py:96:log_dist] [Rank 0] step=1545, skipped=0, lr=[1.6864597333333335e-06, 1.6864597333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:16,688] [INFO] [timer.py:215:stop] epoch=0/micro_step=1545/global_step=1545, RunningAvgSamplesPerSec=7.858745590700032, CurrSamplesPerSec=7.982171777436489, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1545/439453125 | consumed samples:         1545 | consumed tokens:      3164160 | elapsed time per iteration (ms): 146.0 | learning rate: 1.686E-06 | global batch size:     1 | lm loss: 9.350567E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.849 | TFLOPs: 17.02 |
[default0]:[2023-07-30 22:26:17,427] [INFO] [logging.py:96:log_dist] [Rank 0] step=1550, skipped=0, lr=[1.6919210666666668e-06, 1.6919210666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:17,427] [INFO] [timer.py:215:stop] epoch=0/micro_step=1550/global_step=1550, RunningAvgSamplesPerSec=7.858977237672896, CurrSamplesPerSec=7.9453376144877295, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1550/439453125 | consumed samples:         1550 | consumed tokens:      3174400 | elapsed time per iteration (ms): 149.2 | learning rate: 1.692E-06 | global batch size:     1 | lm loss: 9.154230E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.703 | TFLOPs: 16.66 |
[default0]:[2023-07-30 22:26:18,191] [INFO] [logging.py:96:log_dist] [Rank 0] step=1555, skipped=0, lr=[1.6973824000000002e-06, 1.6973824000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:18,193] [INFO] [timer.py:215:stop] epoch=0/micro_step=1555/global_step=1555, RunningAvgSamplesPerSec=7.859064013726638, CurrSamplesPerSec=7.818454988424157, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1555/439453125 | consumed samples:         1555 | consumed tokens:      3184640 | elapsed time per iteration (ms): 151.9 | learning rate: 1.697E-06 | global batch size:     1 | lm loss: 9.076945E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.585 | TFLOPs: 16.36 |
[default0]:[2023-07-30 22:26:18,942] [INFO] [logging.py:96:log_dist] [Rank 0] step=1560, skipped=0, lr=[1.7028437333333335e-06, 1.7028437333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:18,942] [INFO] [timer.py:215:stop] epoch=0/micro_step=1560/global_step=1560, RunningAvgSamplesPerSec=7.8592792944676875, CurrSamplesPerSec=7.95483106217936, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1560/439453125 | consumed samples:         1560 | consumed tokens:      3194880 | elapsed time per iteration (ms): 150.2 | learning rate: 1.703E-06 | global batch size:     1 | lm loss: 9.151138E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.656 | TFLOPs: 16.54 |
[default0]:[2023-07-30 22:26:19,704] [INFO] [logging.py:96:log_dist] [Rank 0] step=1565, skipped=0, lr=[1.7083050666666668e-06, 1.7083050666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:19,704] [INFO] [timer.py:215:stop] epoch=0/micro_step=1565/global_step=1565, RunningAvgSamplesPerSec=7.8595072869060765, CurrSamplesPerSec=7.947249549044277, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1565/439453125 | consumed samples:         1565 | consumed tokens:      3205120 | elapsed time per iteration (ms): 152.2 | learning rate: 1.708E-06 | global batch size:     1 | lm loss: 9.253953E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.569 | TFLOPs: 16.32 |
[default0]:[2023-07-30 22:26:20,464] [INFO] [logging.py:96:log_dist] [Rank 0] step=1570, skipped=0, lr=[1.7137664e-06, 1.7137664e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:20,465] [INFO] [timer.py:215:stop] epoch=0/micro_step=1570/global_step=1570, RunningAvgSamplesPerSec=7.859605436606054, CurrSamplesPerSec=7.905696438736236, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1570/439453125 | consumed samples:         1570 | consumed tokens:      3215360 | elapsed time per iteration (ms): 151.8 | learning rate: 1.714E-06 | global batch size:     1 | lm loss: 9.116786E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.587 | TFLOPs: 16.37 |
[default0]:[2023-07-30 22:26:21,219] [INFO] [logging.py:96:log_dist] [Rank 0] step=1575, skipped=0, lr=[1.7192277333333334e-06, 1.7192277333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:21,220] [INFO] [timer.py:215:stop] epoch=0/micro_step=1575/global_step=1575, RunningAvgSamplesPerSec=7.859729425221129, CurrSamplesPerSec=7.880889570321601, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1575/439453125 | consumed samples:         1575 | consumed tokens:      3225600 | elapsed time per iteration (ms): 150.8 | learning rate: 1.719E-06 | global batch size:     1 | lm loss: 9.112581E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.629 | TFLOPs: 16.47 |
[default0]:[2023-07-30 22:26:21,982] [INFO] [logging.py:96:log_dist] [Rank 0] step=1580, skipped=0, lr=[1.7246890666666667e-06, 1.7246890666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:21,982] [INFO] [timer.py:215:stop] epoch=0/micro_step=1580/global_step=1580, RunningAvgSamplesPerSec=7.859876368090016, CurrSamplesPerSec=7.872502482267507, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1580/439453125 | consumed samples:         1580 | consumed tokens:      3235840 | elapsed time per iteration (ms): 153.1 | learning rate: 1.725E-06 | global batch size:     1 | lm loss: 9.027763E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.533 | TFLOPs: 16.23 |
[default0]:[2023-07-30 22:26:22,765] [INFO] [logging.py:96:log_dist] [Rank 0] step=1585, skipped=0, lr=[1.7301504e-06, 1.7301504e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:22,766] [INFO] [timer.py:215:stop] epoch=0/micro_step=1585/global_step=1585, RunningAvgSamplesPerSec=7.860023458197209, CurrSamplesPerSec=7.854987293222241, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1585/439453125 | consumed samples:         1585 | consumed tokens:      3246080 | elapsed time per iteration (ms): 156.2 | learning rate: 1.730E-06 | global batch size:     1 | lm loss: 9.171111E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.403 | TFLOPs: 15.91 |
[default0]:[2023-07-30 22:26:23,550] [INFO] [logging.py:96:log_dist] [Rank 0] step=1590, skipped=0, lr=[1.7356117333333336e-06, 1.7356117333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:23,551] [INFO] [timer.py:215:stop] epoch=0/micro_step=1590/global_step=1590, RunningAvgSamplesPerSec=7.860176417421438, CurrSamplesPerSec=7.835090216560843, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1590/439453125 | consumed samples:         1590 | consumed tokens:      3256320 | elapsed time per iteration (ms): 157.1 | learning rate: 1.736E-06 | global batch size:     1 | lm loss: 9.257008E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.365 | TFLOPs: 15.82 |
[default0]:[2023-07-30 22:26:24,286] [INFO] [logging.py:96:log_dist] [Rank 0] step=1595, skipped=0, lr=[1.7410730666666669e-06, 1.7410730666666669e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:24,287] [INFO] [timer.py:215:stop] epoch=0/micro_step=1595/global_step=1595, RunningAvgSamplesPerSec=7.860213390066908, CurrSamplesPerSec=7.876360986858661, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1595/439453125 | consumed samples:         1595 | consumed tokens:      3266560 | elapsed time per iteration (ms): 147.4 | learning rate: 1.741E-06 | global batch size:     1 | lm loss: 9.079195E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.785 | TFLOPs: 16.86 |
[default0]:[2023-07-30 22:26:25,039] [INFO] [logging.py:96:log_dist] [Rank 0] step=1600, skipped=0, lr=[1.7465344000000002e-06, 1.7465344000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:25,041] [INFO] [timer.py:215:stop] epoch=0/micro_step=1600/global_step=1600, RunningAvgSamplesPerSec=7.860073740263309, CurrSamplesPerSec=7.853634149035968, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1600/439453125 | consumed samples:         1600 | consumed tokens:      3276800 | elapsed time per iteration (ms): 150.6 | learning rate: 1.747E-06 | global batch size:     1 | lm loss: 9.115938E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.639 | TFLOPs: 16.50 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1600 | lm loss value: 9.137603E+00 | lm loss PPL: 9.298448E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:26:28,254] [INFO] [logging.py:96:log_dist] [Rank 0] step=1605, skipped=0, lr=[1.7519957333333335e-06, 1.7519957333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:28,255] [INFO] [timer.py:215:stop] epoch=0/micro_step=1605/global_step=1605, RunningAvgSamplesPerSec=7.859370576088449, CurrSamplesPerSec=7.842356500326273, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1605/439453125 | consumed samples:         1605 | consumed tokens:      3287040 | elapsed time per iteration (ms): 642.7 | learning rate: 1.752E-06 | global batch size:     1 | lm loss: 9.111037E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.556 | TFLOPs: 3.87 |
[default0]:[2023-07-30 22:26:28,998] [INFO] [logging.py:96:log_dist] [Rank 0] step=1610, skipped=0, lr=[1.7574570666666668e-06, 1.7574570666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:29,000] [INFO] [timer.py:215:stop] epoch=0/micro_step=1610/global_step=1610, RunningAvgSamplesPerSec=7.8593192423668174, CurrSamplesPerSec=7.746743796035669, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1610/439453125 | consumed samples:         1610 | consumed tokens:      3297280 | elapsed time per iteration (ms): 149.2 | learning rate: 1.757E-06 | global batch size:     1 | lm loss: 8.956516E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.703 | TFLOPs: 16.65 |
[default0]:[2023-07-30 22:26:29,772] [INFO] [logging.py:96:log_dist] [Rank 0] step=1615, skipped=0, lr=[1.7629184000000001e-06, 1.7629184000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:29,773] [INFO] [timer.py:215:stop] epoch=0/micro_step=1615/global_step=1615, RunningAvgSamplesPerSec=7.859512261311635, CurrSamplesPerSec=7.826289126276998, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1615/439453125 | consumed samples:         1615 | consumed tokens:      3307520 | elapsed time per iteration (ms): 155.0 | learning rate: 1.763E-06 | global batch size:     1 | lm loss: 9.148135E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.453 | TFLOPs: 16.04 |
[default0]:[2023-07-30 22:26:30,521] [INFO] [logging.py:96:log_dist] [Rank 0] step=1620, skipped=0, lr=[1.7683797333333335e-06, 1.7683797333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:30,522] [INFO] [timer.py:215:stop] epoch=0/micro_step=1620/global_step=1620, RunningAvgSamplesPerSec=7.859657417931643, CurrSamplesPerSec=7.8762574527017515, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1620/439453125 | consumed samples:         1620 | consumed tokens:      3317760 | elapsed time per iteration (ms): 149.3 | learning rate: 1.768E-06 | global batch size:     1 | lm loss: 9.208329E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.697 | TFLOPs: 16.64 |
[default0]:[2023-07-30 22:26:31,282] [INFO] [logging.py:96:log_dist] [Rank 0] step=1625, skipped=0, lr=[1.7738410666666668e-06, 1.7738410666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:31,282] [INFO] [timer.py:215:stop] epoch=0/micro_step=1625/global_step=1625, RunningAvgSamplesPerSec=7.859762109787529, CurrSamplesPerSec=7.969386397923626, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1625/439453125 | consumed samples:         1625 | consumed tokens:      3328000 | elapsed time per iteration (ms): 152.1 | learning rate: 1.774E-06 | global batch size:     1 | lm loss: 9.181581E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.575 | TFLOPs: 16.34 |
[default0]:[2023-07-30 22:26:32,029] [INFO] [logging.py:96:log_dist] [Rank 0] step=1630, skipped=0, lr=[1.7793024e-06, 1.7793024e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:32,030] [INFO] [timer.py:215:stop] epoch=0/micro_step=1630/global_step=1630, RunningAvgSamplesPerSec=7.859935219507914, CurrSamplesPerSec=7.911377864460041, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1630/439453125 | consumed samples:         1630 | consumed tokens:      3338240 | elapsed time per iteration (ms): 149.3 | learning rate: 1.779E-06 | global batch size:     1 | lm loss: 9.096899E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.697 | TFLOPs: 16.64 |
[default0]:[2023-07-30 22:26:32,782] [INFO] [logging.py:96:log_dist] [Rank 0] step=1635, skipped=0, lr=[1.7847637333333336e-06, 1.7847637333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:32,782] [INFO] [timer.py:215:stop] epoch=0/micro_step=1635/global_step=1635, RunningAvgSamplesPerSec=7.860095731014322, CurrSamplesPerSec=7.935821754003572, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1635/439453125 | consumed samples:         1635 | consumed tokens:      3348480 | elapsed time per iteration (ms): 150.6 | learning rate: 1.785E-06 | global batch size:     1 | lm loss: 9.041892E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.639 | TFLOPs: 16.50 |
[default0]:[2023-07-30 22:26:33,533] [INFO] [logging.py:96:log_dist] [Rank 0] step=1640, skipped=0, lr=[1.790225066666667e-06, 1.790225066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:33,534] [INFO] [timer.py:215:stop] epoch=0/micro_step=1640/global_step=1640, RunningAvgSamplesPerSec=7.860274055294508, CurrSamplesPerSec=7.899413142887277, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1640/439453125 | consumed samples:         1640 | consumed tokens:      3358720 | elapsed time per iteration (ms): 150.4 | learning rate: 1.790E-06 | global batch size:     1 | lm loss: 8.998415E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.650 | TFLOPs: 16.52 |
[default0]:[2023-07-30 22:26:34,313] [INFO] [logging.py:96:log_dist] [Rank 0] step=1645, skipped=0, lr=[1.7956864000000002e-06, 1.7956864000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:34,313] [INFO] [timer.py:215:stop] epoch=0/micro_step=1645/global_step=1645, RunningAvgSamplesPerSec=7.860444380508632, CurrSamplesPerSec=7.8657850024567075, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1645/439453125 | consumed samples:         1645 | consumed tokens:      3368960 | elapsed time per iteration (ms): 155.9 | learning rate: 1.796E-06 | global batch size:     1 | lm loss: 9.294838E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.414 | TFLOPs: 15.94 |
[default0]:[2023-07-30 22:26:35,050] [INFO] [logging.py:96:log_dist] [Rank 0] step=1650, skipped=0, lr=[1.8011477333333336e-06, 1.8011477333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:35,065] [INFO] [timer.py:215:stop] epoch=0/micro_step=1650/global_step=1650, RunningAvgSamplesPerSec=7.859798862937742, CurrSamplesPerSec=7.1015512564805, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1650/439453125 | consumed samples:         1650 | consumed tokens:      3379200 | elapsed time per iteration (ms): 150.5 | learning rate: 1.801E-06 | global batch size:     1 | lm loss: 9.119310E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.646 | TFLOPs: 16.51 |
[default0]:[2023-07-30 22:26:35,968] [INFO] [logging.py:96:log_dist] [Rank 0] step=1655, skipped=0, lr=[1.8066090666666669e-06, 1.8066090666666669e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:35,969] [INFO] [timer.py:215:stop] epoch=0/micro_step=1655/global_step=1655, RunningAvgSamplesPerSec=7.860045975181753, CurrSamplesPerSec=7.738011471499283, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1655/439453125 | consumed samples:         1655 | consumed tokens:      3389440 | elapsed time per iteration (ms): 180.6 | learning rate: 1.807E-06 | global batch size:     1 | lm loss: 9.054954E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.537 | TFLOPs: 13.76 |
[default0]:[2023-07-30 22:26:36,749] [INFO] [logging.py:96:log_dist] [Rank 0] step=1660, skipped=0, lr=[1.8120704000000002e-06, 1.8120704000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:36,749] [INFO] [timer.py:215:stop] epoch=0/micro_step=1660/global_step=1660, RunningAvgSamplesPerSec=7.860325915596569, CurrSamplesPerSec=7.962880554057851, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1660/439453125 | consumed samples:         1660 | consumed tokens:      3399680 | elapsed time per iteration (ms): 156.1 | learning rate: 1.812E-06 | global batch size:     1 | lm loss: 9.019099E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.405 | TFLOPs: 15.91 |
[default0]:[2023-07-30 22:26:37,482] [INFO] [logging.py:96:log_dist] [Rank 0] step=1665, skipped=0, lr=[1.8175317333333335e-06, 1.8175317333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:37,482] [INFO] [timer.py:215:stop] epoch=0/micro_step=1665/global_step=1665, RunningAvgSamplesPerSec=7.860594580977246, CurrSamplesPerSec=7.941456358290116, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1665/439453125 | consumed samples:         1665 | consumed tokens:      3409920 | elapsed time per iteration (ms): 146.4 | learning rate: 1.818E-06 | global batch size:     1 | lm loss: 9.019157E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.830 | TFLOPs: 16.97 |
[default0]:[2023-07-30 22:26:38,268] [INFO] [logging.py:96:log_dist] [Rank 0] step=1670, skipped=0, lr=[1.8229930666666668e-06, 1.8229930666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:38,269] [INFO] [timer.py:215:stop] epoch=0/micro_step=1670/global_step=1670, RunningAvgSamplesPerSec=7.8608603731415325, CurrSamplesPerSec=7.911974813297341, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1670/439453125 | consumed samples:         1670 | consumed tokens:      3420160 | elapsed time per iteration (ms): 158.0 | learning rate: 1.823E-06 | global batch size:     1 | lm loss: 8.960911E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.328 | TFLOPs: 15.72 |
[default0]:[2023-07-30 22:26:39,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=1675, skipped=0, lr=[1.8284544000000003e-06, 1.8284544000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:39,053] [INFO] [timer.py:215:stop] epoch=0/micro_step=1675/global_step=1675, RunningAvgSamplesPerSec=7.861083520140669, CurrSamplesPerSec=7.916813420989548, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1675/439453125 | consumed samples:         1675 | consumed tokens:      3430400 | elapsed time per iteration (ms): 156.2 | learning rate: 1.828E-06 | global batch size:     1 | lm loss: 9.113214E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.401 | TFLOPs: 15.90 |
[default0]:[2023-07-30 22:26:39,804] [INFO] [logging.py:96:log_dist] [Rank 0] step=1680, skipped=0, lr=[1.8339157333333336e-06, 1.8339157333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:39,805] [INFO] [timer.py:215:stop] epoch=0/micro_step=1680/global_step=1680, RunningAvgSamplesPerSec=7.86134763874689, CurrSamplesPerSec=7.930360073512173, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1680/439453125 | consumed samples:         1680 | consumed tokens:      3440640 | elapsed time per iteration (ms): 150.3 | learning rate: 1.834E-06 | global batch size:     1 | lm loss: 9.162521E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.655 | TFLOPs: 16.54 |
[default0]:[2023-07-30 22:26:40,569] [INFO] [logging.py:96:log_dist] [Rank 0] step=1685, skipped=0, lr=[1.839377066666667e-06, 1.839377066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:40,575] [INFO] [timer.py:215:stop] epoch=0/micro_step=1685/global_step=1685, RunningAvgSamplesPerSec=7.861298961313486, CurrSamplesPerSec=7.567053050326096, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1685/439453125 | consumed samples:         1685 | consumed tokens:      3450880 | elapsed time per iteration (ms): 154.2 | learning rate: 1.839E-06 | global batch size:     1 | lm loss: 9.039668E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.486 | TFLOPs: 16.12 |
[default0]:[2023-07-30 22:26:41,331] [INFO] [logging.py:96:log_dist] [Rank 0] step=1690, skipped=0, lr=[1.8448383999999999e-06, 1.8448383999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:41,331] [INFO] [timer.py:215:stop] epoch=0/micro_step=1690/global_step=1690, RunningAvgSamplesPerSec=7.861302578953021, CurrSamplesPerSec=7.853604738035543, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1690/439453125 | consumed samples:         1690 | consumed tokens:      3461120 | elapsed time per iteration (ms): 151.1 | learning rate: 1.845E-06 | global batch size:     1 | lm loss: 9.123856E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.619 | TFLOPs: 16.45 |
[default0]:[2023-07-30 22:26:42,083] [INFO] [logging.py:96:log_dist] [Rank 0] step=1695, skipped=0, lr=[1.8502997333333334e-06, 1.8502997333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:42,083] [INFO] [timer.py:215:stop] epoch=0/micro_step=1695/global_step=1695, RunningAvgSamplesPerSec=7.861429543204426, CurrSamplesPerSec=7.678668980718674, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1695/439453125 | consumed samples:         1695 | consumed tokens:      3471360 | elapsed time per iteration (ms): 151.1 | learning rate: 1.850E-06 | global batch size:     1 | lm loss: 9.166754E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.618 | TFLOPs: 16.45 |
[default0]:[2023-07-30 22:26:42,840] [INFO] [logging.py:96:log_dist] [Rank 0] step=1700, skipped=0, lr=[1.8557610666666667e-06, 1.8557610666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:42,842] [INFO] [timer.py:215:stop] epoch=0/micro_step=1700/global_step=1700, RunningAvgSamplesPerSec=7.861434672912055, CurrSamplesPerSec=7.8401576142525755, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1700/439453125 | consumed samples:         1700 | consumed tokens:      3481600 | elapsed time per iteration (ms): 151.1 | learning rate: 1.856E-06 | global batch size:     1 | lm loss: 8.975258E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.617 | TFLOPs: 16.44 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1700 | lm loss value: 9.030015E+00 | lm loss PPL: 8.349985E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:26:46,299] [INFO] [logging.py:96:log_dist] [Rank 0] step=1705, skipped=0, lr=[1.8612224e-06, 1.8612224e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:46,300] [INFO] [timer.py:215:stop] epoch=0/micro_step=1705/global_step=1705, RunningAvgSamplesPerSec=7.860752410442834, CurrSamplesPerSec=7.890407660326956, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1705/439453125 | consumed samples:         1705 | consumed tokens:      3491840 | elapsed time per iteration (ms): 691.5 | learning rate: 1.861E-06 | global batch size:     1 | lm loss: 8.940322E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.446 | TFLOPs: 3.59 |
[default0]:[2023-07-30 22:26:47,124] [INFO] [logging.py:96:log_dist] [Rank 0] step=1710, skipped=0, lr=[1.8666837333333333e-06, 1.8666837333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:47,125] [INFO] [timer.py:215:stop] epoch=0/micro_step=1710/global_step=1710, RunningAvgSamplesPerSec=7.860890470794855, CurrSamplesPerSec=7.886713336680336, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1710/439453125 | consumed samples:         1710 | consumed tokens:      3502080 | elapsed time per iteration (ms): 165.1 | learning rate: 1.867E-06 | global batch size:     1 | lm loss: 9.162346E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.058 | TFLOPs: 15.05 |
[default0]:[2023-07-30 22:26:47,869] [INFO] [logging.py:96:log_dist] [Rank 0] step=1715, skipped=0, lr=[1.8721450666666666e-06, 1.8721450666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:47,871] [INFO] [timer.py:215:stop] epoch=0/micro_step=1715/global_step=1715, RunningAvgSamplesPerSec=7.861052311304668, CurrSamplesPerSec=7.852384375748862, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1715/439453125 | consumed samples:         1715 | consumed tokens:      3512320 | elapsed time per iteration (ms): 149.3 | learning rate: 1.872E-06 | global batch size:     1 | lm loss: 8.892979E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.696 | TFLOPs: 16.64 |
[default0]:[2023-07-30 22:26:48,599] [INFO] [logging.py:96:log_dist] [Rank 0] step=1720, skipped=0, lr=[1.8776064e-06, 1.8776064e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:48,601] [INFO] [timer.py:215:stop] epoch=0/micro_step=1720/global_step=1720, RunningAvgSamplesPerSec=7.86106712314076, CurrSamplesPerSec=7.806551518761167, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1720/439453125 | consumed samples:         1720 | consumed tokens:      3522560 | elapsed time per iteration (ms): 145.8 | learning rate: 1.878E-06 | global batch size:     1 | lm loss: 9.011733E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.860 | TFLOPs: 17.05 |
[default0]:[2023-07-30 22:26:49,326] [INFO] [logging.py:96:log_dist] [Rank 0] step=1725, skipped=0, lr=[1.8830677333333333e-06, 1.8830677333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:49,326] [INFO] [timer.py:215:stop] epoch=0/micro_step=1725/global_step=1725, RunningAvgSamplesPerSec=7.861176193935532, CurrSamplesPerSec=7.903640612044923, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1725/439453125 | consumed samples:         1725 | consumed tokens:      3532800 | elapsed time per iteration (ms): 145.2 | learning rate: 1.883E-06 | global batch size:     1 | lm loss: 9.038589E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.887 | TFLOPs: 17.11 |
[default0]:[2023-07-30 22:26:50,075] [INFO] [logging.py:96:log_dist] [Rank 0] step=1730, skipped=0, lr=[1.8885290666666666e-06, 1.8885290666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:50,076] [INFO] [timer.py:215:stop] epoch=0/micro_step=1730/global_step=1730, RunningAvgSamplesPerSec=7.861402264775104, CurrSamplesPerSec=7.863086478308715, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1730/439453125 | consumed samples:         1730 | consumed tokens:      3543040 | elapsed time per iteration (ms): 149.9 | learning rate: 1.889E-06 | global batch size:     1 | lm loss: 8.958589E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.669 | TFLOPs: 16.57 |
[default0]:[2023-07-30 22:26:50,839] [INFO] [logging.py:96:log_dist] [Rank 0] step=1735, skipped=0, lr=[1.8939904e-06, 1.8939904e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:50,840] [INFO] [timer.py:215:stop] epoch=0/micro_step=1735/global_step=1735, RunningAvgSamplesPerSec=7.861557065862661, CurrSamplesPerSec=7.823953290989302, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1735/439453125 | consumed samples:         1735 | consumed tokens:      3553280 | elapsed time per iteration (ms): 152.9 | learning rate: 1.894E-06 | global batch size:     1 | lm loss: 8.999400E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.540 | TFLOPs: 16.25 |
[default0]:[2023-07-30 22:26:51,578] [INFO] [logging.py:96:log_dist] [Rank 0] step=1740, skipped=0, lr=[1.8994517333333334e-06, 1.8994517333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:51,578] [INFO] [timer.py:215:stop] epoch=0/micro_step=1740/global_step=1740, RunningAvgSamplesPerSec=7.86170363136427, CurrSamplesPerSec=7.878254662935066, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1740/439453125 | consumed samples:         1740 | consumed tokens:      3563520 | elapsed time per iteration (ms): 147.4 | learning rate: 1.899E-06 | global batch size:     1 | lm loss: 9.006310E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.783 | TFLOPs: 16.85 |
[default0]:[2023-07-30 22:26:52,359] [INFO] [logging.py:96:log_dist] [Rank 0] step=1745, skipped=0, lr=[1.9049130666666667e-06, 1.9049130666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:52,360] [INFO] [timer.py:215:stop] epoch=0/micro_step=1745/global_step=1745, RunningAvgSamplesPerSec=7.861876779708596, CurrSamplesPerSec=7.832281075226651, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1745/439453125 | consumed samples:         1745 | consumed tokens:      3573760 | elapsed time per iteration (ms): 156.4 | learning rate: 1.905E-06 | global batch size:     1 | lm loss: 9.058690E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.394 | TFLOPs: 15.89 |
[default0]:[2023-07-30 22:26:53,152] [INFO] [logging.py:96:log_dist] [Rank 0] step=1750, skipped=0, lr=[1.9103744e-06, 1.9103744e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:53,153] [INFO] [timer.py:215:stop] epoch=0/micro_step=1750/global_step=1750, RunningAvgSamplesPerSec=7.86199715483732, CurrSamplesPerSec=7.8926645314987445, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1750/439453125 | consumed samples:         1750 | consumed tokens:      3584000 | elapsed time per iteration (ms): 158.6 | learning rate: 1.910E-06 | global batch size:     1 | lm loss: 8.930757E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.304 | TFLOPs: 15.67 |
[default0]:[2023-07-30 22:26:53,909] [INFO] [logging.py:96:log_dist] [Rank 0] step=1755, skipped=0, lr=[1.915835733333333e-06, 1.915835733333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:53,909] [INFO] [timer.py:215:stop] epoch=0/micro_step=1755/global_step=1755, RunningAvgSamplesPerSec=7.862106044056453, CurrSamplesPerSec=7.929400555055619, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1755/439453125 | consumed samples:         1755 | consumed tokens:      3594240 | elapsed time per iteration (ms): 151.4 | learning rate: 1.916E-06 | global batch size:     1 | lm loss: 8.949020E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.605 | TFLOPs: 16.41 |
[default0]:[2023-07-30 22:26:54,674] [INFO] [logging.py:96:log_dist] [Rank 0] step=1760, skipped=0, lr=[1.9212970666666665e-06, 1.9212970666666665e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:54,675] [INFO] [timer.py:215:stop] epoch=0/micro_step=1760/global_step=1760, RunningAvgSamplesPerSec=7.861984765800591, CurrSamplesPerSec=7.381362091691906, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1760/439453125 | consumed samples:         1760 | consumed tokens:      3604480 | elapsed time per iteration (ms): 153.4 | learning rate: 1.921E-06 | global batch size:     1 | lm loss: 8.953526E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.517 | TFLOPs: 16.19 |
[default0]:[2023-07-30 22:26:55,436] [INFO] [logging.py:96:log_dist] [Rank 0] step=1765, skipped=0, lr=[1.9267584e-06, 1.9267584e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:55,437] [INFO] [timer.py:215:stop] epoch=0/micro_step=1765/global_step=1765, RunningAvgSamplesPerSec=7.862124720188117, CurrSamplesPerSec=7.858239687042151, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1765/439453125 | consumed samples:         1765 | consumed tokens:      3614720 | elapsed time per iteration (ms): 151.9 | learning rate: 1.927E-06 | global batch size:     1 | lm loss: 9.110026E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.582 | TFLOPs: 16.35 |
[default0]:[2023-07-30 22:26:56,177] [INFO] [logging.py:96:log_dist] [Rank 0] step=1770, skipped=0, lr=[1.9322197333333335e-06, 1.9322197333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:56,178] [INFO] [timer.py:215:stop] epoch=0/micro_step=1770/global_step=1770, RunningAvgSamplesPerSec=7.862153972133757, CurrSamplesPerSec=7.9122136180568, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1770/439453125 | consumed samples:         1770 | consumed tokens:      3624960 | elapsed time per iteration (ms): 148.1 | learning rate: 1.932E-06 | global batch size:     1 | lm loss: 8.812612E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.753 | TFLOPs: 16.78 |
[default0]:[2023-07-30 22:26:56,929] [INFO] [logging.py:96:log_dist] [Rank 0] step=1775, skipped=0, lr=[1.937681066666667e-06, 1.937681066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:56,930] [INFO] [timer.py:215:stop] epoch=0/micro_step=1775/global_step=1775, RunningAvgSamplesPerSec=7.862220115415113, CurrSamplesPerSec=7.841887301139178, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1775/439453125 | consumed samples:         1775 | consumed tokens:      3635200 | elapsed time per iteration (ms): 150.4 | learning rate: 1.938E-06 | global batch size:     1 | lm loss: 8.869114E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.650 | TFLOPs: 16.52 |
[default0]:[2023-07-30 22:26:57,673] [INFO] [logging.py:96:log_dist] [Rank 0] step=1780, skipped=0, lr=[1.9431424e-06, 1.9431424e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:57,674] [INFO] [timer.py:215:stop] epoch=0/micro_step=1780/global_step=1780, RunningAvgSamplesPerSec=7.862399781313251, CurrSamplesPerSec=7.9255348497961124, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1780/439453125 | consumed samples:         1780 | consumed tokens:      3645440 | elapsed time per iteration (ms): 148.8 | learning rate: 1.943E-06 | global batch size:     1 | lm loss: 9.129639E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.722 | TFLOPs: 16.70 |
[default0]:[2023-07-30 22:26:58,449] [INFO] [logging.py:96:log_dist] [Rank 0] step=1785, skipped=0, lr=[1.9486037333333335e-06, 1.9486037333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:58,449] [INFO] [timer.py:215:stop] epoch=0/micro_step=1785/global_step=1785, RunningAvgSamplesPerSec=7.862526096651159, CurrSamplesPerSec=7.911527093224383, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1785/439453125 | consumed samples:         1785 | consumed tokens:      3655680 | elapsed time per iteration (ms): 155.2 | learning rate: 1.949E-06 | global batch size:     1 | lm loss: 9.006752E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.444 | TFLOPs: 16.01 |
[default0]:[2023-07-30 22:26:59,174] [INFO] [logging.py:96:log_dist] [Rank 0] step=1790, skipped=0, lr=[1.9540650666666668e-06, 1.9540650666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:59,174] [INFO] [timer.py:215:stop] epoch=0/micro_step=1790/global_step=1790, RunningAvgSamplesPerSec=7.862670702579029, CurrSamplesPerSec=7.93950212291518, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1790/439453125 | consumed samples:         1790 | consumed tokens:      3665920 | elapsed time per iteration (ms): 145.0 | learning rate: 1.954E-06 | global batch size:     1 | lm loss: 8.845825E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.898 | TFLOPs: 17.14 |
[default0]:[2023-07-30 22:26:59,924] [INFO] [logging.py:96:log_dist] [Rank 0] step=1795, skipped=0, lr=[1.9595264e-06, 1.9595264e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:26:59,924] [INFO] [timer.py:215:stop] epoch=0/micro_step=1795/global_step=1795, RunningAvgSamplesPerSec=7.862806360441219, CurrSamplesPerSec=7.860109928619483, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1795/439453125 | consumed samples:         1795 | consumed tokens:      3676160 | elapsed time per iteration (ms): 149.9 | learning rate: 1.960E-06 | global batch size:     1 | lm loss: 9.125856E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.673 | TFLOPs: 16.58 |
[default0]:[2023-07-30 22:27:00,667] [INFO] [logging.py:96:log_dist] [Rank 0] step=1800, skipped=0, lr=[1.9649877333333334e-06, 1.9649877333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:00,669] [INFO] [timer.py:215:stop] epoch=0/micro_step=1800/global_step=1800, RunningAvgSamplesPerSec=7.862837914636609, CurrSamplesPerSec=7.728729108699257, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1800/439453125 | consumed samples:         1800 | consumed tokens:      3686400 | elapsed time per iteration (ms): 149.0 | learning rate: 1.965E-06 | global batch size:     1 | lm loss: 8.832724E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.710 | TFLOPs: 16.67 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1800 | lm loss value: 8.908112E+00 | lm loss PPL: 7.391689E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:27:03,953] [INFO] [logging.py:96:log_dist] [Rank 0] step=1805, skipped=0, lr=[1.9704490666666667e-06, 1.9704490666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:03,954] [INFO] [timer.py:215:stop] epoch=0/micro_step=1805/global_step=1805, RunningAvgSamplesPerSec=7.86176200044595, CurrSamplesPerSec=7.732234110802221, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1805/439453125 | consumed samples:         1805 | consumed tokens:      3696640 | elapsed time per iteration (ms): 657.2 | learning rate: 1.970E-06 | global batch size:     1 | lm loss: 9.072333E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.522 | TFLOPs: 3.78 |
[default0]:[2023-07-30 22:27:04,705] [INFO] [logging.py:96:log_dist] [Rank 0] step=1810, skipped=0, lr=[1.9759104e-06, 1.9759104e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:04,706] [INFO] [timer.py:215:stop] epoch=0/micro_step=1810/global_step=1810, RunningAvgSamplesPerSec=7.861611801376817, CurrSamplesPerSec=7.469793518099668, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1810/439453125 | consumed samples:         1810 | consumed tokens:      3706880 | elapsed time per iteration (ms): 150.8 | learning rate: 1.976E-06 | global batch size:     1 | lm loss: 9.197379E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.632 | TFLOPs: 16.48 |
[default0]:[2023-07-30 22:27:05,483] [INFO] [logging.py:96:log_dist] [Rank 0] step=1815, skipped=0, lr=[1.9813717333333334e-06, 1.9813717333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:05,484] [INFO] [timer.py:215:stop] epoch=0/micro_step=1815/global_step=1815, RunningAvgSamplesPerSec=7.861716603170802, CurrSamplesPerSec=7.868263967313616, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1815/439453125 | consumed samples:         1815 | consumed tokens:      3717120 | elapsed time per iteration (ms): 158.0 | learning rate: 1.981E-06 | global batch size:     1 | lm loss: 8.974052E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.329 | TFLOPs: 15.73 |
[default0]:[2023-07-30 22:27:06,241] [INFO] [logging.py:96:log_dist] [Rank 0] step=1820, skipped=0, lr=[1.9868330666666667e-06, 1.9868330666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:06,242] [INFO] [timer.py:215:stop] epoch=0/micro_step=1820/global_step=1820, RunningAvgSamplesPerSec=7.8615887870828, CurrSamplesPerSec=7.893377495906807, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1820/439453125 | consumed samples:         1820 | consumed tokens:      3727360 | elapsed time per iteration (ms): 148.4 | learning rate: 1.987E-06 | global batch size:     1 | lm loss: 8.949782E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.739 | TFLOPs: 16.74 |
[default0]:[2023-07-30 22:27:07,020] [INFO] [logging.py:96:log_dist] [Rank 0] step=1825, skipped=0, lr=[1.9922944e-06, 1.9922944e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:07,020] [INFO] [timer.py:215:stop] epoch=0/micro_step=1825/global_step=1825, RunningAvgSamplesPerSec=7.861693270493851, CurrSamplesPerSec=7.9098560525625965, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1825/439453125 | consumed samples:         1825 | consumed tokens:      3737600 | elapsed time per iteration (ms): 155.8 | learning rate: 1.992E-06 | global batch size:     1 | lm loss: 8.819199E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.420 | TFLOPs: 15.95 |
[default0]:[2023-07-30 22:27:07,769] [INFO] [logging.py:96:log_dist] [Rank 0] step=1830, skipped=0, lr=[1.9977557333333333e-06, 1.9977557333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:07,770] [INFO] [timer.py:215:stop] epoch=0/micro_step=1830/global_step=1830, RunningAvgSamplesPerSec=7.861767970876885, CurrSamplesPerSec=7.878387846298046, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1830/439453125 | consumed samples:         1830 | consumed tokens:      3747840 | elapsed time per iteration (ms): 150.1 | learning rate: 1.998E-06 | global batch size:     1 | lm loss: 9.000143E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.664 | TFLOPs: 16.56 |
[default0]:[2023-07-30 22:27:08,527] [INFO] [logging.py:96:log_dist] [Rank 0] step=1835, skipped=0, lr=[2.0032170666666666e-06, 2.0032170666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:08,528] [INFO] [timer.py:215:stop] epoch=0/micro_step=1835/global_step=1835, RunningAvgSamplesPerSec=7.861843543409778, CurrSamplesPerSec=7.919952717872606, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1835/439453125 | consumed samples:         1835 | consumed tokens:      3758080 | elapsed time per iteration (ms): 151.6 | learning rate: 2.003E-06 | global batch size:     1 | lm loss: 9.003885E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.596 | TFLOPs: 16.39 |
[default0]:[2023-07-30 22:27:09,326] [INFO] [logging.py:96:log_dist] [Rank 0] step=1840, skipped=0, lr=[2.0086784e-06, 2.0086784e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:09,327] [INFO] [timer.py:215:stop] epoch=0/micro_step=1840/global_step=1840, RunningAvgSamplesPerSec=7.861921656744053, CurrSamplesPerSec=7.844307211227356, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1840/439453125 | consumed samples:         1840 | consumed tokens:      3768320 | elapsed time per iteration (ms): 159.6 | learning rate: 2.009E-06 | global batch size:     1 | lm loss: 8.766272E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.267 | TFLOPs: 15.57 |
[default0]:[2023-07-30 22:27:10,088] [INFO] [logging.py:96:log_dist] [Rank 0] step=1845, skipped=0, lr=[2.0141397333333332e-06, 2.0141397333333332e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:10,088] [INFO] [timer.py:215:stop] epoch=0/micro_step=1845/global_step=1845, RunningAvgSamplesPerSec=7.86206183816516, CurrSamplesPerSec=7.873995171567063, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1845/439453125 | consumed samples:         1845 | consumed tokens:      3778560 | elapsed time per iteration (ms): 152.3 | learning rate: 2.014E-06 | global batch size:     1 | lm loss: 8.867525E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.566 | TFLOPs: 16.31 |
[default0]:[2023-07-30 22:27:10,926] [INFO] [logging.py:96:log_dist] [Rank 0] step=1850, skipped=0, lr=[2.0196010666666666e-06, 2.0196010666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:10,927] [INFO] [timer.py:215:stop] epoch=0/micro_step=1850/global_step=1850, RunningAvgSamplesPerSec=7.862201856131639, CurrSamplesPerSec=7.921179214549437, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1850/439453125 | consumed samples:         1850 | consumed tokens:      3788800 | elapsed time per iteration (ms): 167.7 | learning rate: 2.020E-06 | global batch size:     1 | lm loss: 8.756361E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.962 | TFLOPs: 14.82 |
[default0]:[2023-07-30 22:27:11,679] [INFO] [logging.py:96:log_dist] [Rank 0] step=1855, skipped=0, lr=[2.0250624000000003e-06, 2.0250624000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:11,679] [INFO] [timer.py:215:stop] epoch=0/micro_step=1855/global_step=1855, RunningAvgSamplesPerSec=7.862185274028927, CurrSamplesPerSec=7.899204863478336, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1855/439453125 | consumed samples:         1855 | consumed tokens:      3799040 | elapsed time per iteration (ms): 150.5 | learning rate: 2.025E-06 | global batch size:     1 | lm loss: 8.923556E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.642 | TFLOPs: 16.50 |
[default0]:[2023-07-30 22:27:12,426] [INFO] [logging.py:96:log_dist] [Rank 0] step=1860, skipped=0, lr=[2.0305237333333336e-06, 2.0305237333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:12,427] [INFO] [timer.py:215:stop] epoch=0/micro_step=1860/global_step=1860, RunningAvgSamplesPerSec=7.862087535278632, CurrSamplesPerSec=7.8378720803987045, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1860/439453125 | consumed samples:         1860 | consumed tokens:      3809280 | elapsed time per iteration (ms): 149.4 | learning rate: 2.031E-06 | global batch size:     1 | lm loss: 8.843506E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.692 | TFLOPs: 16.63 |
[default0]:[2023-07-30 22:27:13,190] [INFO] [logging.py:96:log_dist] [Rank 0] step=1865, skipped=0, lr=[2.035985066666667e-06, 2.035985066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:13,191] [INFO] [timer.py:215:stop] epoch=0/micro_step=1865/global_step=1865, RunningAvgSamplesPerSec=7.862095365676653, CurrSamplesPerSec=7.767574855178749, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1865/439453125 | consumed samples:         1865 | consumed tokens:      3819520 | elapsed time per iteration (ms): 153.2 | learning rate: 2.036E-06 | global batch size:     1 | lm loss: 9.110693E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.528 | TFLOPs: 16.22 |
[default0]:[2023-07-30 22:27:13,944] [INFO] [logging.py:96:log_dist] [Rank 0] step=1870, skipped=0, lr=[2.0414464000000002e-06, 2.0414464000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:13,945] [INFO] [timer.py:215:stop] epoch=0/micro_step=1870/global_step=1870, RunningAvgSamplesPerSec=7.862148336684058, CurrSamplesPerSec=7.8931249729481525, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1870/439453125 | consumed samples:         1870 | consumed tokens:      3829760 | elapsed time per iteration (ms): 150.6 | learning rate: 2.041E-06 | global batch size:     1 | lm loss: 8.833565E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.640 | TFLOPs: 16.50 |
[default0]:[2023-07-30 22:27:14,694] [INFO] [logging.py:96:log_dist] [Rank 0] step=1875, skipped=0, lr=[2.0469077333333335e-06, 2.0469077333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:14,694] [INFO] [timer.py:215:stop] epoch=0/micro_step=1875/global_step=1875, RunningAvgSamplesPerSec=7.862129305084431, CurrSamplesPerSec=7.825062638873601, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1875/439453125 | consumed samples:         1875 | consumed tokens:      3840000 | elapsed time per iteration (ms): 150.2 | learning rate: 2.047E-06 | global batch size:     1 | lm loss: 8.608015E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.657 | TFLOPs: 16.54 |
[default0]:[2023-07-30 22:27:15,491] [INFO] [logging.py:96:log_dist] [Rank 0] step=1880, skipped=0, lr=[2.052369066666667e-06, 2.052369066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:15,491] [INFO] [timer.py:215:stop] epoch=0/micro_step=1880/global_step=1880, RunningAvgSamplesPerSec=7.8622475253677635, CurrSamplesPerSec=7.8306579590983265, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1880/439453125 | consumed samples:         1880 | consumed tokens:      3850240 | elapsed time per iteration (ms): 158.9 | learning rate: 2.052E-06 | global batch size:     1 | lm loss: 8.734108E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.295 | TFLOPs: 15.64 |
[default0]:[2023-07-30 22:27:16,229] [INFO] [logging.py:96:log_dist] [Rank 0] step=1885, skipped=0, lr=[2.0578304e-06, 2.0578304e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:16,230] [INFO] [timer.py:215:stop] epoch=0/micro_step=1885/global_step=1885, RunningAvgSamplesPerSec=7.862339339244329, CurrSamplesPerSec=7.83178383303862, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1885/439453125 | consumed samples:         1885 | consumed tokens:      3860480 | elapsed time per iteration (ms): 147.8 | learning rate: 2.058E-06 | global batch size:     1 | lm loss: 8.807556E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.767 | TFLOPs: 16.82 |
[default0]:[2023-07-30 22:27:16,985] [INFO] [logging.py:96:log_dist] [Rank 0] step=1890, skipped=0, lr=[2.0632917333333335e-06, 2.0632917333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:16,986] [INFO] [timer.py:215:stop] epoch=0/micro_step=1890/global_step=1890, RunningAvgSamplesPerSec=7.862375758990179, CurrSamplesPerSec=7.863956292021494, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1890/439453125 | consumed samples:         1890 | consumed tokens:      3870720 | elapsed time per iteration (ms): 151.1 | learning rate: 2.063E-06 | global batch size:     1 | lm loss: 8.846144E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.616 | TFLOPs: 16.44 |
[default0]:[2023-07-30 22:27:17,745] [INFO] [logging.py:96:log_dist] [Rank 0] step=1895, skipped=0, lr=[2.068753066666667e-06, 2.068753066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:17,746] [INFO] [timer.py:215:stop] epoch=0/micro_step=1895/global_step=1895, RunningAvgSamplesPerSec=7.862423478479308, CurrSamplesPerSec=7.910154400906754, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1895/439453125 | consumed samples:         1895 | consumed tokens:      3880960 | elapsed time per iteration (ms): 152.1 | learning rate: 2.069E-06 | global batch size:     1 | lm loss: 9.034340E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.573 | TFLOPs: 16.33 |
[default0]:[2023-07-30 22:27:18,492] [INFO] [logging.py:96:log_dist] [Rank 0] step=1900, skipped=0, lr=[2.0742144e-06, 2.0742144e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:18,493] [INFO] [timer.py:215:stop] epoch=0/micro_step=1900/global_step=1900, RunningAvgSamplesPerSec=7.862505402208335, CurrSamplesPerSec=7.898654463621555, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1900/439453125 | consumed samples:         1900 | consumed tokens:      3891200 | elapsed time per iteration (ms): 149.1 | learning rate: 2.074E-06 | global batch size:     1 | lm loss: 8.722318E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.705 | TFLOPs: 16.66 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1900 | lm loss value: 8.864863E+00 | lm loss PPL: 7.078826E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:27:22,241] [INFO] [logging.py:96:log_dist] [Rank 0] step=1905, skipped=0, lr=[2.0796757333333334e-06, 2.0796757333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:22,242] [INFO] [timer.py:215:stop] epoch=0/micro_step=1905/global_step=1905, RunningAvgSamplesPerSec=7.861873025587638, CurrSamplesPerSec=7.878728224240079, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1905/439453125 | consumed samples:         1905 | consumed tokens:      3901440 | elapsed time per iteration (ms): 749.9 | learning rate: 2.080E-06 | global batch size:     1 | lm loss: 8.552406E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.334 | TFLOPs: 3.31 |
[default0]:[2023-07-30 22:27:23,002] [INFO] [logging.py:96:log_dist] [Rank 0] step=1910, skipped=0, lr=[2.0851370666666668e-06, 2.0851370666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:23,002] [INFO] [timer.py:215:stop] epoch=0/micro_step=1910/global_step=1910, RunningAvgSamplesPerSec=7.862124283916452, CurrSamplesPerSec=7.970158726539237, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1910/439453125 | consumed samples:         1910 | consumed tokens:      3911680 | elapsed time per iteration (ms): 152.4 | learning rate: 2.085E-06 | global batch size:     1 | lm loss: 8.766582E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.561 | TFLOPs: 16.30 |
[default0]:[2023-07-30 22:27:23,738] [INFO] [logging.py:96:log_dist] [Rank 0] step=1915, skipped=0, lr=[2.0905984e-06, 2.0905984e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:23,738] [INFO] [timer.py:215:stop] epoch=0/micro_step=1915/global_step=1915, RunningAvgSamplesPerSec=7.862360330833576, CurrSamplesPerSec=7.976251737666136, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1915/439453125 | consumed samples:         1915 | consumed tokens:      3921920 | elapsed time per iteration (ms): 146.8 | learning rate: 2.091E-06 | global batch size:     1 | lm loss: 8.954799E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.814 | TFLOPs: 16.93 |
[default0]:[2023-07-30 22:27:24,493] [INFO] [logging.py:96:log_dist] [Rank 0] step=1920, skipped=0, lr=[2.0960597333333334e-06, 2.0960597333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:24,496] [INFO] [timer.py:215:stop] epoch=0/micro_step=1920/global_step=1920, RunningAvgSamplesPerSec=7.862477610996147, CurrSamplesPerSec=7.72152961362013, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1920/439453125 | consumed samples:         1920 | consumed tokens:      3932160 | elapsed time per iteration (ms): 151.7 | learning rate: 2.096E-06 | global batch size:     1 | lm loss: 8.815865E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.590 | TFLOPs: 16.38 |
[default0]:[2023-07-30 22:27:25,317] [INFO] [logging.py:96:log_dist] [Rank 0] step=1925, skipped=0, lr=[2.1015210666666667e-06, 2.1015210666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:25,318] [INFO] [timer.py:215:stop] epoch=0/micro_step=1925/global_step=1925, RunningAvgSamplesPerSec=7.862373763514808, CurrSamplesPerSec=7.834577983330781, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1925/439453125 | consumed samples:         1925 | consumed tokens:      3942400 | elapsed time per iteration (ms): 164.4 | learning rate: 2.102E-06 | global batch size:     1 | lm loss: 8.803774E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.083 | TFLOPs: 15.11 |
[default0]:[2023-07-30 22:27:26,097] [INFO] [logging.py:96:log_dist] [Rank 0] step=1930, skipped=0, lr=[2.1069824e-06, 2.1069824e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:26,097] [INFO] [timer.py:215:stop] epoch=0/micro_step=1930/global_step=1930, RunningAvgSamplesPerSec=7.862661436718272, CurrSamplesPerSec=7.930000226879127, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1930/439453125 | consumed samples:         1930 | consumed tokens:      3952640 | elapsed time per iteration (ms): 156.0 | learning rate: 2.107E-06 | global batch size:     1 | lm loss: 8.714468E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.410 | TFLOPs: 15.93 |
[default0]:[2023-07-30 22:27:26,913] [INFO] [logging.py:96:log_dist] [Rank 0] step=1935, skipped=0, lr=[2.1124437333333333e-06, 2.1124437333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:26,914] [INFO] [timer.py:215:stop] epoch=0/micro_step=1935/global_step=1935, RunningAvgSamplesPerSec=7.8627100562200205, CurrSamplesPerSec=7.84797658875392, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1935/439453125 | consumed samples:         1935 | consumed tokens:      3962880 | elapsed time per iteration (ms): 163.1 | learning rate: 2.112E-06 | global batch size:     1 | lm loss: 8.709035E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.133 | TFLOPs: 15.24 |
[default0]:[2023-07-30 22:27:27,660] [INFO] [logging.py:96:log_dist] [Rank 0] step=1940, skipped=0, lr=[2.117905066666667e-06, 2.117905066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:27,660] [INFO] [timer.py:215:stop] epoch=0/micro_step=1940/global_step=1940, RunningAvgSamplesPerSec=7.862883289340146, CurrSamplesPerSec=7.958755609529321, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1940/439453125 | consumed samples:         1940 | consumed tokens:      3973120 | elapsed time per iteration (ms): 149.9 | learning rate: 2.118E-06 | global batch size:     1 | lm loss: 8.645706E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.670 | TFLOPs: 16.57 |
[default0]:[2023-07-30 22:27:28,425] [INFO] [logging.py:96:log_dist] [Rank 0] step=1945, skipped=0, lr=[2.1233664000000004e-06, 2.1233664000000004e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:28,426] [INFO] [timer.py:215:stop] epoch=0/micro_step=1945/global_step=1945, RunningAvgSamplesPerSec=7.862963719694675, CurrSamplesPerSec=7.890021745837064, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1945/439453125 | consumed samples:         1945 | consumed tokens:      3983360 | elapsed time per iteration (ms): 152.6 | learning rate: 2.123E-06 | global batch size:     1 | lm loss: 8.685530E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.555 | TFLOPs: 16.29 |
[default0]:[2023-07-30 22:27:29,186] [INFO] [logging.py:96:log_dist] [Rank 0] step=1950, skipped=0, lr=[2.1288277333333337e-06, 2.1288277333333337e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:29,187] [INFO] [timer.py:215:stop] epoch=0/micro_step=1950/global_step=1950, RunningAvgSamplesPerSec=7.862938738379737, CurrSamplesPerSec=7.83528049167772, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1950/439453125 | consumed samples:         1950 | consumed tokens:      3993600 | elapsed time per iteration (ms): 152.0 | learning rate: 2.129E-06 | global batch size:     1 | lm loss: 8.859682E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.577 | TFLOPs: 16.34 |
[default0]:[2023-07-30 22:27:29,936] [INFO] [logging.py:96:log_dist] [Rank 0] step=1955, skipped=0, lr=[2.134289066666667e-06, 2.134289066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:29,936] [INFO] [timer.py:215:stop] epoch=0/micro_step=1955/global_step=1955, RunningAvgSamplesPerSec=7.863106970807689, CurrSamplesPerSec=7.971234178418032, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1955/439453125 | consumed samples:         1955 | consumed tokens:      4003840 | elapsed time per iteration (ms): 149.8 | learning rate: 2.134E-06 | global batch size:     1 | lm loss: 8.704175E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.675 | TFLOPs: 16.59 |
[default0]:[2023-07-30 22:27:30,729] [INFO] [logging.py:96:log_dist] [Rank 0] step=1960, skipped=0, lr=[2.1397504000000003e-06, 2.1397504000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:30,729] [INFO] [timer.py:215:stop] epoch=0/micro_step=1960/global_step=1960, RunningAvgSamplesPerSec=7.8632631104717055, CurrSamplesPerSec=7.923064571885171, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1960/439453125 | consumed samples:         1960 | consumed tokens:      4014080 | elapsed time per iteration (ms): 158.7 | learning rate: 2.140E-06 | global batch size:     1 | lm loss: 8.713002E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.300 | TFLOPs: 15.65 |
[default0]:[2023-07-30 22:27:31,508] [INFO] [logging.py:96:log_dist] [Rank 0] step=1965, skipped=0, lr=[2.1452117333333336e-06, 2.1452117333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:31,508] [INFO] [timer.py:215:stop] epoch=0/micro_step=1965/global_step=1965, RunningAvgSamplesPerSec=7.863373979127888, CurrSamplesPerSec=7.966903845642453, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1965/439453125 | consumed samples:         1965 | consumed tokens:      4024320 | elapsed time per iteration (ms): 155.9 | learning rate: 2.145E-06 | global batch size:     1 | lm loss: 8.620815E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.413 | TFLOPs: 15.93 |
[default0]:[2023-07-30 22:27:32,250] [INFO] [logging.py:96:log_dist] [Rank 0] step=1970, skipped=0, lr=[2.150673066666667e-06, 2.150673066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:32,250] [INFO] [timer.py:215:stop] epoch=0/micro_step=1970/global_step=1970, RunningAvgSamplesPerSec=7.863565416877646, CurrSamplesPerSec=7.919653629955797, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1970/439453125 | consumed samples:         1970 | consumed tokens:      4034560 | elapsed time per iteration (ms): 148.6 | learning rate: 2.151E-06 | global batch size:     1 | lm loss: 8.814019E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.729 | TFLOPs: 16.72 |
[default0]:[2023-07-30 22:27:32,984] [INFO] [logging.py:96:log_dist] [Rank 0] step=1975, skipped=0, lr=[2.1561344000000003e-06, 2.1561344000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:32,985] [INFO] [timer.py:215:stop] epoch=0/micro_step=1975/global_step=1975, RunningAvgSamplesPerSec=7.863602296830159, CurrSamplesPerSec=7.856149604411412, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1975/439453125 | consumed samples:         1975 | consumed tokens:      4044800 | elapsed time per iteration (ms): 146.4 | learning rate: 2.156E-06 | global batch size:     1 | lm loss: 8.576346E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.831 | TFLOPs: 16.97 |
[default0]:[2023-07-30 22:27:33,730] [INFO] [logging.py:96:log_dist] [Rank 0] step=1980, skipped=0, lr=[2.1615957333333336e-06, 2.1615957333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:33,730] [INFO] [timer.py:215:stop] epoch=0/micro_step=1980/global_step=1980, RunningAvgSamplesPerSec=7.8636954812469515, CurrSamplesPerSec=7.8970037241633815, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1980/439453125 | consumed samples:         1980 | consumed tokens:      4055040 | elapsed time per iteration (ms): 149.1 | learning rate: 2.162E-06 | global batch size:     1 | lm loss: 8.790866E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.707 | TFLOPs: 16.67 |
[default0]:[2023-07-30 22:27:34,485] [INFO] [logging.py:96:log_dist] [Rank 0] step=1985, skipped=0, lr=[2.167057066666667e-06, 2.167057066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:34,485] [INFO] [timer.py:215:stop] epoch=0/micro_step=1985/global_step=1985, RunningAvgSamplesPerSec=7.863879039823583, CurrSamplesPerSec=7.900023167201271, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1985/439453125 | consumed samples:         1985 | consumed tokens:      4065280 | elapsed time per iteration (ms): 151.5 | learning rate: 2.167E-06 | global batch size:     1 | lm loss: 8.602380E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.601 | TFLOPs: 16.40 |
[default0]:[2023-07-30 22:27:35,225] [INFO] [logging.py:96:log_dist] [Rank 0] step=1990, skipped=0, lr=[2.1725184e-06, 2.1725184e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:35,227] [INFO] [timer.py:215:stop] epoch=0/micro_step=1990/global_step=1990, RunningAvgSamplesPerSec=7.863923162129488, CurrSamplesPerSec=7.821823057600176, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1990/439453125 | consumed samples:         1990 | consumed tokens:      4075520 | elapsed time per iteration (ms): 147.9 | learning rate: 2.173E-06 | global batch size:     1 | lm loss: 8.627958E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.761 | TFLOPs: 16.80 |
[default0]:[2023-07-30 22:27:35,985] [INFO] [logging.py:96:log_dist] [Rank 0] step=1995, skipped=0, lr=[2.1779797333333335e-06, 2.1779797333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:35,986] [INFO] [timer.py:215:stop] epoch=0/micro_step=1995/global_step=1995, RunningAvgSamplesPerSec=7.864057483319435, CurrSamplesPerSec=7.901198845611893, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     1995/439453125 | consumed samples:         1995 | consumed tokens:      4085760 | elapsed time per iteration (ms): 151.9 | learning rate: 2.178E-06 | global batch size:     1 | lm loss: 8.811152E+00 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.585 | TFLOPs: 16.36 |
[default0]:[2023-07-30 22:27:36,727] [INFO] [logging.py:96:log_dist] [Rank 0] step=2000, skipped=0, lr=[2.183441066666667e-06, 2.183441066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:36,729] [INFO] [timer.py:215:stop] epoch=0/micro_step=2000/global_step=2000, RunningAvgSamplesPerSec=7.864018730446103, CurrSamplesPerSec=7.773275510582304, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2000/439453125 | consumed samples:         2000 | consumed tokens:      4096000 | elapsed time per iteration (ms): 148.7 | learning rate: 2.183E-06 | global batch size:     1 | lm loss: 8.689746E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.727 | TFLOPs: 16.71 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 2000 | lm loss value: 8.718370E+00 | lm loss PPL: 6.114207E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:27:40,504] [INFO] [logging.py:96:log_dist] [Rank 0] step=2005, skipped=0, lr=[2.1889024e-06, 2.1889024e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:40,505] [INFO] [timer.py:215:stop] epoch=0/micro_step=2005/global_step=2005, RunningAvgSamplesPerSec=7.863133498104152, CurrSamplesPerSec=7.7751920021800105, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2005/439453125 | consumed samples:         2005 | consumed tokens:      4106240 | elapsed time per iteration (ms): 755.2 | learning rate: 2.189E-06 | global batch size:     1 | lm loss: 8.578688E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.324 | TFLOPs: 3.29 |
[default0]:[2023-07-30 22:27:41,281] [INFO] [logging.py:96:log_dist] [Rank 0] step=2010, skipped=0, lr=[2.1943637333333335e-06, 2.1943637333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:41,281] [INFO] [timer.py:215:stop] epoch=0/micro_step=2010/global_step=2010, RunningAvgSamplesPerSec=7.862938351922599, CurrSamplesPerSec=7.810156564227086, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2010/439453125 | consumed samples:         2010 | consumed tokens:      4116480 | elapsed time per iteration (ms): 154.9 | learning rate: 2.194E-06 | global batch size:     1 | lm loss: 8.838112E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.456 | TFLOPs: 16.04 |
[default0]:[2023-07-30 22:27:42,025] [INFO] [logging.py:96:log_dist] [Rank 0] step=2015, skipped=0, lr=[2.1998250666666668e-06, 2.1998250666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:42,026] [INFO] [timer.py:215:stop] epoch=0/micro_step=2015/global_step=2015, RunningAvgSamplesPerSec=7.8630465687686675, CurrSamplesPerSec=7.919653629955797, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2015/439453125 | consumed samples:         2015 | consumed tokens:      4126720 | elapsed time per iteration (ms): 149.0 | learning rate: 2.200E-06 | global batch size:     1 | lm loss: 8.654346E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.711 | TFLOPs: 16.67 |
[default0]:[2023-07-30 22:27:42,778] [INFO] [logging.py:96:log_dist] [Rank 0] step=2020, skipped=0, lr=[2.2052864e-06, 2.2052864e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:42,778] [INFO] [timer.py:215:stop] epoch=0/micro_step=2020/global_step=2020, RunningAvgSamplesPerSec=7.863171952054703, CurrSamplesPerSec=7.829810111931661, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2020/439453125 | consumed samples:         2020 | consumed tokens:      4136960 | elapsed time per iteration (ms): 150.6 | learning rate: 2.205E-06 | global batch size:     1 | lm loss: 8.589731E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.640 | TFLOPs: 16.50 |
[default0]:[2023-07-30 22:27:43,521] [INFO] [logging.py:96:log_dist] [Rank 0] step=2025, skipped=0, lr=[2.2107477333333334e-06, 2.2107477333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:43,521] [INFO] [timer.py:215:stop] epoch=0/micro_step=2025/global_step=2025, RunningAvgSamplesPerSec=7.863104236013297, CurrSamplesPerSec=7.957577838784404, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2025/439453125 | consumed samples:         2025 | consumed tokens:      4147200 | elapsed time per iteration (ms): 148.4 | learning rate: 2.211E-06 | global batch size:     1 | lm loss: 8.946571E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.737 | TFLOPs: 16.74 |
[default0]:[2023-07-30 22:27:44,266] [INFO] [logging.py:96:log_dist] [Rank 0] step=2030, skipped=0, lr=[2.2162090666666667e-06, 2.2162090666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:44,267] [INFO] [timer.py:215:stop] epoch=0/micro_step=2030/global_step=2030, RunningAvgSamplesPerSec=7.863048484865803, CurrSamplesPerSec=7.8386044781837585, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2030/439453125 | consumed samples:         2030 | consumed tokens:      4157440 | elapsed time per iteration (ms): 149.2 | learning rate: 2.216E-06 | global batch size:     1 | lm loss: 8.627065E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.700 | TFLOPs: 16.65 |
[default0]:[2023-07-30 22:27:45,045] [INFO] [logging.py:96:log_dist] [Rank 0] step=2035, skipped=0, lr=[2.2216704e-06, 2.2216704e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:45,046] [INFO] [timer.py:215:stop] epoch=0/micro_step=2035/global_step=2035, RunningAvgSamplesPerSec=7.8629155215237425, CurrSamplesPerSec=7.834768233569007, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2035/439453125 | consumed samples:         2035 | consumed tokens:      4167680 | elapsed time per iteration (ms): 155.9 | learning rate: 2.222E-06 | global batch size:     1 | lm loss: 8.714805E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.416 | TFLOPs: 15.94 |
[default0]:[2023-07-30 22:27:45,807] [INFO] [logging.py:96:log_dist] [Rank 0] step=2040, skipped=0, lr=[2.2271317333333334e-06, 2.2271317333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:45,807] [INFO] [timer.py:215:stop] epoch=0/micro_step=2040/global_step=2040, RunningAvgSamplesPerSec=7.8630505591007935, CurrSamplesPerSec=7.868736328264238, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2040/439453125 | consumed samples:         2040 | consumed tokens:      4177920 | elapsed time per iteration (ms): 152.2 | learning rate: 2.227E-06 | global batch size:     1 | lm loss: 8.913530E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.571 | TFLOPs: 16.33 |
[default0]:[2023-07-30 22:27:46,554] [INFO] [logging.py:96:log_dist] [Rank 0] step=2045, skipped=0, lr=[2.2325930666666667e-06, 2.2325930666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:46,555] [INFO] [timer.py:215:stop] epoch=0/micro_step=2045/global_step=2045, RunningAvgSamplesPerSec=7.863202625628363, CurrSamplesPerSec=7.934080401934005, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2045/439453125 | consumed samples:         2045 | consumed tokens:      4188160 | elapsed time per iteration (ms): 149.4 | learning rate: 2.233E-06 | global batch size:     1 | lm loss: 8.729458E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.692 | TFLOPs: 16.63 |
[default0]:[2023-07-30 22:27:47,311] [INFO] [logging.py:96:log_dist] [Rank 0] step=2050, skipped=0, lr=[2.2380544e-06, 2.2380544e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:47,312] [INFO] [timer.py:215:stop] epoch=0/micro_step=2050/global_step=2050, RunningAvgSamplesPerSec=7.863351169767938, CurrSamplesPerSec=7.940584349814752, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2050/439453125 | consumed samples:         2050 | consumed tokens:      4198400 | elapsed time per iteration (ms): 151.7 | learning rate: 2.238E-06 | global batch size:     1 | lm loss: 8.632713E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.593 | TFLOPs: 16.38 |
[default0]:[2023-07-30 22:27:48,045] [INFO] [logging.py:96:log_dist] [Rank 0] step=2055, skipped=0, lr=[2.2435157333333333e-06, 2.2435157333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:48,046] [INFO] [timer.py:215:stop] epoch=0/micro_step=2055/global_step=2055, RunningAvgSamplesPerSec=7.8635343623445655, CurrSamplesPerSec=7.914811550937763, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2055/439453125 | consumed samples:         2055 | consumed tokens:      4208640 | elapsed time per iteration (ms): 146.7 | learning rate: 2.244E-06 | global batch size:     1 | lm loss: 8.803070E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.817 | TFLOPs: 16.94 |
[default0]:[2023-07-30 22:27:48,769] [INFO] [logging.py:96:log_dist] [Rank 0] step=2060, skipped=0, lr=[2.2489770666666666e-06, 2.2489770666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:48,769] [INFO] [timer.py:215:stop] epoch=0/micro_step=2060/global_step=2060, RunningAvgSamplesPerSec=7.863745887801361, CurrSamplesPerSec=7.95000616014481, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2060/439453125 | consumed samples:         2060 | consumed tokens:      4218880 | elapsed time per iteration (ms): 144.5 | learning rate: 2.249E-06 | global batch size:     1 | lm loss: 8.508890E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.919 | TFLOPs: 17.19 |
[default0]:[2023-07-30 22:27:49,511] [INFO] [logging.py:96:log_dist] [Rank 0] step=2065, skipped=0, lr=[2.2544384e-06, 2.2544384e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:49,512] [INFO] [timer.py:215:stop] epoch=0/micro_step=2065/global_step=2065, RunningAvgSamplesPerSec=7.863849960572643, CurrSamplesPerSec=7.844600635153383, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2065/439453125 | consumed samples:         2065 | consumed tokens:      4229120 | elapsed time per iteration (ms): 148.6 | learning rate: 2.254E-06 | global batch size:     1 | lm loss: 8.608153E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.728 | TFLOPs: 16.72 |
[default0]:[2023-07-30 22:27:50,239] [INFO] [logging.py:96:log_dist] [Rank 0] step=2070, skipped=0, lr=[2.2598997333333332e-06, 2.2598997333333332e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:50,240] [INFO] [timer.py:215:stop] epoch=0/micro_step=2070/global_step=2070, RunningAvgSamplesPerSec=7.863973660028519, CurrSamplesPerSec=7.9588613239518935, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2070/439453125 | consumed samples:         2070 | consumed tokens:      4239360 | elapsed time per iteration (ms): 145.6 | learning rate: 2.260E-06 | global batch size:     1 | lm loss: 8.557301E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.869 | TFLOPs: 17.07 |
[default0]:[2023-07-30 22:27:50,990] [INFO] [logging.py:96:log_dist] [Rank 0] step=2075, skipped=0, lr=[2.2653610666666666e-06, 2.2653610666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:50,991] [INFO] [timer.py:215:stop] epoch=0/micro_step=2075/global_step=2075, RunningAvgSamplesPerSec=7.864123354238195, CurrSamplesPerSec=7.928875916603496, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2075/439453125 | consumed samples:         2075 | consumed tokens:      4249600 | elapsed time per iteration (ms): 150.0 | learning rate: 2.265E-06 | global batch size:     1 | lm loss: 8.659413E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.667 | TFLOPs: 16.57 |
[default0]:[2023-07-30 22:27:51,731] [INFO] [logging.py:96:log_dist] [Rank 0] step=2080, skipped=0, lr=[2.2708224e-06, 2.2708224e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:51,732] [INFO] [timer.py:215:stop] epoch=0/micro_step=2080/global_step=2080, RunningAvgSamplesPerSec=7.864180442019237, CurrSamplesPerSec=7.87986796447741, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2080/439453125 | consumed samples:         2080 | consumed tokens:      4259840 | elapsed time per iteration (ms): 148.4 | learning rate: 2.271E-06 | global batch size:     1 | lm loss: 8.638112E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.740 | TFLOPs: 16.75 |
[default0]:[2023-07-30 22:27:52,471] [INFO] [logging.py:96:log_dist] [Rank 0] step=2085, skipped=0, lr=[2.276283733333333e-06, 2.276283733333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:52,472] [INFO] [timer.py:215:stop] epoch=0/micro_step=2085/global_step=2085, RunningAvgSamplesPerSec=7.864276494939469, CurrSamplesPerSec=7.909677054358587, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2085/439453125 | consumed samples:         2085 | consumed tokens:      4270080 | elapsed time per iteration (ms): 148.3 | learning rate: 2.276E-06 | global batch size:     1 | lm loss: 8.519985E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.741 | TFLOPs: 16.75 |
[default0]:[2023-07-30 22:27:53,225] [INFO] [logging.py:96:log_dist] [Rank 0] step=2090, skipped=0, lr=[2.2817450666666665e-06, 2.2817450666666665e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:53,225] [INFO] [timer.py:215:stop] epoch=0/micro_step=2090/global_step=2090, RunningAvgSamplesPerSec=7.864394152423312, CurrSamplesPerSec=7.871364871560046, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2090/439453125 | consumed samples:         2090 | consumed tokens:      4280320 | elapsed time per iteration (ms): 150.4 | learning rate: 2.282E-06 | global batch size:     1 | lm loss: 8.541341E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.648 | TFLOPs: 16.52 |
[default0]:[2023-07-30 22:27:53,998] [INFO] [logging.py:96:log_dist] [Rank 0] step=2095, skipped=0, lr=[2.2872064000000002e-06, 2.2872064000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:53,998] [INFO] [timer.py:215:stop] epoch=0/micro_step=2095/global_step=2095, RunningAvgSamplesPerSec=7.864440648523017, CurrSamplesPerSec=7.9239027965911175, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2095/439453125 | consumed samples:         2095 | consumed tokens:      4290560 | elapsed time per iteration (ms): 154.7 | learning rate: 2.287E-06 | global batch size:     1 | lm loss: 8.504211E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.462 | TFLOPs: 16.06 |
[default0]:[2023-07-30 22:27:54,782] [INFO] [logging.py:96:log_dist] [Rank 0] step=2100, skipped=0, lr=[2.2926677333333335e-06, 2.2926677333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:54,782] [INFO] [timer.py:215:stop] epoch=0/micro_step=2100/global_step=2100, RunningAvgSamplesPerSec=7.86461872805836, CurrSamplesPerSec=7.915468769756571, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2100/439453125 | consumed samples:         2100 | consumed tokens:      4300800 | elapsed time per iteration (ms): 156.7 | learning rate: 2.293E-06 | global batch size:     1 | lm loss: 8.398265E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.382 | TFLOPs: 15.86 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 2100 | lm loss value: 8.613150E+00 | lm loss PPL: 5.503556E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:27:58,309] [INFO] [logging.py:96:log_dist] [Rank 0] step=2105, skipped=0, lr=[2.298129066666667e-06, 2.298129066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:58,309] [INFO] [timer.py:215:stop] epoch=0/micro_step=2105/global_step=2105, RunningAvgSamplesPerSec=7.863530548085971, CurrSamplesPerSec=7.606976001857172, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2105/439453125 | consumed samples:         2105 | consumed tokens:      4311040 | elapsed time per iteration (ms): 705.2 | learning rate: 2.298E-06 | global batch size:     1 | lm loss: 8.511887E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.418 | TFLOPs: 3.52 |
[default0]:[2023-07-30 22:27:59,101] [INFO] [logging.py:96:log_dist] [Rank 0] step=2110, skipped=0, lr=[2.3035904e-06, 2.3035904e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:59,102] [INFO] [timer.py:215:stop] epoch=0/micro_step=2110/global_step=2110, RunningAvgSamplesPerSec=7.863307843910912, CurrSamplesPerSec=7.819446153387249, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2110/439453125 | consumed samples:         2110 | consumed tokens:      4321280 | elapsed time per iteration (ms): 158.7 | learning rate: 2.304E-06 | global batch size:     1 | lm loss: 8.326281E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.301 | TFLOPs: 15.66 |
[default0]:[2023-07-30 22:27:59,843] [INFO] [logging.py:96:log_dist] [Rank 0] step=2115, skipped=0, lr=[2.3090517333333335e-06, 2.3090517333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:27:59,844] [INFO] [timer.py:215:stop] epoch=0/micro_step=2115/global_step=2115, RunningAvgSamplesPerSec=7.863368952877617, CurrSamplesPerSec=7.932759885915738, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2115/439453125 | consumed samples:         2115 | consumed tokens:      4331520 | elapsed time per iteration (ms): 148.2 | learning rate: 2.309E-06 | global batch size:     1 | lm loss: 8.339863E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.747 | TFLOPs: 16.76 |
[default0]:[2023-07-30 22:28:00,621] [INFO] [logging.py:96:log_dist] [Rank 0] step=2120, skipped=0, lr=[2.314513066666667e-06, 2.314513066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:00,621] [INFO] [timer.py:215:stop] epoch=0/micro_step=2120/global_step=2120, RunningAvgSamplesPerSec=7.863432788147265, CurrSamplesPerSec=7.942042816513101, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2120/439453125 | consumed samples:         2120 | consumed tokens:      4341760 | elapsed time per iteration (ms): 155.4 | learning rate: 2.315E-06 | global batch size:     1 | lm loss: 8.567355E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.437 | TFLOPs: 15.99 |
[default0]:[2023-07-30 22:28:01,381] [INFO] [logging.py:96:log_dist] [Rank 0] step=2125, skipped=0, lr=[2.3199744e-06, 2.3199744e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:01,382] [INFO] [timer.py:215:stop] epoch=0/micro_step=2125/global_step=2125, RunningAvgSamplesPerSec=7.863465630570101, CurrSamplesPerSec=7.839146540671269, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2125/439453125 | consumed samples:         2125 | consumed tokens:      4352000 | elapsed time per iteration (ms): 152.2 | learning rate: 2.320E-06 | global batch size:     1 | lm loss: 8.551724E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.569 | TFLOPs: 16.32 |
[default0]:[2023-07-30 22:28:02,134] [INFO] [logging.py:96:log_dist] [Rank 0] step=2130, skipped=0, lr=[2.3254357333333334e-06, 2.3254357333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:02,135] [INFO] [timer.py:215:stop] epoch=0/micro_step=2130/global_step=2130, RunningAvgSamplesPerSec=7.863531060206131, CurrSamplesPerSec=7.884874883211171, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2130/439453125 | consumed samples:         2130 | consumed tokens:      4362240 | elapsed time per iteration (ms): 150.5 | learning rate: 2.325E-06 | global batch size:     1 | lm loss: 8.368980E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.645 | TFLOPs: 16.51 |
[default0]:[2023-07-30 22:28:02,900] [INFO] [logging.py:96:log_dist] [Rank 0] step=2135, skipped=0, lr=[2.3308970666666667e-06, 2.3308970666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:02,901] [INFO] [timer.py:215:stop] epoch=0/micro_step=2135/global_step=2135, RunningAvgSamplesPerSec=7.8636744749992555, CurrSamplesPerSec=7.970658548358285, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2135/439453125 | consumed samples:         2135 | consumed tokens:      4372480 | elapsed time per iteration (ms): 153.3 | learning rate: 2.331E-06 | global batch size:     1 | lm loss: 8.494485E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.523 | TFLOPs: 16.21 |
[default0]:[2023-07-30 22:28:03,630] [INFO] [logging.py:96:log_dist] [Rank 0] step=2140, skipped=0, lr=[2.3363584e-06, 2.3363584e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:03,631] [INFO] [timer.py:215:stop] epoch=0/micro_step=2140/global_step=2140, RunningAvgSamplesPerSec=7.863694987049041, CurrSamplesPerSec=7.770395346252177, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2140/439453125 | consumed samples:         2140 | consumed tokens:      4382720 | elapsed time per iteration (ms): 146.4 | learning rate: 2.336E-06 | global batch size:     1 | lm loss: 8.731215E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.832 | TFLOPs: 16.98 |
[default0]:[2023-07-30 22:28:04,375] [INFO] [logging.py:96:log_dist] [Rank 0] step=2145, skipped=0, lr=[2.3418197333333334e-06, 2.3418197333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:04,375] [INFO] [timer.py:215:stop] epoch=0/micro_step=2145/global_step=2145, RunningAvgSamplesPerSec=7.8638046625513685, CurrSamplesPerSec=7.877085802178155, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2145/439453125 | consumed samples:         2145 | consumed tokens:      4392960 | elapsed time per iteration (ms): 148.5 | learning rate: 2.342E-06 | global batch size:     1 | lm loss: 8.464569E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.733 | TFLOPs: 16.73 |
[default0]:[2023-07-30 22:28:05,151] [INFO] [logging.py:96:log_dist] [Rank 0] step=2150, skipped=0, lr=[2.3472810666666667e-06, 2.3472810666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:05,165] [INFO] [timer.py:215:stop] epoch=0/micro_step=2150/global_step=2150, RunningAvgSamplesPerSec=7.8633614469046265, CurrSamplesPerSec=7.098967051603414, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2150/439453125 | consumed samples:         2150 | consumed tokens:      4403200 | elapsed time per iteration (ms): 157.8 | learning rate: 2.347E-06 | global batch size:     1 | lm loss: 8.529201E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.338 | TFLOPs: 15.75 |
[default0]:[2023-07-30 22:28:05,904] [INFO] [logging.py:96:log_dist] [Rank 0] step=2155, skipped=0, lr=[2.3527424e-06, 2.3527424e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:05,904] [INFO] [timer.py:215:stop] epoch=0/micro_step=2155/global_step=2155, RunningAvgSamplesPerSec=7.863412203666675, CurrSamplesPerSec=7.914288841170943, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2155/439453125 | consumed samples:         2155 | consumed tokens:      4413440 | elapsed time per iteration (ms): 147.8 | learning rate: 2.353E-06 | global batch size:     1 | lm loss: 8.618301E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.764 | TFLOPs: 16.81 |
[default0]:[2023-07-30 22:28:06,691] [INFO] [logging.py:96:log_dist] [Rank 0] step=2160, skipped=0, lr=[2.3582037333333333e-06, 2.3582037333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:06,692] [INFO] [timer.py:215:stop] epoch=0/micro_step=2160/global_step=2160, RunningAvgSamplesPerSec=7.863401802996951, CurrSamplesPerSec=7.7852365935283645, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2160/439453125 | consumed samples:         2160 | consumed tokens:      4423680 | elapsed time per iteration (ms): 157.7 | learning rate: 2.358E-06 | global batch size:     1 | lm loss: 8.217048E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.341 | TFLOPs: 15.76 |
[default0]:[2023-07-30 22:28:07,473] [INFO] [logging.py:96:log_dist] [Rank 0] step=2165, skipped=0, lr=[2.3636650666666666e-06, 2.3636650666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:07,474] [INFO] [timer.py:215:stop] epoch=0/micro_step=2165/global_step=2165, RunningAvgSamplesPerSec=7.8634506442716114, CurrSamplesPerSec=7.792294844713458, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2165/439453125 | consumed samples:         2165 | consumed tokens:      4433920 | elapsed time per iteration (ms): 156.4 | learning rate: 2.364E-06 | global batch size:     1 | lm loss: 8.578443E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.394 | TFLOPs: 15.89 |
[default0]:[2023-07-30 22:28:08,236] [INFO] [logging.py:96:log_dist] [Rank 0] step=2170, skipped=0, lr=[2.3691264e-06, 2.3691264e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:08,237] [INFO] [timer.py:215:stop] epoch=0/micro_step=2170/global_step=2170, RunningAvgSamplesPerSec=7.8634900264003615, CurrSamplesPerSec=7.873536959202867, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2170/439453125 | consumed samples:         2170 | consumed tokens:      4444160 | elapsed time per iteration (ms): 152.3 | learning rate: 2.369E-06 | global batch size:     1 | lm loss: 8.469314E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.566 | TFLOPs: 16.31 |
[default0]:[2023-07-30 22:28:08,993] [INFO] [logging.py:96:log_dist] [Rank 0] step=2175, skipped=0, lr=[2.3745877333333333e-06, 2.3745877333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:08,994] [INFO] [timer.py:215:stop] epoch=0/micro_step=2175/global_step=2175, RunningAvgSamplesPerSec=7.863486668990552, CurrSamplesPerSec=7.846963497613715, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2175/439453125 | consumed samples:         2175 | consumed tokens:      4454400 | elapsed time per iteration (ms): 151.6 | learning rate: 2.375E-06 | global batch size:     1 | lm loss: 8.382348E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.595 | TFLOPs: 16.39 |
[default0]:[2023-07-30 22:28:09,746] [INFO] [logging.py:96:log_dist] [Rank 0] step=2180, skipped=0, lr=[2.3800490666666666e-06, 2.3800490666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:09,747] [INFO] [timer.py:215:stop] epoch=0/micro_step=2180/global_step=2180, RunningAvgSamplesPerSec=7.8635798987606815, CurrSamplesPerSec=7.867304658704896, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2180/439453125 | consumed samples:         2180 | consumed tokens:      4464640 | elapsed time per iteration (ms): 150.4 | learning rate: 2.380E-06 | global batch size:     1 | lm loss: 8.561995E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.650 | TFLOPs: 16.52 |
[default0]:[2023-07-30 22:28:10,561] [INFO] [logging.py:96:log_dist] [Rank 0] step=2185, skipped=0, lr=[2.3855104000000003e-06, 2.3855104000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:10,561] [INFO] [timer.py:215:stop] epoch=0/micro_step=2185/global_step=2185, RunningAvgSamplesPerSec=7.863800761304863, CurrSamplesPerSec=7.939817741953803, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2185/439453125 | consumed samples:         2185 | consumed tokens:      4474880 | elapsed time per iteration (ms): 162.9 | learning rate: 2.386E-06 | global batch size:     1 | lm loss: 8.241649E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.137 | TFLOPs: 15.25 |
[default0]:[2023-07-30 22:28:11,343] [INFO] [logging.py:96:log_dist] [Rank 0] step=2190, skipped=0, lr=[2.3909717333333336e-06, 2.3909717333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:11,345] [INFO] [timer.py:215:stop] epoch=0/micro_step=2190/global_step=2190, RunningAvgSamplesPerSec=7.8638571605208405, CurrSamplesPerSec=7.876568063338492, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2190/439453125 | consumed samples:         2190 | consumed tokens:      4485120 | elapsed time per iteration (ms): 156.8 | learning rate: 2.391E-06 | global batch size:     1 | lm loss: 8.400076E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.379 | TFLOPs: 15.85 |
[default0]:[2023-07-30 22:28:12,135] [INFO] [logging.py:96:log_dist] [Rank 0] step=2195, skipped=0, lr=[2.396433066666667e-06, 2.396433066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:12,135] [INFO] [timer.py:215:stop] epoch=0/micro_step=2195/global_step=2195, RunningAvgSamplesPerSec=7.863910378751705, CurrSamplesPerSec=7.665631619443779, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2195/439453125 | consumed samples:         2195 | consumed tokens:      4495360 | elapsed time per iteration (ms): 158.1 | learning rate: 2.396E-06 | global batch size:     1 | lm loss: 8.367030E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.324 | TFLOPs: 15.71 |
[default0]:[2023-07-30 22:28:12,876] [INFO] [logging.py:96:log_dist] [Rank 0] step=2200, skipped=0, lr=[2.4018944000000003e-06, 2.4018944000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:12,879] [INFO] [timer.py:215:stop] epoch=0/micro_step=2200/global_step=2200, RunningAvgSamplesPerSec=7.863991388558207, CurrSamplesPerSec=7.781856637939831, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2200/439453125 | consumed samples:         2200 | consumed tokens:      4505600 | elapsed time per iteration (ms): 148.5 | learning rate: 2.402E-06 | global batch size:     1 | lm loss: 8.359882E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.736 | TFLOPs: 16.74 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 2200 | lm loss value: 8.472825E+00 | lm loss PPL: 4.783009E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:28:16,370] [INFO] [logging.py:96:log_dist] [Rank 0] step=2205, skipped=0, lr=[2.4073557333333336e-06, 2.4073557333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:16,371] [INFO] [timer.py:215:stop] epoch=0/micro_step=2205/global_step=2205, RunningAvgSamplesPerSec=7.863486994194647, CurrSamplesPerSec=7.892367501006703, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2205/439453125 | consumed samples:         2205 | consumed tokens:      4515840 | elapsed time per iteration (ms): 698.7 | learning rate: 2.407E-06 | global batch size:     1 | lm loss: 8.349041E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.431 | TFLOPs: 3.56 |
[default0]:[2023-07-30 22:28:17,113] [INFO] [logging.py:96:log_dist] [Rank 0] step=2210, skipped=0, lr=[2.412817066666667e-06, 2.412817066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:17,115] [INFO] [timer.py:215:stop] epoch=0/micro_step=2210/global_step=2210, RunningAvgSamplesPerSec=7.863521240927481, CurrSamplesPerSec=7.796582318246286, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2210/439453125 | consumed samples:         2210 | consumed tokens:      4526080 | elapsed time per iteration (ms): 148.7 | learning rate: 2.413E-06 | global batch size:     1 | lm loss: 8.535759E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.726 | TFLOPs: 16.71 |
[default0]:[2023-07-30 22:28:17,906] [INFO] [logging.py:96:log_dist] [Rank 0] step=2215, skipped=0, lr=[2.4182784e-06, 2.4182784e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:17,906] [INFO] [timer.py:215:stop] epoch=0/micro_step=2215/global_step=2215, RunningAvgSamplesPerSec=7.8635834730710075, CurrSamplesPerSec=7.8882262556961695, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2215/439453125 | consumed samples:         2215 | consumed tokens:      4536320 | elapsed time per iteration (ms): 158.3 | learning rate: 2.418E-06 | global batch size:     1 | lm loss: 8.489569E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.318 | TFLOPs: 15.70 |
[default0]:[2023-07-30 22:28:18,651] [INFO] [logging.py:96:log_dist] [Rank 0] step=2220, skipped=0, lr=[2.4237397333333335e-06, 2.4237397333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:18,652] [INFO] [timer.py:215:stop] epoch=0/micro_step=2220/global_step=2220, RunningAvgSamplesPerSec=7.863521381052166, CurrSamplesPerSec=7.669303979740169, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2220/439453125 | consumed samples:         2220 | consumed tokens:      4546560 | elapsed time per iteration (ms): 149.2 | learning rate: 2.424E-06 | global batch size:     1 | lm loss: 8.297831E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.702 | TFLOPs: 16.65 |
[default0]:[2023-07-30 22:28:19,419] [INFO] [logging.py:96:log_dist] [Rank 0] step=2225, skipped=0, lr=[2.429201066666667e-06, 2.429201066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:19,420] [INFO] [timer.py:215:stop] epoch=0/micro_step=2225/global_step=2225, RunningAvgSamplesPerSec=7.863542765469829, CurrSamplesPerSec=7.863160183872878, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2225/439453125 | consumed samples:         2225 | consumed tokens:      4556800 | elapsed time per iteration (ms): 153.7 | learning rate: 2.429E-06 | global batch size:     1 | lm loss: 8.450448E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.505 | TFLOPs: 16.16 |
[default0]:[2023-07-30 22:28:20,187] [INFO] [logging.py:96:log_dist] [Rank 0] step=2230, skipped=0, lr=[2.4346624e-06, 2.4346624e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:20,188] [INFO] [timer.py:215:stop] epoch=0/micro_step=2230/global_step=2230, RunningAvgSamplesPerSec=7.8635724709067, CurrSamplesPerSec=7.840993045689075, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2230/439453125 | consumed samples:         2230 | consumed tokens:      4567040 | elapsed time per iteration (ms): 153.2 | learning rate: 2.435E-06 | global batch size:     1 | lm loss: 8.284805E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.526 | TFLOPs: 16.22 |
[default0]:[2023-07-30 22:28:20,942] [INFO] [logging.py:96:log_dist] [Rank 0] step=2235, skipped=0, lr=[2.4401237333333335e-06, 2.4401237333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:20,943] [INFO] [timer.py:215:stop] epoch=0/micro_step=2235/global_step=2235, RunningAvgSamplesPerSec=7.863674722188751, CurrSamplesPerSec=7.829561639795333, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2235/439453125 | consumed samples:         2235 | consumed tokens:      4577280 | elapsed time per iteration (ms): 151.2 | learning rate: 2.440E-06 | global batch size:     1 | lm loss: 8.448768E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.614 | TFLOPs: 16.43 |
[default0]:[2023-07-30 22:28:21,694] [INFO] [logging.py:96:log_dist] [Rank 0] step=2240, skipped=0, lr=[2.4455850666666668e-06, 2.4455850666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:21,694] [INFO] [timer.py:215:stop] epoch=0/micro_step=2240/global_step=2240, RunningAvgSamplesPerSec=7.863697413366652, CurrSamplesPerSec=7.841931286177962, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2240/439453125 | consumed samples:         2240 | consumed tokens:      4587520 | elapsed time per iteration (ms): 150.0 | learning rate: 2.446E-06 | global batch size:     1 | lm loss: 8.299670E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.665 | TFLOPs: 16.56 |
[default0]:[2023-07-30 22:28:22,444] [INFO] [logging.py:96:log_dist] [Rank 0] step=2245, skipped=0, lr=[2.4510464e-06, 2.4510464e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:22,445] [INFO] [timer.py:215:stop] epoch=0/micro_step=2245/global_step=2245, RunningAvgSamplesPerSec=7.863731565521346, CurrSamplesPerSec=7.865534241848585, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2245/439453125 | consumed samples:         2245 | consumed tokens:      4597760 | elapsed time per iteration (ms): 150.1 | learning rate: 2.451E-06 | global batch size:     1 | lm loss: 8.508444E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.662 | TFLOPs: 16.55 |
[default0]:[2023-07-30 22:28:23,228] [INFO] [logging.py:96:log_dist] [Rank 0] step=2250, skipped=0, lr=[2.4565077333333334e-06, 2.4565077333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:23,228] [INFO] [timer.py:215:stop] epoch=0/micro_step=2250/global_step=2250, RunningAvgSamplesPerSec=7.86377720741327, CurrSamplesPerSec=7.81557037975627, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2250/439453125 | consumed samples:         2250 | consumed tokens:      4608000 | elapsed time per iteration (ms): 156.7 | learning rate: 2.457E-06 | global batch size:     1 | lm loss: 8.285582E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.380 | TFLOPs: 15.85 |
[default0]:[2023-07-30 22:28:23,965] [INFO] [logging.py:96:log_dist] [Rank 0] step=2255, skipped=0, lr=[2.4619690666666667e-06, 2.4619690666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:23,966] [INFO] [timer.py:215:stop] epoch=0/micro_step=2255/global_step=2255, RunningAvgSamplesPerSec=7.863777421608943, CurrSamplesPerSec=7.918547201051199, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2255/439453125 | consumed samples:         2255 | consumed tokens:      4618240 | elapsed time per iteration (ms): 147.6 | learning rate: 2.462E-06 | global batch size:     1 | lm loss: 8.495763E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.776 | TFLOPs: 16.84 |
[default0]:[2023-07-30 22:28:24,700] [INFO] [logging.py:96:log_dist] [Rank 0] step=2260, skipped=0, lr=[2.4674304e-06, 2.4674304e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:24,700] [INFO] [timer.py:215:stop] epoch=0/micro_step=2260/global_step=2260, RunningAvgSamplesPerSec=7.863818790384857, CurrSamplesPerSec=7.923378885366803, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2260/439453125 | consumed samples:         2260 | consumed tokens:      4628480 | elapsed time per iteration (ms): 146.7 | learning rate: 2.467E-06 | global batch size:     1 | lm loss: 8.272029E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.818 | TFLOPs: 16.94 |
[default0]:[2023-07-30 22:28:25,474] [INFO] [logging.py:96:log_dist] [Rank 0] step=2265, skipped=0, lr=[2.4728917333333333e-06, 2.4728917333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:25,476] [INFO] [timer.py:215:stop] epoch=0/micro_step=2265/global_step=2265, RunningAvgSamplesPerSec=7.863637593581752, CurrSamplesPerSec=7.81303717722797, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2265/439453125 | consumed samples:         2265 | consumed tokens:      4638720 | elapsed time per iteration (ms): 155.3 | learning rate: 2.473E-06 | global batch size:     1 | lm loss: 8.316029E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.440 | TFLOPs: 16.00 |
[default0]:[2023-07-30 22:28:26,208] [INFO] [logging.py:96:log_dist] [Rank 0] step=2270, skipped=0, lr=[2.4783530666666667e-06, 2.4783530666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:26,208] [INFO] [timer.py:215:stop] epoch=0/micro_step=2270/global_step=2270, RunningAvgSamplesPerSec=7.863644465092876, CurrSamplesPerSec=7.88451915250382, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2270/439453125 | consumed samples:         2270 | consumed tokens:      4648960 | elapsed time per iteration (ms): 146.9 | learning rate: 2.478E-06 | global batch size:     1 | lm loss: 8.318745E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.809 | TFLOPs: 16.92 |
[default0]:[2023-07-30 22:28:27,006] [INFO] [logging.py:96:log_dist] [Rank 0] step=2275, skipped=0, lr=[2.4838144000000004e-06, 2.4838144000000004e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:27,007] [INFO] [timer.py:215:stop] epoch=0/micro_step=2275/global_step=2275, RunningAvgSamplesPerSec=7.863699726034369, CurrSamplesPerSec=7.852707808328434, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2275/439453125 | consumed samples:         2275 | consumed tokens:      4659200 | elapsed time per iteration (ms): 160.1 | learning rate: 2.484E-06 | global batch size:     1 | lm loss: 8.376367E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.247 | TFLOPs: 15.52 |
[default0]:[2023-07-30 22:28:27,761] [INFO] [logging.py:96:log_dist] [Rank 0] step=2280, skipped=0, lr=[2.4892757333333337e-06, 2.4892757333333337e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:27,762] [INFO] [timer.py:215:stop] epoch=0/micro_step=2280/global_step=2280, RunningAvgSamplesPerSec=7.863736856274016, CurrSamplesPerSec=7.8280711380862, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2280/439453125 | consumed samples:         2280 | consumed tokens:      4669440 | elapsed time per iteration (ms): 150.2 | learning rate: 2.489E-06 | global batch size:     1 | lm loss: 8.188002E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.659 | TFLOPs: 16.55 |
[default0]:[2023-07-30 22:28:28,498] [INFO] [logging.py:96:log_dist] [Rank 0] step=2285, skipped=0, lr=[2.494737066666667e-06, 2.494737066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:28,498] [INFO] [timer.py:215:stop] epoch=0/micro_step=2285/global_step=2285, RunningAvgSamplesPerSec=7.8638476266299175, CurrSamplesPerSec=7.9429602710334, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2285/439453125 | consumed samples:         2285 | consumed tokens:      4679680 | elapsed time per iteration (ms): 147.3 | learning rate: 2.495E-06 | global batch size:     1 | lm loss: 8.530565E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.791 | TFLOPs: 16.87 |
[default0]:[2023-07-30 22:28:29,261] [INFO] [logging.py:96:log_dist] [Rank 0] step=2290, skipped=0, lr=[2.5001984000000003e-06, 2.5001984000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:29,262] [INFO] [timer.py:215:stop] epoch=0/micro_step=2290/global_step=2290, RunningAvgSamplesPerSec=7.863885922433316, CurrSamplesPerSec=7.906396855766784, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2290/439453125 | consumed samples:         2290 | consumed tokens:      4689920 | elapsed time per iteration (ms): 152.9 | learning rate: 2.500E-06 | global batch size:     1 | lm loss: 8.292604E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.540 | TFLOPs: 16.25 |
[default0]:[2023-07-30 22:28:30,017] [INFO] [logging.py:96:log_dist] [Rank 0] step=2295, skipped=0, lr=[2.5056597333333337e-06, 2.5056597333333337e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:30,017] [INFO] [timer.py:215:stop] epoch=0/micro_step=2295/global_step=2295, RunningAvgSamplesPerSec=7.8639695573553094, CurrSamplesPerSec=7.911079423819412, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2295/439453125 | consumed samples:         2295 | consumed tokens:      4700160 | elapsed time per iteration (ms): 151.9 | learning rate: 2.506E-06 | global batch size:     1 | lm loss: 8.502808E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.581 | TFLOPs: 16.35 |
[default0]:[2023-07-30 22:28:30,817] [INFO] [logging.py:96:log_dist] [Rank 0] step=2300, skipped=0, lr=[2.511121066666667e-06, 2.511121066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:30,817] [INFO] [timer.py:215:stop] epoch=0/micro_step=2300/global_step=2300, RunningAvgSamplesPerSec=7.864085149004129, CurrSamplesPerSec=7.875429277424467, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2300/439453125 | consumed samples:         2300 | consumed tokens:      4710400 | elapsed time per iteration (ms): 159.4 | learning rate: 2.511E-06 | global batch size:     1 | lm loss: 8.311687E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.275 | TFLOPs: 15.59 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 2300 | lm loss value: 8.311310E+00 | lm loss PPL: 4.069640E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:28:34,279] [INFO] [logging.py:96:log_dist] [Rank 0] step=2305, skipped=0, lr=[2.5165824000000003e-06, 2.5165824000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:34,280] [INFO] [timer.py:215:stop] epoch=0/micro_step=2305/global_step=2305, RunningAvgSamplesPerSec=7.863667122280978, CurrSamplesPerSec=7.9473097824027406, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2305/439453125 | consumed samples:         2305 | consumed tokens:      4720640 | elapsed time per iteration (ms): 692.1 | learning rate: 2.517E-06 | global batch size:     1 | lm loss: 8.522324E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.445 | TFLOPs: 3.59 |
[default0]:[2023-07-30 22:28:35,041] [INFO] [logging.py:96:log_dist] [Rank 0] step=2310, skipped=0, lr=[2.5220437333333336e-06, 2.5220437333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:35,043] [INFO] [timer.py:215:stop] epoch=0/micro_step=2310/global_step=2310, RunningAvgSamplesPerSec=7.863625001459638, CurrSamplesPerSec=7.519800347097718, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2310/439453125 | consumed samples:         2310 | consumed tokens:      4730880 | elapsed time per iteration (ms): 152.9 | learning rate: 2.522E-06 | global batch size:     1 | lm loss: 8.254463E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.542 | TFLOPs: 16.26 |
[default0]:[2023-07-30 22:28:35,812] [INFO] [logging.py:96:log_dist] [Rank 0] step=2315, skipped=0, lr=[2.527505066666667e-06, 2.527505066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:35,813] [INFO] [timer.py:215:stop] epoch=0/micro_step=2315/global_step=2315, RunningAvgSamplesPerSec=7.863723049331262, CurrSamplesPerSec=7.837945314018328, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2315/439453125 | consumed samples:         2315 | consumed tokens:      4741120 | elapsed time per iteration (ms): 153.8 | learning rate: 2.528E-06 | global batch size:     1 | lm loss: 8.346016E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.502 | TFLOPs: 16.15 |
[default0]:[2023-07-30 22:28:36,568] [INFO] [logging.py:96:log_dist] [Rank 0] step=2320, skipped=0, lr=[2.5329664000000002e-06, 2.5329664000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:36,568] [INFO] [timer.py:215:stop] epoch=0/micro_step=2320/global_step=2320, RunningAvgSamplesPerSec=7.863947437856878, CurrSamplesPerSec=8.000732488936364, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2320/439453125 | consumed samples:         2320 | consumed tokens:      4751360 | elapsed time per iteration (ms): 151.0 | learning rate: 2.533E-06 | global batch size:     1 | lm loss: 8.232503E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.621 | TFLOPs: 16.45 |
[default0]:[2023-07-30 22:28:37,340] [INFO] [logging.py:96:log_dist] [Rank 0] step=2325, skipped=0, lr=[2.5384277333333335e-06, 2.5384277333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:37,341] [INFO] [timer.py:215:stop] epoch=0/micro_step=2325/global_step=2325, RunningAvgSamplesPerSec=7.863852468073885, CurrSamplesPerSec=7.84492342682717, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2325/439453125 | consumed samples:         2325 | consumed tokens:      4761600 | elapsed time per iteration (ms): 154.5 | learning rate: 2.538E-06 | global batch size:     1 | lm loss: 8.204764E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.473 | TFLOPs: 16.08 |
[default0]:[2023-07-30 22:28:38,089] [INFO] [logging.py:96:log_dist] [Rank 0] step=2330, skipped=0, lr=[2.543889066666667e-06, 2.543889066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:38,090] [INFO] [timer.py:215:stop] epoch=0/micro_step=2330/global_step=2330, RunningAvgSamplesPerSec=7.863862133974285, CurrSamplesPerSec=7.828202630115306, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2330/439453125 | consumed samples:         2330 | consumed tokens:      4771840 | elapsed time per iteration (ms): 150.0 | learning rate: 2.544E-06 | global batch size:     1 | lm loss: 8.227629E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.665 | TFLOPs: 16.56 |
[default0]:[2023-07-30 22:28:38,884] [INFO] [logging.py:96:log_dist] [Rank 0] step=2335, skipped=0, lr=[2.5493504e-06, 2.5493504e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:38,885] [INFO] [timer.py:215:stop] epoch=0/micro_step=2335/global_step=2335, RunningAvgSamplesPerSec=7.863983701354953, CurrSamplesPerSec=7.981518624096578, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2335/439453125 | consumed samples:         2335 | consumed tokens:      4782080 | elapsed time per iteration (ms): 158.8 | learning rate: 2.549E-06 | global batch size:     1 | lm loss: 8.085320E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.298 | TFLOPs: 15.65 |
[default0]:[2023-07-30 22:28:39,649] [INFO] [logging.py:96:log_dist] [Rank 0] step=2340, skipped=0, lr=[2.5548117333333335e-06, 2.5548117333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:39,651] [INFO] [timer.py:215:stop] epoch=0/micro_step=2340/global_step=2340, RunningAvgSamplesPerSec=7.863801158978922, CurrSamplesPerSec=7.844248529076226, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2340/439453125 | consumed samples:         2340 | consumed tokens:      4792320 | elapsed time per iteration (ms): 153.4 | learning rate: 2.555E-06 | global batch size:     1 | lm loss: 8.434754E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.521 | TFLOPs: 16.20 |
[default0]:[2023-07-30 22:28:40,397] [INFO] [logging.py:96:log_dist] [Rank 0] step=2345, skipped=0, lr=[2.560273066666667e-06, 2.560273066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:40,398] [INFO] [timer.py:215:stop] epoch=0/micro_step=2345/global_step=2345, RunningAvgSamplesPerSec=7.863805750148459, CurrSamplesPerSec=7.936317278309161, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2345/439453125 | consumed samples:         2345 | consumed tokens:      4802560 | elapsed time per iteration (ms): 149.3 | learning rate: 2.560E-06 | global batch size:     1 | lm loss: 8.161676E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.697 | TFLOPs: 16.64 |
[default0]:[2023-07-30 22:28:41,160] [INFO] [logging.py:96:log_dist] [Rank 0] step=2350, skipped=0, lr=[2.5657344e-06, 2.5657344e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:41,160] [INFO] [timer.py:215:stop] epoch=0/micro_step=2350/global_step=2350, RunningAvgSamplesPerSec=7.863780212861373, CurrSamplesPerSec=7.630446805414059, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2350/439453125 | consumed samples:         2350 | consumed tokens:      4812800 | elapsed time per iteration (ms): 152.6 | learning rate: 2.566E-06 | global batch size:     1 | lm loss: 8.137408E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.551 | TFLOPs: 16.28 |
[default0]:[2023-07-30 22:28:41,935] [INFO] [logging.py:96:log_dist] [Rank 0] step=2355, skipped=0, lr=[2.5711957333333334e-06, 2.5711957333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:41,935] [INFO] [timer.py:215:stop] epoch=0/micro_step=2355/global_step=2355, RunningAvgSamplesPerSec=7.863637358242483, CurrSamplesPerSec=7.931244835326086, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2355/439453125 | consumed samples:         2355 | consumed tokens:      4823040 | elapsed time per iteration (ms): 154.7 | learning rate: 2.571E-06 | global batch size:     1 | lm loss: 8.142211E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.463 | TFLOPs: 16.06 |
[default0]:[2023-07-30 22:28:42,679] [INFO] [logging.py:96:log_dist] [Rank 0] step=2360, skipped=0, lr=[2.5766570666666667e-06, 2.5766570666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:42,679] [INFO] [timer.py:215:stop] epoch=0/micro_step=2360/global_step=2360, RunningAvgSamplesPerSec=7.863632638720518, CurrSamplesPerSec=7.949539058709364, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2360/439453125 | consumed samples:         2360 | consumed tokens:      4833280 | elapsed time per iteration (ms): 148.7 | learning rate: 2.577E-06 | global batch size:     1 | lm loss: 8.142012E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.724 | TFLOPs: 16.71 |
[default0]:[2023-07-30 22:28:43,448] [INFO] [logging.py:96:log_dist] [Rank 0] step=2365, skipped=0, lr=[2.5821184e-06, 2.5821184e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:43,448] [INFO] [timer.py:215:stop] epoch=0/micro_step=2365/global_step=2365, RunningAvgSamplesPerSec=7.863574626386814, CurrSamplesPerSec=7.818221809654823, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2365/439453125 | consumed samples:         2365 | consumed tokens:      4843520 | elapsed time per iteration (ms): 154.0 | learning rate: 2.582E-06 | global batch size:     1 | lm loss: 8.269713E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.493 | TFLOPs: 16.13 |
[default0]:[2023-07-30 22:28:44,194] [INFO] [logging.py:96:log_dist] [Rank 0] step=2370, skipped=0, lr=[2.5875797333333334e-06, 2.5875797333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:44,195] [INFO] [timer.py:215:stop] epoch=0/micro_step=2370/global_step=2370, RunningAvgSamplesPerSec=7.863526111371309, CurrSamplesPerSec=7.725938779043851, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2370/439453125 | consumed samples:         2370 | consumed tokens:      4853760 | elapsed time per iteration (ms): 149.2 | learning rate: 2.588E-06 | global batch size:     1 | lm loss: 7.967213E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.702 | TFLOPs: 16.65 |
[default0]:[2023-07-30 22:28:44,953] [INFO] [logging.py:96:log_dist] [Rank 0] step=2375, skipped=0, lr=[2.5930410666666667e-06, 2.5930410666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:44,954] [INFO] [timer.py:215:stop] epoch=0/micro_step=2375/global_step=2375, RunningAvgSamplesPerSec=7.863631236370247, CurrSamplesPerSec=7.896394166053238, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2375/439453125 | consumed samples:         2375 | consumed tokens:      4864000 | elapsed time per iteration (ms): 152.1 | learning rate: 2.593E-06 | global batch size:     1 | lm loss: 8.117883E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.575 | TFLOPs: 16.34 |
[default0]:[2023-07-30 22:28:45,713] [INFO] [logging.py:96:log_dist] [Rank 0] step=2380, skipped=0, lr=[2.5985024e-06, 2.5985024e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:45,715] [INFO] [timer.py:215:stop] epoch=0/micro_step=2380/global_step=2380, RunningAvgSamplesPerSec=7.863643693160726, CurrSamplesPerSec=7.792048747863565, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2380/439453125 | consumed samples:         2380 | consumed tokens:      4874240 | elapsed time per iteration (ms): 152.2 | learning rate: 2.599E-06 | global batch size:     1 | lm loss: 8.298535E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.571 | TFLOPs: 16.33 |
[default0]: iteration     2385/439453125 | consumed samples:         2385 | consumed tokens:      4884480 | elapsed time per iteration (ms): 150.9 | learning rate: 2.604E-06 | global batch size:     1 | lm loss: 8.509973E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.625 | TFLOPs: 16.46 |
[default0]:[2023-07-30 22:28:47,219] [INFO] [logging.py:96:log_dist] [Rank 0] step=2390, skipped=0, lr=[2.6094250666666666e-06, 2.6094250666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:47,220] [INFO] [timer.py:215:stop] epoch=0/micro_step=2390/global_step=2390, RunningAvgSamplesPerSec=7.863908083357367, CurrSamplesPerSec=7.899561920618359, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2390/439453125 | consumed samples:         2390 | consumed tokens:      4894720 | elapsed time per iteration (ms): 150.1 | learning rate: 2.609E-06 | global batch size:     1 | lm loss: 8.088727E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.662 | TFLOPs: 16.55 |
[default0]:[2023-07-30 22:28:47,970] [INFO] [logging.py:96:log_dist] [Rank 0] step=2395, skipped=0, lr=[2.6148864e-06, 2.6148864e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:47,971] [INFO] [timer.py:215:stop] epoch=0/micro_step=2395/global_step=2395, RunningAvgSamplesPerSec=7.863904203869972, CurrSamplesPerSec=7.786566269198138, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2395/439453125 | consumed samples:         2395 | consumed tokens:      4904960 | elapsed time per iteration (ms): 149.7 | learning rate: 2.615E-06 | global batch size:     1 | lm loss: 8.246878E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.679 | TFLOPs: 16.60 |
[default0]:[2023-07-30 22:28:48,712] [INFO] [logging.py:96:log_dist] [Rank 0] step=2400, skipped=0, lr=[2.6203477333333333e-06, 2.6203477333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:48,713] [INFO] [timer.py:215:stop] epoch=0/micro_step=2400/global_step=2400, RunningAvgSamplesPerSec=7.863896055084518, CurrSamplesPerSec=7.849239648325654, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2400/439453125 | consumed samples:         2400 | consumed tokens:      4915200 | elapsed time per iteration (ms): 148.5 | learning rate: 2.620E-06 | global batch size:     1 | lm loss: 7.973740E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.735 | TFLOPs: 16.73 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 2400 | lm loss value: 8.282269E+00 | lm loss PPL: 3.953152E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:28:52,069] [INFO] [logging.py:96:log_dist] [Rank 0] step=2405, skipped=0, lr=[2.6258090666666666e-06, 2.6258090666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:52,069] [INFO] [timer.py:215:stop] epoch=0/micro_step=2405/global_step=2405, RunningAvgSamplesPerSec=7.8632865079334096, CurrSamplesPerSec=7.915125209941311, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2405/439453125 | consumed samples:         2405 | consumed tokens:      4925440 | elapsed time per iteration (ms): 671.2 | learning rate: 2.626E-06 | global batch size:     1 | lm loss: 8.171241E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.490 | TFLOPs: 3.70 |
[default0]:[2023-07-30 22:28:52,846] [INFO] [logging.py:96:log_dist] [Rank 0] step=2410, skipped=0, lr=[2.6312704e-06, 2.6312704e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:52,847] [INFO] [timer.py:215:stop] epoch=0/micro_step=2410/global_step=2410, RunningAvgSamplesPerSec=7.863397912097825, CurrSamplesPerSec=7.904534318344578, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2410/439453125 | consumed samples:         2410 | consumed tokens:      4935680 | elapsed time per iteration (ms): 155.4 | learning rate: 2.631E-06 | global batch size:     1 | lm loss: 8.276942E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.436 | TFLOPs: 15.99 |
[default0]:[2023-07-30 22:28:53,630] [INFO] [logging.py:96:log_dist] [Rank 0] step=2415, skipped=0, lr=[2.636731733333333e-06, 2.636731733333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:53,631] [INFO] [timer.py:215:stop] epoch=0/micro_step=2415/global_step=2415, RunningAvgSamplesPerSec=7.863525463749388, CurrSamplesPerSec=7.810127477962289, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2415/439453125 | consumed samples:         2415 | consumed tokens:      4945920 | elapsed time per iteration (ms): 157.3 | learning rate: 2.637E-06 | global batch size:     1 | lm loss: 8.104240E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.355 | TFLOPs: 15.79 |
[default0]:[2023-07-30 22:28:54,371] [INFO] [logging.py:96:log_dist] [Rank 0] step=2420, skipped=0, lr=[2.6421930666666665e-06, 2.6421930666666665e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:54,372] [INFO] [timer.py:215:stop] epoch=0/micro_step=2420/global_step=2420, RunningAvgSamplesPerSec=7.863555449723551, CurrSamplesPerSec=7.851752288992431, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2420/439453125 | consumed samples:         2420 | consumed tokens:      4956160 | elapsed time per iteration (ms): 148.0 | learning rate: 2.642E-06 | global batch size:     1 | lm loss: 8.209084E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.758 | TFLOPs: 16.79 |
[default0]:[2023-07-30 22:28:55,155] [INFO] [logging.py:96:log_dist] [Rank 0] step=2425, skipped=0, lr=[2.6476544000000003e-06, 2.6476544000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:55,156] [INFO] [timer.py:215:stop] epoch=0/micro_step=2425/global_step=2425, RunningAvgSamplesPerSec=7.863622178581697, CurrSamplesPerSec=7.819154608194417, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2425/439453125 | consumed samples:         2425 | consumed tokens:      4966400 | elapsed time per iteration (ms): 156.7 | learning rate: 2.648E-06 | global batch size:     1 | lm loss: 8.132411E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.382 | TFLOPs: 15.86 |
[default0]:[2023-07-30 22:28:55,928] [INFO] [logging.py:96:log_dist] [Rank 0] step=2430, skipped=0, lr=[2.6531157333333336e-06, 2.6531157333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:55,929] [INFO] [timer.py:215:stop] epoch=0/micro_step=2430/global_step=2430, RunningAvgSamplesPerSec=7.8637419052565125, CurrSamplesPerSec=7.883096550596452, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2430/439453125 | consumed samples:         2430 | consumed tokens:      4976640 | elapsed time per iteration (ms): 154.4 | learning rate: 2.653E-06 | global batch size:     1 | lm loss: 8.173010E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.478 | TFLOPs: 16.10 |
[default0]:[2023-07-30 22:28:56,683] [INFO] [logging.py:96:log_dist] [Rank 0] step=2435, skipped=0, lr=[2.658577066666667e-06, 2.658577066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:56,684] [INFO] [timer.py:215:stop] epoch=0/micro_step=2435/global_step=2435, RunningAvgSamplesPerSec=7.863898382081966, CurrSamplesPerSec=7.921882377827892, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2435/439453125 | consumed samples:         2435 | consumed tokens:      4986880 | elapsed time per iteration (ms): 151.3 | learning rate: 2.659E-06 | global batch size:     1 | lm loss: 8.108925E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.608 | TFLOPs: 16.42 |
[default0]:[2023-07-30 22:28:57,433] [INFO] [logging.py:96:log_dist] [Rank 0] step=2440, skipped=0, lr=[2.6640384e-06, 2.6640384e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:57,434] [INFO] [timer.py:215:stop] epoch=0/micro_step=2440/global_step=2440, RunningAvgSamplesPerSec=7.864038789246648, CurrSamplesPerSec=7.962910789208893, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2440/439453125 | consumed samples:         2440 | consumed tokens:      4997120 | elapsed time per iteration (ms): 149.6 | learning rate: 2.664E-06 | global batch size:     1 | lm loss: 8.751484E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.682 | TFLOPs: 16.60 |
[default0]:[2023-07-30 22:28:58,163] [INFO] [logging.py:96:log_dist] [Rank 0] step=2445, skipped=0, lr=[2.6694997333333335e-06, 2.6694997333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:58,163] [INFO] [timer.py:215:stop] epoch=0/micro_step=2445/global_step=2445, RunningAvgSamplesPerSec=7.8641379647618415, CurrSamplesPerSec=7.860934884915183, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2445/439453125 | consumed samples:         2445 | consumed tokens:      5007360 | elapsed time per iteration (ms): 145.9 | learning rate: 2.669E-06 | global batch size:     1 | lm loss: 8.248987E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.855 | TFLOPs: 17.03 |
[default0]:[2023-07-30 22:28:58,924] [INFO] [logging.py:96:log_dist] [Rank 0] step=2450, skipped=0, lr=[2.674961066666667e-06, 2.674961066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:58,926] [INFO] [timer.py:215:stop] epoch=0/micro_step=2450/global_step=2450, RunningAvgSamplesPerSec=7.8642033078962275, CurrSamplesPerSec=7.81777006536703, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2450/439453125 | consumed samples:         2450 | consumed tokens:      5017600 | elapsed time per iteration (ms): 152.6 | learning rate: 2.675E-06 | global batch size:     1 | lm loss: 8.043848E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.554 | TFLOPs: 16.28 |
[default0]:[2023-07-30 22:28:59,664] [INFO] [logging.py:96:log_dist] [Rank 0] step=2455, skipped=0, lr=[2.6804224e-06, 2.6804224e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:28:59,665] [INFO] [timer.py:215:stop] epoch=0/micro_step=2455/global_step=2455, RunningAvgSamplesPerSec=7.8644035192119555, CurrSamplesPerSec=7.912512144278748, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2455/439453125 | consumed samples:         2455 | consumed tokens:      5027840 | elapsed time per iteration (ms): 148.1 | learning rate: 2.680E-06 | global batch size:     1 | lm loss: 8.090579E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.754 | TFLOPs: 16.78 |
[default0]:[2023-07-30 22:29:00,452] [INFO] [logging.py:96:log_dist] [Rank 0] step=2460, skipped=0, lr=[2.6858837333333335e-06, 2.6858837333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:00,452] [INFO] [timer.py:215:stop] epoch=0/micro_step=2460/global_step=2460, RunningAvgSamplesPerSec=7.864583739919576, CurrSamplesPerSec=7.95176958602228, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2460/439453125 | consumed samples:         2460 | consumed tokens:      5038080 | elapsed time per iteration (ms): 157.3 | learning rate: 2.686E-06 | global batch size:     1 | lm loss: 8.110371E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.357 | TFLOPs: 15.80 |
[default0]:[2023-07-30 22:29:01,223] [INFO] [logging.py:96:log_dist] [Rank 0] step=2465, skipped=0, lr=[2.6913450666666668e-06, 2.6913450666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:01,223] [INFO] [timer.py:215:stop] epoch=0/micro_step=2465/global_step=2465, RunningAvgSamplesPerSec=7.864705314281297, CurrSamplesPerSec=7.905860355002818, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2465/439453125 | consumed samples:         2465 | consumed tokens:      5048320 | elapsed time per iteration (ms): 154.5 | learning rate: 2.691E-06 | global batch size:     1 | lm loss: 8.052906E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.474 | TFLOPs: 16.09 |
[default0]:[2023-07-30 22:29:01,989] [INFO] [logging.py:96:log_dist] [Rank 0] step=2470, skipped=0, lr=[2.6968064e-06, 2.6968064e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:01,989] [INFO] [timer.py:215:stop] epoch=0/micro_step=2470/global_step=2470, RunningAvgSamplesPerSec=7.864825838080576, CurrSamplesPerSec=7.859638602757233, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2470/439453125 | consumed samples:         2470 | consumed tokens:      5058560 | elapsed time per iteration (ms): 152.8 | learning rate: 2.697E-06 | global batch size:     1 | lm loss: 8.229518E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.543 | TFLOPs: 16.26 |
[default0]:[2023-07-30 22:29:02,743] [INFO] [logging.py:96:log_dist] [Rank 0] step=2475, skipped=0, lr=[2.7022677333333334e-06, 2.7022677333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:02,743] [INFO] [timer.py:215:stop] epoch=0/micro_step=2475/global_step=2475, RunningAvgSamplesPerSec=7.86490014968449, CurrSamplesPerSec=7.918547201051199, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2475/439453125 | consumed samples:         2475 | consumed tokens:      5068800 | elapsed time per iteration (ms): 150.8 | learning rate: 2.702E-06 | global batch size:     1 | lm loss: 8.274574E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.633 | TFLOPs: 16.48 |
[default0]:[2023-07-30 22:29:03,468] [INFO] [logging.py:96:log_dist] [Rank 0] step=2480, skipped=0, lr=[2.7077290666666667e-06, 2.7077290666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:03,469] [INFO] [timer.py:215:stop] epoch=0/micro_step=2480/global_step=2480, RunningAvgSamplesPerSec=7.8650369823891975, CurrSamplesPerSec=7.921568183062973, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2480/439453125 | consumed samples:         2480 | consumed tokens:      5079040 | elapsed time per iteration (ms): 145.2 | learning rate: 2.708E-06 | global batch size:     1 | lm loss: 8.021267E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.887 | TFLOPs: 17.11 |
[default0]:[2023-07-30 22:29:04,208] [INFO] [logging.py:96:log_dist] [Rank 0] step=2485, skipped=0, lr=[2.7131904e-06, 2.7131904e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:04,209] [INFO] [timer.py:215:stop] epoch=0/micro_step=2485/global_step=2485, RunningAvgSamplesPerSec=7.865071115479367, CurrSamplesPerSec=7.861391631617223, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2485/439453125 | consumed samples:         2485 | consumed tokens:      5089280 | elapsed time per iteration (ms): 147.9 | learning rate: 2.713E-06 | global batch size:     1 | lm loss: 8.358000E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.761 | TFLOPs: 16.80 |
[default0]:[2023-07-30 22:29:05,014] [INFO] [logging.py:96:log_dist] [Rank 0] step=2490, skipped=0, lr=[2.7186517333333333e-06, 2.7186517333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:05,015] [INFO] [timer.py:215:stop] epoch=0/micro_step=2490/global_step=2490, RunningAvgSamplesPerSec=7.865071500785315, CurrSamplesPerSec=7.8688249022565415, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2490/439453125 | consumed samples:         2490 | consumed tokens:      5099520 | elapsed time per iteration (ms): 161.6 | learning rate: 2.719E-06 | global batch size:     1 | lm loss: 8.149575E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.187 | TFLOPs: 15.37 |
[default0]:[2023-07-30 22:29:05,754] [INFO] [logging.py:96:log_dist] [Rank 0] step=2495, skipped=0, lr=[2.7241130666666667e-06, 2.7241130666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:05,755] [INFO] [timer.py:215:stop] epoch=0/micro_step=2495/global_step=2495, RunningAvgSamplesPerSec=7.865028645232884, CurrSamplesPerSec=7.846097438698623, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2495/439453125 | consumed samples:         2495 | consumed tokens:      5109760 | elapsed time per iteration (ms): 147.6 | learning rate: 2.724E-06 | global batch size:     1 | lm loss: 8.061562E+00 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.773 | TFLOPs: 16.83 |
[default0]:[2023-07-30 22:29:06,514] [INFO] [logging.py:96:log_dist] [Rank 0] step=2500, skipped=0, lr=[2.7295744e-06, 2.7295744e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:06,515] [INFO] [timer.py:215:stop] epoch=0/micro_step=2500/global_step=2500, RunningAvgSamplesPerSec=7.86504300029616, CurrSamplesPerSec=7.831579104605807, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2500/439453125 | consumed samples:         2500 | consumed tokens:      5120000 | elapsed time per iteration (ms): 151.9 | learning rate: 2.730E-06 | global batch size:     1 | lm loss: 8.130316E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.583 | TFLOPs: 16.36 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 2500 | lm loss value: 8.195493E+00 | lm loss PPL: 3.624577E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:29:10,113] [INFO] [logging.py:96:log_dist] [Rank 0] step=2505, skipped=0, lr=[2.7350357333333333e-06, 2.7350357333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:10,114] [INFO] [timer.py:215:stop] epoch=0/micro_step=2505/global_step=2505, RunningAvgSamplesPerSec=7.864652354615585, CurrSamplesPerSec=7.900052926894962, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2505/439453125 | consumed samples:         2505 | consumed tokens:      5130240 | elapsed time per iteration (ms): 719.8 | learning rate: 2.735E-06 | global batch size:     1 | lm loss: 8.047238E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.389 | TFLOPs: 3.45 |
[default0]:[2023-07-30 22:29:10,870] [INFO] [logging.py:96:log_dist] [Rank 0] step=2510, skipped=0, lr=[2.7404970666666666e-06, 2.7404970666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:10,872] [INFO] [timer.py:215:stop] epoch=0/micro_step=2510/global_step=2510, RunningAvgSamplesPerSec=7.864561798821754, CurrSamplesPerSec=7.688817925342846, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2510/439453125 | consumed samples:         2510 | consumed tokens:      5140480 | elapsed time per iteration (ms): 151.5 | learning rate: 2.740E-06 | global batch size:     1 | lm loss: 7.961167E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.601 | TFLOPs: 16.40 |
[default0]:[2023-07-30 22:29:11,638] [INFO] [logging.py:96:log_dist] [Rank 0] step=2515, skipped=0, lr=[2.7459584000000003e-06, 2.7459584000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:11,638] [INFO] [timer.py:215:stop] epoch=0/micro_step=2515/global_step=2515, RunningAvgSamplesPerSec=7.8645110559031615, CurrSamplesPerSec=7.979939346202288, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2515/439453125 | consumed samples:         2515 | consumed tokens:      5150720 | elapsed time per iteration (ms): 153.3 | learning rate: 2.746E-06 | global batch size:     1 | lm loss: 8.078535E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.523 | TFLOPs: 16.21 |
[default0]:[2023-07-30 22:29:12,400] [INFO] [logging.py:96:log_dist] [Rank 0] step=2520, skipped=0, lr=[2.7514197333333337e-06, 2.7514197333333337e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:12,401] [INFO] [timer.py:215:stop] epoch=0/micro_step=2520/global_step=2520, RunningAvgSamplesPerSec=7.864347244513128, CurrSamplesPerSec=7.663880778099773, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2520/439453125 | consumed samples:         2520 | consumed tokens:      5160960 | elapsed time per iteration (ms): 152.7 | learning rate: 2.751E-06 | global batch size:     1 | lm loss: 8.277368E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.550 | TFLOPs: 16.28 |
[default0]:[2023-07-30 22:29:13,182] [INFO] [logging.py:96:log_dist] [Rank 0] step=2525, skipped=0, lr=[2.756881066666667e-06, 2.756881066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:13,182] [INFO] [timer.py:215:stop] epoch=0/micro_step=2525/global_step=2525, RunningAvgSamplesPerSec=7.864161197244314, CurrSamplesPerSec=7.875532789809491, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2525/439453125 | consumed samples:         2525 | consumed tokens:      5171200 | elapsed time per iteration (ms): 156.1 | learning rate: 2.757E-06 | global batch size:     1 | lm loss: 7.822893E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.407 | TFLOPs: 15.92 |
[default0]:[2023-07-30 22:29:13,928] [INFO] [logging.py:96:log_dist] [Rank 0] step=2530, skipped=0, lr=[2.7623424000000003e-06, 2.7623424000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:13,929] [INFO] [timer.py:215:stop] epoch=0/micro_step=2530/global_step=2530, RunningAvgSamplesPerSec=7.864170427553652, CurrSamplesPerSec=7.877485247219416, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2530/439453125 | consumed samples:         2530 | consumed tokens:      5181440 | elapsed time per iteration (ms): 149.3 | learning rate: 2.762E-06 | global batch size:     1 | lm loss: 7.750410E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.699 | TFLOPs: 16.65 |
[default0]:[2023-07-30 22:29:14,683] [INFO] [logging.py:96:log_dist] [Rank 0] step=2535, skipped=0, lr=[2.7678037333333336e-06, 2.7678037333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:14,683] [INFO] [timer.py:215:stop] epoch=0/micro_step=2535/global_step=2535, RunningAvgSamplesPerSec=7.864043850359108, CurrSamplesPerSec=7.771316766595765, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2535/439453125 | consumed samples:         2535 | consumed tokens:      5191680 | elapsed time per iteration (ms): 151.2 | learning rate: 2.768E-06 | global batch size:     1 | lm loss: 7.931330E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.614 | TFLOPs: 16.43 |
[default0]:[2023-07-30 22:29:15,484] [INFO] [logging.py:96:log_dist] [Rank 0] step=2540, skipped=0, lr=[2.773265066666667e-06, 2.773265066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:15,485] [INFO] [timer.py:215:stop] epoch=0/micro_step=2540/global_step=2540, RunningAvgSamplesPerSec=7.86369221756175, CurrSamplesPerSec=7.872753687387614, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2540/439453125 | consumed samples:         2540 | consumed tokens:      5201920 | elapsed time per iteration (ms): 160.1 | learning rate: 2.773E-06 | global batch size:     1 | lm loss: 7.799466E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.245 | TFLOPs: 15.52 |
[default0]:[2023-07-30 22:29:16,289] [INFO] [logging.py:96:log_dist] [Rank 0] step=2545, skipped=0, lr=[2.7787264000000002e-06, 2.7787264000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:16,289] [INFO] [timer.py:215:stop] epoch=0/micro_step=2545/global_step=2545, RunningAvgSamplesPerSec=7.863765375322949, CurrSamplesPerSec=7.860551847957885, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2545/439453125 | consumed samples:         2545 | consumed tokens:      5212160 | elapsed time per iteration (ms): 160.6 | learning rate: 2.779E-06 | global batch size:     1 | lm loss: 8.091785E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.226 | TFLOPs: 15.47 |
[default0]:[2023-07-30 22:29:17,033] [INFO] [logging.py:96:log_dist] [Rank 0] step=2550, skipped=0, lr=[2.7841877333333335e-06, 2.7841877333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:17,033] [INFO] [timer.py:215:stop] epoch=0/micro_step=2550/global_step=2550, RunningAvgSamplesPerSec=7.863732739185789, CurrSamplesPerSec=7.7511531638083975, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2550/439453125 | consumed samples:         2550 | consumed tokens:      5222400 | elapsed time per iteration (ms): 150.1 | learning rate: 2.784E-06 | global batch size:     1 | lm loss: 7.902309E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.661 | TFLOPs: 16.55 |
[default0]:[2023-07-30 22:29:17,802] [INFO] [logging.py:96:log_dist] [Rank 0] step=2555, skipped=0, lr=[2.789649066666667e-06, 2.789649066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:17,803] [INFO] [timer.py:215:stop] epoch=0/micro_step=2555/global_step=2555, RunningAvgSamplesPerSec=7.863716937924018, CurrSamplesPerSec=7.924097409835446, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2555/439453125 | consumed samples:         2555 | consumed tokens:      5232640 | elapsed time per iteration (ms): 152.9 | learning rate: 2.790E-06 | global batch size:     1 | lm loss: 7.974411E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.538 | TFLOPs: 16.25 |
[default0]:[2023-07-30 22:29:18,534] [INFO] [logging.py:96:log_dist] [Rank 0] step=2560, skipped=0, lr=[2.7951104e-06, 2.7951104e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:18,534] [INFO] [timer.py:215:stop] epoch=0/micro_step=2560/global_step=2560, RunningAvgSamplesPerSec=7.8637305410760625, CurrSamplesPerSec=7.877218946024114, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2560/439453125 | consumed samples:         2560 | consumed tokens:      5242880 | elapsed time per iteration (ms): 146.1 | learning rate: 2.795E-06 | global batch size:     1 | lm loss: 7.909570E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.845 | TFLOPs: 17.01 |
[default0]:[2023-07-30 22:29:19,289] [INFO] [logging.py:96:log_dist] [Rank 0] step=2565, skipped=0, lr=[2.8005717333333335e-06, 2.8005717333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:19,290] [INFO] [timer.py:215:stop] epoch=0/micro_step=2565/global_step=2565, RunningAvgSamplesPerSec=7.86372421665514, CurrSamplesPerSec=7.729298811388556, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2565/439453125 | consumed samples:         2565 | consumed tokens:      5253120 | elapsed time per iteration (ms): 151.3 | learning rate: 2.801E-06 | global batch size:     1 | lm loss: 7.987360E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.611 | TFLOPs: 16.43 |
[default0]:[2023-07-30 22:29:20,037] [INFO] [logging.py:96:log_dist] [Rank 0] step=2570, skipped=0, lr=[2.806033066666667e-06, 2.806033066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:20,039] [INFO] [timer.py:215:stop] epoch=0/micro_step=2570/global_step=2570, RunningAvgSamplesPerSec=7.863675495544885, CurrSamplesPerSec=7.681298657060551, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2570/439453125 | consumed samples:         2570 | consumed tokens:      5263360 | elapsed time per iteration (ms): 149.7 | learning rate: 2.806E-06 | global batch size:     1 | lm loss: 8.052276E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.681 | TFLOPs: 16.60 |
[default0]:[2023-07-30 22:29:20,799] [INFO] [logging.py:96:log_dist] [Rank 0] step=2575, skipped=0, lr=[2.8114944e-06, 2.8114944e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:20,799] [INFO] [timer.py:215:stop] epoch=0/micro_step=2575/global_step=2575, RunningAvgSamplesPerSec=7.863707395647382, CurrSamplesPerSec=7.898416476627541, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2575/439453125 | consumed samples:         2575 | consumed tokens:      5273600 | elapsed time per iteration (ms): 151.9 | learning rate: 2.811E-06 | global batch size:     1 | lm loss: 8.038145E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.582 | TFLOPs: 16.35 |
[default0]:[2023-07-30 22:29:21,565] [INFO] [logging.py:96:log_dist] [Rank 0] step=2580, skipped=0, lr=[2.8169557333333334e-06, 2.8169557333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:21,566] [INFO] [timer.py:215:stop] epoch=0/micro_step=2580/global_step=2580, RunningAvgSamplesPerSec=7.8637544990509785, CurrSamplesPerSec=7.974507760987444, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2580/439453125 | consumed samples:         2580 | consumed tokens:      5283840 | elapsed time per iteration (ms): 153.3 | learning rate: 2.817E-06 | global batch size:     1 | lm loss: 8.067876E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.521 | TFLOPs: 16.20 |
[default0]:[2023-07-30 22:29:22,316] [INFO] [logging.py:96:log_dist] [Rank 0] step=2585, skipped=0, lr=[2.8224170666666667e-06, 2.8224170666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:22,317] [INFO] [timer.py:215:stop] epoch=0/micro_step=2585/global_step=2585, RunningAvgSamplesPerSec=7.863831444629777, CurrSamplesPerSec=7.883037286657507, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2585/439453125 | consumed samples:         2585 | consumed tokens:      5294080 | elapsed time per iteration (ms): 150.3 | learning rate: 2.822E-06 | global batch size:     1 | lm loss: 7.912202E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.655 | TFLOPs: 16.54 |
[default0]:[2023-07-30 22:29:23,087] [INFO] [logging.py:96:log_dist] [Rank 0] step=2590, skipped=0, lr=[2.8278784e-06, 2.8278784e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:23,088] [INFO] [timer.py:215:stop] epoch=0/micro_step=2590/global_step=2590, RunningAvgSamplesPerSec=7.863850571344722, CurrSamplesPerSec=7.930195139751524, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2590/439453125 | consumed samples:         2590 | consumed tokens:      5304320 | elapsed time per iteration (ms): 154.2 | learning rate: 2.828E-06 | global batch size:     1 | lm loss: 8.233765E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.484 | TFLOPs: 16.11 |
[default0]:[2023-07-30 22:29:23,815] [INFO] [logging.py:96:log_dist] [Rank 0] step=2595, skipped=0, lr=[2.8333397333333334e-06, 2.8333397333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:23,816] [INFO] [timer.py:215:stop] epoch=0/micro_step=2595/global_step=2595, RunningAvgSamplesPerSec=7.864013222357312, CurrSamplesPerSec=7.8112620028456705, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2595/439453125 | consumed samples:         2595 | consumed tokens:      5314560 | elapsed time per iteration (ms): 145.6 | learning rate: 2.833E-06 | global batch size:     1 | lm loss: 8.058354E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.867 | TFLOPs: 17.06 |
[default0]:[2023-07-30 22:29:24,586] [INFO] [logging.py:96:log_dist] [Rank 0] step=2600, skipped=0, lr=[2.8388010666666667e-06, 2.8388010666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:24,586] [INFO] [timer.py:215:stop] epoch=0/micro_step=2600/global_step=2600, RunningAvgSamplesPerSec=7.864066954802844, CurrSamplesPerSec=7.880519392676571, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2600/439453125 | consumed samples:         2600 | consumed tokens:      5324800 | elapsed time per iteration (ms): 154.0 | learning rate: 2.839E-06 | global batch size:     1 | lm loss: 8.066346E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.494 | TFLOPs: 16.14 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 2600 | lm loss value: 7.974008E+00 | lm loss PPL: 2.904475E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:29:28,078] [INFO] [logging.py:96:log_dist] [Rank 0] step=2605, skipped=0, lr=[2.8442624000000004e-06, 2.8442624000000004e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:28,079] [INFO] [timer.py:215:stop] epoch=0/micro_step=2605/global_step=2605, RunningAvgSamplesPerSec=7.86356256189695, CurrSamplesPerSec=7.871069442046555, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2605/439453125 | consumed samples:         2605 | consumed tokens:      5335040 | elapsed time per iteration (ms): 698.4 | learning rate: 2.844E-06 | global batch size:     1 | lm loss: 8.018772E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.432 | TFLOPs: 3.56 |
[default0]:[2023-07-30 22:29:28,861] [INFO] [logging.py:96:log_dist] [Rank 0] step=2610, skipped=0, lr=[2.8497237333333337e-06, 2.8497237333333337e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:28,862] [INFO] [timer.py:215:stop] epoch=0/micro_step=2610/global_step=2610, RunningAvgSamplesPerSec=7.863620790161849, CurrSamplesPerSec=7.8223773902307565, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2610/439453125 | consumed samples:         2610 | consumed tokens:      5345280 | elapsed time per iteration (ms): 156.7 | learning rate: 2.850E-06 | global batch size:     1 | lm loss: 7.729310E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.384 | TFLOPs: 15.86 |
[default0]:[2023-07-30 22:29:29,596] [INFO] [logging.py:96:log_dist] [Rank 0] step=2615, skipped=0, lr=[2.855185066666667e-06, 2.855185066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:29,597] [INFO] [timer.py:215:stop] epoch=0/micro_step=2615/global_step=2615, RunningAvgSamplesPerSec=7.863772707150642, CurrSamplesPerSec=7.921882377827892, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2615/439453125 | consumed samples:         2615 | consumed tokens:      5355520 | elapsed time per iteration (ms): 147.0 | learning rate: 2.855E-06 | global batch size:     1 | lm loss: 7.877682E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.801 | TFLOPs: 16.90 |
[default0]:[2023-07-30 22:29:30,357] [INFO] [logging.py:96:log_dist] [Rank 0] step=2620, skipped=0, lr=[2.8606464000000004e-06, 2.8606464000000004e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:30,357] [INFO] [timer.py:215:stop] epoch=0/micro_step=2620/global_step=2620, RunningAvgSamplesPerSec=7.863879935867016, CurrSamplesPerSec=7.852354974108203, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2620/439453125 | consumed samples:         2620 | consumed tokens:      5365760 | elapsed time per iteration (ms): 152.0 | learning rate: 2.861E-06 | global batch size:     1 | lm loss: 7.844449E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.579 | TFLOPs: 16.35 |
[default0]:[2023-07-30 22:29:31,122] [INFO] [logging.py:96:log_dist] [Rank 0] step=2625, skipped=0, lr=[2.8661077333333337e-06, 2.8661077333333337e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:31,123] [INFO] [timer.py:215:stop] epoch=0/micro_step=2625/global_step=2625, RunningAvgSamplesPerSec=7.863923442247955, CurrSamplesPerSec=7.889294548053682, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2625/439453125 | consumed samples:         2625 | consumed tokens:      5376000 | elapsed time per iteration (ms): 153.3 | learning rate: 2.866E-06 | global batch size:     1 | lm loss: 7.679774E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.521 | TFLOPs: 16.20 |
[default0]:[2023-07-30 22:29:31,875] [INFO] [logging.py:96:log_dist] [Rank 0] step=2630, skipped=0, lr=[2.871569066666667e-06, 2.871569066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:31,875] [INFO] [timer.py:215:stop] epoch=0/micro_step=2630/global_step=2630, RunningAvgSamplesPerSec=7.864060058477133, CurrSamplesPerSec=7.970234453088479, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2630/439453125 | consumed samples:         2630 | consumed tokens:      5386240 | elapsed time per iteration (ms): 150.3 | learning rate: 2.872E-06 | global batch size:     1 | lm loss: 8.299429E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.654 | TFLOPs: 16.53 |
[default0]:[2023-07-30 22:29:32,622] [INFO] [logging.py:96:log_dist] [Rank 0] step=2635, skipped=0, lr=[2.8770304000000003e-06, 2.8770304000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:32,623] [INFO] [timer.py:215:stop] epoch=0/micro_step=2635/global_step=2635, RunningAvgSamplesPerSec=7.864128332405844, CurrSamplesPerSec=7.928591141944387, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2635/439453125 | consumed samples:         2635 | consumed tokens:      5396480 | elapsed time per iteration (ms): 149.5 | learning rate: 2.877E-06 | global batch size:     1 | lm loss: 7.855128E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.687 | TFLOPs: 16.62 |
[default0]:[2023-07-30 22:29:33,372] [INFO] [logging.py:96:log_dist] [Rank 0] step=2640, skipped=0, lr=[2.8824917333333336e-06, 2.8824917333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:33,373] [INFO] [timer.py:215:stop] epoch=0/micro_step=2640/global_step=2640, RunningAvgSamplesPerSec=7.864182704725373, CurrSamplesPerSec=7.89269423577762, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2640/439453125 | consumed samples:         2640 | consumed tokens:      5406720 | elapsed time per iteration (ms): 150.7 | learning rate: 2.882E-06 | global batch size:     1 | lm loss: 7.867330E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.635 | TFLOPs: 16.49 |
[default0]:[2023-07-30 22:29:34,150] [INFO] [logging.py:96:log_dist] [Rank 0] step=2645, skipped=0, lr=[2.887953066666667e-06, 2.887953066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:34,151] [INFO] [timer.py:215:stop] epoch=0/micro_step=2645/global_step=2645, RunningAvgSamplesPerSec=7.864045494825108, CurrSamplesPerSec=7.894625493613609, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2645/439453125 | consumed samples:         2645 | consumed tokens:      5416960 | elapsed time per iteration (ms): 155.0 | learning rate: 2.888E-06 | global batch size:     1 | lm loss: 7.671182E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.453 | TFLOPs: 16.03 |
[default0]:[2023-07-30 22:29:34,912] [INFO] [logging.py:96:log_dist] [Rank 0] step=2650, skipped=0, lr=[2.8934144000000003e-06, 2.8934144000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:34,912] [INFO] [timer.py:215:stop] epoch=0/micro_step=2650/global_step=2650, RunningAvgSamplesPerSec=7.864202007271242, CurrSamplesPerSec=8.001037732249818, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2650/439453125 | consumed samples:         2650 | consumed tokens:      5427200 | elapsed time per iteration (ms): 152.2 | learning rate: 2.893E-06 | global batch size:     1 | lm loss: 7.825533E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.569 | TFLOPs: 16.32 |
[default0]:[2023-07-30 22:29:35,673] [INFO] [logging.py:96:log_dist] [Rank 0] step=2655, skipped=0, lr=[2.8988757333333336e-06, 2.8988757333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:35,674] [INFO] [timer.py:215:stop] epoch=0/micro_step=2655/global_step=2655, RunningAvgSamplesPerSec=7.8641385956947945, CurrSamplesPerSec=7.806115650183321, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2655/439453125 | consumed samples:         2655 | consumed tokens:      5437440 | elapsed time per iteration (ms): 152.4 | learning rate: 2.899E-06 | global batch size:     1 | lm loss: 7.915909E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.563 | TFLOPs: 16.31 |
[default0]:[2023-07-30 22:29:36,418] [INFO] [logging.py:96:log_dist] [Rank 0] step=2660, skipped=0, lr=[2.904337066666667e-06, 2.904337066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:36,418] [INFO] [timer.py:215:stop] epoch=0/micro_step=2660/global_step=2660, RunningAvgSamplesPerSec=7.864241257731086, CurrSamplesPerSec=7.895279364206896, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2660/439453125 | consumed samples:         2660 | consumed tokens:      5447680 | elapsed time per iteration (ms): 148.8 | learning rate: 2.904E-06 | global batch size:     1 | lm loss: 7.839254E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.722 | TFLOPs: 16.70 |
[default0]:[2023-07-30 22:29:37,200] [INFO] [logging.py:96:log_dist] [Rank 0] step=2665, skipped=0, lr=[2.9097984e-06, 2.9097984e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:37,201] [INFO] [timer.py:215:stop] epoch=0/micro_step=2665/global_step=2665, RunningAvgSamplesPerSec=7.864331947479511, CurrSamplesPerSec=7.8560171718515, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2665/439453125 | consumed samples:         2665 | consumed tokens:      5457920 | elapsed time per iteration (ms): 156.6 | learning rate: 2.910E-06 | global batch size:     1 | lm loss: 8.001901E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.387 | TFLOPs: 15.87 |
[default0]:[2023-07-30 22:29:37,957] [INFO] [logging.py:96:log_dist] [Rank 0] step=2670, skipped=0, lr=[2.9152597333333335e-06, 2.9152597333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:37,959] [INFO] [timer.py:215:stop] epoch=0/micro_step=2670/global_step=2670, RunningAvgSamplesPerSec=7.864280009856126, CurrSamplesPerSec=7.790659316165653, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2670/439453125 | consumed samples:         2670 | consumed tokens:      5468160 | elapsed time per iteration (ms): 151.4 | learning rate: 2.915E-06 | global batch size:     1 | lm loss: 7.771239E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.604 | TFLOPs: 16.41 |
[default0]:[2023-07-30 22:29:38,727] [INFO] [logging.py:96:log_dist] [Rank 0] step=2675, skipped=0, lr=[2.920721066666667e-06, 2.920721066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:38,727] [INFO] [timer.py:215:stop] epoch=0/micro_step=2675/global_step=2675, RunningAvgSamplesPerSec=7.864441993736146, CurrSamplesPerSec=7.991174907166958, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2675/439453125 | consumed samples:         2675 | consumed tokens:      5478400 | elapsed time per iteration (ms): 153.8 | learning rate: 2.921E-06 | global batch size:     1 | lm loss: 7.983968E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.503 | TFLOPs: 16.16 |
[default0]:[2023-07-30 22:29:39,475] [INFO] [logging.py:96:log_dist] [Rank 0] step=2680, skipped=0, lr=[2.9261824e-06, 2.9261824e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:39,476] [INFO] [timer.py:215:stop] epoch=0/micro_step=2680/global_step=2680, RunningAvgSamplesPerSec=7.864454450821949, CurrSamplesPerSec=7.875754611226174, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2680/439453125 | consumed samples:         2680 | consumed tokens:      5488640 | elapsed time per iteration (ms): 149.6 | learning rate: 2.926E-06 | global batch size:     1 | lm loss: 7.873128E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.686 | TFLOPs: 16.61 |
[default0]:[2023-07-30 22:29:40,221] [INFO] [logging.py:96:log_dist] [Rank 0] step=2685, skipped=0, lr=[2.9316437333333335e-06, 2.9316437333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:40,222] [INFO] [timer.py:215:stop] epoch=0/micro_step=2685/global_step=2685, RunningAvgSamplesPerSec=7.864520432784651, CurrSamplesPerSec=7.871497822076506, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2685/439453125 | consumed samples:         2685 | consumed tokens:      5498880 | elapsed time per iteration (ms): 149.2 | learning rate: 2.932E-06 | global batch size:     1 | lm loss: 7.759748E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.702 | TFLOPs: 16.65 |
[default0]:[2023-07-30 22:29:41,069] [INFO] [logging.py:96:log_dist] [Rank 0] step=2690, skipped=0, lr=[2.9371050666666668e-06, 2.9371050666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:41,070] [INFO] [timer.py:215:stop] epoch=0/micro_step=2690/global_step=2690, RunningAvgSamplesPerSec=7.864548497610228, CurrSamplesPerSec=7.806536989024365, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2690/439453125 | consumed samples:         2690 | consumed tokens:      5509120 | elapsed time per iteration (ms): 169.6 | learning rate: 2.937E-06 | global batch size:     1 | lm loss: 7.916628E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.895 | TFLOPs: 14.65 |
[default0]:[2023-07-30 22:29:41,885] [INFO] [logging.py:96:log_dist] [Rank 0] step=2695, skipped=0, lr=[2.9425664000000005e-06, 2.9425664000000005e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:41,885] [INFO] [timer.py:215:stop] epoch=0/micro_step=2695/global_step=2695, RunningAvgSamplesPerSec=7.864585931715674, CurrSamplesPerSec=7.890541254907715, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2695/439453125 | consumed samples:         2695 | consumed tokens:      5519360 | elapsed time per iteration (ms): 163.3 | learning rate: 2.943E-06 | global batch size:     1 | lm loss: 8.105237E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.125 | TFLOPs: 15.22 |
[default0]:[2023-07-30 22:29:42,636] [INFO] [logging.py:96:log_dist] [Rank 0] step=2700, skipped=0, lr=[2.948027733333334e-06, 2.948027733333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:42,636] [INFO] [timer.py:215:stop] epoch=0/micro_step=2700/global_step=2700, RunningAvgSamplesPerSec=7.864575587775485, CurrSamplesPerSec=7.891550782418583, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2700/439453125 | consumed samples:         2700 | consumed tokens:      5529600 | elapsed time per iteration (ms): 150.1 | learning rate: 2.948E-06 | global batch size:     1 | lm loss: 7.865871E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.662 | TFLOPs: 16.55 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 2700 | lm loss value: 7.864854E+00 | lm loss PPL: 2.604131E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:29:46,291] [INFO] [logging.py:96:log_dist] [Rank 0] step=2705, skipped=0, lr=[2.953489066666667e-06, 2.953489066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:46,292] [INFO] [timer.py:215:stop] epoch=0/micro_step=2705/global_step=2705, RunningAvgSamplesPerSec=7.864276390798093, CurrSamplesPerSec=7.941862358603818, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2705/439453125 | consumed samples:         2705 | consumed tokens:      5539840 | elapsed time per iteration (ms): 731.1 | learning rate: 2.953E-06 | global batch size:     1 | lm loss: 8.018098E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.368 | TFLOPs: 3.40 |
[default0]:[2023-07-30 22:29:47,040] [INFO] [logging.py:96:log_dist] [Rank 0] step=2710, skipped=0, lr=[2.9589504000000005e-06, 2.9589504000000005e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:47,042] [INFO] [timer.py:215:stop] epoch=0/micro_step=2710/global_step=2710, RunningAvgSamplesPerSec=7.864442337383111, CurrSamplesPerSec=7.8764941062029, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2710/439453125 | consumed samples:         2710 | consumed tokens:      5550080 | elapsed time per iteration (ms): 149.9 | learning rate: 2.959E-06 | global batch size:     1 | lm loss: 7.841415E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.670 | TFLOPs: 16.57 |
[default0]:[2023-07-30 22:29:47,790] [INFO] [logging.py:96:log_dist] [Rank 0] step=2715, skipped=0, lr=[2.9644117333333338e-06, 2.9644117333333338e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:47,791] [INFO] [timer.py:215:stop] epoch=0/micro_step=2715/global_step=2715, RunningAvgSamplesPerSec=7.864469569499933, CurrSamplesPerSec=7.874616060499102, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2715/439453125 | consumed samples:         2715 | consumed tokens:      5560320 | elapsed time per iteration (ms): 149.8 | learning rate: 2.964E-06 | global batch size:     1 | lm loss: 7.847176E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.675 | TFLOPs: 16.59 |
[default0]:[2023-07-30 22:29:48,554] [INFO] [logging.py:96:log_dist] [Rank 0] step=2720, skipped=0, lr=[2.969873066666667e-06, 2.969873066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:48,555] [INFO] [timer.py:215:stop] epoch=0/micro_step=2720/global_step=2720, RunningAvgSamplesPerSec=7.864517866191431, CurrSamplesPerSec=7.899547042593063, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2720/439453125 | consumed samples:         2720 | consumed tokens:      5570560 | elapsed time per iteration (ms): 152.9 | learning rate: 2.970E-06 | global batch size:     1 | lm loss: 7.771892E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.539 | TFLOPs: 16.25 |
[default0]:[2023-07-30 22:29:49,307] [INFO] [logging.py:96:log_dist] [Rank 0] step=2725, skipped=0, lr=[2.9753344000000004e-06, 2.9753344000000004e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:49,308] [INFO] [timer.py:215:stop] epoch=0/micro_step=2725/global_step=2725, RunningAvgSamplesPerSec=7.864546869288257, CurrSamplesPerSec=7.889353906113336, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2725/439453125 | consumed samples:         2725 | consumed tokens:      5580800 | elapsed time per iteration (ms): 150.5 | learning rate: 2.975E-06 | global batch size:     1 | lm loss: 7.856268E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.644 | TFLOPs: 16.51 |
[default0]:[2023-07-30 22:29:50,053] [INFO] [logging.py:96:log_dist] [Rank 0] step=2730, skipped=0, lr=[2.9807957333333337e-06, 2.9807957333333337e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:50,053] [INFO] [timer.py:215:stop] epoch=0/micro_step=2730/global_step=2730, RunningAvgSamplesPerSec=7.864605670341367, CurrSamplesPerSec=7.874734336159571, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2730/439453125 | consumed samples:         2730 | consumed tokens:      5591040 | elapsed time per iteration (ms): 149.1 | learning rate: 2.981E-06 | global batch size:     1 | lm loss: 7.781830E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.707 | TFLOPs: 16.67 |
[default0]:[2023-07-30 22:29:50,804] [INFO] [logging.py:96:log_dist] [Rank 0] step=2735, skipped=0, lr=[2.986257066666667e-06, 2.986257066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:50,804] [INFO] [timer.py:215:stop] epoch=0/micro_step=2735/global_step=2735, RunningAvgSamplesPerSec=7.864686882031579, CurrSamplesPerSec=7.935806739081489, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2735/439453125 | consumed samples:         2735 | consumed tokens:      5601280 | elapsed time per iteration (ms): 150.5 | learning rate: 2.986E-06 | global batch size:     1 | lm loss: 7.938277E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.645 | TFLOPs: 16.51 |
[default0]:[2023-07-30 22:29:51,532] [INFO] [logging.py:96:log_dist] [Rank 0] step=2740, skipped=0, lr=[2.9917184000000003e-06, 2.9917184000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:51,533] [INFO] [timer.py:215:stop] epoch=0/micro_step=2740/global_step=2740, RunningAvgSamplesPerSec=7.864727182031296, CurrSamplesPerSec=7.84046538406897, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2740/439453125 | consumed samples:         2740 | consumed tokens:      5611520 | elapsed time per iteration (ms): 145.7 | learning rate: 2.992E-06 | global batch size:     1 | lm loss: 7.670608E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.861 | TFLOPs: 17.05 |
[default0]:[2023-07-30 22:29:52,260] [INFO] [logging.py:96:log_dist] [Rank 0] step=2745, skipped=0, lr=[2.9971797333333337e-06, 2.9971797333333337e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:52,260] [INFO] [timer.py:215:stop] epoch=0/micro_step=2745/global_step=2745, RunningAvgSamplesPerSec=7.864781566697812, CurrSamplesPerSec=7.877514837352566, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2745/439453125 | consumed samples:         2745 | consumed tokens:      5621760 | elapsed time per iteration (ms): 145.3 | learning rate: 2.997E-06 | global batch size:     1 | lm loss: 7.706844E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.882 | TFLOPs: 17.10 |
[default0]:[2023-07-30 22:29:53,011] [INFO] [logging.py:96:log_dist] [Rank 0] step=2750, skipped=0, lr=[3.002641066666667e-06, 3.002641066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:53,011] [INFO] [timer.py:215:stop] epoch=0/micro_step=2750/global_step=2750, RunningAvgSamplesPerSec=7.864856855901731, CurrSamplesPerSec=7.95085009544499, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2750/439453125 | consumed samples:         2750 | consumed tokens:      5632000 | elapsed time per iteration (ms): 150.0 | learning rate: 3.003E-06 | global batch size:     1 | lm loss: 7.777737E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.666 | TFLOPs: 16.56 |
[default0]:[2023-07-30 22:29:53,835] [INFO] [logging.py:96:log_dist] [Rank 0] step=2755, skipped=0, lr=[3.0081024000000003e-06, 3.0081024000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:53,836] [INFO] [timer.py:215:stop] epoch=0/micro_step=2755/global_step=2755, RunningAvgSamplesPerSec=7.864954099425474, CurrSamplesPerSec=7.875355341672519, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2755/439453125 | consumed samples:         2755 | consumed tokens:      5642240 | elapsed time per iteration (ms): 165.3 | learning rate: 3.008E-06 | global batch size:     1 | lm loss: 7.966647E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.050 | TFLOPs: 15.03 |
[default0]:[2023-07-30 22:29:54,586] [INFO] [logging.py:96:log_dist] [Rank 0] step=2760, skipped=0, lr=[3.0135637333333336e-06, 3.0135637333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:54,587] [INFO] [timer.py:215:stop] epoch=0/micro_step=2760/global_step=2760, RunningAvgSamplesPerSec=7.864964583823534, CurrSamplesPerSec=7.922136744226457, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2760/439453125 | consumed samples:         2760 | consumed tokens:      5652480 | elapsed time per iteration (ms): 149.8 | learning rate: 3.014E-06 | global batch size:     1 | lm loss: 7.773504E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.677 | TFLOPs: 16.59 |
[default0]:[2023-07-30 22:29:55,400] [INFO] [logging.py:96:log_dist] [Rank 0] step=2765, skipped=0, lr=[3.019025066666667e-06, 3.019025066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:55,401] [INFO] [timer.py:215:stop] epoch=0/micro_step=2765/global_step=2765, RunningAvgSamplesPerSec=7.863905544000971, CurrSamplesPerSec=5.5262960952446205, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2765/439453125 | consumed samples:         2765 | consumed tokens:      5662720 | elapsed time per iteration (ms): 162.8 | learning rate: 3.019E-06 | global batch size:     1 | lm loss: 8.089088E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.142 | TFLOPs: 15.26 |
[default0]:[2023-07-30 22:29:56,186] [INFO] [logging.py:96:log_dist] [Rank 0] step=2770, skipped=0, lr=[3.0244864000000002e-06, 3.0244864000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:56,187] [INFO] [timer.py:215:stop] epoch=0/micro_step=2770/global_step=2770, RunningAvgSamplesPerSec=7.863998974899145, CurrSamplesPerSec=7.9283513475708185, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2770/439453125 | consumed samples:         2770 | consumed tokens:      5672960 | elapsed time per iteration (ms): 157.6 | learning rate: 3.024E-06 | global batch size:     1 | lm loss: 7.780885E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.344 | TFLOPs: 15.76 |
[default0]:[2023-07-30 22:29:56,958] [INFO] [logging.py:96:log_dist] [Rank 0] step=2775, skipped=0, lr=[3.0299477333333335e-06, 3.0299477333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:56,959] [INFO] [timer.py:215:stop] epoch=0/micro_step=2775/global_step=2775, RunningAvgSamplesPerSec=7.864089524110865, CurrSamplesPerSec=7.935146138754723, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2775/439453125 | consumed samples:         2775 | consumed tokens:      5683200 | elapsed time per iteration (ms): 154.0 | learning rate: 3.030E-06 | global batch size:     1 | lm loss: 7.738370E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.494 | TFLOPs: 16.14 |
[default0]:[2023-07-30 22:29:57,714] [INFO] [logging.py:96:log_dist] [Rank 0] step=2780, skipped=0, lr=[3.035409066666667e-06, 3.035409066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:57,716] [INFO] [timer.py:215:stop] epoch=0/micro_step=2780/global_step=2780, RunningAvgSamplesPerSec=7.864075043828784, CurrSamplesPerSec=7.577894531447609, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2780/439453125 | consumed samples:         2780 | consumed tokens:      5693440 | elapsed time per iteration (ms): 151.5 | learning rate: 3.035E-06 | global batch size:     1 | lm loss: 8.178326E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.600 | TFLOPs: 16.40 |
[default0]:[2023-07-30 22:29:58,466] [INFO] [logging.py:96:log_dist] [Rank 0] step=2785, skipped=0, lr=[3.0408704000000006e-06, 3.0408704000000006e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:58,467] [INFO] [timer.py:215:stop] epoch=0/micro_step=2785/global_step=2785, RunningAvgSamplesPerSec=7.8641472618012855, CurrSamplesPerSec=7.894476901764741, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2785/439453125 | consumed samples:         2785 | consumed tokens:      5703680 | elapsed time per iteration (ms): 150.0 | learning rate: 3.041E-06 | global batch size:     1 | lm loss: 7.776888E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.666 | TFLOPs: 16.56 |
[default0]:[2023-07-30 22:29:59,208] [INFO] [logging.py:96:log_dist] [Rank 0] step=2790, skipped=0, lr=[3.046331733333334e-06, 3.046331733333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:59,208] [INFO] [timer.py:215:stop] epoch=0/micro_step=2790/global_step=2790, RunningAvgSamplesPerSec=7.864246808628384, CurrSamplesPerSec=7.904042754869943, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2790/439453125 | consumed samples:         2790 | consumed tokens:      5713920 | elapsed time per iteration (ms): 148.2 | learning rate: 3.046E-06 | global batch size:     1 | lm loss: 7.679833E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.750 | TFLOPs: 16.77 |
[default0]:[2023-07-30 22:29:59,943] [INFO] [logging.py:96:log_dist] [Rank 0] step=2795, skipped=0, lr=[3.0517930666666672e-06, 3.0517930666666672e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:29:59,944] [INFO] [timer.py:215:stop] epoch=0/micro_step=2795/global_step=2795, RunningAvgSamplesPerSec=7.864331292833402, CurrSamplesPerSec=7.948861105899431, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2795/439453125 | consumed samples:         2795 | consumed tokens:      5724160 | elapsed time per iteration (ms): 147.0 | learning rate: 3.052E-06 | global batch size:     1 | lm loss: 7.685428E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.801 | TFLOPs: 16.90 |
[default0]:[2023-07-30 22:30:00,674] [INFO] [logging.py:96:log_dist] [Rank 0] step=2800, skipped=0, lr=[3.0572544000000005e-06, 3.0572544000000005e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:00,675] [INFO] [timer.py:215:stop] epoch=0/micro_step=2800/global_step=2800, RunningAvgSamplesPerSec=7.86439889695391, CurrSamplesPerSec=7.952508347253322, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2800/439453125 | consumed samples:         2800 | consumed tokens:      5734400 | elapsed time per iteration (ms): 146.3 | learning rate: 3.057E-06 | global batch size:     1 | lm loss: 7.691234E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.834 | TFLOPs: 16.98 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 2800 | lm loss value: 7.865778E+00 | lm loss PPL: 2.606539E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:30:04,270] [INFO] [logging.py:96:log_dist] [Rank 0] step=2805, skipped=0, lr=[3.062715733333334e-06, 3.062715733333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:04,270] [INFO] [timer.py:215:stop] epoch=0/micro_step=2805/global_step=2805, RunningAvgSamplesPerSec=7.863902738669458, CurrSamplesPerSec=7.875621516876718, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2805/439453125 | consumed samples:         2805 | consumed tokens:      5744640 | elapsed time per iteration (ms): 718.9 | learning rate: 3.063E-06 | global batch size:     1 | lm loss: 7.581349E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.391 | TFLOPs: 3.46 |
[default0]:[2023-07-30 22:30:05,011] [INFO] [logging.py:96:log_dist] [Rank 0] step=2810, skipped=0, lr=[3.068177066666667e-06, 3.068177066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:05,012] [INFO] [timer.py:215:stop] epoch=0/micro_step=2810/global_step=2810, RunningAvgSamplesPerSec=7.863949544753984, CurrSamplesPerSec=7.865371993504131, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2810/439453125 | consumed samples:         2810 | consumed tokens:      5754880 | elapsed time per iteration (ms): 148.4 | learning rate: 3.068E-06 | global batch size:     1 | lm loss: 7.699279E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.737 | TFLOPs: 16.74 |
[default0]:[2023-07-30 22:30:05,783] [INFO] [logging.py:96:log_dist] [Rank 0] step=2815, skipped=0, lr=[3.0736384000000005e-06, 3.0736384000000005e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:05,785] [INFO] [timer.py:215:stop] epoch=0/micro_step=2815/global_step=2815, RunningAvgSamplesPerSec=7.8638839919421235, CurrSamplesPerSec=7.8445126056706815, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2815/439453125 | consumed samples:         2815 | consumed tokens:      5765120 | elapsed time per iteration (ms): 154.6 | learning rate: 3.074E-06 | global batch size:     1 | lm loss: 7.757899E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.470 | TFLOPs: 16.08 |
[default0]:[2023-07-30 22:30:06,543] [INFO] [logging.py:96:log_dist] [Rank 0] step=2820, skipped=0, lr=[3.079099733333334e-06, 3.079099733333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:06,543] [INFO] [timer.py:215:stop] epoch=0/micro_step=2820/global_step=2820, RunningAvgSamplesPerSec=7.863944885922084, CurrSamplesPerSec=7.92671813431355, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2820/439453125 | consumed samples:         2820 | consumed tokens:      5775360 | elapsed time per iteration (ms): 151.7 | learning rate: 3.079E-06 | global batch size:     1 | lm loss: 7.705508E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.590 | TFLOPs: 16.37 |
[default0]:[2023-07-30 22:30:07,307] [INFO] [logging.py:96:log_dist] [Rank 0] step=2825, skipped=0, lr=[3.084561066666667e-06, 3.084561066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:07,307] [INFO] [timer.py:215:stop] epoch=0/micro_step=2825/global_step=2825, RunningAvgSamplesPerSec=7.86398419805521, CurrSamplesPerSec=7.855811174521596, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2825/439453125 | consumed samples:         2825 | consumed tokens:      5785600 | elapsed time per iteration (ms): 152.7 | learning rate: 3.085E-06 | global batch size:     1 | lm loss: 8.027809E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.550 | TFLOPs: 16.28 |
[default0]:[2023-07-30 22:30:08,037] [INFO] [logging.py:96:log_dist] [Rank 0] step=2830, skipped=0, lr=[3.0900224000000004e-06, 3.0900224000000004e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:08,038] [INFO] [timer.py:215:stop] epoch=0/micro_step=2830/global_step=2830, RunningAvgSamplesPerSec=7.864057433151363, CurrSamplesPerSec=7.782621926328368, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2830/439453125 | consumed samples:         2830 | consumed tokens:      5795840 | elapsed time per iteration (ms): 146.3 | learning rate: 3.090E-06 | global batch size:     1 | lm loss: 7.726397E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.837 | TFLOPs: 16.99 |
[default0]:[2023-07-30 22:30:08,803] [INFO] [logging.py:96:log_dist] [Rank 0] step=2835, skipped=0, lr=[3.0954837333333337e-06, 3.0954837333333337e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:08,803] [INFO] [timer.py:215:stop] epoch=0/micro_step=2835/global_step=2835, RunningAvgSamplesPerSec=7.864086197497319, CurrSamplesPerSec=7.8533841625536445, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2835/439453125 | consumed samples:         2835 | consumed tokens:      5806080 | elapsed time per iteration (ms): 153.1 | learning rate: 3.095E-06 | global batch size:     1 | lm loss: 7.765676E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.533 | TFLOPs: 16.23 |
[default0]:[2023-07-30 22:30:09,548] [INFO] [logging.py:96:log_dist] [Rank 0] step=2840, skipped=0, lr=[3.100945066666667e-06, 3.100945066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:09,548] [INFO] [timer.py:215:stop] epoch=0/micro_step=2840/global_step=2840, RunningAvgSamplesPerSec=7.864130608292195, CurrSamplesPerSec=7.916589280725994, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2840/439453125 | consumed samples:         2840 | consumed tokens:      5816320 | elapsed time per iteration (ms): 149.7 | learning rate: 3.101E-06 | global batch size:     1 | lm loss: 7.775134E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.682 | TFLOPs: 16.60 |
[default0]:[2023-07-30 22:30:10,322] [INFO] [logging.py:96:log_dist] [Rank 0] step=2845, skipped=0, lr=[3.1064064e-06, 3.1064064e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:10,323] [INFO] [timer.py:215:stop] epoch=0/micro_step=2845/global_step=2845, RunningAvgSamplesPerSec=7.864201573644083, CurrSamplesPerSec=7.803907997216547, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2845/439453125 | consumed samples:         2845 | consumed tokens:      5826560 | elapsed time per iteration (ms): 154.2 | learning rate: 3.106E-06 | global batch size:     1 | lm loss: 7.602878E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.486 | TFLOPs: 16.12 |
[default0]:[2023-07-30 22:30:11,065] [INFO] [logging.py:96:log_dist] [Rank 0] step=2850, skipped=0, lr=[3.1118677333333333e-06, 3.1118677333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:11,066] [INFO] [timer.py:215:stop] epoch=0/micro_step=2850/global_step=2850, RunningAvgSamplesPerSec=7.864262541938903, CurrSamplesPerSec=7.789574167380133, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2850/439453125 | consumed samples:         2850 | consumed tokens:      5836800 | elapsed time per iteration (ms): 148.7 | learning rate: 3.112E-06 | global batch size:     1 | lm loss: 7.758649E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.725 | TFLOPs: 16.71 |
[default0]:[2023-07-30 22:30:11,826] [INFO] [logging.py:96:log_dist] [Rank 0] step=2855, skipped=0, lr=[3.1173290666666666e-06, 3.1173290666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:11,827] [INFO] [timer.py:215:stop] epoch=0/micro_step=2855/global_step=2855, RunningAvgSamplesPerSec=7.864425763501838, CurrSamplesPerSec=7.986792470794337, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2855/439453125 | consumed samples:         2855 | consumed tokens:      5847040 | elapsed time per iteration (ms): 152.1 | learning rate: 3.117E-06 | global batch size:     1 | lm loss: 7.734835E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.574 | TFLOPs: 16.34 |
[default0]:[2023-07-30 22:30:12,590] [INFO] [logging.py:96:log_dist] [Rank 0] step=2860, skipped=0, lr=[3.1227904e-06, 3.1227904e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:12,590] [INFO] [timer.py:215:stop] epoch=0/micro_step=2860/global_step=2860, RunningAvgSamplesPerSec=7.8644173937099815, CurrSamplesPerSec=7.864206952025064, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2860/439453125 | consumed samples:         2860 | consumed tokens:      5857280 | elapsed time per iteration (ms): 152.7 | learning rate: 3.123E-06 | global batch size:     1 | lm loss: 7.588834E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.549 | TFLOPs: 16.27 |
[default0]:[2023-07-30 22:30:13,353] [INFO] [logging.py:96:log_dist] [Rank 0] step=2865, skipped=0, lr=[3.128251733333333e-06, 3.128251733333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:13,354] [INFO] [timer.py:215:stop] epoch=0/micro_step=2865/global_step=2865, RunningAvgSamplesPerSec=7.864449546753722, CurrSamplesPerSec=7.906277627082222, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2865/439453125 | consumed samples:         2865 | consumed tokens:      5867520 | elapsed time per iteration (ms): 152.7 | learning rate: 3.128E-06 | global batch size:     1 | lm loss: 7.694572E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.549 | TFLOPs: 16.27 |
[default0]:[2023-07-30 22:30:14,122] [INFO] [logging.py:96:log_dist] [Rank 0] step=2870, skipped=0, lr=[3.1337130666666665e-06, 3.1337130666666665e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:14,123] [INFO] [timer.py:215:stop] epoch=0/micro_step=2870/global_step=2870, RunningAvgSamplesPerSec=7.864437365005053, CurrSamplesPerSec=7.75736054316083, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2870/439453125 | consumed samples:         2870 | consumed tokens:      5877760 | elapsed time per iteration (ms): 153.8 | learning rate: 3.134E-06 | global batch size:     1 | lm loss: 7.560663E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.502 | TFLOPs: 16.16 |
[default0]:[2023-07-30 22:30:14,876] [INFO] [logging.py:96:log_dist] [Rank 0] step=2875, skipped=0, lr=[3.1391744e-06, 3.1391744e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:14,876] [INFO] [timer.py:215:stop] epoch=0/micro_step=2875/global_step=2875, RunningAvgSamplesPerSec=7.864453598876846, CurrSamplesPerSec=7.903685292560258, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2875/439453125 | consumed samples:         2875 | consumed tokens:      5888000 | elapsed time per iteration (ms): 150.7 | learning rate: 3.139E-06 | global batch size:     1 | lm loss: 7.700336E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.636 | TFLOPs: 16.49 |
[default0]:[2023-07-30 22:30:15,637] [INFO] [logging.py:96:log_dist] [Rank 0] step=2880, skipped=0, lr=[3.144635733333333e-06, 3.144635733333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:15,638] [INFO] [timer.py:215:stop] epoch=0/micro_step=2880/global_step=2880, RunningAvgSamplesPerSec=7.864492438834169, CurrSamplesPerSec=7.833070942608332, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2880/439453125 | consumed samples:         2880 | consumed tokens:      5898240 | elapsed time per iteration (ms): 152.3 | learning rate: 3.145E-06 | global batch size:     1 | lm loss: 7.599843E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.566 | TFLOPs: 16.32 |
[default0]:[2023-07-30 22:30:16,394] [INFO] [logging.py:96:log_dist] [Rank 0] step=2885, skipped=0, lr=[3.1500970666666665e-06, 3.1500970666666665e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:16,394] [INFO] [timer.py:215:stop] epoch=0/micro_step=2885/global_step=2885, RunningAvgSamplesPerSec=7.86452599881933, CurrSamplesPerSec=7.8197231414588675, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2885/439453125 | consumed samples:         2885 | consumed tokens:      5908480 | elapsed time per iteration (ms): 151.2 | learning rate: 3.150E-06 | global batch size:     1 | lm loss: 7.657892E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.613 | TFLOPs: 16.43 |
[default0]:[2023-07-30 22:30:17,150] [INFO] [logging.py:96:log_dist] [Rank 0] step=2890, skipped=0, lr=[3.1555583999999998e-06, 3.1555583999999998e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:17,150] [INFO] [timer.py:215:stop] epoch=0/micro_step=2890/global_step=2890, RunningAvgSamplesPerSec=7.864578243693065, CurrSamplesPerSec=7.857209225650786, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2890/439453125 | consumed samples:         2890 | consumed tokens:      5918720 | elapsed time per iteration (ms): 151.2 | learning rate: 3.156E-06 | global batch size:     1 | lm loss: 7.538554E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.613 | TFLOPs: 16.43 |
[default0]:[2023-07-30 22:30:17,890] [INFO] [logging.py:96:log_dist] [Rank 0] step=2895, skipped=0, lr=[3.161019733333333e-06, 3.161019733333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:17,890] [INFO] [timer.py:215:stop] epoch=0/micro_step=2895/global_step=2895, RunningAvgSamplesPerSec=7.864686670966928, CurrSamplesPerSec=7.889695232290856, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2895/439453125 | consumed samples:         2895 | consumed tokens:      5928960 | elapsed time per iteration (ms): 148.1 | learning rate: 3.161E-06 | global batch size:     1 | lm loss: 7.782962E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.752 | TFLOPs: 16.78 |
[default0]:[2023-07-30 22:30:18,645] [INFO] [logging.py:96:log_dist] [Rank 0] step=2900, skipped=0, lr=[3.1664810666666664e-06, 3.1664810666666664e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:18,645] [INFO] [timer.py:215:stop] epoch=0/micro_step=2900/global_step=2900, RunningAvgSamplesPerSec=7.8647116378079165, CurrSamplesPerSec=7.864280678596607, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2900/439453125 | consumed samples:         2900 | consumed tokens:      5939200 | elapsed time per iteration (ms): 151.1 | learning rate: 3.166E-06 | global batch size:     1 | lm loss: 7.681091E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.616 | TFLOPs: 16.44 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 2900 | lm loss value: 7.698184E+00 | lm loss PPL: 2.204341E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:30:21,979] [INFO] [logging.py:96:log_dist] [Rank 0] step=2905, skipped=0, lr=[3.1719423999999997e-06, 3.1719423999999997e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:21,979] [INFO] [timer.py:215:stop] epoch=0/micro_step=2905/global_step=2905, RunningAvgSamplesPerSec=7.864295104074403, CurrSamplesPerSec=7.842752430815258, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2905/439453125 | consumed samples:         2905 | consumed tokens:      5949440 | elapsed time per iteration (ms): 666.5 | learning rate: 3.172E-06 | global batch size:     1 | lm loss: 7.550127E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.500 | TFLOPs: 3.73 |
[default0]:[2023-07-30 22:30:22,742] [INFO] [logging.py:96:log_dist] [Rank 0] step=2910, skipped=0, lr=[3.177403733333333e-06, 3.177403733333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:22,743] [INFO] [timer.py:215:stop] epoch=0/micro_step=2910/global_step=2910, RunningAvgSamplesPerSec=7.864305722620694, CurrSamplesPerSec=7.852090369249893, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2910/439453125 | consumed samples:         2910 | consumed tokens:      5959680 | elapsed time per iteration (ms): 152.8 | learning rate: 3.177E-06 | global batch size:     1 | lm loss: 7.360532E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.543 | TFLOPs: 16.26 |
[default0]:[2023-07-30 22:30:23,475] [INFO] [logging.py:96:log_dist] [Rank 0] step=2915, skipped=0, lr=[3.1828650666666668e-06, 3.1828650666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:23,476] [INFO] [timer.py:215:stop] epoch=0/micro_step=2915/global_step=2915, RunningAvgSamplesPerSec=7.86438490547326, CurrSamplesPerSec=7.921074498783786, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2915/439453125 | consumed samples:         2915 | consumed tokens:      5969920 | elapsed time per iteration (ms): 146.7 | learning rate: 3.183E-06 | global batch size:     1 | lm loss: 7.981425E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.815 | TFLOPs: 16.93 |
[default0]:[2023-07-30 22:30:24,206] [INFO] [logging.py:96:log_dist] [Rank 0] step=2920, skipped=0, lr=[3.1883264e-06, 3.1883264e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:24,206] [INFO] [timer.py:215:stop] epoch=0/micro_step=2920/global_step=2920, RunningAvgSamplesPerSec=7.8643851008300585, CurrSamplesPerSec=7.862202119304112, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2920/439453125 | consumed samples:         2920 | consumed tokens:      5980160 | elapsed time per iteration (ms): 146.2 | learning rate: 3.188E-06 | global batch size:     1 | lm loss: 8.283781E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.840 | TFLOPs: 17.00 |
[default0]:[2023-07-30 22:30:24,964] [INFO] [logging.py:96:log_dist] [Rank 0] step=2925, skipped=0, lr=[3.1937877333333334e-06, 3.1937877333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:24,965] [INFO] [timer.py:215:stop] epoch=0/micro_step=2925/global_step=2925, RunningAvgSamplesPerSec=7.864438013654593, CurrSamplesPerSec=7.9490117520861325, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2925/439453125 | consumed samples:         2925 | consumed tokens:      5990400 | elapsed time per iteration (ms): 151.3 | learning rate: 3.194E-06 | global batch size:     1 | lm loss: 7.608449E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.610 | TFLOPs: 16.42 |
[default0]:[2023-07-30 22:30:25,706] [INFO] [logging.py:96:log_dist] [Rank 0] step=2930, skipped=0, lr=[3.1992490666666667e-06, 3.1992490666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:25,708] [INFO] [timer.py:215:stop] epoch=0/micro_step=2930/global_step=2930, RunningAvgSamplesPerSec=7.864298143536154, CurrSamplesPerSec=7.7422108187431355, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2930/439453125 | consumed samples:         2930 | consumed tokens:      6000640 | elapsed time per iteration (ms): 148.8 | learning rate: 3.199E-06 | global batch size:     1 | lm loss: 7.690855E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.719 | TFLOPs: 16.69 |
[default0]:[2023-07-30 22:30:26,461] [INFO] [logging.py:96:log_dist] [Rank 0] step=2935, skipped=0, lr=[3.2047104e-06, 3.2047104e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:26,462] [INFO] [timer.py:215:stop] epoch=0/micro_step=2935/global_step=2935, RunningAvgSamplesPerSec=7.864344245936872, CurrSamplesPerSec=7.884741480434325, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2935/439453125 | consumed samples:         2935 | consumed tokens:      6010880 | elapsed time per iteration (ms): 150.6 | learning rate: 3.205E-06 | global batch size:     1 | lm loss: 7.802498E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.642 | TFLOPs: 16.50 |
[default0]:[2023-07-30 22:30:27,190] [INFO] [logging.py:96:log_dist] [Rank 0] step=2940, skipped=0, lr=[3.2101717333333333e-06, 3.2101717333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:27,191] [INFO] [timer.py:215:stop] epoch=0/micro_step=2940/global_step=2940, RunningAvgSamplesPerSec=7.864391346331126, CurrSamplesPerSec=7.912452437232238, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2940/439453125 | consumed samples:         2940 | consumed tokens:      6021120 | elapsed time per iteration (ms): 145.7 | learning rate: 3.210E-06 | global batch size:     1 | lm loss: 7.647134E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.862 | TFLOPs: 17.05 |
[default0]:[2023-07-30 22:30:27,933] [INFO] [logging.py:96:log_dist] [Rank 0] step=2945, skipped=0, lr=[3.2156330666666667e-06, 3.2156330666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:27,934] [INFO] [timer.py:215:stop] epoch=0/micro_step=2945/global_step=2945, RunningAvgSamplesPerSec=7.864448694167119, CurrSamplesPerSec=7.9060838881390945, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2945/439453125 | consumed samples:         2945 | consumed tokens:      6031360 | elapsed time per iteration (ms): 148.6 | learning rate: 3.216E-06 | global batch size:     1 | lm loss: 7.603999E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.731 | TFLOPs: 16.72 |
[default0]:[2023-07-30 22:30:28,667] [INFO] [logging.py:96:log_dist] [Rank 0] step=2950, skipped=0, lr=[3.2210944e-06, 3.2210944e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:28,667] [INFO] [timer.py:215:stop] epoch=0/micro_step=2950/global_step=2950, RunningAvgSamplesPerSec=7.864492912801478, CurrSamplesPerSec=7.87877262353129, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2950/439453125 | consumed samples:         2950 | consumed tokens:      6041600 | elapsed time per iteration (ms): 146.8 | learning rate: 3.221E-06 | global batch size:     1 | lm loss: 7.935950E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.814 | TFLOPs: 16.93 |
[default0]:[2023-07-30 22:30:29,417] [INFO] [logging.py:96:log_dist] [Rank 0] step=2955, skipped=0, lr=[3.2265557333333333e-06, 3.2265557333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:29,417] [INFO] [timer.py:215:stop] epoch=0/micro_step=2955/global_step=2955, RunningAvgSamplesPerSec=7.864524273228044, CurrSamplesPerSec=7.962049177371499, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2955/439453125 | consumed samples:         2955 | consumed tokens:      6051840 | elapsed time per iteration (ms): 150.2 | learning rate: 3.227E-06 | global batch size:     1 | lm loss: 7.756580E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.656 | TFLOPs: 16.54 |
[default0]:[2023-07-30 22:30:30,166] [INFO] [logging.py:96:log_dist] [Rank 0] step=2960, skipped=0, lr=[3.2320170666666666e-06, 3.2320170666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:30,166] [INFO] [timer.py:215:stop] epoch=0/micro_step=2960/global_step=2960, RunningAvgSamplesPerSec=7.864605809825234, CurrSamplesPerSec=7.917321519245398, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2960/439453125 | consumed samples:         2960 | consumed tokens:      6062080 | elapsed time per iteration (ms): 149.6 | learning rate: 3.232E-06 | global batch size:     1 | lm loss: 7.600658E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.686 | TFLOPs: 16.61 |
[default0]:[2023-07-30 22:30:30,903] [INFO] [logging.py:96:log_dist] [Rank 0] step=2965, skipped=0, lr=[3.2374784e-06, 3.2374784e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:30,904] [INFO] [timer.py:215:stop] epoch=0/micro_step=2965/global_step=2965, RunningAvgSamplesPerSec=7.8646609236283105, CurrSamplesPerSec=7.854134169748607, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2965/439453125 | consumed samples:         2965 | consumed tokens:      6072320 | elapsed time per iteration (ms): 147.9 | learning rate: 3.237E-06 | global batch size:     1 | lm loss: 7.765060E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.763 | TFLOPs: 16.80 |
[default0]:[2023-07-30 22:30:31,654] [INFO] [logging.py:96:log_dist] [Rank 0] step=2970, skipped=0, lr=[3.2429397333333332e-06, 3.2429397333333332e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:31,654] [INFO] [timer.py:215:stop] epoch=0/micro_step=2970/global_step=2970, RunningAvgSamplesPerSec=7.864808514777034, CurrSamplesPerSec=7.963455061193026, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2970/439453125 | consumed samples:         2970 | consumed tokens:      6082560 | elapsed time per iteration (ms): 149.6 | learning rate: 3.243E-06 | global batch size:     1 | lm loss: 7.805237E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.683 | TFLOPs: 16.61 |
[default0]:[2023-07-30 22:30:32,415] [INFO] [logging.py:96:log_dist] [Rank 0] step=2975, skipped=0, lr=[3.2484010666666665e-06, 3.2484010666666665e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:32,416] [INFO] [timer.py:215:stop] epoch=0/micro_step=2975/global_step=2975, RunningAvgSamplesPerSec=7.864945525069548, CurrSamplesPerSec=7.935776709407774, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2975/439453125 | consumed samples:         2975 | consumed tokens:      6092800 | elapsed time per iteration (ms): 152.5 | learning rate: 3.248E-06 | global batch size:     1 | lm loss: 7.367676E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.556 | TFLOPs: 16.29 |
[default0]:[2023-07-30 22:30:33,179] [INFO] [logging.py:96:log_dist] [Rank 0] step=2980, skipped=0, lr=[3.2538624e-06, 3.2538624e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:33,180] [INFO] [timer.py:215:stop] epoch=0/micro_step=2980/global_step=2980, RunningAvgSamplesPerSec=7.865047863565235, CurrSamplesPerSec=7.87986796447741, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2980/439453125 | consumed samples:         2980 | consumed tokens:      6103040 | elapsed time per iteration (ms): 152.8 | learning rate: 3.254E-06 | global batch size:     1 | lm loss: 7.604456E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.543 | TFLOPs: 16.26 |
[default0]:[2023-07-30 22:30:33,933] [INFO] [logging.py:96:log_dist] [Rank 0] step=2985, skipped=0, lr=[3.259323733333333e-06, 3.259323733333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:33,934] [INFO] [timer.py:215:stop] epoch=0/micro_step=2985/global_step=2985, RunningAvgSamplesPerSec=7.865180397474791, CurrSamplesPerSec=7.868721566126052, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2985/439453125 | consumed samples:         2985 | consumed tokens:      6113280 | elapsed time per iteration (ms): 150.7 | learning rate: 3.259E-06 | global batch size:     1 | lm loss: 7.265110E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.637 | TFLOPs: 16.49 |
[default0]:[2023-07-30 22:30:34,675] [INFO] [logging.py:96:log_dist] [Rank 0] step=2990, skipped=0, lr=[3.2647850666666665e-06, 3.2647850666666665e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:34,675] [INFO] [timer.py:215:stop] epoch=0/micro_step=2990/global_step=2990, RunningAvgSamplesPerSec=7.8652838131419625, CurrSamplesPerSec=7.9483790764706, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2990/439453125 | consumed samples:         2990 | consumed tokens:      6123520 | elapsed time per iteration (ms): 148.2 | learning rate: 3.265E-06 | global batch size:     1 | lm loss: 7.744699E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.749 | TFLOPs: 16.77 |
[default0]:[2023-07-30 22:30:35,406] [INFO] [logging.py:96:log_dist] [Rank 0] step=2995, skipped=0, lr=[3.2702464e-06, 3.2702464e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:35,407] [INFO] [timer.py:215:stop] epoch=0/micro_step=2995/global_step=2995, RunningAvgSamplesPerSec=7.865363280785422, CurrSamplesPerSec=7.894595774796344, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     2995/439453125 | consumed samples:         2995 | consumed tokens:      6133760 | elapsed time per iteration (ms): 146.6 | learning rate: 3.270E-06 | global batch size:     1 | lm loss: 7.781438E+00 | loss scale: 65536.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.820 | TFLOPs: 16.95 |
[default0]:[2023-07-30 22:30:36,137] [INFO] [logging.py:96:log_dist] [Rank 0] step=3000, skipped=0, lr=[3.2757077333333335e-06, 3.2757077333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:36,138] [INFO] [timer.py:215:stop] epoch=0/micro_step=3000/global_step=3000, RunningAvgSamplesPerSec=7.8654111257478, CurrSamplesPerSec=7.895873886016996, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3000/439453125 | consumed samples:         3000 | consumed tokens:      6144000 | elapsed time per iteration (ms): 145.9 | learning rate: 3.276E-06 | global batch size:     1 | lm loss: 7.796114E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.853 | TFLOPs: 17.03 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 3000 | lm loss value: 7.669748E+00 | lm loss PPL: 2.142541E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:30:39,557] [INFO] [logging.py:96:log_dist] [Rank 0] step=3005, skipped=0, lr=[3.281169066666667e-06, 3.281169066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:39,558] [INFO] [timer.py:215:stop] epoch=0/micro_step=3005/global_step=3005, RunningAvgSamplesPerSec=7.8647900999537015, CurrSamplesPerSec=7.7559547694555135, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3005/439453125 | consumed samples:         3005 | consumed tokens:      6154240 | elapsed time per iteration (ms): 684.2 | learning rate: 3.281E-06 | global batch size:     1 | lm loss: 7.342090E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.462 | TFLOPs: 3.63 |
[default0]:[2023-07-30 22:30:40,305] [INFO] [logging.py:96:log_dist] [Rank 0] step=3010, skipped=0, lr=[3.2866304e-06, 3.2866304e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:40,305] [INFO] [timer.py:215:stop] epoch=0/micro_step=3010/global_step=3010, RunningAvgSamplesPerSec=7.864827793534686, CurrSamplesPerSec=7.86100855014825, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3010/439453125 | consumed samples:         3010 | consumed tokens:      6164480 | elapsed time per iteration (ms): 149.3 | learning rate: 3.287E-06 | global batch size:     1 | lm loss: 7.509265E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.698 | TFLOPs: 16.64 |
[default0]:[2023-07-30 22:30:41,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=3015, skipped=0, lr=[3.2920917333333335e-06, 3.2920917333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:41,053] [INFO] [timer.py:215:stop] epoch=0/micro_step=3015/global_step=3015, RunningAvgSamplesPerSec=7.864789843210857, CurrSamplesPerSec=7.704778122514361, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3015/439453125 | consumed samples:         3015 | consumed tokens:      6174720 | elapsed time per iteration (ms): 149.9 | learning rate: 3.292E-06 | global batch size:     1 | lm loss: 7.864438E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.672 | TFLOPs: 16.58 |
[default0]:[2023-07-30 22:30:41,827] [INFO] [logging.py:96:log_dist] [Rank 0] step=3020, skipped=0, lr=[3.297553066666667e-06, 3.297553066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:41,829] [INFO] [timer.py:215:stop] epoch=0/micro_step=3020/global_step=3020, RunningAvgSamplesPerSec=7.8648287170180256, CurrSamplesPerSec=7.871172839853697, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3020/439453125 | consumed samples:         3020 | consumed tokens:      6184960 | elapsed time per iteration (ms): 155.0 | learning rate: 3.298E-06 | global batch size:     1 | lm loss: 7.569568E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.452 | TFLOPs: 16.03 |
[default0]:[2023-07-30 22:30:42,670] [INFO] [logging.py:96:log_dist] [Rank 0] step=3025, skipped=0, lr=[3.3030144e-06, 3.3030144e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:42,670] [INFO] [timer.py:215:stop] epoch=0/micro_step=3025/global_step=3025, RunningAvgSamplesPerSec=7.864838879688129, CurrSamplesPerSec=7.896855042776238, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3025/439453125 | consumed samples:         3025 | consumed tokens:      6195200 | elapsed time per iteration (ms): 168.2 | learning rate: 3.303E-06 | global batch size:     1 | lm loss: 7.575790E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.945 | TFLOPs: 14.77 |
[default0]:[2023-07-30 22:30:43,436] [INFO] [logging.py:96:log_dist] [Rank 0] step=3030, skipped=0, lr=[3.3084757333333334e-06, 3.3084757333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:43,437] [INFO] [timer.py:215:stop] epoch=0/micro_step=3030/global_step=3030, RunningAvgSamplesPerSec=7.864850255645713, CurrSamplesPerSec=7.9318147864484345, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3030/439453125 | consumed samples:         3030 | consumed tokens:      6205440 | elapsed time per iteration (ms): 153.4 | learning rate: 3.308E-06 | global batch size:     1 | lm loss: 7.631976E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.519 | TFLOPs: 16.20 |
[default0]:[2023-07-30 22:30:44,281] [INFO] [logging.py:96:log_dist] [Rank 0] step=3035, skipped=0, lr=[3.3139370666666667e-06, 3.3139370666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:44,281] [INFO] [timer.py:215:stop] epoch=0/micro_step=3035/global_step=3035, RunningAvgSamplesPerSec=7.864885463677245, CurrSamplesPerSec=7.919279801824663, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3035/439453125 | consumed samples:         3035 | consumed tokens:      6215680 | elapsed time per iteration (ms): 168.7 | learning rate: 3.314E-06 | global batch size:     1 | lm loss: 7.583051E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.929 | TFLOPs: 14.73 |
[default0]:[2023-07-30 22:30:45,111] [INFO] [logging.py:96:log_dist] [Rank 0] step=3040, skipped=0, lr=[3.3193984e-06, 3.3193984e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:45,111] [INFO] [timer.py:215:stop] epoch=0/micro_step=3040/global_step=3040, RunningAvgSamplesPerSec=7.864927813556033, CurrSamplesPerSec=7.893674602427779, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3040/439453125 | consumed samples:         3040 | consumed tokens:      6225920 | elapsed time per iteration (ms): 166.1 | learning rate: 3.319E-06 | global batch size:     1 | lm loss: 7.657893E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.020 | TFLOPs: 14.96 |
[default0]:[2023-07-30 22:30:45,892] [INFO] [logging.py:96:log_dist] [Rank 0] step=3045, skipped=0, lr=[3.3248597333333334e-06, 3.3248597333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:45,893] [INFO] [timer.py:215:stop] epoch=0/micro_step=3045/global_step=3045, RunningAvgSamplesPerSec=7.8649754722380045, CurrSamplesPerSec=7.824960448941822, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3045/439453125 | consumed samples:         3045 | consumed tokens:      6236160 | elapsed time per iteration (ms): 156.8 | learning rate: 3.325E-06 | global batch size:     1 | lm loss: 7.380492E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.377 | TFLOPs: 15.85 |
[default0]:[2023-07-30 22:30:46,623] [INFO] [logging.py:96:log_dist] [Rank 0] step=3050, skipped=0, lr=[3.3303210666666667e-06, 3.3303210666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:46,623] [INFO] [timer.py:215:stop] epoch=0/micro_step=3050/global_step=3050, RunningAvgSamplesPerSec=7.865020691287276, CurrSamplesPerSec=7.946436488058474, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3050/439453125 | consumed samples:         3050 | consumed tokens:      6246400 | elapsed time per iteration (ms): 145.4 | learning rate: 3.330E-06 | global batch size:     1 | lm loss: 7.816769E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.879 | TFLOPs: 17.09 |
[default0]:[2023-07-30 22:30:47,352] [INFO] [logging.py:96:log_dist] [Rank 0] step=3055, skipped=0, lr=[3.3357824e-06, 3.3357824e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:47,352] [INFO] [timer.py:215:stop] epoch=0/micro_step=3055/global_step=3055, RunningAvgSamplesPerSec=7.86506945346448, CurrSamplesPerSec=7.8903779732566806, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3055/439453125 | consumed samples:         3055 | consumed tokens:      6256640 | elapsed time per iteration (ms): 145.8 | learning rate: 3.336E-06 | global batch size:     1 | lm loss: 7.648205E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.857 | TFLOPs: 17.04 |
[default0]:[2023-07-30 22:30:48,087] [INFO] [logging.py:96:log_dist] [Rank 0] step=3060, skipped=0, lr=[3.3412437333333333e-06, 3.3412437333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:48,087] [INFO] [timer.py:215:stop] epoch=0/micro_step=3060/global_step=3060, RunningAvgSamplesPerSec=7.865138824479729, CurrSamplesPerSec=7.897509282760803, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3060/439453125 | consumed samples:         3060 | consumed tokens:      6266880 | elapsed time per iteration (ms): 147.2 | learning rate: 3.341E-06 | global batch size:     1 | lm loss: 7.877189E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.792 | TFLOPs: 16.88 |
[default0]:[2023-07-30 22:30:48,849] [INFO] [logging.py:96:log_dist] [Rank 0] step=3065, skipped=0, lr=[3.3467050666666666e-06, 3.3467050666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:48,852] [INFO] [timer.py:215:stop] epoch=0/micro_step=3065/global_step=3065, RunningAvgSamplesPerSec=7.86514531546574, CurrSamplesPerSec=7.767344701402984, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3065/439453125 | consumed samples:         3065 | consumed tokens:      6277120 | elapsed time per iteration (ms): 153.1 | learning rate: 3.347E-06 | global batch size:     1 | lm loss: 7.263308E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.533 | TFLOPs: 16.23 |
[default0]:[2023-07-30 22:30:49,642] [INFO] [logging.py:96:log_dist] [Rank 0] step=3070, skipped=0, lr=[3.3521664e-06, 3.3521664e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:49,643] [INFO] [timer.py:215:stop] epoch=0/micro_step=3070/global_step=3070, RunningAvgSamplesPerSec=7.865213746759524, CurrSamplesPerSec=7.920924909635483, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3070/439453125 | consumed samples:         3070 | consumed tokens:      6287360 | elapsed time per iteration (ms): 158.6 | learning rate: 3.352E-06 | global batch size:     1 | lm loss: 7.808696E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.306 | TFLOPs: 15.67 |
[default0]:[2023-07-30 22:30:50,406] [INFO] [logging.py:96:log_dist] [Rank 0] step=3075, skipped=0, lr=[3.3576277333333333e-06, 3.3576277333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:50,407] [INFO] [timer.py:215:stop] epoch=0/micro_step=3075/global_step=3075, RunningAvgSamplesPerSec=7.865292717297409, CurrSamplesPerSec=7.866847224670925, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3075/439453125 | consumed samples:         3075 | consumed tokens:      6297600 | elapsed time per iteration (ms): 152.3 | learning rate: 3.358E-06 | global batch size:     1 | lm loss: 7.389410E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.568 | TFLOPs: 16.32 |
[default0]:[2023-07-30 22:30:51,164] [INFO] [logging.py:96:log_dist] [Rank 0] step=3080, skipped=0, lr=[3.3630890666666666e-06, 3.3630890666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:51,164] [INFO] [timer.py:215:stop] epoch=0/micro_step=3080/global_step=3080, RunningAvgSamplesPerSec=7.8653558112066015, CurrSamplesPerSec=7.856561645375192, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3080/439453125 | consumed samples:         3080 | consumed tokens:      6307840 | elapsed time per iteration (ms): 151.3 | learning rate: 3.363E-06 | global batch size:     1 | lm loss: 7.838920E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.609 | TFLOPs: 16.42 |
[default0]:[2023-07-30 22:30:51,913] [INFO] [logging.py:96:log_dist] [Rank 0] step=3085, skipped=0, lr=[3.3685504e-06, 3.3685504e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:51,913] [INFO] [timer.py:215:stop] epoch=0/micro_step=3085/global_step=3085, RunningAvgSamplesPerSec=7.865464831098572, CurrSamplesPerSec=7.922929873740999, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3085/439453125 | consumed samples:         3085 | consumed tokens:      6318080 | elapsed time per iteration (ms): 149.7 | learning rate: 3.369E-06 | global batch size:     1 | lm loss: 7.487600E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.681 | TFLOPs: 16.60 |
[default0]:[2023-07-30 22:30:52,666] [INFO] [logging.py:96:log_dist] [Rank 0] step=3090, skipped=0, lr=[3.3740117333333336e-06, 3.3740117333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:52,667] [INFO] [timer.py:215:stop] epoch=0/micro_step=3090/global_step=3090, RunningAvgSamplesPerSec=7.865555832158816, CurrSamplesPerSec=7.8742021236652, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3090/439453125 | consumed samples:         3090 | consumed tokens:      6328320 | elapsed time per iteration (ms): 150.9 | learning rate: 3.374E-06 | global batch size:     1 | lm loss: 7.715652E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.627 | TFLOPs: 16.47 |
[default0]:[2023-07-30 22:30:53,476] [INFO] [logging.py:96:log_dist] [Rank 0] step=3095, skipped=0, lr=[3.379473066666667e-06, 3.379473066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:53,476] [INFO] [timer.py:215:stop] epoch=0/micro_step=3095/global_step=3095, RunningAvgSamplesPerSec=7.865667992203201, CurrSamplesPerSec=7.961535322244178, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3095/439453125 | consumed samples:         3095 | consumed tokens:      6338560 | elapsed time per iteration (ms): 161.8 | learning rate: 3.379E-06 | global batch size:     1 | lm loss: 7.179585E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.179 | TFLOPs: 15.35 |
[default0]:[2023-07-30 22:30:54,207] [INFO] [logging.py:96:log_dist] [Rank 0] step=3100, skipped=0, lr=[3.3849344000000003e-06, 3.3849344000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:54,208] [INFO] [timer.py:215:stop] epoch=0/micro_step=3100/global_step=3100, RunningAvgSamplesPerSec=7.865713066532209, CurrSamplesPerSec=7.927931742317419, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3100/439453125 | consumed samples:         3100 | consumed tokens:      6348800 | elapsed time per iteration (ms): 146.4 | learning rate: 3.385E-06 | global batch size:     1 | lm loss: 7.530729E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.832 | TFLOPs: 16.98 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 3100 | lm loss value: 7.582953E+00 | lm loss PPL: 1.964422E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:[2023-07-30 22:30:57,516] [INFO] [logging.py:96:log_dist] [Rank 0] step=3105, skipped=0, lr=[3.3903957333333336e-06, 3.3903957333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:57,516] [INFO] [timer.py:215:stop] epoch=0/micro_step=3105/global_step=3105, RunningAvgSamplesPerSec=7.865390232026954, CurrSamplesPerSec=7.909677054358587, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3105/439453125 | consumed samples:         3105 | consumed tokens:      6359040 | elapsed time per iteration (ms): 661.5 | learning rate: 3.390E-06 | global batch size:     1 | lm loss: 7.683675E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.512 | TFLOPs: 3.76 |
[default0]:[2023-07-30 22:30:58,310] [INFO] [logging.py:96:log_dist] [Rank 0] step=3110, skipped=0, lr=[3.395857066666667e-06, 3.395857066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:58,311] [INFO] [timer.py:215:stop] epoch=0/micro_step=3110/global_step=3110, RunningAvgSamplesPerSec=7.865420005749972, CurrSamplesPerSec=7.853854738560868, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3110/439453125 | consumed samples:         3110 | consumed tokens:      6369280 | elapsed time per iteration (ms): 159.1 | learning rate: 3.396E-06 | global batch size:     1 | lm loss: 7.357943E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.285 | TFLOPs: 15.62 |
[default0]:[2023-07-30 22:30:59,071] [INFO] [logging.py:96:log_dist] [Rank 0] step=3115, skipped=0, lr=[3.4013184e-06, 3.4013184e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:59,072] [INFO] [timer.py:215:stop] epoch=0/micro_step=3115/global_step=3115, RunningAvgSamplesPerSec=7.865448347898265, CurrSamplesPerSec=7.706660982941475, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3115/439453125 | consumed samples:         3115 | consumed tokens:      6379520 | elapsed time per iteration (ms): 152.4 | learning rate: 3.401E-06 | global batch size:     1 | lm loss: 7.499728E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.563 | TFLOPs: 16.31 |
[default0]:[2023-07-30 22:30:59,799] [INFO] [logging.py:96:log_dist] [Rank 0] step=3120, skipped=0, lr=[3.4067797333333335e-06, 3.4067797333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:30:59,800] [INFO] [timer.py:215:stop] epoch=0/micro_step=3120/global_step=3120, RunningAvgSamplesPerSec=7.865582655576201, CurrSamplesPerSec=7.926178872236007, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3120/439453125 | consumed samples:         3120 | consumed tokens:      6389760 | elapsed time per iteration (ms): 145.4 | learning rate: 3.407E-06 | global batch size:     1 | lm loss: 7.364668E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.880 | TFLOPs: 17.09 |
[default0]:[2023-07-30 22:31:00,539] [INFO] [logging.py:96:log_dist] [Rank 0] step=3125, skipped=0, lr=[3.412241066666667e-06, 3.412241066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:00,540] [INFO] [timer.py:215:stop] epoch=0/micro_step=3125/global_step=3125, RunningAvgSamplesPerSec=7.865677249621714, CurrSamplesPerSec=7.888997771152888, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3125/439453125 | consumed samples:         3125 | consumed tokens:      6400000 | elapsed time per iteration (ms): 148.1 | learning rate: 3.412E-06 | global batch size:     1 | lm loss: 7.612502E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.753 | TFLOPs: 16.78 |
[default0]:[2023-07-30 22:31:01,344] [INFO] [logging.py:96:log_dist] [Rank 0] step=3130, skipped=0, lr=[3.4177024e-06, 3.4177024e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:01,344] [INFO] [timer.py:215:stop] epoch=0/micro_step=3130/global_step=3130, RunningAvgSamplesPerSec=7.865772184870744, CurrSamplesPerSec=7.928306387740559, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3130/439453125 | consumed samples:         3130 | consumed tokens:      6410240 | elapsed time per iteration (ms): 160.7 | learning rate: 3.418E-06 | global batch size:     1 | lm loss: 7.196811E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.224 | TFLOPs: 15.47 |
[default0]:[2023-07-30 22:31:02,100] [INFO] [logging.py:96:log_dist] [Rank 0] step=3135, skipped=0, lr=[3.4231637333333335e-06, 3.4231637333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:02,101] [INFO] [timer.py:215:stop] epoch=0/micro_step=3135/global_step=3135, RunningAvgSamplesPerSec=7.865872328209282, CurrSamplesPerSec=7.856959011526077, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3135/439453125 | consumed samples:         3135 | consumed tokens:      6420480 | elapsed time per iteration (ms): 151.6 | learning rate: 3.423E-06 | global batch size:     1 | lm loss: 7.615810E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.598 | TFLOPs: 16.40 |
[default0]:[2023-07-30 22:31:02,855] [INFO] [logging.py:96:log_dist] [Rank 0] step=3140, skipped=0, lr=[3.4286250666666668e-06, 3.4286250666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:02,855] [INFO] [timer.py:215:stop] epoch=0/micro_step=3140/global_step=3140, RunningAvgSamplesPerSec=7.865952457736105, CurrSamplesPerSec=7.893734026415933, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3140/439453125 | consumed samples:         3140 | consumed tokens:      6430720 | elapsed time per iteration (ms): 150.6 | learning rate: 3.429E-06 | global batch size:     1 | lm loss: 7.405987E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.642 | TFLOPs: 16.50 |
[default0]:[2023-07-30 22:31:03,687] [INFO] [logging.py:96:log_dist] [Rank 0] step=3145, skipped=0, lr=[3.4340864e-06, 3.4340864e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:03,688] [INFO] [timer.py:215:stop] epoch=0/micro_step=3145/global_step=3145, RunningAvgSamplesPerSec=7.865987754269303, CurrSamplesPerSec=7.940824884749004, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3145/439453125 | consumed samples:         3145 | consumed tokens:      6440960 | elapsed time per iteration (ms): 167.0 | learning rate: 3.434E-06 | global batch size:     1 | lm loss: 7.320753E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.990 | TFLOPs: 14.88 |
[default0]:[2023-07-30 22:31:04,427] [INFO] [logging.py:96:log_dist] [Rank 0] step=3150, skipped=0, lr=[3.4395477333333334e-06, 3.4395477333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:04,427] [INFO] [timer.py:215:stop] epoch=0/micro_step=3150/global_step=3150, RunningAvgSamplesPerSec=7.8660523352960166, CurrSamplesPerSec=7.903000246833094, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3150/439453125 | consumed samples:         3150 | consumed tokens:      6451200 | elapsed time per iteration (ms): 149.0 | learning rate: 3.440E-06 | global batch size:     1 | lm loss: 7.753758E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.709 | TFLOPs: 16.67 |
[default0]:[2023-07-30 22:31:05,172] [INFO] [logging.py:96:log_dist] [Rank 0] step=3155, skipped=0, lr=[3.4450090666666667e-06, 3.4450090666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:05,173] [INFO] [timer.py:215:stop] epoch=0/micro_step=3155/global_step=3155, RunningAvgSamplesPerSec=7.866093800409797, CurrSamplesPerSec=7.878669025963536, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3155/439453125 | consumed samples:         3155 | consumed tokens:      6461440 | elapsed time per iteration (ms): 147.6 | learning rate: 3.445E-06 | global batch size:     1 | lm loss: 7.404151E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.774 | TFLOPs: 16.83 |
[default0]:[2023-07-30 22:31:05,919] [INFO] [logging.py:96:log_dist] [Rank 0] step=3160, skipped=0, lr=[3.4504704e-06, 3.4504704e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:05,921] [INFO] [timer.py:215:stop] epoch=0/micro_step=3160/global_step=3160, RunningAvgSamplesPerSec=7.8660555761667625, CurrSamplesPerSec=7.873832573978437, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3160/439453125 | consumed samples:         3160 | consumed tokens:      6471680 | elapsed time per iteration (ms): 149.6 | learning rate: 3.450E-06 | global batch size:     1 | lm loss: 7.337421E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.683 | TFLOPs: 16.61 |
[default0]:[2023-07-30 22:31:06,665] [INFO] [logging.py:96:log_dist] [Rank 0] step=3165, skipped=0, lr=[3.4559317333333333e-06, 3.4559317333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:06,665] [INFO] [timer.py:215:stop] epoch=0/micro_step=3165/global_step=3165, RunningAvgSamplesPerSec=7.866111629404152, CurrSamplesPerSec=7.872413825464306, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3165/439453125 | consumed samples:         3165 | consumed tokens:      6481920 | elapsed time per iteration (ms): 148.8 | learning rate: 3.456E-06 | global batch size:     1 | lm loss: 7.608592E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.721 | TFLOPs: 16.70 |
[default0]:[2023-07-30 22:31:07,415] [INFO] [logging.py:96:log_dist] [Rank 0] step=3170, skipped=0, lr=[3.4613930666666667e-06, 3.4613930666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:07,416] [INFO] [timer.py:215:stop] epoch=0/micro_step=3170/global_step=3170, RunningAvgSamplesPerSec=7.866156134776276, CurrSamplesPerSec=7.884222734766075, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3170/439453125 | consumed samples:         3170 | consumed tokens:      6492160 | elapsed time per iteration (ms): 150.2 | learning rate: 3.461E-06 | global batch size:     1 | lm loss: 7.295531E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.660 | TFLOPs: 16.55 |
[default0]:[2023-07-30 22:31:08,164] [INFO] [logging.py:96:log_dist] [Rank 0] step=3175, skipped=0, lr=[3.4668544e-06, 3.4668544e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:08,164] [INFO] [timer.py:215:stop] epoch=0/micro_step=3175/global_step=3175, RunningAvgSamplesPerSec=7.8662049591961996, CurrSamplesPerSec=7.839322360821929, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3175/439453125 | consumed samples:         3175 | consumed tokens:      6502400 | elapsed time per iteration (ms): 149.5 | learning rate: 3.467E-06 | global batch size:     1 | lm loss: 7.565343E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.691 | TFLOPs: 16.63 |
[default0]:[2023-07-30 22:31:08,909] [INFO] [logging.py:96:log_dist] [Rank 0] step=3180, skipped=0, lr=[3.4723157333333337e-06, 3.4723157333333337e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:08,910] [INFO] [timer.py:215:stop] epoch=0/micro_step=3180/global_step=3180, RunningAvgSamplesPerSec=7.866247628251056, CurrSamplesPerSec=7.880815532010439, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3180/439453125 | consumed samples:         3180 | consumed tokens:      6512640 | elapsed time per iteration (ms): 149.6 | learning rate: 3.472E-06 | global batch size:     1 | lm loss: 7.532167E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.686 | TFLOPs: 16.61 |
[default0]:[2023-07-30 22:31:09,695] [INFO] [logging.py:96:log_dist] [Rank 0] step=3185, skipped=0, lr=[3.477777066666667e-06, 3.477777066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-07-30 22:31:09,696] [INFO] [timer.py:215:stop] epoch=0/micro_step=3185/global_step=3185, RunningAvgSamplesPerSec=7.8662667851853945, CurrSamplesPerSec=7.941696946057557, MemAllocated=1.73GB, MaxMemAllocated=3.28GB
[default0]: iteration     3185/439453125 | consumed samples:         3185 | consumed tokens:      6522880 | elapsed time per iteration (ms): 157.0 | learning rate: 3.478E-06 | global batch size:     1 | lm loss: 7.691015E+00 | loss scale: 131072.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 6.369 | TFLOPs: 15.83 |
slurmstepd: error: *** JOB 4504978 ON n2gpu1227 CANCELLED AT 2023-07-30T22:31:10 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 4504978.0 ON n2gpu1227 CANCELLED AT 2023-07-30T22:31:10 DUE TO TIME LIMIT ***
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3528640 closing signal SIGTERM
