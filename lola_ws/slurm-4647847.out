cpu-bind=MASK - n2gpu1232, task  0  0 [2575402]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
LAUNCHER: python -u -m torch.distributed.run --nproc_per_node 1 --nnodes 1 --rdzv_id=22956 --rdzv_endpoint n2gpu1232:6005 --rdzv_backend c10d --max_restarts 0 --tee 3
CMD: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/pretrain_gpt.py --override-opt_param-scheduler --adam-beta1 0.9 --adam-beta2 0.95 --tensor-model-parallel-size 1 --moe-expert-parallel-size 1 --num-experts 4 --moe-loss-coeff 0.01 --moe-train-capacity-factor 1.0 --moe-eval-capacity-factor 1.0 --moe-min-capacity 4 --init-method-std 0.01 --lr-decay-tokens 300000000000 --lr-warmup-tokens 375000000 --micro-batch-size 1 --exit-duration-in-mins 30000000 --global-batch-size 1 --num-layers 12 --hidden-size 768 --num-attention-heads 12 --seq-length 2048 --max-position-embeddings 2048 --train-tokens 300000000000 --train-iters 439453125 --lr 2.0e-4 --min-lr 2e-06 --lr-decay-style cosine --split 98,2,0 --log-interval 5 --eval-interval 100 --eval-iters 50 --save-interval 100 --weight-decay 0.1 --clip-grad 1.0 --hysteresis 2 --num-workers 0 --fp16 --load /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true --save /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true --tensorboard-queue-size 1 --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --tensorboard-dir /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/tensorboard/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true_n2gpu1232_2023.08.25-17.57.33 --checkpoint-activations --create-moe-param-group --vocab-file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/gpt2-vocab.json --merge-file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/gpt2-merges.txt --data-path /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/meg-gpt2-oscar-en-10k_text_document --data-impl mmap --deepspeed --deepspeed_config /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/ds_config_gpt_gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true.json --zero-stage 2 --pipeline-model-parallel-size 1 --no-pipeline-parallel --deepspeed-activation-checkpointing
cpu-bind=MASK - n2gpu1232, task  0  0 [2575530]: mask |--------|--------||--------|--------||--------|--------||--------|--------||||B-------|--------||--------|--------||--------|--------||--------|--------|  set
[default0]:[2023-08-25 17:57:36,574] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[default0]:--------------------------------------------------
[default0]:DeepSpeed C++/CUDA extension op report
[default0]:--------------------------------------------------
[default0]:NOTE: Ops not installed will be just-in-time (JIT) compiled at
[default0]:      runtime if needed. Op compatibility means that your system
[default0]:      meet the required dependencies to JIT install the op.
[default0]:--------------------------------------------------
[default0]:JIT compiled ops requires ninja
[default0]:ninja .................. [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:op name ................ installed .. compatible
[default0]:--------------------------------------------------
[default0]:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[default0]:[93m [WARNING] [0m async_io: please install the libaio-devel package with yum
[default0]:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[default0]:async_io ............... [93m[NO][0m ....... [93m[NO][0m
[default0]:cpu_adagrad ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:cpu_adam ............... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_adam ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:fused_lamb ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[default0]:sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
[default0]:spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer ............ [93m[NO][0m ....... [92m[OKAY][0m
[default0]:stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
[default0]:transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
[default0]:--------------------------------------------------
[default0]:DeepSpeed general environment info:
[default0]:torch install path ............... ['/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch']
[default0]:torch version .................... 1.12.0
[default0]:deepspeed install path ........... ['/scratch/hpc-prf-lola/lib_repo/custom-venvs/lola1/lib/python3.10/site-packages/deepspeed']
[default0]:deepspeed info ................... 0.10.0, unknown, unknown
[default0]:torch cuda version ............... 11.7
[default0]:torch hip version ................ None
[default0]:nvcc version ..................... 11.7
[default0]:deepspeed wheel compiled w. ...... torch 1.12, cuda 11.7
[default0]:**** Git info for Megatron: git_hash=e7cf3d4 git_branch=main ****
[default0]:using world size: 1, data-parallel-size: 1, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
[default0]:using torch.float16 for parameters ...
[default0]:------------------------ arguments ------------------------
[default0]:  accumulate_allreduce_grads_in_fp32 .............. False
[default0]:  adam_beta1 ...................................... 0.9
[default0]:  adam_beta2 ...................................... 0.95
[default0]:  adam_eps ........................................ 1e-08
[default0]:  add_bias_linear ................................. True
[default0]:  add_position_embedding .......................... True
[default0]:  adlr_autoresume ................................. False
[default0]:  adlr_autoresume_interval ........................ 1000
[default0]:  aml_data_download_path .......................... None
[default0]:  apply_layernorm_1p .............................. False
[default0]:  apply_query_key_layer_scaling ................... True
[default0]:  apply_residual_connection_post_layernorm ........ False
[default0]:  async_tensor_model_parallel_allreduce ........... False
[default0]:  attention_dropout ............................... 0.1
[default0]:  attention_softmax_in_fp32 ....................... False
[default0]:  barrier_with_L1_time ............................ True
[default0]:  bert_binary_head ................................ True
[default0]:  bert_embedder_type .............................. megatron
[default0]:  bert_load ....................................... None
[default0]:  bf16 ............................................ False
[default0]:  bias_dropout_fusion ............................. True
[default0]:  bias_gelu_fusion ................................ True
[default0]:  biencoder_projection_dim ........................ 0
[default0]:  biencoder_shared_query_context_model ............ False
[default0]:  block_data_path ................................. None
[default0]:  checkpoint_activations .......................... True
[default0]:  checkpoint_in_cpu ............................... False
[default0]:  checkpoint_num_layers ........................... 1
[default0]:  classes_fraction ................................ 1.0
[default0]:  clip_grad ....................................... 1.0
[default0]:  compression_training ............................ False
[default0]:  consumed_train_samples .......................... 0
[default0]:  consumed_train_tokens ........................... 0
[default0]:  consumed_valid_samples .......................... 0
[default0]:  contigious_checkpointing ........................ False
[default0]:  cpu_optimizer ................................... False
[default0]:  cpu_torch_adam .................................. False
[default0]:  create_moe_param_group .......................... True
[default0]:  curriculum_learning_legacy ...................... False
[default0]:  data_cache_path ................................. None
[default0]:  data_efficiency_curriculum_learning ............. False
[default0]:  data_impl ....................................... mmap
[default0]:  data_parallel_random_init ....................... False
[default0]:  data_parallel_size .............................. 1
[default0]:  data_path ....................................... ['/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/meg-gpt2-oscar-en-10k_text_document']
[default0]:  data_per_class_fraction ......................... 1.0
[default0]:  data_sharding ................................... True
[default0]:  dataloader_type ................................. single
[default0]:  DDP_impl ........................................ local
[default0]:  decoder_num_layers .............................. None
[default0]:  decoder_seq_length .............................. None
[default0]:  deepscale ....................................... False
[default0]:  deepscale_config ................................ None
[default0]:  deepspeed ....................................... True
[default0]:  deepspeed_activation_checkpointing .............. True
[default0]:  deepspeed_config ................................ /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/ds_config_gpt_gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true.json
[default0]:  deepspeed_mpi ................................... False
[default0]:  dino_bottleneck_size ............................ 256
[default0]:  dino_freeze_last_layer .......................... 1
[default0]:  dino_head_hidden_size ........................... 2048
[default0]:  dino_local_crops_number ......................... 10
[default0]:  dino_local_img_size ............................. 96
[default0]:  dino_norm_last_layer ............................ False
[default0]:  dino_teacher_temp ............................... 0.07
[default0]:  dino_warmup_teacher_temp ........................ 0.04
[default0]:  dino_warmup_teacher_temp_epochs ................. 30
[default0]:  distribute_checkpointed_activations ............. False
[default0]:  distribute_saved_activations .................... False
[default0]:  distributed_backend ............................. nccl
[default0]:  distributed_timeout_minutes ..................... 10
[default0]:  ds_inference .................................... False
[default0]:  ds_pipeline_enabled ............................. False
[default0]:  embedding_path .................................. None
[default0]:  embedding_weights_in_fp32 ....................... False
[default0]:  empty_unused_memory_level ....................... 0
[default0]:  enable_expert_tensor_parallelism ................ False
[default0]:  encoder_num_layers .............................. 12
[default0]:  encoder_seq_length .............................. 2048
[default0]:  end_weight_decay ................................ 0.1
[default0]:  eod_mask_loss ................................... False
[default0]:  eval_interval ................................... 100
[default0]:  eval_iters ...................................... 50
[default0]:  evidence_data_path .............................. None
[default0]:  exit_duration_in_mins ........................... 30000000
[default0]:  exit_interval ................................... None
[default0]:  exit_on_missing_checkpoint ...................... False
[default0]:  exit_signal_handler ............................. False
[default0]:  expert_interval ................................. 2
[default0]:  ffn_hidden_size ................................. 3072
[default0]:  finetune ........................................ False
[default0]:  fp16 ............................................ True
[default0]:  fp16_lm_cross_entropy ........................... False
[default0]:  fp32_residual_connection ........................ False
[default0]:  fp8_amax_compute_algo ........................... most_recent
[default0]:  fp8_amax_history_len ............................ 1
[default0]:  fp8_e4m3 ........................................ False
[default0]:  fp8_hybrid ...................................... False
[default0]:  fp8_interval .................................... 1
[default0]:  fp8_margin ...................................... 0
[default0]:  fp8_wgrad ....................................... True
[default0]:  global_batch_size ............................... 1
[default0]:  gradient_accumulation_fusion .................... True
[default0]:  head_lr_mult .................................... 1.0
[default0]:  hidden_dropout .................................. 0.1
[default0]:  hidden_size ..................................... 768
[default0]:  hidden_size_teacher ............................. None
[default0]:  hysteresis ...................................... 2
[default0]:  ict_head_size ................................... None
[default0]:  ict_load ........................................ None
[default0]:  img_h ........................................... 224
[default0]:  img_w ........................................... 224
[default0]:  indexer_batch_size .............................. 128
[default0]:  indexer_log_interval ............................ 1000
[default0]:  inference ....................................... False
[default0]:  inference_batch_times_seqlen_threshold .......... 512
[default0]:  init_method_std ................................. 0.01
[default0]:  init_method_xavier_uniform ...................... False
[default0]:  initial_loss_scale .............................. 4294967296
[default0]:  iter_per_epoch .................................. 1250
[default0]:  kd .............................................. False
[default0]:  kd_alpha_ce ..................................... 1
[default0]:  kd_beta_ce ...................................... 1
[default0]:  kd_temp ......................................... 1.0
[default0]:  kv_channels ..................................... 64
[default0]:  layernorm_epsilon ............................... 1e-05
[default0]:  lazy_mpu_init ................................... None
[default0]:  load ............................................ /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:  load_teacher .................................... None
[default0]:  local_rank ...................................... None
[default0]:  log_batch_size_to_tensorboard ................... True
[default0]:  log_interval .................................... 5
[default0]:  log_learning_rate_to_tensorboard ................ True
[default0]:  log_loss_scale_to_tensorboard ................... True
[default0]:  log_memory_to_tensorboard ....................... False
[default0]:  log_num_zeros_in_grad ........................... False
[default0]:  log_optimizer_states_to_tensorboard ............. False
[default0]:  log_params_norm ................................. False
[default0]:  log_timers_to_tensorboard ....................... True
[default0]:  log_validation_ppl_to_tensorboard ............... True
[default0]:  log_world_size_to_tensorboard ................... False
[default0]:  loss_scale ...................................... None
[default0]:  loss_scale_window ............................... 1000
[default0]:  lr .............................................. 0.0002
[default0]:  lr_decay_iters .................................. None
[default0]:  lr_decay_samples ................................ None
[default0]:  lr_decay_style .................................. cosine
[default0]:  lr_decay_tokens ................................. 300000000000
[default0]:  lr_warmup_fraction .............................. None
[default0]:  lr_warmup_iters ................................. 0
[default0]:  lr_warmup_samples ............................... 0
[default0]:  lr_warmup_tokens ................................ 375000000
[default0]:  make_vocab_size_divisible_by .................... 128
[default0]:  mask_factor ..................................... 1.0
[default0]:  mask_prob ....................................... 0.15
[default0]:  mask_type ....................................... random
[default0]:  masked_softmax_fusion ........................... True
[default0]:  max_position_embeddings ......................... 2048
[default0]:  max_tokens_to_oom ............................... 12000
[default0]:  memory_centric_tiled_linear ..................... False
[default0]:  merge_file ...................................... /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/gpt2-merges.txt
[default0]:  micro_batch_size ................................ 1
[default0]:  min_loss_scale .................................. 1.0
[default0]:  min_lr .......................................... 2e-06
[default0]:  mlp_type ........................................ standard
[default0]:  mmap_warmup ..................................... False
[default0]:  moe_eval_capacity_factor ........................ 1.0
[default0]:  moe_expert_parallel_size ........................ 1
[default0]:  moe_loss_coeff .................................. 0.01
[default0]:  moe_min_capacity ................................ 4
[default0]:  moe_token_dropping .............................. True
[default0]:  moe_train_capacity_factor ....................... 1.0
[default0]:  mos ............................................. False
[default0]:  no_load_lr_state ................................ False
[default0]:  no_load_optim ................................... None
[default0]:  no_load_rng ..................................... None
[default0]:  no_persist_layer_norm ........................... False
[default0]:  no_pipeline_parallel ............................ True
[default0]:  no_save_optim ................................... None
[default0]:  no_save_rng ..................................... None
[default0]:  normalization ................................... layernorm
[default0]:  num_attention_heads ............................. 12
[default0]:  num_attention_heads_teacher ..................... None
[default0]:  num_channels .................................... 3
[default0]:  num_classes ..................................... 1000
[default0]:  num_experts ..................................... [4]
[default0]:  num_experts_switch .............................. None
[default0]:  num_experts_teacher ............................. [1]
[default0]:  num_key_value_heads ............................. 12
[default0]:  num_layers ...................................... 12
[default0]:  num_layers_per_virtual_pipeline_stage ........... None
[default0]:  num_layers_teacher .............................. None
[default0]:  num_workers ..................................... 0
[default0]:  onnx_safe ....................................... None
[default0]:  openai_gelu ..................................... False
[default0]:  optimizer ....................................... adam
[default0]:  output_bert_embeddings .......................... False
[default0]:  overlap_p2p_comm ................................ False
[default0]:  override_opt_param_scheduler .................... True
[default0]:  params_dtype .................................... torch.float16
[default0]:  partition_activations ........................... False
[default0]:  patch_dim ....................................... 16
[default0]:  perform_initialization .......................... True
[default0]:  pipeline_model_parallel_size .................... 1
[default0]:  pipeline_model_parallel_split_rank .............. None
[default0]:  profile_backward ................................ False
[default0]:  query_in_block_prob ............................. 0.1
[default0]:  rampup_batch_size ............................... None
[default0]:  random_ltd ...................................... False
[default0]:  rank ............................................ 0
[default0]:  recompute_granularity ........................... None
[default0]:  recompute_method ................................ None
[default0]:  recompute_num_layers ............................ 1
[default0]:  remote_device ................................... none
[default0]:  reset_attention_mask ............................ False
[default0]:  reset_iteration ................................. False
[default0]:  reset_position_ids .............................. False
[default0]:  retriever_report_topk_accuracies ................ []
[default0]:  retriever_score_scaling ......................... False
[default0]:  retriever_seq_length ............................ 256
[default0]:  retro_add_retriever ............................. False
[default0]:  retro_cyclic_train_iters ........................ None
[default0]:  retro_encoder_attention_dropout ................. 0.1
[default0]:  retro_encoder_hidden_dropout .................... 0.1
[default0]:  retro_encoder_layers ............................ 2
[default0]:  retro_num_neighbors ............................. 2
[default0]:  retro_num_retrieved_chunks ...................... 2
[default0]:  retro_return_doc_ids ............................ False
[default0]:  retro_workdir ................................... None
[default0]:  return_data_index ............................... False
[default0]:  rotary_percent .................................. 1.0
[default0]:  sample_rate ..................................... 1.0
[default0]:  save ............................................ /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:  save_interval ................................... 100
[default0]:  scatter_gather_tensors_in_pipeline .............. True
[default0]:  scattered_embeddings ............................ False
[default0]:  seed ............................................ 1234
[default0]:  seq_length ...................................... 2048
[default0]:  sequence_parallel ............................... False
[default0]:  sgd_momentum .................................... 0.9
[default0]:  short_seq_prob .................................. 0.1
[default0]:  skip_train ...................................... False
[default0]:  split ........................................... 98,2,0
[default0]:  split_transformers .............................. False
[default0]:  squared_relu .................................... False
[default0]:  standalone_embedding_stage ...................... False
[default0]:  start_weight_decay .............................. 0.1
[default0]:  swiglu .......................................... False
[default0]:  swin_backbone_type .............................. tiny
[default0]:  synchronize_each_layer .......................... False
[default0]:  tensor_model_parallel_size ...................... 1
[default0]:  tensorboard_dir ................................. /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/tensorboard/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true_n2gpu1232_2023.08.25-17.57.33
[default0]:  tensorboard_log_interval ........................ 1
[default0]:  tensorboard_queue_size .......................... 1
[default0]:  test_data_path .................................. None
[default0]:  tile_factor ..................................... 1
[default0]:  timing_log_level ................................ 0
[default0]:  timing_log_option ............................... minmax
[default0]:  titles_data_path ................................ None
[default0]:  tokenizer_model ................................. None
[default0]:  tokenizer_type .................................. GPT2BPETokenizer
[default0]:  topk ............................................ 1
[default0]:  train_data_exact_num_epochs ..................... None
[default0]:  train_data_path ................................. None
[default0]:  train_desc_path ................................. None
[default0]:  train_doc_idx_path .............................. None
[default0]:  train_idx_path .................................. None
[default0]:  train_iters ..................................... 439453125
[default0]:  train_sample_idx_path ........................... None
[default0]:  train_samples ................................... None
[default0]:  train_shuffle_idx_path .......................... None
[default0]:  train_tokens .................................... 300000000000
[default0]:  transformer_impl ................................ local
[default0]:  transformer_pipeline_model_parallel_size ........ 1
[default0]:  untie_embeddings_and_output_weights ............. False
[default0]:  use_checkpoint_args ............................. False
[default0]:  use_checkpoint_opt_param_scheduler .............. False
[default0]:  use_contiguous_buffers_in_local_ddp ............. True
[default0]:  use_cpu_initialization .......................... None
[default0]:  use_distributed_optimizer ....................... False
[default0]:  use_flash_attn .................................. False
[default0]:  use_one_sent_docs ............................... False
[default0]:  use_pin_memory .................................. False
[default0]:  use_ring_exchange_p2p ........................... False
[default0]:  use_rotary_position_embeddings .................. False
[default0]:  use_tutel ....................................... False
[default0]:  valid_data_path ................................. None
[default0]:  variable_seq_lengths ............................ False
[default0]:  virtual_pipeline_model_parallel_size ............ None
[default0]:  vision_backbone_type ............................ vit
[default0]:  vision_pretraining .............................. False
[default0]:  vision_pretraining_type ......................... classify
[default0]:  vocab_extra_ids ................................. 0
[default0]:  vocab_file ...................................... /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/gpt2-vocab.json
[default0]:  vocab_size ...................................... None
[default0]:  weight_decay .................................... 0.1
[default0]:  weight_decay_incr_style ......................... constant
[default0]:  world_size ...................................... 1
[default0]:  zero_allgather_bucket_size ...................... 0.0
[default0]:  zero_contigious_gradients ....................... False
[default0]:  zero_reduce_bucket_size ......................... 0.0
[default0]:  zero_reduce_scatter ............................. False
[default0]:  zero_stage ...................................... 2
[default0]:-------------------- end of arguments ---------------------
[default0]:setting number of micro-batches to constant 1
[default0]:> building GPT2BPETokenizer tokenizer ...
[default0]: > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
[default0]:> setting tensorboard ...
[default0]:> initializing torch distributed ...
[default0]:[2023-08-25 17:57:58,481] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[default0]:[2023-08-25 17:57:58,481] [INFO] [comm.py:616:init_distributed] cdb=None
[default0]:[2023-08-25 17:57:58,481] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[default0]:> initialized tensor model parallel with size 1
[default0]:> initialized pipeline model parallel with size 1
[default0]:> setting random seeds to 1234 ...
[default0]:> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
[default0]:> compiling dataset index builder ...
[default0]:make: Entering directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/data'
[default0]:make: Nothing to be done for 'default'.
[default0]:make: Leaving directory '/scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/data'
[default0]:>>> done with dataset index builder. Compilation time: 0.071 seconds
[default0]:> compiling and loading fused kernels ...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:[1/3] c++ -MMD -MF scaled_upper_triang_masked_softmax.o.d -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++14 -O3 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/scaled_upper_triang_masked_softmax.cpp -o scaled_upper_triang_masked_softmax.o 
[default0]:[2/3] /opt/software/pc2/EB-SW/software/CUDA/11.7.0/bin/nvcc  -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_87,code=sm_87 -std=c++14 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/scaled_upper_triang_masked_softmax_cuda.cu -o scaled_upper_triang_masked_softmax_cuda.cuda.o 
[default0]:[3/3] c++ scaled_upper_triang_masked_softmax.o scaled_upper_triang_masked_softmax_cuda.cuda.o -shared -L/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/software/pc2/EB-SW/software/CUDA/11.7.0/lib64 -lcudart -o scaled_upper_triang_masked_softmax_cuda.so
[default0]:Loading extension module scaled_upper_triang_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_masked_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:[1/3] c++ -MMD -MF scaled_masked_softmax.o.d -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++14 -O3 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/scaled_masked_softmax.cpp -o scaled_masked_softmax.o 
[default0]:[2/3] /opt/software/pc2/EB-SW/software/CUDA/11.7.0/bin/nvcc  -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_87,code=sm_87 -std=c++14 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/scaled_masked_softmax_cuda.cu -o scaled_masked_softmax_cuda.cuda.o 
[default0]:[3/3] c++ scaled_masked_softmax.o scaled_masked_softmax_cuda.cuda.o -shared -L/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/software/pc2/EB-SW/software/CUDA/11.7.0/lib64 -lcudart -o scaled_masked_softmax_cuda.so
[default0]:Loading extension module scaled_masked_softmax_cuda...
[default0]:Detected CUDA files, patching ldflags
[default0]:Emitting ninja build file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/build/build.ninja...
[default0]:Building extension module scaled_softmax_cuda...
[default0]:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[default0]:[1/3] c++ -MMD -MF scaled_softmax.o.d -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++14 -O3 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/scaled_softmax.cpp -o scaled_softmax.o 
[default0]:[2/3] /opt/software/pc2/EB-SW/software/CUDA/11.7.0/bin/nvcc  -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/TH -isystem /opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/include/THC -isystem /opt/software/pc2/EB-SW/software/CUDA/11.7.0/include -isystem /opt/software/pc2/EB-SW/software/Python/3.10.4-GCCcore-11.3.0/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_87,code=sm_87 -std=c++14 -c /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/megatron/fused_kernels/scaled_softmax_cuda.cu -o scaled_softmax_cuda.cuda.o 
[default0]:[3/3] c++ scaled_softmax.o scaled_softmax_cuda.cuda.o -shared -L/opt/software/pc2/EB-SW/software/PyTorch/1.12.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/software/pc2/EB-SW/software/CUDA/11.7.0/lib64 -lcudart -o scaled_softmax_cuda.so
[default0]:Loading extension module scaled_softmax_cuda...
[default0]:n2gpu1232:2575539:2575539 [0] NCCL INFO Bootstrap : Using ib1:10.10.103.100<0>
[default0]:n2gpu1232:2575539:2575539 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[default0]:n2gpu1232:2575539:2575539 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib1:10.10.103.100<0>
[default0]:n2gpu1232:2575539:2575539 [0] NCCL INFO Using network IB
[default0]:NCCL version 2.12.12+cuda11.7
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1232:2575539:2575918 [0] NCCL INFO comm 0x1530b00090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:>>> done with compiling and loading fused kernels. Compilation time: 453.557 seconds
[default0]:time to initialize megatron (seconds): 458.313
[default0]:[after megatron is initialized] datetime: 2023-08-25 18:05:33 
[default0]:building GPT model ...
[default0]:[2023-08-25 18:05:33,964] [INFO] [utils.py:785:see_memory_usage] Before Building Model
[default0]:[2023-08-25 18:05:33,965] [INFO] [utils.py:786:see_memory_usage] MA 0.0 GB         Max_MA 0.2 GB         CA 0.0 GB         Max_CA 0 GB 
[default0]:[2023-08-25 18:05:33,965] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 18.9 GB, percent = 3.8%
[default0]:LOLA: Number of experts passed to language model: [4]
[default0]:LOLA: Building Encoder
[default0]:LOLA: Number of experts being sent to encoder layers: [4]
[default0]:LOLA: Number of experts for the MoE layers: [4, 4, 4, 4, 4, 4]
[default0]:LOLA: Setting experts for layer number: 1
[default0]:LOLA: Building MLP layer, num_experts: 1
[default0]:LOLA: Built MLP layer: ParallelMLP(
[default0]:  (dense_h_to_4h): ColumnParallelLinear()
[default0]:  (dense_4h_to_h): RowParallelLinear()
[default0]:)
[default0]:LOLA: Setting experts for layer number: 2
[default0]:LOLA: Building MLP layer, num_experts: 4
[default0]:[2023-08-25 18:05:34,539] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[default0]:LOLA: Built MLP layer: MoE(
[default0]:  (deepspeed_moe): MOELayer(
[default0]:    (gate): TopKGate(
[default0]:      (wg): Linear(in_features=768, out_features=4, bias=False)
[default0]:    )
[default0]:    (experts): Experts(
[default0]:      (deepspeed_experts): ModuleList(
[default0]:        (0): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (1): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (2): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (3): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:      )
[default0]:    )
[default0]:  )
[default0]:)
[default0]:LOLA: Setting experts for layer number: 3
[default0]:LOLA: Building MLP layer, num_experts: 1
[default0]:LOLA: Built MLP layer: ParallelMLP(
[default0]:  (dense_h_to_4h): ColumnParallelLinear()
[default0]:  (dense_4h_to_h): RowParallelLinear()
[default0]:)
[default0]:LOLA: Setting experts for layer number: 4
[default0]:LOLA: Building MLP layer, num_experts: 4
[default0]:[2023-08-25 18:05:34,563] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[default0]:LOLA: Built MLP layer: MoE(
[default0]:  (deepspeed_moe): MOELayer(
[default0]:    (gate): TopKGate(
[default0]:      (wg): Linear(in_features=768, out_features=4, bias=False)
[default0]:    )
[default0]:    (experts): Experts(
[default0]:      (deepspeed_experts): ModuleList(
[default0]:        (0): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (1): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (2): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (3): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:      )
[default0]:    )
[default0]:  )
[default0]:)
[default0]:LOLA: Setting experts for layer number: 5
[default0]:LOLA: Building MLP layer, num_experts: 1
[default0]:LOLA: Built MLP layer: ParallelMLP(
[default0]:  (dense_h_to_4h): ColumnParallelLinear()
[default0]:  (dense_4h_to_h): RowParallelLinear()
[default0]:)
[default0]:LOLA: Setting experts for layer number: 6
[default0]:LOLA: Building MLP layer, num_experts: 4
[default0]:[2023-08-25 18:05:34,567] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[default0]:LOLA: Built MLP layer: MoE(
[default0]:  (deepspeed_moe): MOELayer(
[default0]:    (gate): TopKGate(
[default0]:      (wg): Linear(in_features=768, out_features=4, bias=False)
[default0]:    )
[default0]:    (experts): Experts(
[default0]:      (deepspeed_experts): ModuleList(
[default0]:        (0): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (1): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (2): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (3): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:      )
[default0]:    )
[default0]:  )
[default0]:)
[default0]:LOLA: Setting experts for layer number: 7
[default0]:LOLA: Building MLP layer, num_experts: 1
[default0]:LOLA: Built MLP layer: ParallelMLP(
[default0]:  (dense_h_to_4h): ColumnParallelLinear()
[default0]:  (dense_4h_to_h): RowParallelLinear()
[default0]:)
[default0]:LOLA: Setting experts for layer number: 8
[default0]:LOLA: Building MLP layer, num_experts: 4
[default0]:[2023-08-25 18:05:34,572] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[default0]:LOLA: Built MLP layer: MoE(
[default0]:  (deepspeed_moe): MOELayer(
[default0]:    (gate): TopKGate(
[default0]:      (wg): Linear(in_features=768, out_features=4, bias=False)
[default0]:    )
[default0]:    (experts): Experts(
[default0]:      (deepspeed_experts): ModuleList(
[default0]:        (0): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (1): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (2): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (3): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:      )
[default0]:    )
[default0]:  )
[default0]:)
[default0]:LOLA: Setting experts for layer number: 9
[default0]:LOLA: Building MLP layer, num_experts: 1
[default0]:LOLA: Built MLP layer: ParallelMLP(
[default0]:  (dense_h_to_4h): ColumnParallelLinear()
[default0]:  (dense_4h_to_h): RowParallelLinear()
[default0]:)
[default0]:LOLA: Setting experts for layer number: 10
[default0]:LOLA: Building MLP layer, num_experts: 4
[default0]:[2023-08-25 18:05:34,577] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[default0]:LOLA: Built MLP layer: MoE(
[default0]:  (deepspeed_moe): MOELayer(
[default0]:    (gate): TopKGate(
[default0]:      (wg): Linear(in_features=768, out_features=4, bias=False)
[default0]:    )
[default0]:    (experts): Experts(
[default0]:      (deepspeed_experts): ModuleList(
[default0]:        (0): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (1): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (2): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (3): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:      )
[default0]:    )
[default0]:  )
[default0]:)
[default0]:LOLA: Setting experts for layer number: 11
[default0]:LOLA: Building MLP layer, num_experts: 1
[default0]:LOLA: Built MLP layer: ParallelMLP(
[default0]:  (dense_h_to_4h): ColumnParallelLinear()
[default0]:  (dense_4h_to_h): RowParallelLinear()
[default0]:)
[default0]:LOLA: Setting experts for layer number: 12
[default0]:LOLA: Building MLP layer, num_experts: 4
[default0]:[2023-08-25 18:05:34,581] [INFO] [logging.py:96:log_dist] [Rank 0] Creating MoE layer with num_experts: 4 | num_local_experts: 4 | expert_parallel_size: 1
[default0]:LOLA: Built MLP layer: MoE(
[default0]:  (deepspeed_moe): MOELayer(
[default0]:    (gate): TopKGate(
[default0]:      (wg): Linear(in_features=768, out_features=4, bias=False)
[default0]:    )
[default0]:    (experts): Experts(
[default0]:      (deepspeed_experts): ModuleList(
[default0]:        (0): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (1): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (2): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:        (3): ParallelMLP(
[default0]:          (dense_h_to_4h): ColumnParallelLinear()
[default0]:          (dense_4h_to_h): RowParallelLinear()
[default0]:        )
[default0]:      )
[default0]:    )
[default0]:  )
[default0]:)
[default0]:[2023-08-25 18:05:34,621] [INFO] [utils.py:785:see_memory_usage] After Building Model
[default0]:[2023-08-25 18:05:34,621] [INFO] [utils.py:786:see_memory_usage] MA 0.39 GB         Max_MA 0.4 GB         CA 0.45 GB         Max_CA 0 GB 
[default0]:[2023-08-25 18:05:34,621] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 18.9 GB, percent = 3.8%
[default0]: > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 210284544
[default0]:param_group keyset: dict_keys(['name', 'params', 'wd_mult', 'lr_mult'])
[default0]:> learning rate decay style: cosine
[default0]:DeepSpeed is enabled.
[default0]:[2023-08-25 18:05:34,624] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
[default0]:No existing process group found, creating a new group named: ep_size_1
[default0]:[2023-08-25 18:05:34,653] [INFO] [logging.py:96:log_dist] [Rank 0] Creating expert and data parallel groups with size 1
[default0]:[2023-08-25 18:05:34,654] [INFO] [logging.py:96:log_dist] [Rank 0] Creating expert data parallel process group named ep_size_1 with ranks: [0]
[default0]:[2023-08-25 18:05:34,654] [INFO] [logging.py:96:log_dist] [Rank 0] creating expert parallel process group named ep_size_1 with ranks: [0]
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1232:2575539:2575989 [0] NCCL INFO comm 0x152fc80090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1232:2575539:2575993 [0] NCCL INFO comm 0x152fc8303ac0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:[2023-08-25 18:05:34,964] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: True
[default0]:[2023-08-25 18:05:34,965] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[default0]:[2023-08-25 18:05:34,965] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[default0]:[2023-08-25 18:05:34,970] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[default0]:[2023-08-25 18:05:34,970] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'apex.optimizers.fused_adam.FusedAdam'>
[default0]:[2023-08-25 18:05:34,970] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[default0]:[2023-08-25 18:05:34,970] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000
[default0]:[2023-08-25 18:05:34,970] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000
[default0]:[2023-08-25 18:05:34,970] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[default0]:[2023-08-25 18:05:34,970] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
[default0]:Rank: 0 partition count [1, 1, 1, 1] and sizes[(96847872, False), (98304, False), (113246208, True), (92160, True)] 
[default0]:[2023-08-25 18:05:35,460] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[default0]:[2023-08-25 18:05:35,461] [INFO] [utils.py:786:see_memory_usage] MA 1.18 GB         Max_MA 1.18 GB         CA 1.18 GB         Max_CA 1 GB 
[default0]:[2023-08-25 18:05:35,461] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 19.09 GB, percent = 3.8%
[default0]:[2023-08-25 18:05:35,566] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[default0]:[2023-08-25 18:05:35,566] [INFO] [utils.py:786:see_memory_usage] MA 2.74 GB         Max_MA 3.53 GB         CA 3.53 GB         Max_CA 4 GB 
[default0]:[2023-08-25 18:05:35,566] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 19.09 GB, percent = 3.8%
[default0]:[2023-08-25 18:05:35,567] [INFO] [stage_1_and_2.py:493:__init__] optimizer state initialized
[default0]:[2023-08-25 18:05:35,600] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[default0]:[2023-08-25 18:05:35,600] [INFO] [utils.py:786:see_memory_usage] MA 2.74 GB         Max_MA 2.74 GB         CA 3.53 GB         Max_CA 4 GB 
[default0]:[2023-08-25 18:05:35,600] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 19.09 GB, percent = 3.8%
[default0]:[2023-08-25 18:05:35,604] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[default0]:[2023-08-25 18:05:35,604] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[default0]:[2023-08-25 18:05:35,604] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.optimizer_param_scheduler.OptimizerParamScheduler object at 0x153140965270>
[default0]:[2023-08-25 18:05:35,604] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0, 0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:35,604] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[default0]:[2023-08-25 18:05:35,605] [INFO] [config.py:964:print]   activation_checkpointing_config  {
[default0]:    "partition_activations": false, 
[default0]:    "contiguous_memory_optimization": false, 
[default0]:    "cpu_checkpointing": false, 
[default0]:    "number_checkpoints": null, 
[default0]:    "synchronize_checkpoint_boundary": false, 
[default0]:    "profile": false
[default0]:}
[default0]:[2023-08-25 18:05:35,605] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[default0]:[2023-08-25 18:05:35,605] [INFO] [config.py:964:print]   amp_enabled .................. False
[default0]:[2023-08-25 18:05:35,605] [INFO] [config.py:964:print]   amp_params ................... False
[default0]:[2023-08-25 18:05:35,605] [INFO] [config.py:964:print]   autotuning_config ............ {
[default0]:    "enabled": false, 
[default0]:    "start_step": null, 
[default0]:    "end_step": null, 
[default0]:    "metric_path": null, 
[default0]:    "arg_mappings": null, 
[default0]:    "metric": "throughput", 
[default0]:    "model_info": null, 
[default0]:    "results_dir": "autotuning_results", 
[default0]:    "exps_dir": "autotuning_exps", 
[default0]:    "overwrite": true, 
[default0]:    "fast": true, 
[default0]:    "start_profile_step": 3, 
[default0]:    "end_profile_step": 5, 
[default0]:    "tuner_type": "gridsearch", 
[default0]:    "tuner_early_stopping": 5, 
[default0]:    "tuner_num_trials": 50, 
[default0]:    "model_info_path": null, 
[default0]:    "mp_size": 1, 
[default0]:    "max_train_batch_size": null, 
[default0]:    "min_train_batch_size": 1, 
[default0]:    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[default0]:    "min_train_micro_batch_size_per_gpu": 1, 
[default0]:    "num_tuning_micro_batch_sizes": 3
[default0]:}
[default0]:[2023-08-25 18:05:35,605] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[default0]:[2023-08-25 18:05:35,605] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[default0]:[2023-08-25 18:05:35,605] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[default0]:[2023-08-25 18:05:35,605] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[default0]:[2023-08-25 18:05:35,605] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1531409665f0>
[default0]:[2023-08-25 18:05:35,605] [INFO] [config.py:964:print]   communication_data_type ...... None
[default0]:[2023-08-25 18:05:35,605] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   curriculum_params_legacy ..... {'curriculum_type': 'seqlen', 'min_difficulty': 80, 'max_difficulty': 2048, 'schedule_type': 'fixed_linear', 'schedule_config': {'total_curriculum_step': 56390977, 'difficulty_step': 8}}
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   disable_allgather ............ False
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   dump_state ................... False
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 500, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[default0]:[2023-08-25 18:05:35,606] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[default0]:[2023-08-25 18:05:35,607] [INFO] [config.py:964:print]   flops_profiler_config ........ {
[default0]:    "enabled": true, 
[default0]:    "recompute_fwd_factor": 0.0, 
[default0]:    "profile_step": 15, 
[default0]:    "module_depth": -1, 
[default0]:    "top_modules": 1, 
[default0]:    "detailed": true, 
[default0]:    "output_file": null
[default0]:}
[default0]:[2023-08-25 18:05:35,607] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[default0]:[2023-08-25 18:05:35,607] [INFO] [config.py:964:print]   fp16_enabled ................. True
[default0]:[2023-08-25 18:05:35,607] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[default0]:[2023-08-25 18:05:35,607] [INFO] [config.py:964:print]   global_rank .................. 0
[default0]:[2023-08-25 18:05:35,607] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[default0]:[2023-08-25 18:05:35,607] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 1
[default0]:[2023-08-25 18:05:35,607] [INFO] [config.py:964:print]   gradient_clipping ............ 1
[default0]:[2023-08-25 18:05:35,607] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[default0]:[2023-08-25 18:05:35,620] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[default0]:[2023-08-25 18:05:35,620] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 2048
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   loss_scale ................... 0
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   memory_breakdown ............. False
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   nebula_config ................ {
[default0]:    "enabled": false, 
[default0]:    "persistent_storage_path": null, 
[default0]:    "persistent_time_interval": 100, 
[default0]:    "num_of_version_in_retention": 2, 
[default0]:    "enable_nebula_load": true, 
[default0]:    "load_path": null
[default0]:}
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   optimizer_name ............... None
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   optimizer_params ............. None
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   pld_enabled .................. False
[default0]:[2023-08-25 18:05:35,621] [INFO] [config.py:964:print]   pld_params ................... False
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   prescale_gradients ........... False
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   scheduler_name ............... None
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   scheduler_params ............. None
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   sparse_attention ............. None
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   steps_per_print .............. 5
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   train_batch_size ............. 1
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  1
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   wall_clock_breakdown ......... True
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   world_size ................... 1
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  False
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   zero_enabled ................. True
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2
[default0]:[2023-08-25 18:05:35,622] [INFO] [config.py:950:print_user_config]   json = {
[default0]:    "train_batch_size": 1, 
[default0]:    "train_micro_batch_size_per_gpu": 1, 
[default0]:    "steps_per_print": 5, 
[default0]:    "zero_optimization": {
[default0]:        "stage": 2
[default0]:    }, 
[default0]:    "gradient_clipping": 1, 
[default0]:    "prescale_gradients": false, 
[default0]:    "fp16": {
[default0]:        "enabled": true, 
[default0]:        "loss_scale": 0, 
[default0]:        "loss_scale_window": 500, 
[default0]:        "hysteresis": 2, 
[default0]:        "min_loss_scale": 1, 
[default0]:        "initial_scale_power": 11
[default0]:    }, 
[default0]:    "bf16": {
[default0]:        "enabled": false
[default0]:    }, 
[default0]:    "curriculum_learning": {
[default0]:        "enabled": false, 
[default0]:        "curriculum_type": "seqlen", 
[default0]:        "min_difficulty": 80, 
[default0]:        "max_difficulty": 2.048000e+03, 
[default0]:        "schedule_type": "fixed_linear", 
[default0]:        "schedule_config": {
[default0]:            "total_curriculum_step": 5.639098e+07, 
[default0]:            "difficulty_step": 8
[default0]:        }
[default0]:    }, 
[default0]:    "wall_clock_breakdown": true, 
[default0]:    "flops_profiler": {
[default0]:        "enabled": true, 
[default0]:        "profile_step": 15, 
[default0]:        "module_depth": -1, 
[default0]:        "top_modules": 1, 
[default0]:        "detailed": true, 
[default0]:        "output_file": null
[default0]:    }
[default0]:}
[default0]:[2023-08-25 18:05:35,623] [WARNING] [engine.py:2635:load_checkpoint] Unable to find latest file at /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
[default0]:WARNING: could not find the metadata file /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true 
[default0]:    will not load any checkpoints and will start from random
[default0]:(min, max) time across ranks (ms):
[default0]:    load-checkpoint ................................: (0.76, 0.76)
[default0]:[after model, optimizer, and learning rate scheduler are built] datetime: 2023-08-25 18:05:35 
[default0]:> building train, validation, and test datasets ...
[default0]: > datasets target sizes (minimum size):
[default0]:    train:      439453125
[default0]:    validation: 219726600
[default0]:    test:       50
[default0]:> building train, validation, and test datasets for GPT ...
[default0]:Single data path provided for train, valid & test
[default0]: > building dataset index ...
[default0]:    reading sizes...
[default0]:    reading pointers...
[default0]:    reading document index...
[default0]:    creating numpy buffer of mmap...
[default0]:    creating memory view of numpy buffer...
[default0]: > finished creating indexed dataset in 0.010666 seconds
[default0]:    number of documents: 10000
[default0]: > dataset split:
[default0]:    train:
[default0]:     document indices in [0, 9800) total of 9800 documents
[default0]:    validation:
[default0]:     document indices in [9800, 10000) total of 200 documents
[default0]:    test:
[default0]:     document indices in [10000, 10000) total of 0 documents
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1232:2575539:2575997 [0] NCCL INFO comm 0x152f380090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]: > loading doc-idx mapping from /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/index-cache/153ec6eb4421dfd1cf9815ea8f6e40e4_doc_idx.npy
[default0]: > loading sample-idx mapping from /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/index-cache/153ec6eb4421dfd1cf9815ea8f6e40e4_sample_idx.npy
[default0]: > loading shuffle-idx mapping from /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/index-cache/153ec6eb4421dfd1cf9815ea8f6e40e4_shuffle_idx.npy
[default0]:    loaded indexed file in 0.187 seconds
[default0]:    total number of samples: 439466004
[default0]:    total number of epochs: 30909
[default0]: > loading doc-idx mapping from /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/index-cache/de3819301120d9a35080a0a129b3870d_doc_idx.npy
[default0]: > loading sample-idx mapping from /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/index-cache/de3819301120d9a35080a0a129b3870d_sample_idx.npy
[default0]: > loading shuffle-idx mapping from /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/data/index-cache/de3819301120d9a35080a0a129b3870d_shuffle_idx.npy
[default0]:    loaded indexed file in 0.101 seconds
[default0]:    total number of samples: 219726809
[default0]:    total number of epochs: 648115
[default0]:> finished creating GPT datasets ...
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1232:2575539:2576001 [0] NCCL INFO comm 0x152f38303e80 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:[after dataloaders are built] datetime: 2023-08-25 18:05:36 
[default0]:done with setup ...
[default0]:(min, max) time across ranks (ms):
[default0]:    model-and-optimizer-setup ......................: (1779.94, 1779.94)
[default0]:    train/valid/test-data-iterators-setup ..........: (967.91, 967.91)
[default0]:training ...
[default0]:[before the start of training step] datetime: 2023-08-25 18:05:36 
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 00/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 01/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 02/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 03/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 04/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 05/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 06/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 07/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 08/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 09/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 10/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 11/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 12/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 13/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 14/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 15/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 16/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 17/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 18/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 19/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 20/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 21/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 22/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 23/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 24/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 25/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 26/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 27/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 28/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 29/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 30/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Channel 31/32 :    0
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Connected all rings
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO Connected all trees
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
[default0]:n2gpu1232:2575539:2576005 [0] NCCL INFO comm 0x152af80090d0 rank 0 nranks 1 cudaDev 0 busId 3000 - Init COMPLETE
[default0]:n2gpu1232:2575539:2575539 [0] NCCL INFO Launch mode Parallel
[default0]:[2023-08-25 18:05:39,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.25 | optimizer_step: 19.82
[default0]:[2023-08-25 18:05:39,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 1578.65 | backward_microstep: 697.55 | backward_inner_microstep: 685.84 | backward_allreduce_microstep: 11.59 | step_microstep: 59.57
[default0]:[2023-08-25 18:05:39,318] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 1578.65 (forward_moe: 28.84, 1st alltoall: 0.99, 2nd alltoall: 0.87, top-k: 9.11)
[default0]:[2023-08-25 18:05:39,318] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 697.55 | backward_inner: 685.86 | backward_allreduce: 11.59 | step: 59.58
[default0]:[2023-08-25 18:05:39,629] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 6.54
[default0]:[2023-08-25 18:05:39,629] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.42 | backward_microstep: 118.15 | backward_inner_microstep: 106.68 | backward_allreduce_microstep: 11.37 | step_microstep: 44.53
[default0]:[2023-08-25 18:05:39,629] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.42 (forward_moe: 21.76, 1st alltoall: 0.93, 2nd alltoall: 0.86, top-k: 8.88)
[default0]:[2023-08-25 18:05:39,630] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 118.15 | backward_inner: 106.68 | backward_allreduce: 11.37 | step: 44.54
[default0]:[2023-08-25 18:05:39,908] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.17 | optimizer_step: 6.59
[default0]:[2023-08-25 18:05:39,909] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.43 | backward_microstep: 120.07 | backward_inner_microstep: 108.64 | backward_allreduce_microstep: 11.33 | step_microstep: 45.18
[default0]:[2023-08-25 18:05:39,909] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.42 (forward_moe: 21.87, 1st alltoall: 0.92, 2nd alltoall: 0.85, top-k: 8.89)
[default0]:[2023-08-25 18:05:39,909] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 120.07 | backward_inner: 108.65 | backward_allreduce: 11.33 | step: 45.19
[default0]:[2023-08-25 18:05:40,187] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.11 | optimizer_step: 6.45
[default0]:[2023-08-25 18:05:40,188] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.62 | backward_microstep: 117.87 | backward_inner_microstep: 106.45 | backward_allreduce_microstep: 11.32 | step_microstep: 44.51
[default0]:[2023-08-25 18:05:40,188] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.62 (forward_moe: 21.66, 1st alltoall: 0.92, 2nd alltoall: 0.87, top-k: 8.87)
[default0]:[2023-08-25 18:05:40,188] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.87 | backward_inner: 106.46 | backward_allreduce: 11.32 | step: 44.51
[default0]:[2023-08-25 18:05:40,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.42
[default0]:[2023-08-25 18:05:40,470] [INFO] [logging.py:96:log_dist] [Rank 0] step=5, skipped=0, lr=[4.369066666666667e-09, 4.369066666666667e-09, 4.369066666666667e-09, 4.369066666666667e-09], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:40,470] [INFO] [timer.py:215:stop] epoch=0/micro_step=5/global_step=5, RunningAvgSamplesPerSec=4.729719255764092, CurrSamplesPerSec=4.855546950337861, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:40,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.69 | backward_microstep: 114.16 | backward_inner_microstep: 102.97 | backward_allreduce_microstep: 11.09 | step_microstep: 43.56
[default0]:[2023-08-25 18:05:40,471] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.69 (forward_moe: 20.91, 1st alltoall: 0.89, 2nd alltoall: 0.85, top-k: 8.37)
[default0]:[2023-08-25 18:05:40,471] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.15 | backward_inner: 102.98 | backward_allreduce: 11.09 | step: 43.57
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([54.2253], device='cuda:0'), 'moe loss': tensor([0.3339], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration        5/439453125 | consumed samples:            5 | consumed tokens:        10240 | elapsed time per iteration (ms): 722.2 | learning rate: 4.369E-09 | global batch size:     1 | lm loss: 1.084505E+01 | moe loss: 6.677464E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.385 | TFLOPs: 3.44 |
[default0]:[Rank 0] (after 5 iterations) memory (MB) | allocated: 2941.27294921875 | max allocated: 4497.39404296875 | reserved: 4968.0 | max reserved: 4968.0
[default0]:[2023-08-25 18:05:40,795] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:05:40,795] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.05 | backward_microstep: 114.28 | backward_inner_microstep: 103.10 | backward_allreduce_microstep: 11.09 | step_microstep: 43.08
[default0]:[2023-08-25 18:05:40,795] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.05 (forward_moe: 20.88, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.39)
[default0]:[2023-08-25 18:05:40,795] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.28 | backward_inner: 103.11 | backward_allreduce: 11.09 | step: 43.08
[default0]:[2023-08-25 18:05:41,087] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.61
[default0]:[2023-08-25 18:05:41,088] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.27 | backward_microstep: 113.81 | backward_inner_microstep: 102.64 | backward_allreduce_microstep: 11.08 | step_microstep: 43.13
[default0]:[2023-08-25 18:05:41,088] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.27 (forward_moe: 21.05, 1st alltoall: 0.89, 2nd alltoall: 1.14, top-k: 8.27)
[default0]:[2023-08-25 18:05:41,088] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.81 | backward_inner: 102.64 | backward_allreduce: 11.08 | step: 43.13
[default0]:[2023-08-25 18:05:41,366] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.40
[default0]:[2023-08-25 18:05:41,366] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 52.98 | backward_microstep: 113.51 | backward_inner_microstep: 102.26 | backward_allreduce_microstep: 11.15 | step_microstep: 42.93
[default0]:[2023-08-25 18:05:41,366] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 52.97 (forward_moe: 20.86, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.40)
[default0]:[2023-08-25 18:05:41,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.51 | backward_inner: 102.27 | backward_allreduce: 11.16 | step: 42.94
[default0]:[2023-08-25 18:05:41,653] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.95 | optimizer_step: 6.32
[default0]:[2023-08-25 18:05:41,653] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.52 | backward_microstep: 112.88 | backward_inner_microstep: 101.87 | backward_allreduce_microstep: 10.92 | step_microstep: 42.35
[default0]:[2023-08-25 18:05:41,654] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.52 (forward_moe: 20.28, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.05)
[default0]:[2023-08-25 18:05:41,654] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.88 | backward_inner: 101.87 | backward_allreduce: 10.93 | step: 42.35
[default0]:[2023-08-25 18:05:41,999] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:05:41,999] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[9.830400000000001e-09, 9.830400000000001e-09, 9.830400000000001e-09, 9.830400000000001e-09], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:42,000] [INFO] [timer.py:215:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=4.819532284159435, CurrSamplesPerSec=4.9618941373684935, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:42,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.78 | backward_microstep: 111.51 | backward_inner_microstep: 100.47 | backward_allreduce_microstep: 10.95 | step_microstep: 42.69
[default0]:[2023-08-25 18:05:42,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.77 (forward_moe: 20.34, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.05)
[default0]:[2023-08-25 18:05:42,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.51 | backward_inner: 100.47 | backward_allreduce: 10.95 | step: 42.70
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([54.2262], device='cuda:0'), 'moe loss': tensor([0.3311], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       10/439453125 | consumed samples:           10 | consumed tokens:        20480 | elapsed time per iteration (ms): 316.9 | learning rate: 9.830E-09 | global batch size:     1 | lm loss: 1.084525E+01 | moe loss: 6.622190E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.155 | TFLOPs: 7.84 |
[default0]:[2023-08-25 18:05:42,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:05:42,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.59 | backward_microstep: 111.36 | backward_inner_microstep: 100.33 | backward_allreduce_microstep: 10.94 | step_microstep: 42.53
[default0]:[2023-08-25 18:05:42,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.58 (forward_moe: 20.31, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.04)
[default0]:[2023-08-25 18:05:42,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.36 | backward_inner: 100.34 | backward_allreduce: 10.94 | step: 42.54
[default0]:[2023-08-25 18:05:42,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:05:42,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.85 | backward_microstep: 111.33 | backward_inner_microstep: 100.34 | backward_allreduce_microstep: 10.90 | step_microstep: 42.13
[default0]:[2023-08-25 18:05:42,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.85 (forward_moe: 20.32, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.06)
[default0]:[2023-08-25 18:05:42,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.33 | backward_inner: 100.34 | backward_allreduce: 10.90 | step: 42.13
[default0]:[2023-08-25 18:05:42,871] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:05:42,871] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.73 | backward_microstep: 111.45 | backward_inner_microstep: 100.44 | backward_allreduce_microstep: 10.90 | step_microstep: 42.27
[default0]:[2023-08-25 18:05:42,871] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.73 (forward_moe: 20.31, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.06)
[default0]:[2023-08-25 18:05:42,871] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.44 | backward_inner: 100.44 | backward_allreduce: 10.91 | step: 42.27
[default0]:[2023-08-25 18:05:43,153] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:05:43,153] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.60 | backward_microstep: 111.34 | backward_inner_microstep: 100.29 | backward_allreduce_microstep: 10.95 | step_microstep: 42.59
[default0]:[2023-08-25 18:05:43,153] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.60 (forward_moe: 20.50, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.06)
[default0]:[2023-08-25 18:05:43,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.34 | backward_inner: 100.30 | backward_allreduce: 10.95 | step: 42.59
[default0]:[2023-08-25 18:05:43,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.42
[default0]:[2023-08-25 18:05:43,421] [INFO] [logging.py:96:log_dist] [Rank 0] step=15, skipped=0, lr=[1.5291733333333332e-08, 1.5291733333333332e-08, 1.5291733333333332e-08, 1.5291733333333332e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:43,421] [INFO] [timer.py:215:stop] epoch=0/micro_step=15/global_step=15, RunningAvgSamplesPerSec=4.867194370524089, CurrSamplesPerSec=4.854321873535215, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:43,422] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.88 | backward_microstep: 113.92 | backward_inner_microstep: 102.74 | backward_allreduce_microstep: 11.09 | step_microstep: 43.64
[default0]:[2023-08-25 18:05:43,422] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.88 (forward_moe: 20.99, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.39)
[default0]:[2023-08-25 18:05:43,422] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.92 | backward_inner: 102.75 | backward_allreduce: 11.09 | step: 43.65
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([54.2111], device='cuda:0'), 'moe loss': tensor([0.3293], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       15/439453125 | consumed samples:           15 | consumed tokens:        30720 | elapsed time per iteration (ms): 272.5 | learning rate: 1.529E-08 | global batch size:     1 | lm loss: 1.084222E+01 | moe loss: 6.585598E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.670 | TFLOPs: 9.12 |
[default0]:[2023-08-25 18:05:43,727] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.11 | optimizer_step: 6.48
[default0]:
[default0]:-------------------------- DeepSpeed Flops Profiler --------------------------
[default0]:Profile Summary at step 16:
[default0]:Notations:
[default0]:data parallel size (dp_size), model parallel size(mp_size),
[default0]:number of parameters (params), number of multiply-accumulate operations(MACs),
[default0]:number of floating-point operations (flops), floating-point operations per second (FLOPS),
[default0]:fwd latency (forward propagation latency), bwd latency (backward propagation latency),
[default0]:step (weights update latency), iter latency (sum of fwd, bwd and step latency)
[default0]:
[default0]:world size:                                                   1       
[default0]:data parallel size:                                           1       
[default0]:model parallel size:                                          1       
[default0]:batch size per GPU:                                           1       
[default0]:expert tensor parallelism enabled:                            0       
[default0]:params per gpu:                                               210.28 M
[default0]:params of model:                                              210.28 M
[default0]:   non-expert params of model:                                96.95 M 
[default0]:   expert params of model:                                    113.34 M
[default0]:fwd MACs per GPU:                                             330.41 GMACs
[default0]:fwd flops per GPU:                                            738.76 G
[default0]:fwd flops of model = fwd flops per GPU * mp_size:             738.76 G
[default0]:fwd latency:                                                  67.89 ms
[default0]:fwd FLOPS per GPU = fwd flops per GPU / fwd latency:          10.88 TFLOPS
[default0]:bwd latency:                                                  115.6 ms
[default0]:bwd FLOPS per GPU = 2.0 * fwd flops per GPU / bwd latency:    12.78 TFLOPS
[default0]:fwd+bwd FLOPS per GPU = 3.0 * fwd flops per GPU / (fwd+bwd latency):   12.08 TFLOPS
[default0]:step latency:                                                 43.77 ms
[default0]:iter latency:                                                 227.26 ms
[default0]:FLOPS per GPU = 3.0 * fwd flops per GPU / iter latency:       9.75 TFLOPS
[default0]:samples/second:                                               4.40    
[default0]:
[default0]:----------------------------- Aggregated Profile per GPU -----------------------------
[default0]:Top 1 modules in terms of params, MACs or fwd latency at different model depths:
[default0]:depth 0:
[default0]:    params      - {'GPTModel': '210.28 M'}
[default0]:    MACs        - {'GPTModel': '330.41 GMACs'}
[default0]:    fwd latency - {'GPTModel': '67.8 ms'}
[default0]:depth 1:
[default0]:    params      - {'TransformerLanguageModel': '210.28 M'}
[default0]:    MACs        - {'TransformerLanguageModel': '251.29 GMACs'}
[default0]:    fwd latency - {'TransformerLanguageModel': '63.22 ms'}
[default0]:depth 2:
[default0]:    params      - {'ParallelTransformer': '170.08 M'}
[default0]:    MACs        - {'ParallelTransformer': '251.29 GMACs'}
[default0]:    fwd latency - {'ParallelTransformer': '62.82 ms'}
[default0]:depth 3:
[default0]:    params      - {'ModuleList': '170.08 M'}
[default0]:    MACs        - {'ModuleList': '251.29 GMACs'}
[default0]:    fwd latency - {'ModuleList': '61.89 ms'}
[default0]:depth 4:
[default0]:    params      - {'ParallelTransformerLayer': '170.08 M'}
[default0]:    MACs        - {'ParallelTransformerLayer': '251.29 GMACs'}
[default0]:    fwd latency - {'ParallelTransformerLayer': '61.89 ms'}
[default0]:depth 5:
[default0]:    params      - {'MoE': '113.36 M'}
[default0]:    MACs        - {'ParallelAttention': '135.29 GMACs'}
[default0]:    fwd latency - {'MoE': '35.12 ms'}
[default0]:depth 6:
[default0]:    params      - {'MOELayer': '113.36 M'}
[default0]:    MACs        - {'CoreAttention': '77.31 GMACs'}
[default0]:    fwd latency - {'MOELayer': '34.9 ms'}
[default0]:depth 7:
[default0]:    params      - {'Experts': '113.34 M'}
[default0]:    MACs        - {'Experts': '57.98 GMACs'}
[default0]:    fwd latency - {'TopKGate': '11.76 ms'}
[default0]:depth 8:
[default0]:    params      - {'ModuleList': '113.34 M'}
[default0]:    MACs        - {'ModuleList': '57.98 GMACs'}
[default0]:    fwd latency - {'ModuleList': '9.37 ms'}
[default0]:depth 9:
[default0]:    params      - {'ParallelMLP': '113.34 M'}
[default0]:    MACs        - {'ParallelMLP': '57.98 GMACs'}
[default0]:    fwd latency - {'ParallelMLP': '9.37 ms'}
[default0]:
[default0]:------------------------------ Detailed Profile per GPU ------------------------------
[default0]:Each module profile is listed after its name in the following order: 
[default0]:params, percentage of total params, MACs, percentage of total MACs, fwd latency, percentage of total fwd latency, fwd FLOPS
[default0]:
[default0]:Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). They are not counted as submodules, thus not to be printed out. However they make up the difference between a parent's MACs (or latency) and the sum of its submodules'.
[default0]:2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.
[default0]:3. The fwd latency listed in the top module's profile is directly captured at the module forward function in PyTorch, thus it's less than the fwd latency shown above which is captured in DeepSpeed.
[default0]:
[default0]:GPTModel(
[default0]:  210.28 M, 100.00% Params, 330.41 GMACs, 100.00% MACs, 67.8 ms, 100.00% latency, 10.9 TFLOPS, 
[default0]:  (language_model): TransformerLanguageModel(
[default0]:    210.28 M, 100.00% Params, 251.29 GMACs, 76.05% MACs, 63.22 ms, 93.25% latency, 9.18 TFLOPS, 
[default0]:    (embedding): Embedding(
[default0]:      40.21 M, 19.12% Params, 0 MACs, 0.00% MACs, 347.14 us, 0.51% latency, 0.0 FLOPS, 
[default0]:      (word_embeddings): VocabParallelEmbedding(38.63 M, 18.37% Params, 0 MACs, 0.00% MACs, 108.24 us, 0.16% latency, 0.0 FLOPS, )
[default0]:      (position_embeddings): Embedding(1.57 M, 0.75% Params, 0 MACs, 0.00% MACs, 74.39 us, 0.11% latency, 0.0 FLOPS, 2048, 768)
[default0]:      (embedding_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 61.99 us, 0.09% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:    )
[default0]:    (encoder): ParallelTransformer(
[default0]:      170.08 M, 80.88% Params, 251.29 GMACs, 76.05% MACs, 62.82 ms, 92.66% latency, 9.24 TFLOPS, 
[default0]:      (layers): ModuleList(
[default0]:        170.08 M, 80.88% Params, 251.29 GMACs, 76.05% MACs, 61.89 ms, 91.28% latency, 9.38 TFLOPS, 
[default0]:        (0): ParallelTransformerLayer(
[default0]:          7.09 M, 3.37% Params, 20.94 GMACs, 6.34% MACs, 2.51 ms, 3.71% latency, 16.67 TFLOPS, 
[default0]:          (input_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 72.48 us, 0.11% latency, 0.0 FLOPS, )
[default0]:          (self_attention): ParallelAttention(
[default0]:            2.36 M, 1.12% Params, 11.27 GMACs, 3.41% MACs, 1.49 ms, 2.20% latency, 15.13 TFLOPS, 
[default0]:            (query_key_value): ColumnParallelLinear(1.77 M, 0.84% Params, 3.62 GMACs, 1.10% MACs, 210.29 us, 0.31% latency, 34.47 TFLOPS, )
[default0]:            (core_attention): CoreAttention(
[default0]:              0, 0.00% Params, 6.44 GMACs, 1.95% MACs, 1.06 ms, 1.56% latency, 12.21 TFLOPS, 
[default0]:              (scale_mask_softmax): FusedScaleMaskSoftmax(0, 0.00% Params, 0 MACs, 0.00% MACs, 232.7 us, 0.34% latency, 0.0 FLOPS, )
[default0]:              (attention_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 276.33 us, 0.41% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:            )
[default0]:            (dense): RowParallelLinear(590.59 k, 0.28% Params, 1.21 GMACs, 0.37% MACs, 129.7 us, 0.19% latency, 18.63 TFLOPS, )
[default0]:          )
[default0]:          (post_attention_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 72.0 us, 0.11% latency, 0.0 FLOPS, )
[default0]:          (mlp): ParallelMLP(
[default0]:            4.72 M, 2.25% Params, 9.66 GMACs, 2.92% MACs, 567.44 us, 0.84% latency, 34.06 TFLOPS, 
[default0]:            (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 4.83 GMACs, 1.46% MACs, 162.12 us, 0.24% latency, 59.61 TFLOPS, )
[default0]:            (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 4.83 GMACs, 1.46% MACs, 200.51 us, 0.30% latency, 48.2 TFLOPS, )
[default0]:          )
[default0]:        )
[default0]:        (1): ParallelTransformerLayer(
[default0]:          21.26 M, 10.11% Params, 20.94 GMACs, 6.34% MACs, 10.14 ms, 14.95% latency, 5.41 TFLOPS, 
[default0]:          (input_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 69.38 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (self_attention): ParallelAttention(
[default0]:            2.36 M, 1.12% Params, 11.27 GMACs, 3.41% MACs, 1.45 ms, 2.13% latency, 15.63 TFLOPS, 
[default0]:            (query_key_value): ColumnParallelLinear(1.77 M, 0.84% Params, 3.62 GMACs, 1.10% MACs, 191.69 us, 0.28% latency, 37.81 TFLOPS, )
[default0]:            (core_attention): CoreAttention(
[default0]:              0, 0.00% Params, 6.44 GMACs, 1.95% MACs, 1.04 ms, 1.53% latency, 12.48 TFLOPS, 
[default0]:              (scale_mask_softmax): FusedScaleMaskSoftmax(0, 0.00% Params, 0 MACs, 0.00% MACs, 222.44 us, 0.33% latency, 0.0 FLOPS, )
[default0]:              (attention_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 262.98 us, 0.39% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:            )
[default0]:            (dense): RowParallelLinear(590.59 k, 0.28% Params, 1.21 GMACs, 0.37% MACs, 127.32 us, 0.19% latency, 18.98 TFLOPS, )
[default0]:          )
[default0]:          (post_attention_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 71.76 us, 0.11% latency, 0.0 FLOPS, )
[default0]:          (mlp): MoE(
[default0]:            18.89 M, 8.98% Params, 9.67 GMACs, 2.93% MACs, 8.19 ms, 12.08% latency, 3.94 TFLOPS, 
[default0]:            (deepspeed_moe): MOELayer(
[default0]:              18.89 M, 8.98% Params, 9.67 GMACs, 2.93% MACs, 8.15 ms, 12.02% latency, 3.95 TFLOPS, 
[default0]:              (gate): TopKGate(
[default0]:                3.07 k, 0.00% Params, 6.29 MMACs, 0.00% MACs, 2.12 ms, 3.13% latency, 7.91 GFLOPS, 
[default0]:                (wg): Linear(3.07 k, 0.00% Params, 6.29 MMACs, 0.00% MACs, 95.84 us, 0.14% latency, 131.28 GFLOPS, in_features=768, out_features=4, bias=False)
[default0]:              )
[default0]:              (experts): Experts(
[default0]:                18.89 M, 8.98% Params, 9.66 GMACs, 2.92% MACs, 1.7 ms, 2.50% latency, 11.4 TFLOPS, 
[default0]:                (deepspeed_experts): ModuleList(
[default0]:                  18.89 M, 8.98% Params, 9.66 GMACs, 2.92% MACs, 1.56 ms, 2.30% latency, 12.37 TFLOPS, 
[default0]:                  (0): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 418.66 us, 0.62% latency, 11.54 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 114.2 us, 0.17% latency, 21.15 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 150.44 us, 0.22% latency, 16.06 TFLOPS, )
[default0]:                  )
[default0]:                  (1): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 389.34 us, 0.57% latency, 12.41 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 103.0 us, 0.15% latency, 23.46 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 143.29 us, 0.21% latency, 16.86 TFLOPS, )
[default0]:                  )
[default0]:                  (2): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 376.94 us, 0.56% latency, 12.82 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 95.84 us, 0.14% latency, 25.21 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 143.29 us, 0.21% latency, 16.86 TFLOPS, )
[default0]:                  )
[default0]:                  (3): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 377.42 us, 0.56% latency, 12.8 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 94.41 us, 0.14% latency, 25.59 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 145.91 us, 0.22% latency, 16.56 TFLOPS, )
[default0]:                  )
[default0]:                )
[default0]:              )
[default0]:            )
[default0]:          )
[default0]:        )
[default0]:        (2): ParallelTransformerLayer(
[default0]:          7.09 M, 3.37% Params, 20.94 GMACs, 6.34% MACs, 2.52 ms, 3.72% latency, 16.61 TFLOPS, 
[default0]:          (input_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 75.1 us, 0.11% latency, 0.0 FLOPS, )
[default0]:          (self_attention): ParallelAttention(
[default0]:            2.36 M, 1.12% Params, 11.27 GMACs, 3.41% MACs, 1.5 ms, 2.22% latency, 15.04 TFLOPS, 
[default0]:            (query_key_value): ColumnParallelLinear(1.77 M, 0.84% Params, 3.62 GMACs, 1.10% MACs, 199.08 us, 0.29% latency, 36.41 TFLOPS, )
[default0]:            (core_attention): CoreAttention(
[default0]:              0, 0.00% Params, 6.44 GMACs, 1.95% MACs, 1.08 ms, 1.59% latency, 12.01 TFLOPS, 
[default0]:              (scale_mask_softmax): FusedScaleMaskSoftmax(0, 0.00% Params, 0 MACs, 0.00% MACs, 232.46 us, 0.34% latency, 0.0 FLOPS, )
[default0]:              (attention_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 279.9 us, 0.41% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:            )
[default0]:            (dense): RowParallelLinear(590.59 k, 0.28% Params, 1.21 GMACs, 0.37% MACs, 130.65 us, 0.19% latency, 18.49 TFLOPS, )
[default0]:          )
[default0]:          (post_attention_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 71.76 us, 0.11% latency, 0.0 FLOPS, )
[default0]:          (mlp): ParallelMLP(
[default0]:            4.72 M, 2.25% Params, 9.66 GMACs, 2.92% MACs, 572.2 us, 0.84% latency, 33.78 TFLOPS, 
[default0]:            (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 4.83 GMACs, 1.46% MACs, 161.89 us, 0.24% latency, 59.69 TFLOPS, )
[default0]:            (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 4.83 GMACs, 1.46% MACs, 199.56 us, 0.29% latency, 48.43 TFLOPS, )
[default0]:          )
[default0]:        )
[default0]:        (3): ParallelTransformerLayer(
[default0]:          21.26 M, 10.11% Params, 20.94 GMACs, 6.34% MACs, 7.59 ms, 11.19% latency, 7.22 TFLOPS, 
[default0]:          (input_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 68.43 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (self_attention): ParallelAttention(
[default0]:            2.36 M, 1.12% Params, 11.27 GMACs, 3.41% MACs, 1.45 ms, 2.14% latency, 15.59 TFLOPS, 
[default0]:            (query_key_value): ColumnParallelLinear(1.77 M, 0.84% Params, 3.62 GMACs, 1.10% MACs, 195.74 us, 0.29% latency, 37.03 TFLOPS, )
[default0]:            (core_attention): CoreAttention(
[default0]:              0, 0.00% Params, 6.44 GMACs, 1.95% MACs, 1.03 ms, 1.53% latency, 12.5 TFLOPS, 
[default0]:              (scale_mask_softmax): FusedScaleMaskSoftmax(0, 0.00% Params, 0 MACs, 0.00% MACs, 221.97 us, 0.33% latency, 0.0 FLOPS, )
[default0]:              (attention_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 267.51 us, 0.39% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:            )
[default0]:            (dense): RowParallelLinear(590.59 k, 0.28% Params, 1.21 GMACs, 0.37% MACs, 128.03 us, 0.19% latency, 18.87 TFLOPS, )
[default0]:          )
[default0]:          (post_attention_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 69.62 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (mlp): MoE(
[default0]:            18.89 M, 8.98% Params, 9.67 GMACs, 2.93% MACs, 5.66 ms, 8.35% latency, 5.69 TFLOPS, 
[default0]:            (deepspeed_moe): MOELayer(
[default0]:              18.89 M, 8.98% Params, 9.67 GMACs, 2.93% MACs, 5.63 ms, 8.30% latency, 5.73 TFLOPS, 
[default0]:              (gate): TopKGate(
[default0]:                3.07 k, 0.00% Params, 6.29 MMACs, 0.00% MACs, 2.05 ms, 3.03% latency, 8.18 GFLOPS, 
[default0]:                (wg): Linear(3.07 k, 0.00% Params, 6.29 MMACs, 0.00% MACs, 98.94 us, 0.15% latency, 127.17 GFLOPS, in_features=768, out_features=4, bias=False)
[default0]:              )
[default0]:              (experts): Experts(
[default0]:                18.89 M, 8.98% Params, 9.66 GMACs, 2.92% MACs, 1.69 ms, 2.49% latency, 11.46 TFLOPS, 
[default0]:                (deepspeed_experts): ModuleList(
[default0]:                  18.89 M, 8.98% Params, 9.66 GMACs, 2.92% MACs, 1.56 ms, 2.30% latency, 12.41 TFLOPS, 
[default0]:                  (0): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 419.62 us, 0.62% latency, 11.51 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 111.82 us, 0.16% latency, 21.61 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 156.64 us, 0.23% latency, 15.42 TFLOPS, )
[default0]:                  )
[default0]:                  (1): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 384.09 us, 0.57% latency, 12.58 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 98.71 us, 0.15% latency, 24.48 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 144.0 us, 0.21% latency, 16.78 TFLOPS, )
[default0]:                  )
[default0]:                  (2): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 376.22 us, 0.55% latency, 12.84 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 97.04 us, 0.14% latency, 24.9 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 143.05 us, 0.21% latency, 16.89 TFLOPS, )
[default0]:                  )
[default0]:                  (3): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 377.42 us, 0.56% latency, 12.8 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 96.32 us, 0.14% latency, 25.08 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 143.29 us, 0.21% latency, 16.86 TFLOPS, )
[default0]:                  )
[default0]:                )
[default0]:              )
[default0]:            )
[default0]:          )
[default0]:        )
[default0]:        (4): ParallelTransformerLayer(
[default0]:          7.09 M, 3.37% Params, 20.94 GMACs, 6.34% MACs, 2.46 ms, 3.63% latency, 17.02 TFLOPS, 
[default0]:          (input_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 71.53 us, 0.11% latency, 0.0 FLOPS, )
[default0]:          (self_attention): ParallelAttention(
[default0]:            2.36 M, 1.12% Params, 11.27 GMACs, 3.41% MACs, 1.46 ms, 2.15% latency, 15.53 TFLOPS, 
[default0]:            (query_key_value): ColumnParallelLinear(1.77 M, 0.84% Params, 3.62 GMACs, 1.10% MACs, 195.74 us, 0.29% latency, 37.03 TFLOPS, )
[default0]:            (core_attention): CoreAttention(
[default0]:              0, 0.00% Params, 6.44 GMACs, 1.95% MACs, 1.04 ms, 1.54% latency, 12.42 TFLOPS, 
[default0]:              (scale_mask_softmax): FusedScaleMaskSoftmax(0, 0.00% Params, 0 MACs, 0.00% MACs, 229.12 us, 0.34% latency, 0.0 FLOPS, )
[default0]:              (attention_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 268.7 us, 0.40% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:            )
[default0]:            (dense): RowParallelLinear(590.59 k, 0.28% Params, 1.21 GMACs, 0.37% MACs, 129.7 us, 0.19% latency, 18.63 TFLOPS, )
[default0]:          )
[default0]:          (post_attention_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 72.96 us, 0.11% latency, 0.0 FLOPS, )
[default0]:          (mlp): ParallelMLP(
[default0]:            4.72 M, 2.25% Params, 9.66 GMACs, 2.92% MACs, 562.67 us, 0.83% latency, 34.35 TFLOPS, 
[default0]:            (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 4.83 GMACs, 1.46% MACs, 162.12 us, 0.24% latency, 59.61 TFLOPS, )
[default0]:            (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 4.83 GMACs, 1.46% MACs, 199.56 us, 0.29% latency, 48.43 TFLOPS, )
[default0]:          )
[default0]:        )
[default0]:        (5): ParallelTransformerLayer(
[default0]:          21.26 M, 10.11% Params, 20.94 GMACs, 6.34% MACs, 7.28 ms, 10.73% latency, 7.54 TFLOPS, 
[default0]:          (input_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 68.43 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (self_attention): ParallelAttention(
[default0]:            2.36 M, 1.12% Params, 11.27 GMACs, 3.41% MACs, 1.45 ms, 2.14% latency, 15.56 TFLOPS, 
[default0]:            (query_key_value): ColumnParallelLinear(1.77 M, 0.84% Params, 3.62 GMACs, 1.10% MACs, 195.74 us, 0.29% latency, 37.03 TFLOPS, )
[default0]:            (core_attention): CoreAttention(
[default0]:              0, 0.00% Params, 6.44 GMACs, 1.95% MACs, 1.04 ms, 1.53% latency, 12.5 TFLOPS, 
[default0]:              (scale_mask_softmax): FusedScaleMaskSoftmax(0, 0.00% Params, 0 MACs, 0.00% MACs, 221.49 us, 0.33% latency, 0.0 FLOPS, )
[default0]:              (attention_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 263.21 us, 0.39% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:            )
[default0]:            (dense): RowParallelLinear(590.59 k, 0.28% Params, 1.21 GMACs, 0.37% MACs, 127.55 us, 0.19% latency, 18.94 TFLOPS, )
[default0]:          )
[default0]:          (post_attention_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 70.33 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (mlp): MoE(
[default0]:            18.89 M, 8.98% Params, 9.67 GMACs, 2.93% MACs, 5.34 ms, 7.87% latency, 6.04 TFLOPS, 
[default0]:            (deepspeed_moe): MOELayer(
[default0]:              18.89 M, 8.98% Params, 9.67 GMACs, 2.93% MACs, 5.3 ms, 7.82% latency, 6.08 TFLOPS, 
[default0]:              (gate): TopKGate(
[default0]:                3.07 k, 0.00% Params, 6.29 MMACs, 0.00% MACs, 1.92 ms, 2.83% latency, 8.75 GFLOPS, 
[default0]:                (wg): Linear(3.07 k, 0.00% Params, 6.29 MMACs, 0.00% MACs, 95.84 us, 0.14% latency, 131.28 GFLOPS, in_features=768, out_features=4, bias=False)
[default0]:              )
[default0]:              (experts): Experts(
[default0]:                18.89 M, 8.98% Params, 9.66 GMACs, 2.92% MACs, 1.7 ms, 2.51% latency, 11.36 TFLOPS, 
[default0]:                (deepspeed_experts): ModuleList(
[default0]:                  18.89 M, 8.98% Params, 9.66 GMACs, 2.92% MACs, 1.57 ms, 2.31% latency, 12.31 TFLOPS, 
[default0]:                  (0): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 427.01 us, 0.63% latency, 11.32 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 118.02 us, 0.17% latency, 20.47 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 153.54 us, 0.23% latency, 15.73 TFLOPS, )
[default0]:                  )
[default0]:                  (1): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 385.52 us, 0.57% latency, 12.53 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 98.94 us, 0.15% latency, 24.42 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 144.72 us, 0.21% latency, 16.69 TFLOPS, )
[default0]:                  )
[default0]:                  (2): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 376.7 us, 0.56% latency, 12.83 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 95.61 us, 0.14% latency, 25.27 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 142.57 us, 0.21% latency, 16.94 TFLOPS, )
[default0]:                  )
[default0]:                  (3): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 380.28 us, 0.56% latency, 12.71 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 96.56 us, 0.14% latency, 25.02 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 145.44 us, 0.21% latency, 16.61 TFLOPS, )
[default0]:                  )
[default0]:                )
[default0]:              )
[default0]:            )
[default0]:          )
[default0]:        )
[default0]:        (6): ParallelTransformerLayer(
[default0]:          7.09 M, 3.37% Params, 20.94 GMACs, 6.34% MACs, 2.47 ms, 3.64% latency, 16.97 TFLOPS, 
[default0]:          (input_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 73.19 us, 0.11% latency, 0.0 FLOPS, )
[default0]:          (self_attention): ParallelAttention(
[default0]:            2.36 M, 1.12% Params, 11.27 GMACs, 3.41% MACs, 1.46 ms, 2.15% latency, 15.5 TFLOPS, 
[default0]:            (query_key_value): ColumnParallelLinear(1.77 M, 0.84% Params, 3.62 GMACs, 1.10% MACs, 197.41 us, 0.29% latency, 36.71 TFLOPS, )
[default0]:            (core_attention): CoreAttention(
[default0]:              0, 0.00% Params, 6.44 GMACs, 1.95% MACs, 1.04 ms, 1.54% latency, 12.4 TFLOPS, 
[default0]:              (scale_mask_softmax): FusedScaleMaskSoftmax(0, 0.00% Params, 0 MACs, 0.00% MACs, 228.17 us, 0.34% latency, 0.0 FLOPS, )
[default0]:              (attention_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 267.51 us, 0.39% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:            )
[default0]:            (dense): RowParallelLinear(590.59 k, 0.28% Params, 1.21 GMACs, 0.37% MACs, 128.51 us, 0.19% latency, 18.8 TFLOPS, )
[default0]:          )
[default0]:          (post_attention_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 71.05 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (mlp): ParallelMLP(
[default0]:            4.72 M, 2.25% Params, 9.66 GMACs, 2.92% MACs, 560.28 us, 0.83% latency, 34.5 TFLOPS, 
[default0]:            (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 4.83 GMACs, 1.46% MACs, 162.12 us, 0.24% latency, 59.61 TFLOPS, )
[default0]:            (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 4.83 GMACs, 1.46% MACs, 198.36 us, 0.29% latency, 48.72 TFLOPS, )
[default0]:          )
[default0]:        )
[default0]:        (7): ParallelTransformerLayer(
[default0]:          21.26 M, 10.11% Params, 20.94 GMACs, 6.34% MACs, 7.21 ms, 10.64% latency, 7.6 TFLOPS, 
[default0]:          (input_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 68.19 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (self_attention): ParallelAttention(
[default0]:            2.36 M, 1.12% Params, 11.27 GMACs, 3.41% MACs, 1.46 ms, 2.15% latency, 15.53 TFLOPS, 
[default0]:            (query_key_value): ColumnParallelLinear(1.77 M, 0.84% Params, 3.62 GMACs, 1.10% MACs, 196.93 us, 0.29% latency, 36.8 TFLOPS, )
[default0]:            (core_attention): CoreAttention(
[default0]:              0, 0.00% Params, 6.44 GMACs, 1.95% MACs, 1.04 ms, 1.53% latency, 12.44 TFLOPS, 
[default0]:              (scale_mask_softmax): FusedScaleMaskSoftmax(0, 0.00% Params, 0 MACs, 0.00% MACs, 221.01 us, 0.33% latency, 0.0 FLOPS, )
[default0]:              (attention_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 272.27 us, 0.40% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:            )
[default0]:            (dense): RowParallelLinear(590.59 k, 0.28% Params, 1.21 GMACs, 0.37% MACs, 130.41 us, 0.19% latency, 18.52 TFLOPS, )
[default0]:          )
[default0]:          (post_attention_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 71.05 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (mlp): MoE(
[default0]:            18.89 M, 8.98% Params, 9.67 GMACs, 2.93% MACs, 5.28 ms, 7.79% latency, 6.1 TFLOPS, 
[default0]:            (deepspeed_moe): MOELayer(
[default0]:              18.89 M, 8.98% Params, 9.67 GMACs, 2.93% MACs, 5.24 ms, 7.73% latency, 6.15 TFLOPS, 
[default0]:              (gate): TopKGate(
[default0]:                3.07 k, 0.00% Params, 6.29 MMACs, 0.00% MACs, 1.87 ms, 2.76% latency, 8.98 GFLOPS, 
[default0]:                (wg): Linear(3.07 k, 0.00% Params, 6.29 MMACs, 0.00% MACs, 96.32 us, 0.14% latency, 130.64 GFLOPS, in_features=768, out_features=4, bias=False)
[default0]:              )
[default0]:              (experts): Experts(
[default0]:                18.89 M, 8.98% Params, 9.66 GMACs, 2.92% MACs, 1.7 ms, 2.51% latency, 11.37 TFLOPS, 
[default0]:                (deepspeed_experts): ModuleList(
[default0]:                  18.89 M, 8.98% Params, 9.66 GMACs, 2.92% MACs, 1.57 ms, 2.31% latency, 12.33 TFLOPS, 
[default0]:                  (0): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 424.62 us, 0.63% latency, 11.38 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 117.06 us, 0.17% latency, 20.64 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 151.87 us, 0.22% latency, 15.91 TFLOPS, )
[default0]:                  )
[default0]:                  (1): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 388.62 us, 0.57% latency, 12.43 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 98.47 us, 0.15% latency, 24.54 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 150.44 us, 0.22% latency, 16.06 TFLOPS, )
[default0]:                  )
[default0]:                  (2): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 379.32 us, 0.56% latency, 12.74 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 97.75 us, 0.14% latency, 24.71 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 142.57 us, 0.21% latency, 16.94 TFLOPS, )
[default0]:                  )
[default0]:                  (3): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 375.51 us, 0.55% latency, 12.87 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 95.84 us, 0.14% latency, 25.21 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 141.62 us, 0.21% latency, 17.06 TFLOPS, )
[default0]:                  )
[default0]:                )
[default0]:              )
[default0]:            )
[default0]:          )
[default0]:        )
[default0]:        (8): ParallelTransformerLayer(
[default0]:          7.09 M, 3.37% Params, 20.94 GMACs, 6.34% MACs, 2.72 ms, 4.01% latency, 15.43 TFLOPS, 
[default0]:          (input_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 73.91 us, 0.11% latency, 0.0 FLOPS, )
[default0]:          (self_attention): ParallelAttention(
[default0]:            2.36 M, 1.12% Params, 11.27 GMACs, 3.41% MACs, 1.55 ms, 2.29% latency, 14.54 TFLOPS, 
[default0]:            (query_key_value): ColumnParallelLinear(1.77 M, 0.84% Params, 3.62 GMACs, 1.10% MACs, 195.98 us, 0.29% latency, 36.98 TFLOPS, )
[default0]:            (core_attention): CoreAttention(
[default0]:              0, 0.00% Params, 6.44 GMACs, 1.95% MACs, 1.13 ms, 1.66% latency, 11.48 TFLOPS, 
[default0]:              (scale_mask_softmax): FusedScaleMaskSoftmax(0, 0.00% Params, 0 MACs, 0.00% MACs, 225.31 us, 0.33% latency, 0.0 FLOPS, )
[default0]:              (attention_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 335.93 us, 0.50% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:            )
[default0]:            (dense): RowParallelLinear(590.59 k, 0.28% Params, 1.21 GMACs, 0.37% MACs, 132.32 us, 0.20% latency, 18.26 TFLOPS, )
[default0]:          )
[default0]:          (post_attention_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 71.53 us, 0.11% latency, 0.0 FLOPS, )
[default0]:          (mlp): ParallelMLP(
[default0]:            4.72 M, 2.25% Params, 9.66 GMACs, 2.92% MACs, 716.21 us, 1.06% latency, 26.99 TFLOPS, 
[default0]:            (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 4.83 GMACs, 1.46% MACs, 311.37 us, 0.46% latency, 31.04 TFLOPS, )
[default0]:            (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 4.83 GMACs, 1.46% MACs, 200.51 us, 0.30% latency, 48.2 TFLOPS, )
[default0]:          )
[default0]:        )
[default0]:        (9): ParallelTransformerLayer(
[default0]:          21.26 M, 10.11% Params, 20.94 GMACs, 6.34% MACs, 7.3 ms, 10.77% latency, 7.51 TFLOPS, 
[default0]:          (input_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 69.38 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (self_attention): ParallelAttention(
[default0]:            2.36 M, 1.12% Params, 11.27 GMACs, 3.41% MACs, 1.45 ms, 2.13% latency, 15.63 TFLOPS, 
[default0]:            (query_key_value): ColumnParallelLinear(1.77 M, 0.84% Params, 3.62 GMACs, 1.10% MACs, 195.74 us, 0.29% latency, 37.03 TFLOPS, )
[default0]:            (core_attention): CoreAttention(
[default0]:              0, 0.00% Params, 6.44 GMACs, 1.95% MACs, 1.04 ms, 1.53% latency, 12.48 TFLOPS, 
[default0]:              (scale_mask_softmax): FusedScaleMaskSoftmax(0, 0.00% Params, 0 MACs, 0.00% MACs, 221.73 us, 0.33% latency, 0.0 FLOPS, )
[default0]:              (attention_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 265.84 us, 0.39% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:            )
[default0]:            (dense): RowParallelLinear(590.59 k, 0.28% Params, 1.21 GMACs, 0.37% MACs, 127.55 us, 0.19% latency, 18.94 TFLOPS, )
[default0]:          )
[default0]:          (post_attention_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 70.57 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (mlp): MoE(
[default0]:            18.89 M, 8.98% Params, 9.67 GMACs, 2.93% MACs, 5.37 ms, 7.91% latency, 6.01 TFLOPS, 
[default0]:            (deepspeed_moe): MOELayer(
[default0]:              18.89 M, 8.98% Params, 9.67 GMACs, 2.93% MACs, 5.33 ms, 7.86% latency, 6.05 TFLOPS, 
[default0]:              (gate): TopKGate(
[default0]:                3.07 k, 0.00% Params, 6.29 MMACs, 0.00% MACs, 1.91 ms, 2.82% latency, 8.78 GFLOPS, 
[default0]:                (wg): Linear(3.07 k, 0.00% Params, 6.29 MMACs, 0.00% MACs, 98.47 us, 0.15% latency, 127.79 GFLOPS, in_features=768, out_features=4, bias=False)
[default0]:              )
[default0]:              (experts): Experts(
[default0]:                18.89 M, 8.98% Params, 9.66 GMACs, 2.92% MACs, 1.7 ms, 2.50% latency, 11.39 TFLOPS, 
[default0]:                (deepspeed_experts): ModuleList(
[default0]:                  18.89 M, 8.98% Params, 9.66 GMACs, 2.92% MACs, 1.57 ms, 2.31% latency, 12.34 TFLOPS, 
[default0]:                  (0): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 427.25 us, 0.63% latency, 11.31 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 118.02 us, 0.17% latency, 20.47 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 152.59 us, 0.23% latency, 15.83 TFLOPS, )
[default0]:                  )
[default0]:                  (1): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 389.1 us, 0.57% latency, 12.42 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 105.14 us, 0.16% latency, 22.98 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 144.24 us, 0.21% latency, 16.75 TFLOPS, )
[default0]:                  )
[default0]:                  (2): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 371.46 us, 0.55% latency, 13.01 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 95.61 us, 0.14% latency, 25.27 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 139.95 us, 0.21% latency, 17.26 TFLOPS, )
[default0]:                  )
[default0]:                  (3): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 378.85 us, 0.56% latency, 12.75 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 95.37 us, 0.14% latency, 25.33 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 147.58 us, 0.22% latency, 16.37 TFLOPS, )
[default0]:                  )
[default0]:                )
[default0]:              )
[default0]:            )
[default0]:          )
[default0]:        )
[default0]:        (10): ParallelTransformerLayer(
[default0]:          7.09 M, 3.37% Params, 20.94 GMACs, 6.34% MACs, 2.48 ms, 3.65% latency, 16.93 TFLOPS, 
[default0]:          (input_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 74.15 us, 0.11% latency, 0.0 FLOPS, )
[default0]:          (self_attention): ParallelAttention(
[default0]:            2.36 M, 1.12% Params, 11.27 GMACs, 3.41% MACs, 1.47 ms, 2.16% latency, 15.42 TFLOPS, 
[default0]:            (query_key_value): ColumnParallelLinear(1.77 M, 0.84% Params, 3.62 GMACs, 1.10% MACs, 196.93 us, 0.29% latency, 36.8 TFLOPS, )
[default0]:            (core_attention): CoreAttention(
[default0]:              0, 0.00% Params, 6.44 GMACs, 1.95% MACs, 1.05 ms, 1.55% latency, 12.35 TFLOPS, 
[default0]:              (scale_mask_softmax): FusedScaleMaskSoftmax(0, 0.00% Params, 0 MACs, 0.00% MACs, 227.45 us, 0.34% latency, 0.0 FLOPS, )
[default0]:              (attention_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 269.89 us, 0.40% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:            )
[default0]:            (dense): RowParallelLinear(590.59 k, 0.28% Params, 1.21 GMACs, 0.37% MACs, 130.18 us, 0.19% latency, 18.56 TFLOPS, )
[default0]:          )
[default0]:          (post_attention_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 71.05 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (mlp): ParallelMLP(
[default0]:            4.72 M, 2.25% Params, 9.66 GMACs, 2.92% MACs, 565.77 us, 0.83% latency, 34.16 TFLOPS, 
[default0]:            (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 4.83 GMACs, 1.46% MACs, 163.56 us, 0.24% latency, 59.09 TFLOPS, )
[default0]:            (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 4.83 GMACs, 1.46% MACs, 199.79 us, 0.29% latency, 48.37 TFLOPS, )
[default0]:          )
[default0]:        )
[default0]:        (11): ParallelTransformerLayer(
[default0]:          21.26 M, 10.11% Params, 20.94 GMACs, 6.34% MACs, 7.21 ms, 10.63% latency, 7.6 TFLOPS, 
[default0]:          (input_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 69.38 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (self_attention): ParallelAttention(
[default0]:            2.36 M, 1.12% Params, 11.27 GMACs, 3.41% MACs, 1.44 ms, 2.12% latency, 15.69 TFLOPS, 
[default0]:            (query_key_value): ColumnParallelLinear(1.77 M, 0.84% Params, 3.62 GMACs, 1.10% MACs, 191.93 us, 0.28% latency, 37.76 TFLOPS, )
[default0]:            (core_attention): CoreAttention(
[default0]:              0, 0.00% Params, 6.44 GMACs, 1.95% MACs, 1.03 ms, 1.52% latency, 12.54 TFLOPS, 
[default0]:              (scale_mask_softmax): FusedScaleMaskSoftmax(0, 0.00% Params, 0 MACs, 0.00% MACs, 222.68 us, 0.33% latency, 0.0 FLOPS, )
[default0]:              (attention_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 261.78 us, 0.39% latency, 0.0 FLOPS, p=0.1, inplace=False)
[default0]:            )
[default0]:            (dense): RowParallelLinear(590.59 k, 0.28% Params, 1.21 GMACs, 0.37% MACs, 128.27 us, 0.19% latency, 18.83 TFLOPS, )
[default0]:          )
[default0]:          (post_attention_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 71.05 us, 0.10% latency, 0.0 FLOPS, )
[default0]:          (mlp): MoE(
[default0]:            18.89 M, 8.98% Params, 9.67 GMACs, 2.93% MACs, 5.29 ms, 7.80% latency, 6.1 TFLOPS, 
[default0]:            (deepspeed_moe): MOELayer(
[default0]:              18.89 M, 8.98% Params, 9.67 GMACs, 2.93% MACs, 5.25 ms, 7.74% latency, 6.14 TFLOPS, 
[default0]:              (gate): TopKGate(
[default0]:                3.07 k, 0.00% Params, 6.29 MMACs, 0.00% MACs, 1.88 ms, 2.78% latency, 8.91 GFLOPS, 
[default0]:                (wg): Linear(3.07 k, 0.00% Params, 6.29 MMACs, 0.00% MACs, 98.47 us, 0.15% latency, 127.79 GFLOPS, in_features=768, out_features=4, bias=False)
[default0]:              )
[default0]:              (experts): Experts(
[default0]:                18.89 M, 8.98% Params, 9.66 GMACs, 2.92% MACs, 1.68 ms, 2.48% latency, 11.52 TFLOPS, 
[default0]:                (deepspeed_experts): ModuleList(
[default0]:                  18.89 M, 8.98% Params, 9.66 GMACs, 2.92% MACs, 1.55 ms, 2.28% latency, 12.48 TFLOPS, 
[default0]:                  (0): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 421.76 us, 0.62% latency, 11.46 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 116.35 us, 0.17% latency, 20.76 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 151.4 us, 0.22% latency, 15.96 TFLOPS, )
[default0]:                  )
[default0]:                  (1): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 380.75 us, 0.56% latency, 12.69 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 97.04 us, 0.14% latency, 24.9 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 145.91 us, 0.22% latency, 16.56 TFLOPS, )
[default0]:                  )
[default0]:                  (2): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 373.6 us, 0.55% latency, 12.93 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 95.84 us, 0.14% latency, 25.21 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 141.86 us, 0.21% latency, 17.03 TFLOPS, )
[default0]:                  )
[default0]:                  (3): ParallelMLP(
[default0]:                    4.72 M, 2.25% Params, 2.42 GMACs, 0.73% MACs, 372.65 us, 0.55% latency, 12.97 TFLOPS, 
[default0]:                    (dense_h_to_4h): ColumnParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 95.84 us, 0.14% latency, 25.21 TFLOPS, )
[default0]:                    (dense_4h_to_h): RowParallelLinear(2.36 M, 1.12% Params, 1.21 GMACs, 0.37% MACs, 140.19 us, 0.21% latency, 17.23 TFLOPS, )
[default0]:                  )
[default0]:                )
[default0]:              )
[default0]:            )
[default0]:          )
[default0]:        )
[default0]:      )
[default0]:      (final_layernorm): MixedFusedLayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 85.35 us, 0.13% latency, 0.0 FLOPS, )
[default0]:    )
[default0]:  )
[default0]:)
[default0]:------------------------------------------------------------------------------
[default0]:[2023-08-25 18:05:43,745] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 67.89 | backward_microstep: 115.60 | backward_inner_microstep: 104.25 | backward_allreduce_microstep: 11.26 | step_microstep: 43.77
[default0]:[2023-08-25 18:05:43,745] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 (forward_moe: 21.26, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.54)
[default0]:[2023-08-25 18:05:43,745] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 0.00 | backward_inner: 104.25 | backward_allreduce: 11.26 | step: 0.00
[default0]:[2023-08-25 18:05:44,023] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.43
[default0]:[2023-08-25 18:05:44,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.85 | backward_microstep: 116.47 | backward_inner_microstep: 105.10 | backward_allreduce_microstep: 11.28 | step_microstep: 43.75
[default0]:[2023-08-25 18:05:44,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.85 (forward_moe: 21.37, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.69)
[default0]:[2023-08-25 18:05:44,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.47 | backward_inner: 105.10 | backward_allreduce: 11.28 | step: 43.75
[default0]:[2023-08-25 18:05:44,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:05:44,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.41 | backward_microstep: 115.60 | backward_inner_microstep: 104.31 | backward_allreduce_microstep: 11.20 | step_microstep: 43.60
[default0]:[2023-08-25 18:05:44,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.41 (forward_moe: 21.15, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.56)
[default0]:[2023-08-25 18:05:44,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.60 | backward_inner: 104.31 | backward_allreduce: 11.20 | step: 43.60
[default0]:[2023-08-25 18:05:44,619] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.41
[default0]:[2023-08-25 18:05:44,619] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.68 | backward_microstep: 115.39 | backward_inner_microstep: 104.14 | backward_allreduce_microstep: 11.16 | step_microstep: 43.38
[default0]:[2023-08-25 18:05:44,619] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.68 (forward_moe: 21.16, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.58)
[default0]:[2023-08-25 18:05:44,619] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.39 | backward_inner: 104.14 | backward_allreduce: 11.16 | step: 43.39
[default0]:[2023-08-25 18:05:44,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.41
[default0]:[2023-08-25 18:05:44,912] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[2.0753066666666666e-08, 2.0753066666666666e-08, 2.0753066666666666e-08, 2.0753066666666666e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:44,912] [INFO] [timer.py:215:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=4.821079102189226, CurrSamplesPerSec=4.8520475683679605, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:44,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.83 | backward_microstep: 114.22 | backward_inner_microstep: 102.97 | backward_allreduce_microstep: 11.14 | step_microstep: 43.50
[default0]:[2023-08-25 18:05:44,913] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.82 (forward_moe: 20.82, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.37)
[default0]:[2023-08-25 18:05:44,913] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.22 | backward_inner: 102.98 | backward_allreduce: 11.15 | step: 43.51
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([54.2442], device='cuda:0'), 'moe loss': tensor([0.3330], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       20/439453125 | consumed samples:           20 | consumed tokens:        40960 | elapsed time per iteration (ms): 298.4 | learning rate: 2.075E-08 | global batch size:     1 | lm loss: 1.084883E+01 | moe loss: 6.660810E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.351 | TFLOPs: 8.33 |
[default0]:[2023-08-25 18:05:45,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.43
[default0]:[2023-08-25 18:05:45,187] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.78 | backward_microstep: 114.08 | backward_inner_microstep: 102.94 | backward_allreduce_microstep: 11.05 | step_microstep: 43.20
[default0]:[2023-08-25 18:05:45,187] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.78 (forward_moe: 20.96, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.37)
[default0]:[2023-08-25 18:05:45,187] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.08 | backward_inner: 102.95 | backward_allreduce: 11.05 | step: 43.21
[default0]:[2023-08-25 18:05:45,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:05:45,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.29 | backward_microstep: 128.50 | backward_inner_microstep: 117.44 | backward_allreduce_microstep: 10.97 | step_microstep: 42.61
[default0]:[2023-08-25 18:05:45,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.29 (forward_moe: 20.50, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.18)
[default0]:[2023-08-25 18:05:45,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 128.50 | backward_inner: 117.45 | backward_allreduce: 10.97 | step: 42.61
[default0]:[2023-08-25 18:05:45,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:05:45,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.01 | backward_microstep: 113.28 | backward_inner_microstep: 101.52 | backward_allreduce_microstep: 11.65 | step_microstep: 42.93
[default0]:[2023-08-25 18:05:45,737] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.01 (forward_moe: 20.45, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:05:45,737] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.28 | backward_inner: 101.53 | backward_allreduce: 11.66 | step: 42.93
[default0]:[2023-08-25 18:05:46,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.12 | optimizer_step: 6.37
[default0]:[2023-08-25 18:05:46,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.97 | backward_microstep: 112.48 | backward_inner_microstep: 101.39 | backward_allreduce_microstep: 11.00 | step_microstep: 42.64
[default0]:[2023-08-25 18:05:46,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.97 (forward_moe: 20.49, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.16)
[default0]:[2023-08-25 18:05:46,007] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.48 | backward_inner: 101.39 | backward_allreduce: 11.00 | step: 42.64
[default0]:[2023-08-25 18:05:46,283] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:05:46,286] [INFO] [logging.py:96:log_dist] [Rank 0] step=25, skipped=0, lr=[2.62144e-08, 2.62144e-08, 2.62144e-08, 2.62144e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:46,286] [INFO] [timer.py:215:stop] epoch=0/micro_step=25/global_step=25, RunningAvgSamplesPerSec=4.826338646313683, CurrSamplesPerSec=5.002891304140386, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:46,286] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.12 | backward_microstep: 109.15 | backward_inner_microstep: 98.28 | backward_allreduce_microstep: 10.77 | step_microstep: 44.05
[default0]:[2023-08-25 18:05:46,286] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.12 (forward_moe: 19.92, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:05:46,286] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.15 | backward_inner: 98.28 | backward_allreduce: 10.78 | step: 44.06
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([54.2087], device='cuda:0'), 'moe loss': tensor([0.3300], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       25/439453125 | consumed samples:           25 | consumed tokens:        51200 | elapsed time per iteration (ms): 274.7 | learning rate: 2.621E-08 | global batch size:     1 | lm loss: 1.084173E+01 | moe loss: 6.599430E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.640 | TFLOPs: 9.04 |
[default0]:[2023-08-25 18:05:46,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.91 | optimizer_step: 6.44
[default0]:[2023-08-25 18:05:46,572] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 109.06 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.75 | step_microstep: 44.36
[default0]:[2023-08-25 18:05:46,572] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:05:46,573] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.22 | backward_allreduce: 10.75 | step: 44.37
[default0]:[2023-08-25 18:05:46,839] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:05:46,840] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.69 | backward_microstep: 109.25 | backward_inner_microstep: 98.33 | backward_allreduce_microstep: 10.82 | step_microstep: 41.57
[default0]:[2023-08-25 18:05:46,840] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.69 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:05:46,840] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.25 | backward_inner: 98.34 | backward_allreduce: 10.82 | step: 41.58
[default0]:[2023-08-25 18:05:47,090] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.33
[default0]:[2023-08-25 18:05:47,091] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.53 | backward_microstep: 108.92 | backward_inner_microstep: 98.07 | backward_allreduce_microstep: 10.76 | step_microstep: 41.48
[default0]:[2023-08-25 18:05:47,091] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.53 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:05:47,091] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.07 | backward_allreduce: 10.77 | step: 41.49
[default0]:[2023-08-25 18:05:47,346] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:05:47,346] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.83 | backward_microstep: 108.97 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.79 | step_microstep: 41.39
[default0]:[2023-08-25 18:05:47,346] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.83 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.79)
[default0]:[2023-08-25 18:05:47,347] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.97 | backward_inner: 98.09 | backward_allreduce: 10.79 | step: 41.39
[default0]:[2023-08-25 18:05:47,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.28
[default0]:[2023-08-25 18:05:47,801] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[3.1675733333333335e-08, 3.1675733333333335e-08, 3.1675733333333335e-08, 3.1675733333333335e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:47,801] [INFO] [timer.py:215:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=4.865548059506587, CurrSamplesPerSec=5.064783228740381, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:47,802] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.48 | backward_microstep: 109.25 | backward_inner_microstep: 98.38 | backward_allreduce_microstep: 10.77 | step_microstep: 42.16
[default0]:[2023-08-25 18:05:47,802] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.98, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:05:47,802] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.25 | backward_inner: 98.39 | backward_allreduce: 10.78 | step: 42.17
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([54.2045], device='cuda:0'), 'moe loss': tensor([0.3345], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       30/439453125 | consumed samples:           30 | consumed tokens:        61440 | elapsed time per iteration (ms): 302.9 | learning rate: 3.168E-08 | global batch size:     1 | lm loss: 1.084090E+01 | moe loss: 6.689396E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.301 | TFLOPs: 8.20 |
[default0]:[2023-08-25 18:05:48,060] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:05:48,060] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.59 | backward_microstep: 108.96 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.74 | step_microstep: 41.62
[default0]:[2023-08-25 18:05:48,060] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.59 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:05:48,060] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.13 | backward_allreduce: 10.74 | step: 41.62
[default0]:[2023-08-25 18:05:48,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:05:48,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.78 | backward_microstep: 110.12 | backward_inner_microstep: 99.20 | backward_allreduce_microstep: 10.83 | step_microstep: 42.03
[default0]:[2023-08-25 18:05:48,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.78 (forward_moe: 19.99, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.88)
[default0]:[2023-08-25 18:05:48,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.12 | backward_inner: 99.21 | backward_allreduce: 10.83 | step: 42.03
[default0]:[2023-08-25 18:05:48,618] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:05:48,619] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.51 | backward_microstep: 111.44 | backward_inner_microstep: 100.35 | backward_allreduce_microstep: 11.00 | step_microstep: 42.37
[default0]:[2023-08-25 18:05:48,619] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.51 (forward_moe: 20.30, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.06)
[default0]:[2023-08-25 18:05:48,619] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.44 | backward_inner: 100.36 | backward_allreduce: 11.00 | step: 42.38
[default0]:[2023-08-25 18:05:48,895] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:05:48,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.62 | backward_microstep: 112.79 | backward_inner_microstep: 101.95 | backward_allreduce_microstep: 10.74 | step_microstep: 41.50
[default0]:[2023-08-25 18:05:48,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.63 (forward_moe: 20.75, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 7.95)
[default0]:[2023-08-25 18:05:48,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.79 | backward_inner: 101.95 | backward_allreduce: 10.74 | step: 41.50
[default0]:[2023-08-25 18:05:49,141] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:05:49,141] [INFO] [logging.py:96:log_dist] [Rank 0] step=35, skipped=0, lr=[3.713706666666667e-08, 3.713706666666667e-08, 3.713706666666667e-08, 3.713706666666667e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:49,141] [INFO] [timer.py:215:stop] epoch=0/micro_step=35/global_step=35, RunningAvgSamplesPerSec=4.887678689334578, CurrSamplesPerSec=5.0706735866552055, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:49,141] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.51 | backward_microstep: 109.14 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.83 | step_microstep: 42.04
[default0]:[2023-08-25 18:05:49,141] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.51 (forward_moe: 19.83, 1st alltoall: 0.85, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:05:49,142] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.13 | backward_inner: 98.22 | backward_allreduce: 10.83 | step: 42.04
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([54.1801], device='cuda:0'), 'moe loss': tensor([0.3308], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       35/439453125 | consumed samples:           35 | consumed tokens:        71680 | elapsed time per iteration (ms): 267.7 | learning rate: 3.714E-08 | global batch size:     1 | lm loss: 1.083602E+01 | moe loss: 6.616983E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.735 | TFLOPs: 9.28 |
[default0]:[2023-08-25 18:05:49,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 9.97
[default0]:[2023-08-25 18:05:49,394] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 109.26 | backward_inner_microstep: 98.37 | backward_allreduce_microstep: 10.79 | step_microstep: 45.21
[default0]:[2023-08-25 18:05:49,394] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:05:49,394] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.26 | backward_inner: 98.38 | backward_allreduce: 10.80 | step: 45.22
[default0]:[2023-08-25 18:05:49,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:05:49,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.54 | backward_microstep: 109.00 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.78 | step_microstep: 41.57
[default0]:[2023-08-25 18:05:49,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.53 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:05:49,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.14 | backward_allreduce: 10.78 | step: 41.57
[default0]:[2023-08-25 18:05:49,940] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:05:49,941] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.07 | backward_microstep: 112.58 | backward_inner_microstep: 101.66 | backward_allreduce_microstep: 10.82 | step_microstep: 41.62
[default0]:[2023-08-25 18:05:49,941] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.07 (forward_moe: 20.12, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.87)
[default0]:[2023-08-25 18:05:49,941] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.58 | backward_inner: 101.67 | backward_allreduce: 10.82 | step: 41.63
[default0]:[2023-08-25 18:05:50,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:05:50,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.35 | backward_microstep: 109.03 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.77 | step_microstep: 41.61
[default0]:[2023-08-25 18:05:50,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.35 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:05:50,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.17 | backward_allreduce: 10.77 | step: 41.61
[default0]:[2023-08-25 18:05:50,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:05:50,470] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[4.2598400000000004e-08, 4.2598400000000004e-08, 4.2598400000000004e-08, 4.2598400000000004e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:50,470] [INFO] [timer.py:215:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=4.905185565485153, CurrSamplesPerSec=5.072188187035779, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:50,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.79 | backward_microstep: 109.07 | backward_inner_microstep: 98.23 | backward_allreduce_microstep: 10.75 | step_microstep: 41.75
[default0]:[2023-08-25 18:05:50,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.79 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:05:50,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.07 | backward_inner: 98.23 | backward_allreduce: 10.75 | step: 41.76
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([54.2010], device='cuda:0'), 'moe loss': tensor([0.3280], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       40/439453125 | consumed samples:           40 | consumed tokens:        81920 | elapsed time per iteration (ms): 265.6 | learning rate: 4.260E-08 | global batch size:     1 | lm loss: 1.084019E+01 | moe loss: 6.560197E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.764 | TFLOPs: 9.35 |
[default0]:[2023-08-25 18:05:50,718] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:05:50,719] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 108.99 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.80 | step_microstep: 41.55
[default0]:[2023-08-25 18:05:50,719] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:05:50,719] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.99 | backward_inner: 98.10 | backward_allreduce: 10.80 | step: 41.55
[default0]:[2023-08-25 18:05:50,966] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:05:50,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.75 | backward_microstep: 109.02 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.80 | step_microstep: 41.69
[default0]:[2023-08-25 18:05:50,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.75 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:05:50,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.02 | backward_inner: 98.13 | backward_allreduce: 10.80 | step: 41.69
[default0]:[2023-08-25 18:05:51,255] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:05:51,255] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 112.39 | backward_inner_microstep: 101.47 | backward_allreduce_microstep: 10.82 | step_microstep: 41.44
[default0]:[2023-08-25 18:05:51,256] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.59 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.76)
[default0]:[2023-08-25 18:05:51,256] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.39 | backward_inner: 101.48 | backward_allreduce: 10.82 | step: 41.44
[default0]:[2023-08-25 18:05:51,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.74 | optimizer_gradients: 3.95 | optimizer_step: 6.30
[default0]:[2023-08-25 18:05:51,521] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 108.97 | backward_inner_microstep: 98.08 | backward_allreduce_microstep: 10.80 | step_microstep: 41.58
[default0]:[2023-08-25 18:05:51,521] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.43 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:05:51,521] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.97 | backward_inner: 98.08 | backward_allreduce: 10.80 | step: 41.58
[default0]:[2023-08-25 18:05:51,802] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:05:51,802] [INFO] [logging.py:96:log_dist] [Rank 0] step=45, skipped=0, lr=[4.805973333333334e-08, 4.805973333333334e-08, 4.805973333333334e-08, 4.805973333333334e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:51,802] [INFO] [timer.py:215:stop] epoch=0/micro_step=45/global_step=45, RunningAvgSamplesPerSec=4.922388036971103, CurrSamplesPerSec=5.062301381833279, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:51,803] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.65 | backward_microstep: 108.93 | backward_inner_microstep: 98.12 | backward_allreduce_microstep: 10.72 | step_microstep: 42.42
[default0]:[2023-08-25 18:05:51,803] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.64 (forward_moe: 19.86, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:05:51,803] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.93 | backward_inner: 98.12 | backward_allreduce: 10.72 | step: 42.43
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([54.1324], device='cuda:0'), 'moe loss': tensor([0.3327], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       45/439453125 | consumed samples:           45 | consumed tokens:        92160 | elapsed time per iteration (ms): 266.8 | learning rate: 4.806E-08 | global batch size:     1 | lm loss: 1.082648E+01 | moe loss: 6.653681E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.748 | TFLOPs: 9.31 |
[default0]:[2023-08-25 18:05:52,069] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.33
[default0]:[2023-08-25 18:05:52,069] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.39 | backward_microstep: 108.89 | backward_inner_microstep: 98.03 | backward_allreduce_microstep: 10.77 | step_microstep: 41.85
[default0]:[2023-08-25 18:05:52,069] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.39 (forward_moe: 19.73, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:05:52,069] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.89 | backward_inner: 98.03 | backward_allreduce: 10.77 | step: 41.85
[default0]:[2023-08-25 18:05:52,330] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:05:52,330] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.91 | backward_microstep: 112.14 | backward_inner_microstep: 101.06 | backward_allreduce_microstep: 10.98 | step_microstep: 42.65
[default0]:[2023-08-25 18:05:52,330] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.91 (forward_moe: 20.45, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.12)
[default0]:[2023-08-25 18:05:52,331] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.14 | backward_inner: 101.06 | backward_allreduce: 10.98 | step: 42.66
[default0]:[2023-08-25 18:05:52,730] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.44
[default0]:[2023-08-25 18:05:52,731] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.11 | backward_microstep: 114.81 | backward_inner_microstep: 103.56 | backward_allreduce_microstep: 11.15 | step_microstep: 43.55
[default0]:[2023-08-25 18:05:52,731] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.11 (forward_moe: 21.03, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.43)
[default0]:[2023-08-25 18:05:52,731] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.80 | backward_inner: 103.57 | backward_allreduce: 11.15 | step: 43.55
[default0]:[2023-08-25 18:05:52,981] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:05:52,981] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.58 | backward_microstep: 115.46 | backward_inner_microstep: 104.16 | backward_allreduce_microstep: 11.21 | step_microstep: 43.82
[default0]:[2023-08-25 18:05:52,981] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.58 (forward_moe: 21.17, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.54)
[default0]:[2023-08-25 18:05:52,981] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.46 | backward_inner: 104.16 | backward_allreduce: 11.22 | step: 43.82
[default0]:[2023-08-25 18:05:53,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.42
[default0]:[2023-08-25 18:05:53,268] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[5.3521066666666666e-08, 5.3521066666666666e-08, 5.3521066666666666e-08, 5.3521066666666666e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:53,268] [INFO] [timer.py:215:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=4.917123392358212, CurrSamplesPerSec=4.744918587668857, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:53,269] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.77 | backward_microstep: 117.26 | backward_inner_microstep: 105.95 | backward_allreduce_microstep: 11.21 | step_microstep: 44.17
[default0]:[2023-08-25 18:05:53,269] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.76 (forward_moe: 21.79, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.66)
[default0]:[2023-08-25 18:05:53,269] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.26 | backward_inner: 105.96 | backward_allreduce: 11.22 | step: 44.18
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([54.1546], device='cuda:0'), 'moe loss': tensor([0.3331], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       50/439453125 | consumed samples:           50 | consumed tokens:       102400 | elapsed time per iteration (ms): 293.1 | learning rate: 5.352E-08 | global batch size:     1 | lm loss: 1.083091E+01 | moe loss: 6.661253E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.412 | TFLOPs: 8.48 |
[default0]:[2023-08-25 18:05:53,514] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.40
[default0]:[2023-08-25 18:05:53,515] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.57 | backward_microstep: 114.12 | backward_inner_microstep: 102.93 | backward_allreduce_microstep: 11.10 | step_microstep: 43.33
[default0]:[2023-08-25 18:05:53,515] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.57 (forward_moe: 20.80, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.38)
[default0]:[2023-08-25 18:05:53,515] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.12 | backward_inner: 102.93 | backward_allreduce: 11.11 | step: 43.33
[default0]:[2023-08-25 18:05:53,794] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.40
[default0]:[2023-08-25 18:05:53,795] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.72 | backward_microstep: 114.09 | backward_inner_microstep: 102.85 | backward_allreduce_microstep: 11.14 | step_microstep: 43.23
[default0]:[2023-08-25 18:05:53,795] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.72 (forward_moe: 20.81, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.37)
[default0]:[2023-08-25 18:05:53,795] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.09 | backward_inner: 102.86 | backward_allreduce: 11.15 | step: 43.23
[default0]:[2023-08-25 18:05:54,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.36
[default0]:[2023-08-25 18:05:54,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.86 | backward_microstep: 114.16 | backward_inner_microstep: 102.98 | backward_allreduce_microstep: 11.09 | step_microstep: 43.11
[default0]:[2023-08-25 18:05:54,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.85 (forward_moe: 20.92, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.37)
[default0]:[2023-08-25 18:05:54,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.16 | backward_inner: 102.98 | backward_allreduce: 11.09 | step: 43.11
[default0]:[2023-08-25 18:05:54,307] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:05:54,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.91 | backward_microstep: 112.19 | backward_inner_microstep: 101.13 | backward_allreduce_microstep: 10.96 | step_microstep: 42.76
[default0]:[2023-08-25 18:05:54,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.91 (forward_moe: 20.40, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:05:54,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.19 | backward_inner: 101.14 | backward_allreduce: 10.97 | step: 42.76
[default0]:[2023-08-25 18:05:54,569] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:05:54,569] [INFO] [logging.py:96:log_dist] [Rank 0] step=55, skipped=0, lr=[5.89824e-08, 5.89824e-08, 5.89824e-08, 5.89824e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:54,569] [INFO] [timer.py:215:stop] epoch=0/micro_step=55/global_step=55, RunningAvgSamplesPerSec=4.914186956005605, CurrSamplesPerSec=4.927350924369353, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:54,569] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.19 | backward_microstep: 112.38 | backward_inner_microstep: 101.33 | backward_allreduce_microstep: 10.96 | step_microstep: 42.82
[default0]:[2023-08-25 18:05:54,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.19 (forward_moe: 20.60, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.15)
[default0]:[2023-08-25 18:05:54,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.38 | backward_inner: 101.34 | backward_allreduce: 10.96 | step: 42.83
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([54.0851], device='cuda:0'), 'moe loss': tensor([0.3270], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       55/439453125 | consumed samples:           55 | consumed tokens:       112640 | elapsed time per iteration (ms): 260.6 | learning rate: 5.898E-08 | global batch size:     1 | lm loss: 1.081703E+01 | moe loss: 6.540324E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.837 | TFLOPs: 9.53 |
[default0]:[2023-08-25 18:05:54,847] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:05:54,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.04 | backward_microstep: 112.52 | backward_inner_microstep: 101.47 | backward_allreduce_microstep: 10.96 | step_microstep: 42.80
[default0]:[2023-08-25 18:05:54,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.04 (forward_moe: 20.46, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.17)
[default0]:[2023-08-25 18:05:54,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.52 | backward_inner: 101.47 | backward_allreduce: 10.96 | step: 42.81
[default0]:[2023-08-25 18:05:55,084] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:05:55,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.28 | backward_microstep: 110.32 | backward_inner_microstep: 99.39 | backward_allreduce_microstep: 10.84 | step_microstep: 41.87
[default0]:[2023-08-25 18:05:55,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.28 (forward_moe: 20.02, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:05:55,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.32 | backward_inner: 99.39 | backward_allreduce: 10.84 | step: 41.87
[default0]:[2023-08-25 18:05:55,353] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:05:55,353] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.17 | backward_microstep: 110.51 | backward_inner_microstep: 99.57 | backward_allreduce_microstep: 10.85 | step_microstep: 41.97
[default0]:[2023-08-25 18:05:55,353] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.17 (forward_moe: 20.14, 1st alltoall: 0.89, 2nd alltoall: 0.80, top-k: 7.91)
[default0]:[2023-08-25 18:05:55,353] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.51 | backward_inner: 99.57 | backward_allreduce: 10.86 | step: 41.97
[default0]:[2023-08-25 18:05:55,622] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:05:55,623] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.02 | backward_microstep: 113.33 | backward_inner_microstep: 102.32 | backward_allreduce_microstep: 10.92 | step_microstep: 42.61
[default0]:[2023-08-25 18:05:55,623] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.02 (forward_moe: 20.06, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.92)
[default0]:[2023-08-25 18:05:55,623] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.33 | backward_inner: 102.32 | backward_allreduce: 10.92 | step: 42.61
[default0]:[2023-08-25 18:05:55,900] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:05:55,901] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[6.444373333333333e-08, 6.444373333333333e-08, 6.444373333333333e-08, 6.444373333333333e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:55,901] [INFO] [timer.py:215:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=4.9196428204886615, CurrSamplesPerSec=5.007334963325183, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:55,901] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.23 | backward_microstep: 110.65 | backward_inner_microstep: 99.76 | backward_allreduce_microstep: 10.79 | step_microstep: 42.27
[default0]:[2023-08-25 18:05:55,901] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.23 (forward_moe: 20.40, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.91)
[default0]:[2023-08-25 18:05:55,901] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.65 | backward_inner: 99.77 | backward_allreduce: 10.80 | step: 42.27
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.9719], device='cuda:0'), 'moe loss': tensor([0.3250], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       60/439453125 | consumed samples:           60 | consumed tokens:       122880 | elapsed time per iteration (ms): 266.6 | learning rate: 6.444E-08 | global batch size:     1 | lm loss: 1.079438E+01 | moe loss: 6.500546E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.751 | TFLOPs: 9.32 |
[default0]:[2023-08-25 18:05:56,166] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:05:56,167] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.24 | backward_microstep: 111.97 | backward_inner_microstep: 100.69 | backward_allreduce_microstep: 11.19 | step_microstep: 42.46
[default0]:[2023-08-25 18:05:56,167] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.24 (forward_moe: 20.27, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.00)
[default0]:[2023-08-25 18:05:56,167] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.97 | backward_inner: 100.69 | backward_allreduce: 11.19 | step: 42.46
[default0]:[2023-08-25 18:05:56,434] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:05:56,434] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.43 | backward_microstep: 110.27 | backward_inner_microstep: 99.35 | backward_allreduce_microstep: 10.83 | step_microstep: 42.37
[default0]:[2023-08-25 18:05:56,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.43 (forward_moe: 20.00, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.89)
[default0]:[2023-08-25 18:05:56,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.27 | backward_inner: 99.36 | backward_allreduce: 10.83 | step: 42.37
[default0]:[2023-08-25 18:05:56,735] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:05:56,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.40 | backward_microstep: 110.74 | backward_inner_microstep: 99.66 | backward_allreduce_microstep: 10.99 | step_microstep: 42.95
[default0]:[2023-08-25 18:05:56,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.40 (forward_moe: 20.03, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.91)
[default0]:[2023-08-25 18:05:56,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.73 | backward_inner: 99.66 | backward_allreduce: 10.99 | step: 42.96
[default0]:[2023-08-25 18:05:56,996] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.42
[default0]:[2023-08-25 18:05:56,997] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.59 | backward_microstep: 113.39 | backward_inner_microstep: 102.27 | backward_allreduce_microstep: 11.03 | step_microstep: 43.08
[default0]:[2023-08-25 18:05:56,997] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.59 (forward_moe: 20.68, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.29)
[default0]:[2023-08-25 18:05:56,997] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.38 | backward_inner: 102.27 | backward_allreduce: 11.03 | step: 43.08
[default0]:[2023-08-25 18:05:57,580] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 6.51
[default0]:[2023-08-25 18:05:57,580] [INFO] [logging.py:96:log_dist] [Rank 0] step=65, skipped=0, lr=[6.990506666666667e-08, 6.990506666666667e-08, 6.990506666666667e-08, 6.990506666666667e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:57,580] [INFO] [timer.py:215:stop] epoch=0/micro_step=65/global_step=65, RunningAvgSamplesPerSec=4.917897616868003, CurrSamplesPerSec=4.7046292484692, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:57,580] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.37 | backward_microstep: 117.73 | backward_inner_microstep: 106.36 | backward_allreduce_microstep: 11.29 | step_microstep: 44.88
[default0]:[2023-08-25 18:05:57,580] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.37 (forward_moe: 21.65, 1st alltoall: 0.92, 2nd alltoall: 0.84, top-k: 8.81)
[default0]:[2023-08-25 18:05:57,580] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.73 | backward_inner: 106.36 | backward_allreduce: 11.29 | step: 44.88
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([54.0148], device='cuda:0'), 'moe loss': tensor([0.3280], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       65/439453125 | consumed samples:           65 | consumed tokens:       133120 | elapsed time per iteration (ms): 335.1 | learning rate: 6.991E-08 | global batch size:     1 | lm loss: 1.080296E+01 | moe loss: 6.559541E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.985 | TFLOPs: 7.42 |
[default0]:[2023-08-25 18:05:57,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.18 | optimizer_step: 6.54
[default0]:[2023-08-25 18:05:57,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.52 | backward_microstep: 117.86 | backward_inner_microstep: 106.46 | backward_allreduce_microstep: 11.31 | step_microstep: 44.87
[default0]:[2023-08-25 18:05:57,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.52 (forward_moe: 21.59, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.84)
[default0]:[2023-08-25 18:05:57,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.86 | backward_inner: 106.46 | backward_allreduce: 11.31 | step: 44.87
[default0]:[2023-08-25 18:05:58,125] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.38
[default0]:[2023-08-25 18:05:58,126] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.40 | backward_microstep: 113.46 | backward_inner_microstep: 102.35 | backward_allreduce_microstep: 11.02 | step_microstep: 43.05
[default0]:[2023-08-25 18:05:58,126] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.39 (forward_moe: 20.71, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.30)
[default0]:[2023-08-25 18:05:58,126] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.46 | backward_inner: 102.35 | backward_allreduce: 11.02 | step: 43.05
[default0]:[2023-08-25 18:05:58,402] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.38
[default0]:[2023-08-25 18:05:58,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.43 | backward_microstep: 113.58 | backward_inner_microstep: 102.42 | backward_allreduce_microstep: 11.07 | step_microstep: 43.13
[default0]:[2023-08-25 18:05:58,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.42 (forward_moe: 20.79, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.37)
[default0]:[2023-08-25 18:05:58,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.58 | backward_inner: 102.43 | backward_allreduce: 11.07 | step: 43.14
[default0]:[2023-08-25 18:05:58,674] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.40
[default0]:[2023-08-25 18:05:58,675] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.78 | backward_microstep: 113.55 | backward_inner_microstep: 102.45 | backward_allreduce_microstep: 11.01 | step_microstep: 43.02
[default0]:[2023-08-25 18:05:58,675] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.78 (forward_moe: 20.72, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.32)
[default0]:[2023-08-25 18:05:58,675] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.55 | backward_inner: 102.45 | backward_allreduce: 11.02 | step: 43.03
[default0]:[2023-08-25 18:05:58,918] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:05:58,918] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[7.536640000000001e-08, 7.536640000000001e-08, 7.536640000000001e-08, 7.536640000000001e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:05:58,918] [INFO] [timer.py:215:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=4.914362881419332, CurrSamplesPerSec=5.034060862833584, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:05:58,919] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.92 | backward_microstep: 110.03 | backward_inner_microstep: 99.10 | backward_allreduce_microstep: 10.84 | step_microstep: 42.15
[default0]:[2023-08-25 18:05:58,919] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.92 (forward_moe: 19.99, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.84)
[default0]:[2023-08-25 18:05:58,919] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.03 | backward_inner: 99.10 | backward_allreduce: 10.84 | step: 42.15
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.9532], device='cuda:0'), 'moe loss': tensor([0.3270], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       70/439453125 | consumed samples:           70 | consumed tokens:       143360 | elapsed time per iteration (ms): 268.0 | learning rate: 7.537E-08 | global batch size:     1 | lm loss: 1.079064E+01 | moe loss: 6.540836E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.732 | TFLOPs: 9.27 |
[default0]:[2023-08-25 18:05:59,163] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:05:59,163] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.12 | backward_microstep: 109.50 | backward_inner_microstep: 98.58 | backward_allreduce_microstep: 10.82 | step_microstep: 41.57
[default0]:[2023-08-25 18:05:59,163] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.12 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:05:59,163] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.50 | backward_inner: 98.59 | backward_allreduce: 10.82 | step: 41.58
[default0]:[2023-08-25 18:05:59,439] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 9.74
[default0]:[2023-08-25 18:05:59,440] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.85 | backward_microstep: 109.56 | backward_inner_microstep: 98.64 | backward_allreduce_microstep: 10.83 | step_microstep: 45.28
[default0]:[2023-08-25 18:05:59,440] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.84 (forward_moe: 19.93, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:05:59,440] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.56 | backward_inner: 98.64 | backward_allreduce: 10.84 | step: 45.28
[default0]:[2023-08-25 18:05:59,699] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.33
[default0]:[2023-08-25 18:05:59,700] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.06 | backward_microstep: 109.64 | backward_inner_microstep: 98.74 | backward_allreduce_microstep: 10.80 | step_microstep: 41.79
[default0]:[2023-08-25 18:05:59,700] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.06 (forward_moe: 19.89, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.81)
[default0]:[2023-08-25 18:05:59,700] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.63 | backward_inner: 98.74 | backward_allreduce: 10.81 | step: 41.80
[default0]:[2023-08-25 18:05:59,948] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:05:59,949] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.78 | backward_microstep: 112.03 | backward_inner_microstep: 101.15 | backward_allreduce_microstep: 10.78 | step_microstep: 42.42
[default0]:[2023-08-25 18:05:59,949] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 20.08, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.04)
[default0]:[2023-08-25 18:05:59,949] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.03 | backward_inner: 101.16 | backward_allreduce: 10.78 | step: 42.43
[default0]:[2023-08-25 18:06:00,206] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:06:00,206] [INFO] [logging.py:96:log_dist] [Rank 0] step=75, skipped=0, lr=[8.082773333333334e-08, 8.082773333333334e-08, 8.082773333333334e-08, 8.082773333333334e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:00,206] [INFO] [timer.py:215:stop] epoch=0/micro_step=75/global_step=75, RunningAvgSamplesPerSec=4.9210348811703195, CurrSamplesPerSec=5.0398920479055445, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:00,206] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.99 | backward_microstep: 109.76 | backward_inner_microstep: 98.86 | backward_allreduce_microstep: 10.80 | step_microstep: 42.12
[default0]:[2023-08-25 18:06:00,207] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.99 (forward_moe: 19.99, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:06:00,207] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.75 | backward_inner: 98.86 | backward_allreduce: 10.80 | step: 42.13
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.9063], device='cuda:0'), 'moe loss': tensor([0.3258], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       75/439453125 | consumed samples:           75 | consumed tokens:       153600 | elapsed time per iteration (ms): 257.2 | learning rate: 8.083E-08 | global batch size:     1 | lm loss: 1.078126E+01 | moe loss: 6.515117E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.888 | TFLOPs: 9.66 |
[default0]:[2023-08-25 18:06:00,508] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:06:00,509] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.79 | backward_microstep: 109.67 | backward_inner_microstep: 98.72 | backward_allreduce_microstep: 10.85 | step_microstep: 41.91
[default0]:[2023-08-25 18:06:00,509] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.79 (forward_moe: 19.89, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.85)
[default0]:[2023-08-25 18:06:00,509] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.67 | backward_inner: 98.72 | backward_allreduce: 10.86 | step: 41.91
[default0]:[2023-08-25 18:06:00,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.34
[default0]:[2023-08-25 18:06:00,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.68 | backward_microstep: 112.26 | backward_inner_microstep: 101.15 | backward_allreduce_microstep: 11.02 | step_microstep: 42.76
[default0]:[2023-08-25 18:06:00,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.68 (forward_moe: 20.45, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:06:00,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.25 | backward_inner: 101.15 | backward_allreduce: 11.02 | step: 42.77
[default0]:[2023-08-25 18:06:01,057] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.12 | optimizer_step: 6.42
[default0]:[2023-08-25 18:06:01,058] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.33 | backward_microstep: 114.24 | backward_inner_microstep: 103.06 | backward_allreduce_microstep: 11.10 | step_microstep: 43.02
[default0]:[2023-08-25 18:06:01,058] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.33 (forward_moe: 21.06, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.64)
[default0]:[2023-08-25 18:06:01,058] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.24 | backward_inner: 103.06 | backward_allreduce: 11.10 | step: 43.03
[default0]:[2023-08-25 18:06:01,336] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.42
[default0]:[2023-08-25 18:06:01,336] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.02 | backward_microstep: 115.83 | backward_inner_microstep: 104.65 | backward_allreduce_microstep: 11.09 | step_microstep: 43.13
[default0]:[2023-08-25 18:06:01,336] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.02 (forward_moe: 20.78, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.36)
[default0]:[2023-08-25 18:06:01,336] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.83 | backward_inner: 104.65 | backward_allreduce: 11.09 | step: 43.14
[default0]:[2023-08-25 18:06:01,597] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.44
[default0]:[2023-08-25 18:06:01,597] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[8.628906666666668e-08, 8.628906666666668e-08, 8.628906666666668e-08, 8.628906666666668e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:01,598] [INFO] [timer.py:215:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=4.91916592971936, CurrSamplesPerSec=4.805275567277001, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:01,598] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.63 | backward_microstep: 114.31 | backward_inner_microstep: 103.12 | backward_allreduce_microstep: 11.09 | step_microstep: 45.61
[default0]:[2023-08-25 18:06:01,598] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.63 (forward_moe: 21.08, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.39)
[default0]:[2023-08-25 18:06:01,599] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.31 | backward_inner: 103.13 | backward_allreduce: 11.10 | step: 45.62
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.9416], device='cuda:0'), 'moe loss': tensor([0.3215], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       80/439453125 | consumed samples:           80 | consumed tokens:       163840 | elapsed time per iteration (ms): 278.9 | learning rate: 8.629E-08 | global batch size:     1 | lm loss: 1.078832E+01 | moe loss: 6.429726E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.586 | TFLOPs: 8.91 |
[default0]:[2023-08-25 18:06:01,922] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.46
[default0]:[2023-08-25 18:06:01,922] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.39 | backward_microstep: 116.27 | backward_inner_microstep: 104.78 | backward_allreduce_microstep: 11.39 | step_microstep: 43.64
[default0]:[2023-08-25 18:06:01,922] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.39 (forward_moe: 21.19, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.60)
[default0]:[2023-08-25 18:06:01,922] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.27 | backward_inner: 104.79 | backward_allreduce: 11.40 | step: 43.64
[default0]:[2023-08-25 18:06:02,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.43
[default0]:[2023-08-25 18:06:02,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.15 | backward_microstep: 114.84 | backward_inner_microstep: 103.59 | backward_allreduce_microstep: 11.16 | step_microstep: 43.64
[default0]:[2023-08-25 18:06:02,200] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.15 (forward_moe: 21.01, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.51)
[default0]:[2023-08-25 18:06:02,200] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.84 | backward_inner: 103.60 | backward_allreduce: 11.16 | step: 43.64
[default0]:[2023-08-25 18:06:02,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:06:02,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.29 | backward_microstep: 114.87 | backward_inner_microstep: 103.64 | backward_allreduce_microstep: 11.14 | step_microstep: 43.55
[default0]:[2023-08-25 18:06:02,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.29 (forward_moe: 20.99, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.49)
[default0]:[2023-08-25 18:06:02,484] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.87 | backward_inner: 103.65 | backward_allreduce: 11.14 | step: 43.56
[default0]:[2023-08-25 18:06:02,755] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:02,756] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.39 | backward_microstep: 113.11 | backward_inner_microstep: 102.01 | backward_allreduce_microstep: 11.00 | step_microstep: 42.95
[default0]:[2023-08-25 18:06:02,756] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.38 (forward_moe: 20.74, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:06:02,756] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.10 | backward_inner: 102.02 | backward_allreduce: 11.01 | step: 42.95
[default0]:[2023-08-25 18:06:03,014] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:03,014] [INFO] [logging.py:96:log_dist] [Rank 0] step=85, skipped=0, lr=[9.175040000000002e-08, 9.175040000000002e-08, 9.175040000000002e-08, 9.175040000000002e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:03,015] [INFO] [timer.py:215:stop] epoch=0/micro_step=85/global_step=85, RunningAvgSamplesPerSec=4.914261831151549, CurrSamplesPerSec=4.881178566731954, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:03,015] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.31 | backward_microstep: 113.48 | backward_inner_microstep: 102.33 | backward_allreduce_microstep: 11.04 | step_microstep: 43.54
[default0]:[2023-08-25 18:06:03,015] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.31 (forward_moe: 20.79, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.28)
[default0]:[2023-08-25 18:06:03,015] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.47 | backward_inner: 102.34 | backward_allreduce: 11.05 | step: 43.55
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.8564], device='cuda:0'), 'moe loss': tensor([0.3222], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       85/439453125 | consumed samples:           85 | consumed tokens:       174080 | elapsed time per iteration (ms): 282.9 | learning rate: 9.175E-08 | global batch size:     1 | lm loss: 1.077129E+01 | moe loss: 6.444328E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.535 | TFLOPs: 8.78 |
[default0]:[2023-08-25 18:06:03,330] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.41
[default0]:[2023-08-25 18:06:03,330] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.33 | backward_microstep: 113.98 | backward_inner_microstep: 102.88 | backward_allreduce_microstep: 11.01 | step_microstep: 43.03
[default0]:[2023-08-25 18:06:03,330] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.33 (forward_moe: 20.64, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:06:03,331] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.98 | backward_inner: 102.89 | backward_allreduce: 11.01 | step: 43.03
[default0]:[2023-08-25 18:06:03,763] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.02 | optimizer_step: 6.37
[default0]:[2023-08-25 18:06:03,764] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.29 | backward_microstep: 113.01 | backward_inner_microstep: 101.84 | backward_allreduce_microstep: 11.07 | step_microstep: 42.99
[default0]:[2023-08-25 18:06:03,764] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.28 (forward_moe: 20.59, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:06:03,764] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.01 | backward_inner: 101.84 | backward_allreduce: 11.08 | step: 42.99
[default0]:[2023-08-25 18:06:04,029] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.41
[default0]:[2023-08-25 18:06:04,029] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.22 | backward_microstep: 113.33 | backward_inner_microstep: 102.18 | backward_allreduce_microstep: 11.05 | step_microstep: 43.04
[default0]:[2023-08-25 18:06:04,029] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.22 (forward_moe: 20.68, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:06:04,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.33 | backward_inner: 102.19 | backward_allreduce: 11.06 | step: 43.05
[default0]:[2023-08-25 18:06:04,279] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:04,279] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.49 | backward_microstep: 113.49 | backward_inner_microstep: 102.32 | backward_allreduce_microstep: 11.08 | step_microstep: 42.93
[default0]:[2023-08-25 18:06:04,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.49 (forward_moe: 20.68, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.27)
[default0]:[2023-08-25 18:06:04,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.49 | backward_inner: 102.32 | backward_allreduce: 11.08 | step: 42.93
[default0]:[2023-08-25 18:06:04,725] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.16 | optimizer_step: 6.49
[default0]:[2023-08-25 18:06:04,726] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[9.721173333333333e-08, 9.721173333333333e-08, 9.721173333333333e-08, 9.721173333333333e-08], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:04,726] [INFO] [timer.py:215:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=4.910555113590797, CurrSamplesPerSec=4.705204516848437, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:04,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.26 | backward_microstep: 117.86 | backward_inner_microstep: 106.43 | backward_allreduce_microstep: 11.34 | step_microstep: 44.84
[default0]:[2023-08-25 18:06:04,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.26 (forward_moe: 21.68, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.82)
[default0]:[2023-08-25 18:06:04,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.85 | backward_inner: 106.43 | backward_allreduce: 11.34 | step: 44.84
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.7306], device='cuda:0'), 'moe loss': tensor([0.3222], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       90/439453125 | consumed samples:           90 | consumed tokens:       184320 | elapsed time per iteration (ms): 342.2 | learning rate: 9.721E-08 | global batch size:     1 | lm loss: 1.074612E+01 | moe loss: 6.444761E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.922 | TFLOPs: 7.26 |
[default0]:[2023-08-25 18:06:05,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:05,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.51 | backward_microstep: 113.65 | backward_inner_microstep: 102.51 | backward_allreduce_microstep: 11.05 | step_microstep: 43.17
[default0]:[2023-08-25 18:06:05,001] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.52 (forward_moe: 20.84, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.30)
[default0]:[2023-08-25 18:06:05,001] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.65 | backward_inner: 102.51 | backward_allreduce: 11.05 | step: 43.18
[default0]:[2023-08-25 18:06:05,264] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.38
[default0]:[2023-08-25 18:06:05,265] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.65 | backward_microstep: 113.62 | backward_inner_microstep: 102.53 | backward_allreduce_microstep: 11.00 | step_microstep: 43.86
[default0]:[2023-08-25 18:06:05,265] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.64 (forward_moe: 20.79, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.32)
[default0]:[2023-08-25 18:06:05,265] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.62 | backward_inner: 102.53 | backward_allreduce: 11.00 | step: 43.86
[default0]:[2023-08-25 18:06:05,521] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.40
[default0]:[2023-08-25 18:06:05,521] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.55 | backward_microstep: 113.65 | backward_inner_microstep: 102.52 | backward_allreduce_microstep: 11.04 | step_microstep: 43.03
[default0]:[2023-08-25 18:06:05,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.55 (forward_moe: 20.84, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.31)
[default0]:[2023-08-25 18:06:05,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.65 | backward_inner: 102.52 | backward_allreduce: 11.04 | step: 43.04
[default0]:[2023-08-25 18:06:05,783] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:06:05,783] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.39 | backward_microstep: 109.28 | backward_inner_microstep: 98.37 | backward_allreduce_microstep: 10.81 | step_microstep: 41.63
[default0]:[2023-08-25 18:06:05,783] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.39 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:06:05,784] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.27 | backward_inner: 98.38 | backward_allreduce: 10.81 | step: 41.64
[default0]:[2023-08-25 18:06:06,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:06:06,024] [INFO] [logging.py:96:log_dist] [Rank 0] step=95, skipped=0, lr=[1.0267306666666667e-07, 1.0267306666666667e-07, 1.0267306666666667e-07, 1.0267306666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:06,024] [INFO] [timer.py:215:stop] epoch=0/micro_step=95/global_step=95, RunningAvgSamplesPerSec=4.911348836608451, CurrSamplesPerSec=5.028285351894522, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:06,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.58 | backward_microstep: 110.67 | backward_inner_microstep: 99.83 | backward_allreduce_microstep: 10.74 | step_microstep: 42.07
[default0]:[2023-08-25 18:06:06,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.58 (forward_moe: 20.27, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.88)
[default0]:[2023-08-25 18:06:06,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.67 | backward_inner: 99.84 | backward_allreduce: 10.74 | step: 42.08
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.5975], device='cuda:0'), 'moe loss': tensor([0.3245], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration       95/439453125 | consumed samples:           95 | consumed tokens:       194560 | elapsed time per iteration (ms): 259.5 | learning rate: 1.027E-07 | global batch size:     1 | lm loss: 1.071950E+01 | moe loss: 6.490695E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.853 | TFLOPs: 9.57 |
[default0]:[2023-08-25 18:06:06,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.33
[default0]:[2023-08-25 18:06:06,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 109.26 | backward_inner_microstep: 98.39 | backward_allreduce_microstep: 10.78 | step_microstep: 41.65
[default0]:[2023-08-25 18:06:06,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.95, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:06:06,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.26 | backward_inner: 98.39 | backward_allreduce: 10.78 | step: 41.65
[default0]:[2023-08-25 18:06:06,552] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:06:06,552] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.97 | backward_microstep: 109.18 | backward_inner_microstep: 98.30 | backward_allreduce_microstep: 10.78 | step_microstep: 41.72
[default0]:[2023-08-25 18:06:06,552] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.97 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.75)
[default0]:[2023-08-25 18:06:06,553] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.18 | backward_inner: 98.30 | backward_allreduce: 10.79 | step: 41.73
[default0]:[2023-08-25 18:06:06,814] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:06,814] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 109.29 | backward_inner_microstep: 98.44 | backward_allreduce_microstep: 10.76 | step_microstep: 41.75
[default0]:[2023-08-25 18:06:06,814] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.84)
[default0]:[2023-08-25 18:06:06,814] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.29 | backward_inner: 98.44 | backward_allreduce: 10.76 | step: 41.75
[default0]:[2023-08-25 18:06:07,092] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:07,093] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 109.42 | backward_inner_microstep: 98.49 | backward_allreduce_microstep: 10.83 | step_microstep: 41.79
[default0]:[2023-08-25 18:06:07,093] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.65 (forward_moe: 19.80, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.78)
[default0]:[2023-08-25 18:06:07,093] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.42 | backward_inner: 98.50 | backward_allreduce: 10.83 | step: 41.80
[default0]:[2023-08-25 18:06:07,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:06:07,350] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[1.081344e-07, 1.081344e-07, 1.081344e-07, 1.081344e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:07,350] [INFO] [timer.py:215:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=4.9188687804730185, CurrSamplesPerSec=5.059681579220378, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:07,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 109.41 | backward_inner_microstep: 98.50 | backward_allreduce_microstep: 10.82 | step_microstep: 42.18
[default0]:[2023-08-25 18:06:07,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.93, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.75)
[default0]:[2023-08-25 18:06:07,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.41 | backward_inner: 98.50 | backward_allreduce: 10.83 | step: 42.19
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.5833], device='cuda:0'), 'moe loss': tensor([0.3231], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      100/439453125 | consumed samples:          100 | consumed tokens:       204800 | elapsed time per iteration (ms): 266.3 | learning rate: 1.081E-07 | global batch size:     1 | lm loss: 1.071666E+01 | moe loss: 6.461568E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.755 | TFLOPs: 9.33 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 100 | lm loss value: 1.069640E+01 | lm loss PPL: 4.419641E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration     100 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:06:11,221] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is about to be saved!
[default0]:[2023-08-25 18:06:11,224] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,255] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,255] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,264] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,264] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,272] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,273] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,281] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,282] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,290] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,291] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,299] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,299] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,308] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,308] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,317] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,318] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,326] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,327] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,335] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,335] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,344] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,344] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,352] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,353] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,361] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,362] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,370] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,370] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,379] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,379] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,388] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,388] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,397] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,397] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,406] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,406] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,415] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,425] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,426] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,435] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,435] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,443] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,443] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,452] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,452] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,461] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,461] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:06:11,462] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:06:11,463] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:06:11,464] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:11,735] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:11,736] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:06:15,394] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:06:15,407] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:06:15,408] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
[default0]:  successfully saved checkpoint at iteration     100 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.7, Latency(second): 4.191
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4190.55, 4190.55)
[default0]:[2023-08-25 18:06:15,677] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.17 | optimizer_step: 10.09
[default0]:[2023-08-25 18:06:15,678] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2505.71 | backward_microstep: 120.01 | backward_inner_microstep: 108.84 | backward_allreduce_microstep: 11.07 | step_microstep: 47.47
[default0]:[2023-08-25 18:06:15,678] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2505.58 (forward_moe: 21.70, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.85)
[default0]:[2023-08-25 18:06:15,678] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 120.01 | backward_inner: 108.84 | backward_allreduce: 11.08 | step: 47.48
[default0]:[2023-08-25 18:06:15,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.43
[default0]:[2023-08-25 18:06:15,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.84 | backward_microstep: 116.44 | backward_inner_microstep: 105.26 | backward_allreduce_microstep: 11.08 | step_microstep: 43.84
[default0]:[2023-08-25 18:06:15,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.84 (forward_moe: 21.33, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.72)
[default0]:[2023-08-25 18:06:15,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.43 | backward_inner: 105.27 | backward_allreduce: 11.08 | step: 43.84
[default0]:[2023-08-25 18:06:16,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.41
[default0]:[2023-08-25 18:06:16,281] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.52 | backward_microstep: 113.60 | backward_inner_microstep: 102.52 | backward_allreduce_microstep: 10.99 | step_microstep: 43.05
[default0]:[2023-08-25 18:06:16,281] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.52 (forward_moe: 20.89, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.32)
[default0]:[2023-08-25 18:06:16,281] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.60 | backward_inner: 102.53 | backward_allreduce: 10.99 | step: 43.05
[default0]:[2023-08-25 18:06:16,540] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.44
[default0]:[2023-08-25 18:06:16,540] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.47 | backward_microstep: 114.10 | backward_inner_microstep: 102.93 | backward_allreduce_microstep: 11.08 | step_microstep: 43.34
[default0]:[2023-08-25 18:06:16,540] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.46 (forward_moe: 20.93, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.36)
[default0]:[2023-08-25 18:06:16,541] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.10 | backward_inner: 102.93 | backward_allreduce: 11.08 | step: 43.34
[default0]:[2023-08-25 18:06:17,087] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.41
[default0]:[2023-08-25 18:06:17,088] [INFO] [logging.py:96:log_dist] [Rank 0] step=105, skipped=0, lr=[1.1359573333333334e-07, 1.1359573333333334e-07, 1.1359573333333334e-07, 1.1359573333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:17,089] [INFO] [timer.py:215:stop] epoch=0/micro_step=105/global_step=105, RunningAvgSamplesPerSec=4.911322461743626, CurrSamplesPerSec=4.806784478214032, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:17,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.82 | backward_microstep: 114.78 | backward_inner_microstep: 103.58 | backward_allreduce_microstep: 11.10 | step_microstep: 44.89
[default0]:[2023-08-25 18:06:17,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.81 (forward_moe: 21.09, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.53)
[default0]:[2023-08-25 18:06:17,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.78 | backward_inner: 103.59 | backward_allreduce: 11.10 | step: 44.90
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.5451], device='cuda:0'), 'moe loss': tensor([0.3210], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      105/439453125 | consumed samples:          105 | consumed tokens:       215040 | elapsed time per iteration (ms): 1946.6 | learning rate: 1.136E-07 | global batch size:     1 | lm loss: 1.070902E+01 | moe loss: 6.419289E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.514 | TFLOPs: 1.28 |
[default0]:[2023-08-25 18:06:17,363] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.44
[default0]:[2023-08-25 18:06:17,364] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.82 | backward_microstep: 114.38 | backward_inner_microstep: 103.20 | backward_allreduce_microstep: 11.09 | step_microstep: 43.96
[default0]:[2023-08-25 18:06:17,364] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.82 (forward_moe: 20.86, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.41)
[default0]:[2023-08-25 18:06:17,364] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.38 | backward_inner: 103.21 | backward_allreduce: 11.09 | step: 43.96
[default0]:[2023-08-25 18:06:17,608] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:17,609] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.11 | backward_microstep: 114.48 | backward_inner_microstep: 103.38 | backward_allreduce_microstep: 11.00 | step_microstep: 42.85
[default0]:[2023-08-25 18:06:17,609] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.11 (forward_moe: 20.55, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:06:17,609] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.48 | backward_inner: 103.39 | backward_allreduce: 11.00 | step: 42.85
[default0]:[2023-08-25 18:06:17,913] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:06:17,913] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.99 | backward_microstep: 115.85 | backward_inner_microstep: 104.74 | backward_allreduce_microstep: 11.01 | step_microstep: 42.76
[default0]:[2023-08-25 18:06:17,914] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.99 (forward_moe: 21.33, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.39)
[default0]:[2023-08-25 18:06:17,914] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.84 | backward_inner: 104.74 | backward_allreduce: 11.01 | step: 42.77
[default0]:[2023-08-25 18:06:18,239] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:06:18,239] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.11 | backward_microstep: 112.59 | backward_inner_microstep: 101.46 | backward_allreduce_microstep: 11.03 | step_microstep: 42.71
[default0]:[2023-08-25 18:06:18,239] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.10 (forward_moe: 20.49, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:06:18,240] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.59 | backward_inner: 101.47 | backward_allreduce: 11.04 | step: 42.71
[default0]:[2023-08-25 18:06:18,558] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:06:18,558] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=0, lr=[1.1905706666666667e-07, 1.1905706666666667e-07, 1.1905706666666667e-07, 1.1905706666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:18,558] [INFO] [timer.py:215:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=4.909225564110309, CurrSamplesPerSec=4.915092482351948, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:18,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.08 | backward_microstep: 112.73 | backward_inner_microstep: 101.68 | backward_allreduce_microstep: 10.95 | step_microstep: 43.10
[default0]:[2023-08-25 18:06:18,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.08 (forward_moe: 20.68, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.24)
[default0]:[2023-08-25 18:06:18,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.73 | backward_inner: 101.69 | backward_allreduce: 10.96 | step: 43.10
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.5022], device='cuda:0'), 'moe loss': tensor([0.3193], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      110/439453125 | consumed samples:          110 | consumed tokens:       225280 | elapsed time per iteration (ms): 294.0 | learning rate: 1.191E-07 | global batch size:     1 | lm loss: 1.070044E+01 | moe loss: 6.386805E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.402 | TFLOPs: 8.45 |
[default0]:[2023-08-25 18:06:18,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:18,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.12 | backward_microstep: 112.65 | backward_inner_microstep: 101.50 | backward_allreduce_microstep: 11.05 | step_microstep: 42.80
[default0]:[2023-08-25 18:06:18,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.12 (forward_moe: 20.55, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.22)
[default0]:[2023-08-25 18:06:18,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.65 | backward_inner: 101.51 | backward_allreduce: 11.06 | step: 42.81
[default0]:[2023-08-25 18:06:19,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:19,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 112.89 | backward_inner_microstep: 101.79 | backward_allreduce_microstep: 11.01 | step_microstep: 42.69
[default0]:[2023-08-25 18:06:19,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.01 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.20)
[default0]:[2023-08-25 18:06:19,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.89 | backward_inner: 101.80 | backward_allreduce: 11.01 | step: 42.69
[default0]:[2023-08-25 18:06:19,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.10 | optimizer_step: 6.45
[default0]:[2023-08-25 18:06:19,381] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.79 | backward_microstep: 115.42 | backward_inner_microstep: 104.16 | backward_allreduce_microstep: 11.17 | step_microstep: 43.73
[default0]:[2023-08-25 18:06:19,381] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.78 (forward_moe: 21.13, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.56)
[default0]:[2023-08-25 18:06:19,381] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.41 | backward_inner: 104.16 | backward_allreduce: 11.17 | step: 43.73
[default0]:[2023-08-25 18:06:19,665] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:06:19,665] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.00 | backward_microstep: 112.18 | backward_inner_microstep: 101.10 | backward_allreduce_microstep: 10.98 | step_microstep: 42.53
[default0]:[2023-08-25 18:06:19,665] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.00 (forward_moe: 20.41, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:06:19,665] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.18 | backward_inner: 101.11 | backward_allreduce: 10.98 | step: 42.52
[default0]:[2023-08-25 18:06:19,931] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:06:19,932] [INFO] [logging.py:96:log_dist] [Rank 0] step=115, skipped=0, lr=[1.245184e-07, 1.245184e-07, 1.245184e-07, 1.245184e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:19,932] [INFO] [timer.py:215:stop] epoch=0/micro_step=115/global_step=115, RunningAvgSamplesPerSec=4.908132699507329, CurrSamplesPerSec=4.8431673450535495, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:19,932] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.67 | backward_microstep: 113.97 | backward_inner_microstep: 102.90 | backward_allreduce_microstep: 10.98 | step_microstep: 43.21
[default0]:[2023-08-25 18:06:19,932] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.68 (forward_moe: 21.00, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.26)
[default0]:[2023-08-25 18:06:19,932] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.96 | backward_inner: 102.90 | backward_allreduce: 10.98 | step: 43.21
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.4305], device='cuda:0'), 'moe loss': tensor([0.3189], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      115/439453125 | consumed samples:          115 | consumed tokens:       235520 | elapsed time per iteration (ms): 275.3 | learning rate: 1.245E-07 | global batch size:     1 | lm loss: 1.068610E+01 | moe loss: 6.377946E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.632 | TFLOPs: 9.02 |
[default0]:[2023-08-25 18:06:20,238] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:06:20,238] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.86 | backward_microstep: 114.38 | backward_inner_microstep: 103.27 | backward_allreduce_microstep: 11.01 | step_microstep: 43.15
[default0]:[2023-08-25 18:06:20,239] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.86 (forward_moe: 20.43, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:06:20,239] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.38 | backward_inner: 103.28 | backward_allreduce: 11.02 | step: 43.15
[default0]:[2023-08-25 18:06:20,506] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:06:20,506] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.05 | backward_microstep: 112.18 | backward_inner_microstep: 101.11 | backward_allreduce_microstep: 10.98 | step_microstep: 42.60
[default0]:[2023-08-25 18:06:20,506] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.05 (forward_moe: 20.40, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:06:20,506] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.18 | backward_inner: 101.11 | backward_allreduce: 10.98 | step: 42.60
[default0]:[2023-08-25 18:06:20,757] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:06:20,758] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.90 | backward_microstep: 112.39 | backward_inner_microstep: 101.25 | backward_allreduce_microstep: 11.04 | step_microstep: 42.67
[default0]:[2023-08-25 18:06:20,758] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.90 (forward_moe: 20.50, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:06:20,758] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.38 | backward_inner: 101.26 | backward_allreduce: 11.04 | step: 42.67
[default0]:[2023-08-25 18:06:21,021] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:06:21,022] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.15 | backward_microstep: 112.06 | backward_inner_microstep: 100.99 | backward_allreduce_microstep: 10.97 | step_microstep: 43.78
[default0]:[2023-08-25 18:06:21,022] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.14 (forward_moe: 20.43, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:06:21,022] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.06 | backward_inner: 101.00 | backward_allreduce: 10.97 | step: 43.78
[default0]:[2023-08-25 18:06:21,283] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.04 | optimizer_step: 6.40
[default0]:[2023-08-25 18:06:21,283] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=0, lr=[1.2997973333333334e-07, 1.2997973333333334e-07, 1.2997973333333334e-07, 1.2997973333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:21,339] [INFO] [timer.py:215:stop] epoch=0/micro_step=120/global_step=120, RunningAvgSamplesPerSec=4.8966518077961565, CurrSamplesPerSec=3.8369812812063753, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:21,551] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.93 | backward_microstep: 113.66 | backward_inner_microstep: 102.48 | backward_allreduce_microstep: 11.09 | step_microstep: 310.90
[default0]:[2023-08-25 18:06:21,551] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.93 (forward_moe: 20.68, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.22)
[default0]:[2023-08-25 18:06:21,551] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.66 | backward_inner: 102.48 | backward_allreduce: 11.09 | step: 310.90
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.4560], device='cuda:0'), 'moe loss': tensor([0.3209], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      120/439453125 | consumed samples:          120 | consumed tokens:       245760 | elapsed time per iteration (ms): 325.0 | learning rate: 1.300E-07 | global batch size:     1 | lm loss: 1.069120E+01 | moe loss: 6.418381E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.077 | TFLOPs: 7.64 |
[default0]:[2023-08-25 18:06:21,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.17 | optimizer_step: 6.53
[default0]:[2023-08-25 18:06:21,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 53.30 | backward_microstep: 118.01 | backward_inner_microstep: 106.56 | backward_allreduce_microstep: 11.36 | step_microstep: 44.61
[default0]:[2023-08-25 18:06:21,849] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 53.30 (forward_moe: 21.65, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.89)
[default0]:[2023-08-25 18:06:21,849] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 118.01 | backward_inner: 106.57 | backward_allreduce: 11.36 | step: 44.61
[default0]:[2023-08-25 18:06:22,130] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 6.53
[default0]:[2023-08-25 18:06:22,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.38 | backward_microstep: 117.79 | backward_inner_microstep: 106.36 | backward_allreduce_microstep: 11.33 | step_microstep: 44.47
[default0]:[2023-08-25 18:06:22,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.38 (forward_moe: 21.55, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.82)
[default0]:[2023-08-25 18:06:22,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.78 | backward_inner: 106.36 | backward_allreduce: 11.33 | step: 44.47
[default0]:[2023-08-25 18:06:22,455] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 6.53
[default0]:[2023-08-25 18:06:22,455] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.47 | backward_microstep: 117.74 | backward_inner_microstep: 106.33 | backward_allreduce_microstep: 11.31 | step_microstep: 44.36
[default0]:[2023-08-25 18:06:22,455] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.47 (forward_moe: 21.62, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.85)
[default0]:[2023-08-25 18:06:22,455] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.74 | backward_inner: 106.34 | backward_allreduce: 11.31 | step: 44.36
[default0]:[2023-08-25 18:06:22,999] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 6.53
[default0]:[2023-08-25 18:06:23,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.14 | backward_microstep: 117.39 | backward_inner_microstep: 106.07 | backward_allreduce_microstep: 11.23 | step_microstep: 44.58
[default0]:[2023-08-25 18:06:23,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.14 (forward_moe: 21.51, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.80)
[default0]:[2023-08-25 18:06:23,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.39 | backward_inner: 106.07 | backward_allreduce: 11.24 | step: 44.58
[default0]:[2023-08-25 18:06:23,281] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.44
[default0]:[2023-08-25 18:06:23,281] [INFO] [logging.py:96:log_dist] [Rank 0] step=125, skipped=0, lr=[1.3544106666666668e-07, 1.3544106666666668e-07, 1.3544106666666668e-07, 1.3544106666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:23,282] [INFO] [timer.py:215:stop] epoch=0/micro_step=125/global_step=125, RunningAvgSamplesPerSec=4.888892346738469, CurrSamplesPerSec=4.822435923968782, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:23,282] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.83 | backward_microstep: 115.09 | backward_inner_microstep: 103.86 | backward_allreduce_microstep: 11.13 | step_microstep: 43.87
[default0]:[2023-08-25 18:06:23,282] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.83 (forward_moe: 21.04, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.44)
[default0]:[2023-08-25 18:06:23,282] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.09 | backward_inner: 103.87 | backward_allreduce: 11.13 | step: 43.87
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.2379], device='cuda:0'), 'moe loss': tensor([0.3224], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      125/439453125 | consumed samples:          125 | consumed tokens:       256000 | elapsed time per iteration (ms): 344.8 | learning rate: 1.354E-07 | global batch size:     1 | lm loss: 1.064759E+01 | moe loss: 6.448761E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.901 | TFLOPs: 7.21 |
[default0]:[2023-08-25 18:06:23,553] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.42
[default0]:[2023-08-25 18:06:23,553] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.13 | backward_microstep: 114.49 | backward_inner_microstep: 103.26 | backward_allreduce_microstep: 11.13 | step_microstep: 43.27
[default0]:[2023-08-25 18:06:23,553] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.13 (forward_moe: 21.03, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.41)
[default0]:[2023-08-25 18:06:23,553] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.48 | backward_inner: 103.27 | backward_allreduce: 11.13 | step: 43.27
[default0]:[2023-08-25 18:06:23,845] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:06:23,845] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.91 | backward_microstep: 114.44 | backward_inner_microstep: 103.25 | backward_allreduce_microstep: 11.09 | step_microstep: 43.36
[default0]:[2023-08-25 18:06:23,845] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.91 (forward_moe: 20.91, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.44)
[default0]:[2023-08-25 18:06:23,845] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.44 | backward_inner: 103.26 | backward_allreduce: 11.10 | step: 43.36
[default0]:[2023-08-25 18:06:24,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.44
[default0]:[2023-08-25 18:06:24,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.78 | backward_microstep: 114.52 | backward_inner_microstep: 103.32 | backward_allreduce_microstep: 11.10 | step_microstep: 43.50
[default0]:[2023-08-25 18:06:24,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.78 (forward_moe: 21.09, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.41)
[default0]:[2023-08-25 18:06:24,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.52 | backward_inner: 103.32 | backward_allreduce: 11.11 | step: 43.50
[default0]:[2023-08-25 18:06:24,381] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.19 | optimizer_step: 6.42
[default0]:[2023-08-25 18:06:24,382] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.00 | backward_microstep: 114.34 | backward_inner_microstep: 103.18 | backward_allreduce_microstep: 11.06 | step_microstep: 43.37
[default0]:[2023-08-25 18:06:24,382] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.99 (forward_moe: 20.91, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.43)
[default0]:[2023-08-25 18:06:24,382] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.33 | backward_inner: 103.18 | backward_allreduce: 11.07 | step: 43.38
[default0]:[2023-08-25 18:06:24,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.06 | optimizer_step: 6.41
[default0]:[2023-08-25 18:06:24,627] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=0, lr=[1.409024e-07, 1.409024e-07, 1.409024e-07, 1.409024e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:24,627] [INFO] [timer.py:215:stop] epoch=0/micro_step=130/global_step=130, RunningAvgSamplesPerSec=4.886869015184012, CurrSamplesPerSec=4.8270645886704555, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:24,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.96 | backward_microstep: 114.94 | backward_inner_microstep: 103.60 | backward_allreduce_microstep: 11.24 | step_microstep: 43.71
[default0]:[2023-08-25 18:06:24,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.96 (forward_moe: 21.12, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.51)
[default0]:[2023-08-25 18:06:24,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.93 | backward_inner: 103.61 | backward_allreduce: 11.24 | step: 43.72
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.2531], device='cuda:0'), 'moe loss': tensor([0.3200], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      130/439453125 | consumed samples:          130 | consumed tokens:       266240 | elapsed time per iteration (ms): 268.6 | learning rate: 1.409E-07 | global batch size:     1 | lm loss: 1.065062E+01 | moe loss: 6.400806E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.723 | TFLOPs: 9.25 |
[default0]:[2023-08-25 18:06:24,877] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:06:24,877] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.25 | backward_microstep: 110.36 | backward_inner_microstep: 99.39 | backward_allreduce_microstep: 10.88 | step_microstep: 41.94
[default0]:[2023-08-25 18:06:24,877] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.25 (forward_moe: 20.02, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:06:24,877] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.36 | backward_inner: 99.39 | backward_allreduce: 10.88 | step: 41.94
[default0]:[2023-08-25 18:06:25,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:25,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.05 | backward_microstep: 110.55 | backward_inner_microstep: 99.58 | backward_allreduce_microstep: 10.87 | step_microstep: 41.87
[default0]:[2023-08-25 18:06:25,156] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.04 (forward_moe: 20.03, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.88)
[default0]:[2023-08-25 18:06:25,156] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.55 | backward_inner: 99.59 | backward_allreduce: 10.88 | step: 41.88
[default0]:[2023-08-25 18:06:25,420] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:06:25,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.03 | backward_microstep: 110.36 | backward_inner_microstep: 99.39 | backward_allreduce_microstep: 10.88 | step_microstep: 42.09
[default0]:[2023-08-25 18:06:25,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.03 (forward_moe: 20.02, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.89)
[default0]:[2023-08-25 18:06:25,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.36 | backward_inner: 99.39 | backward_allreduce: 10.88 | step: 42.09
[default0]:[2023-08-25 18:06:25,666] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:06:25,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 109.32 | backward_inner_microstep: 98.42 | backward_allreduce_microstep: 10.80 | step_microstep: 41.49
[default0]:[2023-08-25 18:06:25,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:06:25,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.32 | backward_inner: 98.43 | backward_allreduce: 10.80 | step: 41.50
[default0]:[2023-08-25 18:06:25,959] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 10.42
[default0]:[2023-08-25 18:06:25,960] [INFO] [logging.py:96:log_dist] [Rank 0] step=135, skipped=0, lr=[1.4636373333333334e-07, 1.4636373333333334e-07, 1.4636373333333334e-07, 1.4636373333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:25,960] [INFO] [timer.py:215:stop] epoch=0/micro_step=135/global_step=135, RunningAvgSamplesPerSec=4.891147300470925, CurrSamplesPerSec=4.89404472697317, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:25,961] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.03 | backward_microstep: 109.16 | backward_inner_microstep: 98.27 | backward_allreduce_microstep: 10.80 | step_microstep: 46.60
[default0]:[2023-08-25 18:06:25,961] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.03 (forward_moe: 19.86, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:06:25,961] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.16 | backward_inner: 98.27 | backward_allreduce: 10.80 | step: 46.60
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.1496], device='cuda:0'), 'moe loss': tensor([0.3174], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      135/439453125 | consumed samples:          135 | consumed tokens:       276480 | elapsed time per iteration (ms): 266.7 | learning rate: 1.464E-07 | global batch size:     1 | lm loss: 1.062993E+01 | moe loss: 6.348337E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.750 | TFLOPs: 9.32 |
[default0]:[2023-08-25 18:06:26,227] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:06:26,228] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.57 | backward_microstep: 109.46 | backward_inner_microstep: 98.34 | backward_allreduce_microstep: 11.02 | step_microstep: 41.58
[default0]:[2023-08-25 18:06:26,228] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.57 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:06:26,228] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.46 | backward_inner: 98.35 | backward_allreduce: 11.03 | step: 41.59
[default0]:[2023-08-25 18:06:26,493] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:06:26,493] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.67 | backward_microstep: 108.95 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.76 | step_microstep: 41.49
[default0]:[2023-08-25 18:06:26,493] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:06:26,493] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.95 | backward_inner: 98.10 | backward_allreduce: 10.76 | step: 41.49
[default0]:[2023-08-25 18:06:26,766] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:06:26,767] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.90 | backward_microstep: 108.85 | backward_inner_microstep: 97.98 | backward_allreduce_microstep: 10.78 | step_microstep: 41.63
[default0]:[2023-08-25 18:06:26,767] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.90 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:06:26,767] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.85 | backward_inner: 97.98 | backward_allreduce: 10.78 | step: 41.63
[default0]:[2023-08-25 18:06:27,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:27,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 108.95 | backward_inner_microstep: 98.04 | backward_allreduce_microstep: 10.81 | step_microstep: 41.38
[default0]:[2023-08-25 18:06:27,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 19.88, 1st alltoall: 0.85, 2nd alltoall: 0.79, top-k: 7.85)
[default0]:[2023-08-25 18:06:27,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.95 | backward_inner: 98.05 | backward_allreduce: 10.81 | step: 41.38
[default0]:[2023-08-25 18:06:27,267] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.34
[default0]:[2023-08-25 18:06:27,268] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=0, lr=[1.5182506666666668e-07, 1.5182506666666668e-07, 1.5182506666666668e-07, 1.5182506666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:27,268] [INFO] [timer.py:215:stop] epoch=0/micro_step=140/global_step=140, RunningAvgSamplesPerSec=4.8972600008493, CurrSamplesPerSec=5.061629378975607, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:27,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 109.14 | backward_inner_microstep: 98.27 | backward_allreduce_microstep: 10.77 | step_microstep: 42.44
[default0]:[2023-08-25 18:06:27,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:06:27,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.13 | backward_inner: 98.28 | backward_allreduce: 10.77 | step: 42.44
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([53.0120], device='cuda:0'), 'moe loss': tensor([0.3182], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      140/439453125 | consumed samples:          140 | consumed tokens:       286720 | elapsed time per iteration (ms): 261.6 | learning rate: 1.518E-07 | global batch size:     1 | lm loss: 1.060240E+01 | moe loss: 6.364571E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.823 | TFLOPs: 9.50 |
[default0]:[2023-08-25 18:06:27,540] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:06:27,540] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 109.13 | backward_inner_microstep: 98.25 | backward_allreduce_microstep: 10.78 | step_microstep: 41.79
[default0]:[2023-08-25 18:06:27,540] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.76 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:06:27,540] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.13 | backward_inner: 98.25 | backward_allreduce: 10.79 | step: 41.80
[default0]:[2023-08-25 18:06:27,796] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:06:27,796] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.42 | backward_microstep: 108.86 | backward_inner_microstep: 97.97 | backward_allreduce_microstep: 10.80 | step_microstep: 41.40
[default0]:[2023-08-25 18:06:27,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.42 (forward_moe: 19.81, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:06:27,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.86 | backward_inner: 97.97 | backward_allreduce: 10.80 | step: 41.40
[default0]:[2023-08-25 18:06:28,063] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:06:28,063] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.56 | backward_microstep: 108.98 | backward_inner_microstep: 98.07 | backward_allreduce_microstep: 10.81 | step_microstep: 41.85
[default0]:[2023-08-25 18:06:28,063] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.56 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:06:28,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.98 | backward_inner: 98.07 | backward_allreduce: 10.82 | step: 41.85
[default0]:[2023-08-25 18:06:28,315] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:06:28,315] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.41 | backward_microstep: 111.49 | backward_inner_microstep: 100.45 | backward_allreduce_microstep: 10.94 | step_microstep: 42.55
[default0]:[2023-08-25 18:06:28,315] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.41 (forward_moe: 20.32, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.09)
[default0]:[2023-08-25 18:06:28,316] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.49 | backward_inner: 100.46 | backward_allreduce: 10.94 | step: 42.55
[default0]:[2023-08-25 18:06:28,597] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:06:28,597] [INFO] [logging.py:96:log_dist] [Rank 0] step=145, skipped=0, lr=[1.5728640000000002e-07, 1.5728640000000002e-07, 1.5728640000000002e-07, 1.5728640000000002e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:28,597] [INFO] [timer.py:215:stop] epoch=0/micro_step=145/global_step=145, RunningAvgSamplesPerSec=4.90115385909312, CurrSamplesPerSec=4.871037197904932, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:28,597] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.72 | backward_microstep: 113.40 | backward_inner_microstep: 101.73 | backward_allreduce_microstep: 11.56 | step_microstep: 44.64
[default0]:[2023-08-25 18:06:28,597] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.72 (forward_moe: 20.69, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.18)
[default0]:[2023-08-25 18:06:28,598] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.39 | backward_inner: 101.74 | backward_allreduce: 11.56 | step: 44.64
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.9638], device='cuda:0'), 'moe loss': tensor([0.3191], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      145/439453125 | consumed samples:          145 | consumed tokens:       296960 | elapsed time per iteration (ms): 265.9 | learning rate: 1.573E-07 | global batch size:     1 | lm loss: 1.059275E+01 | moe loss: 6.382896E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.760 | TFLOPs: 9.34 |
[default0]:[2023-08-25 18:06:28,870] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.40
[default0]:[2023-08-25 18:06:28,870] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.91 | backward_microstep: 113.19 | backward_inner_microstep: 102.04 | backward_allreduce_microstep: 11.05 | step_microstep: 42.92
[default0]:[2023-08-25 18:06:28,870] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.91 (forward_moe: 20.72, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:06:28,870] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.18 | backward_inner: 102.05 | backward_allreduce: 11.06 | step: 42.92
[default0]:[2023-08-25 18:06:29,140] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:06:29,141] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.38 | backward_microstep: 113.45 | backward_inner_microstep: 102.28 | backward_allreduce_microstep: 11.07 | step_microstep: 43.35
[default0]:[2023-08-25 18:06:29,141] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.38 (forward_moe: 20.66, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.28)
[default0]:[2023-08-25 18:06:29,141] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.45 | backward_inner: 102.29 | backward_allreduce: 11.08 | step: 43.35
[default0]:[2023-08-25 18:06:29,443] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:06:29,443] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.15 | backward_microstep: 115.14 | backward_inner_microstep: 103.88 | backward_allreduce_microstep: 11.16 | step_microstep: 43.56
[default0]:[2023-08-25 18:06:29,443] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.15 (forward_moe: 21.06, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.52)
[default0]:[2023-08-25 18:06:29,443] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.14 | backward_inner: 103.89 | backward_allreduce: 11.16 | step: 43.57
[default0]:[2023-08-25 18:06:29,717] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:06:29,717] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.52 | backward_microstep: 111.49 | backward_inner_microstep: 100.41 | backward_allreduce_microstep: 10.99 | step_microstep: 42.33
[default0]:[2023-08-25 18:06:29,717] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.52 (forward_moe: 20.35, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.04)
[default0]:[2023-08-25 18:06:29,717] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.49 | backward_inner: 100.41 | backward_allreduce: 10.99 | step: 42.33
[default0]:[2023-08-25 18:06:29,968] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:06:29,968] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=0, lr=[1.6274773333333333e-07, 1.6274773333333333e-07, 1.6274773333333333e-07, 1.6274773333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:29,968] [INFO] [timer.py:215:stop] epoch=0/micro_step=150/global_step=150, RunningAvgSamplesPerSec=4.901193695472317, CurrSamplesPerSec=4.96900108281779, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:29,968] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.62 | backward_microstep: 111.56 | backward_inner_microstep: 100.51 | backward_allreduce_microstep: 10.95 | step_microstep: 42.52
[default0]:[2023-08-25 18:06:29,968] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.62 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.06)
[default0]:[2023-08-25 18:06:29,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.56 | backward_inner: 100.52 | backward_allreduce: 10.96 | step: 42.52
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.9716], device='cuda:0'), 'moe loss': tensor([0.3183], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      150/439453125 | consumed samples:          150 | consumed tokens:       307200 | elapsed time per iteration (ms): 273.9 | learning rate: 1.627E-07 | global batch size:     1 | lm loss: 1.059432E+01 | moe loss: 6.365113E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.651 | TFLOPs: 9.07 |
[default0]:[2023-08-25 18:06:30,355] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:06:30,356] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.67 | backward_microstep: 111.48 | backward_inner_microstep: 100.47 | backward_allreduce_microstep: 10.92 | step_microstep: 42.91
[default0]:[2023-08-25 18:06:30,356] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.68 (forward_moe: 20.31, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.02)
[default0]:[2023-08-25 18:06:30,357] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.48 | backward_inner: 100.47 | backward_allreduce: 10.92 | step: 42.91
[default0]:[2023-08-25 18:06:30,602] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:06:30,602] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.76 | backward_microstep: 111.60 | backward_inner_microstep: 100.63 | backward_allreduce_microstep: 10.88 | step_microstep: 42.37
[default0]:[2023-08-25 18:06:30,603] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.76 (forward_moe: 20.32, 1st alltoall: 0.87, 2nd alltoall: 0.83, top-k: 8.09)
[default0]:[2023-08-25 18:06:30,603] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.60 | backward_inner: 100.64 | backward_allreduce: 10.88 | step: 42.38
[default0]:[2023-08-25 18:06:30,928] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.37
[default0]:[2023-08-25 18:06:30,928] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.52 | backward_microstep: 111.39 | backward_inner_microstep: 100.35 | backward_allreduce_microstep: 10.94 | step_microstep: 42.28
[default0]:[2023-08-25 18:06:30,928] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.51 (forward_moe: 20.29, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.03)
[default0]:[2023-08-25 18:06:30,929] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.39 | backward_inner: 100.36 | backward_allreduce: 10.95 | step: 42.28
[default0]:[2023-08-25 18:06:31,208] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:06:31,209] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.61 | backward_microstep: 112.56 | backward_inner_microstep: 101.55 | backward_allreduce_microstep: 10.91 | step_microstep: 42.62
[default0]:[2023-08-25 18:06:31,209] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.60 (forward_moe: 20.29, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.07)
[default0]:[2023-08-25 18:06:31,209] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.56 | backward_inner: 101.56 | backward_allreduce: 10.91 | step: 42.63
[default0]:[2023-08-25 18:06:31,487] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:06:31,487] [INFO] [logging.py:96:log_dist] [Rank 0] step=155, skipped=0, lr=[1.6820906666666667e-07, 1.6820906666666667e-07, 1.6820906666666667e-07, 1.6820906666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:31,487] [INFO] [timer.py:215:stop] epoch=0/micro_step=155/global_step=155, RunningAvgSamplesPerSec=4.900957118904737, CurrSamplesPerSec=4.74835647904433, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:31,488] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.96 | backward_microstep: 116.85 | backward_inner_microstep: 105.44 | backward_allreduce_microstep: 11.31 | step_microstep: 44.27
[default0]:[2023-08-25 18:06:31,488] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.96 (forward_moe: 21.51, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.74)
[default0]:[2023-08-25 18:06:31,488] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.85 | backward_inner: 105.45 | backward_allreduce: 11.32 | step: 44.27
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.9575], device='cuda:0'), 'moe loss': tensor([0.3151], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      155/439453125 | consumed samples:          155 | consumed tokens:       317440 | elapsed time per iteration (ms): 303.8 | learning rate: 1.682E-07 | global batch size:     1 | lm loss: 1.059150E+01 | moe loss: 6.302161E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.292 | TFLOPs: 8.18 |
[default0]:[2023-08-25 18:06:31,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.45
[default0]:[2023-08-25 18:06:31,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.53 | backward_microstep: 116.75 | backward_inner_microstep: 105.47 | backward_allreduce_microstep: 11.19 | step_microstep: 43.73
[default0]:[2023-08-25 18:06:31,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.53 (forward_moe: 21.09, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.54)
[default0]:[2023-08-25 18:06:31,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.75 | backward_inner: 105.48 | backward_allreduce: 11.19 | step: 43.74
[default0]:[2023-08-25 18:06:32,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.10 | optimizer_step: 6.45
[default0]:[2023-08-25 18:06:32,026] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.22 | backward_microstep: 115.38 | backward_inner_microstep: 104.16 | backward_allreduce_microstep: 11.12 | step_microstep: 43.66
[default0]:[2023-08-25 18:06:32,026] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.22 (forward_moe: 21.13, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.58)
[default0]:[2023-08-25 18:06:32,026] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.37 | backward_inner: 104.16 | backward_allreduce: 11.13 | step: 43.66
[default0]:[2023-08-25 18:06:32,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.47
[default0]:[2023-08-25 18:06:32,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.34 | backward_microstep: 115.32 | backward_inner_microstep: 104.09 | backward_allreduce_microstep: 11.13 | step_microstep: 43.75
[default0]:[2023-08-25 18:06:32,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.34 (forward_moe: 21.23, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.57)
[default0]:[2023-08-25 18:06:32,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.32 | backward_inner: 104.10 | backward_allreduce: 11.14 | step: 43.75
[default0]:[2023-08-25 18:06:32,548] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.44
[default0]:[2023-08-25 18:06:32,549] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.55 | backward_microstep: 115.50 | backward_inner_microstep: 104.28 | backward_allreduce_microstep: 11.12 | step_microstep: 43.76
[default0]:[2023-08-25 18:06:32,549] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.55 (forward_moe: 21.21, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.55)
[default0]:[2023-08-25 18:06:32,549] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.50 | backward_inner: 104.29 | backward_allreduce: 11.13 | step: 43.76
[default0]:[2023-08-25 18:06:32,826] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.46
[default0]:[2023-08-25 18:06:32,826] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=0, lr=[1.7367040000000001e-07, 1.7367040000000001e-07, 1.7367040000000001e-07, 1.7367040000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:32,826] [INFO] [timer.py:215:stop] epoch=0/micro_step=160/global_step=160, RunningAvgSamplesPerSec=4.897165420734585, CurrSamplesPerSec=4.80069407007315, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:32,827] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.32 | backward_microstep: 115.37 | backward_inner_microstep: 104.13 | backward_allreduce_microstep: 11.15 | step_microstep: 44.04
[default0]:[2023-08-25 18:06:32,827] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.32 (forward_moe: 21.22, 1st alltoall: 0.94, 2nd alltoall: 0.83, top-k: 8.52)
[default0]:[2023-08-25 18:06:32,827] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.37 | backward_inner: 104.13 | backward_allreduce: 11.16 | step: 44.04
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.9836], device='cuda:0'), 'moe loss': tensor([0.3174], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      160/439453125 | consumed samples:          160 | consumed tokens:       327680 | elapsed time per iteration (ms): 267.9 | learning rate: 1.737E-07 | global batch size:     1 | lm loss: 1.059672E+01 | moe loss: 6.348830E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.732 | TFLOPs: 9.27 |
[default0]:[2023-08-25 18:06:33,100] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:06:33,100] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.21 | backward_microstep: 115.39 | backward_inner_microstep: 104.14 | backward_allreduce_microstep: 11.16 | step_microstep: 43.88
[default0]:[2023-08-25 18:06:33,100] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.21 (forward_moe: 21.10, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.56)
[default0]:[2023-08-25 18:06:33,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.39 | backward_inner: 104.14 | backward_allreduce: 11.16 | step: 43.88
[default0]:[2023-08-25 18:06:33,357] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.16 | optimizer_step: 6.48
[default0]:[2023-08-25 18:06:33,357] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.78 | backward_microstep: 115.85 | backward_inner_microstep: 104.59 | backward_allreduce_microstep: 11.16 | step_microstep: 43.87
[default0]:[2023-08-25 18:06:33,357] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.78 (forward_moe: 21.17, 1st alltoall: 0.89, 2nd alltoall: 0.85, top-k: 8.59)
[default0]:[2023-08-25 18:06:33,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.85 | backward_inner: 104.60 | backward_allreduce: 11.17 | step: 43.87
[default0]:[2023-08-25 18:06:33,637] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.15 | optimizer_step: 6.50
[default0]:[2023-08-25 18:06:33,637] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.57 | backward_microstep: 116.62 | backward_inner_microstep: 105.27 | backward_allreduce_microstep: 11.26 | step_microstep: 44.21
[default0]:[2023-08-25 18:06:33,637] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.57 (forward_moe: 21.42, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.76)
[default0]:[2023-08-25 18:06:33,638] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.62 | backward_inner: 105.27 | backward_allreduce: 11.26 | step: 44.22
[default0]:[2023-08-25 18:06:33,898] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.44
[default0]:[2023-08-25 18:06:33,898] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.02 | backward_microstep: 116.83 | backward_inner_microstep: 105.42 | backward_allreduce_microstep: 11.31 | step_microstep: 43.85
[default0]:[2023-08-25 18:06:33,898] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.02 (forward_moe: 21.42, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.72)
[default0]:[2023-08-25 18:06:33,899] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.82 | backward_inner: 105.43 | backward_allreduce: 11.31 | step: 43.86
[default0]:[2023-08-25 18:06:34,151] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.10 | optimizer_step: 6.45
[default0]:[2023-08-25 18:06:34,151] [INFO] [logging.py:96:log_dist] [Rank 0] step=165, skipped=0, lr=[1.7913173333333336e-07, 1.7913173333333336e-07, 1.7913173333333336e-07, 1.7913173333333336e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:34,151] [INFO] [timer.py:215:stop] epoch=0/micro_step=165/global_step=165, RunningAvgSamplesPerSec=4.893333572296175, CurrSamplesPerSec=4.7930630183823615, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:34,151] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.20 | backward_microstep: 115.73 | backward_inner_microstep: 104.45 | backward_allreduce_microstep: 11.18 | step_microstep: 44.13
[default0]:[2023-08-25 18:06:34,152] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.20 (forward_moe: 21.45, 1st alltoall: 0.89, 2nd alltoall: 1.07, top-k: 8.54)
[default0]:[2023-08-25 18:06:34,152] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.73 | backward_inner: 104.46 | backward_allreduce: 11.18 | step: 44.14
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.7773], device='cuda:0'), 'moe loss': tensor([0.3157], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      165/439453125 | consumed samples:          165 | consumed tokens:       337920 | elapsed time per iteration (ms): 265.0 | learning rate: 1.791E-07 | global batch size:     1 | lm loss: 1.055547E+01 | moe loss: 6.313936E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.774 | TFLOPs: 9.38 |
[default0]:[2023-08-25 18:06:34,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.43
[default0]:[2023-08-25 18:06:34,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.46 | backward_microstep: 115.40 | backward_inner_microstep: 104.17 | backward_allreduce_microstep: 11.14 | step_microstep: 43.45
[default0]:[2023-08-25 18:06:34,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.46 (forward_moe: 21.13, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.55)
[default0]:[2023-08-25 18:06:34,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.40 | backward_inner: 104.17 | backward_allreduce: 11.15 | step: 43.46
[default0]:[2023-08-25 18:06:34,727] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.09 | optimizer_step: 6.43
[default0]:[2023-08-25 18:06:34,728] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.16 | backward_microstep: 115.29 | backward_inner_microstep: 104.05 | backward_allreduce_microstep: 11.15 | step_microstep: 43.64
[default0]:[2023-08-25 18:06:34,728] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.16 (forward_moe: 21.09, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.53)
[default0]:[2023-08-25 18:06:34,728] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.29 | backward_inner: 104.05 | backward_allreduce: 11.15 | step: 43.64
[default0]:[2023-08-25 18:06:35,007] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:06:35,007] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.33 | backward_microstep: 115.31 | backward_inner_microstep: 104.05 | backward_allreduce_microstep: 11.17 | step_microstep: 43.74
[default0]:[2023-08-25 18:06:35,008] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.33 (forward_moe: 21.10, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.55)
[default0]:[2023-08-25 18:06:35,008] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.31 | backward_inner: 104.06 | backward_allreduce: 11.17 | step: 43.74
[default0]:[2023-08-25 18:06:35,324] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:06:35,324] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.19 | backward_microstep: 115.43 | backward_inner_microstep: 104.10 | backward_allreduce_microstep: 11.23 | step_microstep: 43.56
[default0]:[2023-08-25 18:06:35,324] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.19 (forward_moe: 21.20, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.56)
[default0]:[2023-08-25 18:06:35,325] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.43 | backward_inner: 104.10 | backward_allreduce: 11.24 | step: 43.57
[default0]:[2023-08-25 18:06:35,611] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.45
[default0]:[2023-08-25 18:06:35,612] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=0, lr=[1.845930666666667e-07, 1.845930666666667e-07, 1.845930666666667e-07, 1.845930666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:35,612] [INFO] [timer.py:215:stop] epoch=0/micro_step=170/global_step=170, RunningAvgSamplesPerSec=4.8905462365282135, CurrSamplesPerSec=4.782984119454182, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:35,612] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.35 | backward_microstep: 115.57 | backward_inner_microstep: 104.21 | backward_allreduce_microstep: 11.27 | step_microstep: 44.58
[default0]:[2023-08-25 18:06:35,612] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.35 (forward_moe: 21.20, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.54)
[default0]:[2023-08-25 18:06:35,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.57 | backward_inner: 104.21 | backward_allreduce: 11.27 | step: 44.59
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.5391], device='cuda:0'), 'moe loss': tensor([0.3131], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      170/439453125 | consumed samples:          170 | consumed tokens:       348160 | elapsed time per iteration (ms): 292.1 | learning rate: 1.846E-07 | global batch size:     1 | lm loss: 1.050782E+01 | moe loss: 6.261725E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.424 | TFLOPs: 8.51 |
[default0]:[2023-08-25 18:06:35,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.69 | optimizer_gradients: 4.18 | optimizer_step: 6.50
[default0]:[2023-08-25 18:06:35,898] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.35 | backward_microstep: 124.95 | backward_inner_microstep: 113.52 | backward_allreduce_microstep: 11.33 | step_microstep: 45.62
[default0]:[2023-08-25 18:06:35,898] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.35 (forward_moe: 22.82, 1st alltoall: 0.94, 2nd alltoall: 0.88, top-k: 9.36)
[default0]:[2023-08-25 18:06:35,898] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 124.95 | backward_inner: 113.53 | backward_allreduce: 11.33 | step: 45.63
[default0]:[2023-08-25 18:06:36,185] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.10 | optimizer_step: 10.03
[default0]:[2023-08-25 18:06:36,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.26 | backward_microstep: 115.15 | backward_inner_microstep: 103.87 | backward_allreduce_microstep: 11.19 | step_microstep: 47.46
[default0]:[2023-08-25 18:06:36,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.26 (forward_moe: 21.11, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.49)
[default0]:[2023-08-25 18:06:36,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.15 | backward_inner: 103.88 | backward_allreduce: 11.19 | step: 47.47
[default0]:[2023-08-25 18:06:36,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.09 | optimizer_step: 6.43
[default0]:[2023-08-25 18:06:36,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.12 | backward_microstep: 114.93 | backward_inner_microstep: 103.67 | backward_allreduce_microstep: 11.16 | step_microstep: 43.51
[default0]:[2023-08-25 18:06:36,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.12 (forward_moe: 20.99, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.47)
[default0]:[2023-08-25 18:06:36,466] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.93 | backward_inner: 103.68 | backward_allreduce: 11.16 | step: 43.51
[default0]:[2023-08-25 18:06:36,742] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.41
[default0]:[2023-08-25 18:06:36,742] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.77 | backward_microstep: 114.30 | backward_inner_microstep: 103.08 | backward_allreduce_microstep: 11.12 | step_microstep: 44.71
[default0]:[2023-08-25 18:06:36,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.77 (forward_moe: 20.87, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.42)
[default0]:[2023-08-25 18:06:36,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.30 | backward_inner: 103.09 | backward_allreduce: 11.13 | step: 44.72
[default0]:[2023-08-25 18:06:37,173] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:06:37,173] [INFO] [logging.py:96:log_dist] [Rank 0] step=175, skipped=0, lr=[1.9005440000000004e-07, 1.9005440000000004e-07, 1.9005440000000004e-07, 1.9005440000000004e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:37,173] [INFO] [timer.py:215:stop] epoch=0/micro_step=175/global_step=175, RunningAvgSamplesPerSec=4.886232775273159, CurrSamplesPerSec=4.852693142047262, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:37,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.70 | backward_microstep: 114.21 | backward_inner_microstep: 103.02 | backward_allreduce_microstep: 11.09 | step_microstep: 43.63
[default0]:[2023-08-25 18:06:37,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.70 (forward_moe: 20.81, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.36)
[default0]:[2023-08-25 18:06:37,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.21 | backward_inner: 103.03 | backward_allreduce: 11.09 | step: 43.63
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.7477], device='cuda:0'), 'moe loss': tensor([0.3139], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      175/439453125 | consumed samples:          175 | consumed tokens:       358400 | elapsed time per iteration (ms): 313.2 | learning rate: 1.901E-07 | global batch size:     1 | lm loss: 1.054954E+01 | moe loss: 6.277572E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.193 | TFLOPs: 7.93 |
[default0]:[2023-08-25 18:06:37,447] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.38
[default0]:[2023-08-25 18:06:37,448] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.56 | backward_microstep: 113.93 | backward_inner_microstep: 102.80 | backward_allreduce_microstep: 11.04 | step_microstep: 43.71
[default0]:[2023-08-25 18:06:37,448] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.55 (forward_moe: 20.81, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.38)
[default0]:[2023-08-25 18:06:37,448] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.93 | backward_inner: 102.81 | backward_allreduce: 11.04 | step: 43.71
[default0]:[2023-08-25 18:06:37,696] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.42
[default0]:[2023-08-25 18:06:37,696] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.84 | backward_microstep: 114.32 | backward_inner_microstep: 103.16 | backward_allreduce_microstep: 11.06 | step_microstep: 43.20
[default0]:[2023-08-25 18:06:37,697] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.84 (forward_moe: 20.89, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.43)
[default0]:[2023-08-25 18:06:37,697] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.32 | backward_inner: 103.17 | backward_allreduce: 11.07 | step: 43.20
[default0]:[2023-08-25 18:06:37,961] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:37,961] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.72 | backward_microstep: 109.83 | backward_inner_microstep: 98.91 | backward_allreduce_microstep: 10.82 | step_microstep: 41.77
[default0]:[2023-08-25 18:06:37,961] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.72 (forward_moe: 19.93, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:06:37,961] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.83 | backward_inner: 98.91 | backward_allreduce: 10.83 | step: 41.77
[default0]:[2023-08-25 18:06:38,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:38,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.05 | backward_microstep: 110.18 | backward_inner_microstep: 99.23 | backward_allreduce_microstep: 10.86 | step_microstep: 41.63
[default0]:[2023-08-25 18:06:38,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.05 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:06:38,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.18 | backward_inner: 99.23 | backward_allreduce: 10.86 | step: 41.63
[default0]:[2023-08-25 18:06:38,460] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:38,460] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=0, lr=[1.9551573333333333e-07, 1.9551573333333333e-07, 1.9551573333333333e-07, 1.9551573333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:38,461] [INFO] [timer.py:215:stop] epoch=0/micro_step=180/global_step=180, RunningAvgSamplesPerSec=4.888396390923964, CurrSamplesPerSec=5.047224348144191, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:38,461] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 109.71 | backward_inner_microstep: 98.81 | backward_allreduce_microstep: 10.81 | step_microstep: 42.22
[default0]:[2023-08-25 18:06:38,461] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 20.07, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 7.81)
[default0]:[2023-08-25 18:06:38,461] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.71 | backward_inner: 98.82 | backward_allreduce: 10.81 | step: 42.22
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.7845], device='cuda:0'), 'moe loss': tensor([0.3281], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      180/439453125 | consumed samples:          180 | consumed tokens:       368640 | elapsed time per iteration (ms): 256.6 | learning rate: 1.955E-07 | global batch size:     1 | lm loss: 1.035689E+01 | moe loss: 6.562438E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.898 | TFLOPs: 9.68 |
[default0]:[2023-08-25 18:06:38,735] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:38,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.92 | backward_microstep: 109.64 | backward_inner_microstep: 98.68 | backward_allreduce_microstep: 10.86 | step_microstep: 41.72
[default0]:[2023-08-25 18:06:38,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.92 (forward_moe: 19.94, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:06:38,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.64 | backward_inner: 98.69 | backward_allreduce: 10.86 | step: 41.72
[default0]:[2023-08-25 18:06:38,997] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.34
[default0]:[2023-08-25 18:06:38,997] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.66 | backward_microstep: 109.64 | backward_inner_microstep: 98.66 | backward_allreduce_microstep: 10.88 | step_microstep: 41.87
[default0]:[2023-08-25 18:06:38,997] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:06:38,998] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.64 | backward_inner: 98.66 | backward_allreduce: 10.88 | step: 41.88
[default0]:[2023-08-25 18:06:39,376] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:39,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.83 | backward_microstep: 109.79 | backward_inner_microstep: 98.83 | backward_allreduce_microstep: 10.86 | step_microstep: 41.67
[default0]:[2023-08-25 18:06:39,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.83 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:06:39,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.79 | backward_inner: 98.84 | backward_allreduce: 10.86 | step: 41.67
[default0]:[2023-08-25 18:06:39,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.08 | optimizer_step: 6.44
[default0]:[2023-08-25 18:06:39,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.79 | backward_microstep: 113.21 | backward_inner_microstep: 101.96 | backward_allreduce_microstep: 11.16 | step_microstep: 43.55
[default0]:[2023-08-25 18:06:39,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.79 (forward_moe: 20.62, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:06:39,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.21 | backward_inner: 101.96 | backward_allreduce: 11.16 | step: 43.56
[default0]:[2023-08-25 18:06:39,919] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.06 | optimizer_step: 6.38
[default0]:[2023-08-25 18:06:39,920] [INFO] [logging.py:96:log_dist] [Rank 0] step=185, skipped=0, lr=[2.0097706666666667e-07, 2.0097706666666667e-07, 2.0097706666666667e-07, 2.0097706666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:39,920] [INFO] [timer.py:215:stop] epoch=0/micro_step=185/global_step=185, RunningAvgSamplesPerSec=4.890487691748315, CurrSamplesPerSec=4.779207283375968, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:39,920] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.64 | backward_microstep: 115.94 | backward_inner_microstep: 104.63 | backward_allreduce_microstep: 11.21 | step_microstep: 44.12
[default0]:[2023-08-25 18:06:39,920] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.63 (forward_moe: 21.29, 1st alltoall: 0.94, 2nd alltoall: 0.84, top-k: 8.61)
[default0]:[2023-08-25 18:06:39,920] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.94 | backward_inner: 104.63 | backward_allreduce: 11.22 | step: 44.12
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.3757], device='cuda:0'), 'moe loss': tensor([0.3160], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      185/439453125 | consumed samples:          185 | consumed tokens:       378880 | elapsed time per iteration (ms): 292.2 | learning rate: 2.010E-07 | global batch size:     1 | lm loss: 1.047515E+01 | moe loss: 6.319352E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.423 | TFLOPs: 8.50 |
[default0]:[2023-08-25 18:06:40,211] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.41
[default0]:[2023-08-25 18:06:40,212] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.15 | backward_microstep: 113.29 | backward_inner_microstep: 102.15 | backward_allreduce_microstep: 11.05 | step_microstep: 43.66
[default0]:[2023-08-25 18:06:40,212] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.14 (forward_moe: 20.86, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:06:40,212] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.29 | backward_inner: 102.16 | backward_allreduce: 11.05 | step: 43.66
[default0]:[2023-08-25 18:06:40,501] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:40,501] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.04 | backward_microstep: 113.25 | backward_inner_microstep: 102.12 | backward_allreduce_microstep: 11.04 | step_microstep: 42.93
[default0]:[2023-08-25 18:06:40,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.04 (forward_moe: 20.59, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:06:40,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.25 | backward_inner: 102.12 | backward_allreduce: 11.04 | step: 42.93
[default0]:[2023-08-25 18:06:40,759] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:40,760] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 110.27 | backward_inner_microstep: 99.27 | backward_allreduce_microstep: 10.90 | step_microstep: 42.03
[default0]:[2023-08-25 18:06:40,760] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.99 (forward_moe: 20.01, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.89)
[default0]:[2023-08-25 18:06:40,760] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.27 | backward_inner: 99.28 | backward_allreduce: 10.91 | step: 42.03
[default0]:[2023-08-25 18:06:41,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:06:41,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.04 | backward_microstep: 110.33 | backward_inner_microstep: 99.40 | backward_allreduce_microstep: 10.83 | step_microstep: 42.52
[default0]:[2023-08-25 18:06:41,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.04 (forward_moe: 20.06, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.90)
[default0]:[2023-08-25 18:06:41,029] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.32 | backward_inner: 99.40 | backward_allreduce: 10.83 | step: 42.52
[default0]:[2023-08-25 18:06:41,287] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:06:41,288] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=0, lr=[2.064384e-07, 2.064384e-07, 2.064384e-07, 2.064384e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:41,288] [INFO] [timer.py:215:stop] epoch=0/micro_step=190/global_step=190, RunningAvgSamplesPerSec=4.8918143262736775, CurrSamplesPerSec=4.970502666977943, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:41,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.92 | backward_microstep: 111.39 | backward_inner_microstep: 100.40 | backward_allreduce_microstep: 10.90 | step_microstep: 42.31
[default0]:[2023-08-25 18:06:41,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.92 (forward_moe: 20.70, 1st alltoall: 0.86, 2nd alltoall: 0.82, top-k: 8.40)
[default0]:[2023-08-25 18:06:41,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.39 | backward_inner: 100.40 | backward_allreduce: 10.91 | step: 42.32
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.3735], device='cuda:0'), 'moe loss': tensor([0.3139], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      190/439453125 | consumed samples:          190 | consumed tokens:       389120 | elapsed time per iteration (ms): 273.5 | learning rate: 2.064E-07 | global batch size:     1 | lm loss: 1.047471E+01 | moe loss: 6.277785E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.656 | TFLOPs: 9.08 |
[default0]:[2023-08-25 18:06:41,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:06:41,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.92 | backward_microstep: 110.32 | backward_inner_microstep: 99.37 | backward_allreduce_microstep: 10.86 | step_microstep: 42.10
[default0]:[2023-08-25 18:06:41,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.92 (forward_moe: 20.14, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.91)
[default0]:[2023-08-25 18:06:41,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.32 | backward_inner: 99.37 | backward_allreduce: 10.86 | step: 42.11
[default0]:[2023-08-25 18:06:41,814] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:06:41,815] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.21 | backward_microstep: 111.63 | backward_inner_microstep: 100.66 | backward_allreduce_microstep: 10.87 | step_microstep: 41.82
[default0]:[2023-08-25 18:06:41,815] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.21 (forward_moe: 20.04, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.88)
[default0]:[2023-08-25 18:06:41,815] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.63 | backward_inner: 100.66 | backward_allreduce: 10.88 | step: 41.82
[default0]:[2023-08-25 18:06:42,053] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:06:42,054] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.85 | backward_microstep: 110.32 | backward_inner_microstep: 99.41 | backward_allreduce_microstep: 10.82 | step_microstep: 41.94
[default0]:[2023-08-25 18:06:42,054] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.85 (forward_moe: 20.15, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 8.00)
[default0]:[2023-08-25 18:06:42,054] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.32 | backward_inner: 99.41 | backward_allreduce: 10.82 | step: 41.95
[default0]:[2023-08-25 18:06:42,696] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.18 | optimizer_step: 6.52
[default0]:[2023-08-25 18:06:42,696] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.87 | backward_microstep: 117.77 | backward_inner_microstep: 106.37 | backward_allreduce_microstep: 11.31 | step_microstep: 44.74
[default0]:[2023-08-25 18:06:42,696] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.87 (forward_moe: 21.59, 1st alltoall: 0.92, 2nd alltoall: 0.85, top-k: 8.85)
[default0]:[2023-08-25 18:06:42,696] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.77 | backward_inner: 106.37 | backward_allreduce: 11.31 | step: 44.74
[default0]:[2023-08-25 18:06:42,963] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.12 | optimizer_step: 6.48
[default0]:[2023-08-25 18:06:42,963] [INFO] [logging.py:96:log_dist] [Rank 0] step=195, skipped=0, lr=[2.1189973333333335e-07, 2.1189973333333335e-07, 2.1189973333333335e-07, 2.1189973333333335e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:42,964] [INFO] [timer.py:215:stop] epoch=0/micro_step=195/global_step=195, RunningAvgSamplesPerSec=4.891700718444908, CurrSamplesPerSec=4.755619251492118, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:42,964] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.06 | backward_microstep: 116.28 | backward_inner_microstep: 104.93 | backward_allreduce_microstep: 11.26 | step_microstep: 44.35
[default0]:[2023-08-25 18:06:42,964] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.06 (forward_moe: 21.39, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.75)
[default0]:[2023-08-25 18:06:42,964] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.28 | backward_inner: 104.93 | backward_allreduce: 11.26 | step: 44.35
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.2789], device='cuda:0'), 'moe loss': tensor([0.3148], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      195/439453125 | consumed samples:          195 | consumed tokens:       399360 | elapsed time per iteration (ms): 334.8 | learning rate: 2.119E-07 | global batch size:     1 | lm loss: 1.045578E+01 | moe loss: 6.296698E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.987 | TFLOPs: 7.42 |
[default0]:[2023-08-25 18:06:43,249] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.13 | optimizer_step: 6.49
[default0]:[2023-08-25 18:06:43,249] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.78 | backward_microstep: 117.39 | backward_inner_microstep: 105.77 | backward_allreduce_microstep: 11.51 | step_microstep: 43.95
[default0]:[2023-08-25 18:06:43,249] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.78 (forward_moe: 21.51, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.77)
[default0]:[2023-08-25 18:06:43,249] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.39 | backward_inner: 105.78 | backward_allreduce: 11.52 | step: 43.95
[default0]:[2023-08-25 18:06:43,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.13 | optimizer_step: 6.48
[default0]:[2023-08-25 18:06:43,521] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.70 | backward_microstep: 116.31 | backward_inner_microstep: 105.05 | backward_allreduce_microstep: 11.17 | step_microstep: 44.14
[default0]:[2023-08-25 18:06:43,521] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.69 (forward_moe: 21.43, 1st alltoall: 0.91, 2nd alltoall: 0.83, top-k: 8.68)
[default0]:[2023-08-25 18:06:43,521] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.31 | backward_inner: 105.05 | backward_allreduce: 11.17 | step: 44.14
[default0]:[2023-08-25 18:06:43,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:06:43,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.36 | backward_microstep: 111.50 | backward_inner_microstep: 100.44 | backward_allreduce_microstep: 10.97 | step_microstep: 42.48
[default0]:[2023-08-25 18:06:43,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.36 (forward_moe: 20.37, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.05)
[default0]:[2023-08-25 18:06:43,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.49 | backward_inner: 100.44 | backward_allreduce: 10.97 | step: 42.49
[default0]:[2023-08-25 18:06:44,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.34
[default0]:[2023-08-25 18:06:44,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.66 | backward_microstep: 111.22 | backward_inner_microstep: 100.21 | backward_allreduce_microstep: 10.92 | step_microstep: 42.27
[default0]:[2023-08-25 18:06:44,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.65 (forward_moe: 20.21, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.01)
[default0]:[2023-08-25 18:06:44,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.22 | backward_inner: 100.22 | backward_allreduce: 10.92 | step: 42.28
[default0]:[2023-08-25 18:06:44,375] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:06:44,375] [INFO] [logging.py:96:log_dist] [Rank 0] step=200, skipped=0, lr=[2.173610666666667e-07, 2.173610666666667e-07, 2.173610666666667e-07, 2.173610666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:44,376] [INFO] [timer.py:215:stop] epoch=0/micro_step=200/global_step=200, RunningAvgSamplesPerSec=4.891408145617567, CurrSamplesPerSec=4.962469460071817, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:44,376] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.54 | backward_microstep: 111.65 | backward_inner_microstep: 100.57 | backward_allreduce_microstep: 10.98 | step_microstep: 42.77
[default0]:[2023-08-25 18:06:44,376] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.54 (forward_moe: 20.54, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.16)
[default0]:[2023-08-25 18:06:44,376] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.65 | backward_inner: 100.58 | backward_allreduce: 10.99 | step: 42.78
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.3020], device='cuda:0'), 'moe loss': tensor([0.3140], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      200/439453125 | consumed samples:          200 | consumed tokens:       409600 | elapsed time per iteration (ms): 282.4 | learning rate: 2.174E-07 | global batch size:     1 | lm loss: 1.046039E+01 | moe loss: 6.279755E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.541 | TFLOPs: 8.80 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 200 | lm loss value: 1.042219E+01 | lm loss PPL: 3.359683E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration     200 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:06:48,170] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step200 is about to be saved!
[default0]:[2023-08-25 18:06:48,172] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,182] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,182] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,191] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,192] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,200] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,200] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,209] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,210] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,218] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,218] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,227] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,227] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,236] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,236] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,245] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,245] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,254] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,254] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,264] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,265] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,274] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,274] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,283] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,284] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,293] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,293] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,302] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,313] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,313] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,321] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,322] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,331] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,331] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,339] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,339] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,348] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,348] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,357] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,358] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,366] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,366] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,375] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,375] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,385] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,385] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,394] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,394] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:06:48,396] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:06:48,397] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:06:48,397] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:06:48,672] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:06:48,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:06:52,469] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:06:52,482] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step200/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:06:52,482] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step200 is ready now!
[default0]:  successfully saved checkpoint at iteration     200 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.68, Latency(second): 4.317
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4317.13, 4317.13)
[default0]:[2023-08-25 18:06:52,739] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.15 | optimizer_step: 10.06
[default0]:[2023-08-25 18:06:52,740] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2314.97 | backward_microstep: 116.96 | backward_inner_microstep: 105.74 | backward_allreduce_microstep: 11.12 | step_microstep: 47.40
[default0]:[2023-08-25 18:06:52,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2314.86 (forward_moe: 21.42, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.74)
[default0]:[2023-08-25 18:06:52,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.95 | backward_inner: 105.75 | backward_allreduce: 11.12 | step: 47.40
[default0]:[2023-08-25 18:06:53,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.07 | optimizer_step: 6.44
[default0]:[2023-08-25 18:06:53,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.30 | backward_microstep: 116.56 | backward_inner_microstep: 105.41 | backward_allreduce_microstep: 11.05 | step_microstep: 43.78
[default0]:[2023-08-25 18:06:53,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.30 (forward_moe: 21.35, 1st alltoall: 0.92, 2nd alltoall: 0.82, top-k: 8.73)
[default0]:[2023-08-25 18:06:53,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.56 | backward_inner: 105.42 | backward_allreduce: 11.06 | step: 43.78
[default0]:[2023-08-25 18:06:53,279] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:06:53,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.43 | backward_microstep: 116.46 | backward_inner_microstep: 105.22 | backward_allreduce_microstep: 11.15 | step_microstep: 43.76
[default0]:[2023-08-25 18:06:53,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.43 (forward_moe: 21.42, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.58)
[default0]:[2023-08-25 18:06:53,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.46 | backward_inner: 105.22 | backward_allreduce: 11.15 | step: 43.77
[default0]:[2023-08-25 18:06:53,532] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.10 | optimizer_step: 6.46
[default0]:[2023-08-25 18:06:53,532] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.24 | backward_microstep: 115.26 | backward_inner_microstep: 104.05 | backward_allreduce_microstep: 11.12 | step_microstep: 43.79
[default0]:[2023-08-25 18:06:53,532] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.24 (forward_moe: 21.06, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.53)
[default0]:[2023-08-25 18:06:53,532] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.26 | backward_inner: 104.06 | backward_allreduce: 11.13 | step: 43.80
[default0]:[2023-08-25 18:06:53,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.42
[default0]:[2023-08-25 18:06:53,808] [INFO] [logging.py:96:log_dist] [Rank 0] step=205, skipped=0, lr=[2.228224e-07, 2.228224e-07, 2.228224e-07, 2.228224e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:53,808] [INFO] [timer.py:215:stop] epoch=0/micro_step=205/global_step=205, RunningAvgSamplesPerSec=4.887573173213773, CurrSamplesPerSec=4.800117190361092, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:53,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.57 | backward_microstep: 115.22 | backward_inner_microstep: 103.94 | backward_allreduce_microstep: 11.18 | step_microstep: 43.95
[default0]:[2023-08-25 18:06:53,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.57 (forward_moe: 21.08, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.55)
[default0]:[2023-08-25 18:06:53,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.22 | backward_inner: 103.95 | backward_allreduce: 11.19 | step: 43.95
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.2368], device='cuda:0'), 'moe loss': tensor([0.3136], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      205/439453125 | consumed samples:          205 | consumed tokens:       419840 | elapsed time per iteration (ms): 1886.5 | learning rate: 2.228E-07 | global batch size:     1 | lm loss: 1.044735E+01 | moe loss: 6.271278E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.530 | TFLOPs: 1.32 |
[default0]:[2023-08-25 18:06:54,137] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.46
[default0]:[2023-08-25 18:06:54,138] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.88 | backward_microstep: 114.84 | backward_inner_microstep: 103.60 | backward_allreduce_microstep: 11.14 | step_microstep: 44.02
[default0]:[2023-08-25 18:06:54,138] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.88 (forward_moe: 21.06, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.47)
[default0]:[2023-08-25 18:06:54,139] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.83 | backward_inner: 103.61 | backward_allreduce: 11.14 | step: 44.03
[default0]:[2023-08-25 18:06:54,418] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.44
[default0]:[2023-08-25 18:06:54,419] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.63 | backward_microstep: 114.96 | backward_inner_microstep: 103.72 | backward_allreduce_microstep: 11.15 | step_microstep: 43.52
[default0]:[2023-08-25 18:06:54,419] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.63 (forward_moe: 21.01, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.47)
[default0]:[2023-08-25 18:06:54,419] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.96 | backward_inner: 103.73 | backward_allreduce: 11.15 | step: 43.52
[default0]:[2023-08-25 18:06:54,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.13 | optimizer_step: 6.44
[default0]:[2023-08-25 18:06:54,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.03 | backward_microstep: 114.92 | backward_inner_microstep: 103.69 | backward_allreduce_microstep: 11.14 | step_microstep: 43.64
[default0]:[2023-08-25 18:06:54,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.03 (forward_moe: 21.10, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.47)
[default0]:[2023-08-25 18:06:54,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.92 | backward_inner: 103.69 | backward_allreduce: 11.15 | step: 43.64
[default0]:[2023-08-25 18:06:54,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.43
[default0]:[2023-08-25 18:06:54,968] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.06 | backward_microstep: 114.82 | backward_inner_microstep: 103.62 | backward_allreduce_microstep: 11.10 | step_microstep: 43.49
[default0]:[2023-08-25 18:06:54,968] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.05 (forward_moe: 21.05, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.50)
[default0]:[2023-08-25 18:06:54,968] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.81 | backward_inner: 103.63 | backward_allreduce: 11.10 | step: 43.49
[default0]:[2023-08-25 18:06:55,236] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.41
[default0]:[2023-08-25 18:06:55,236] [INFO] [logging.py:96:log_dist] [Rank 0] step=210, skipped=0, lr=[2.2828373333333334e-07, 2.2828373333333334e-07, 2.2828373333333334e-07, 2.2828373333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:55,236] [INFO] [timer.py:215:stop] epoch=0/micro_step=210/global_step=210, RunningAvgSamplesPerSec=4.886173452062885, CurrSamplesPerSec=4.874592360670446, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:55,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.51 | backward_microstep: 113.68 | backward_inner_microstep: 102.57 | backward_allreduce_microstep: 11.01 | step_microstep: 43.41
[default0]:[2023-08-25 18:06:55,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.51 (forward_moe: 20.84, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.31)
[default0]:[2023-08-25 18:06:55,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.68 | backward_inner: 102.58 | backward_allreduce: 11.02 | step: 43.41
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.1564], device='cuda:0'), 'moe loss': tensor([0.3139], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      210/439453125 | consumed samples:          210 | consumed tokens:       430080 | elapsed time per iteration (ms): 285.8 | learning rate: 2.283E-07 | global batch size:     1 | lm loss: 1.043128E+01 | moe loss: 6.278817E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.499 | TFLOPs: 8.69 |
[default0]:[2023-08-25 18:06:55,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:55,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.59 | backward_microstep: 113.73 | backward_inner_microstep: 102.59 | backward_allreduce_microstep: 11.04 | step_microstep: 42.99
[default0]:[2023-08-25 18:06:55,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.59 (forward_moe: 20.77, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.31)
[default0]:[2023-08-25 18:06:55,484] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.72 | backward_inner: 102.60 | backward_allreduce: 11.04 | step: 42.99
[default0]:[2023-08-25 18:06:55,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:06:55,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.65 | backward_microstep: 113.50 | backward_inner_microstep: 102.44 | backward_allreduce_microstep: 10.97 | step_microstep: 43.05
[default0]:[2023-08-25 18:06:55,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.65 (forward_moe: 20.72, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.32)
[default0]:[2023-08-25 18:06:55,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.49 | backward_inner: 102.44 | backward_allreduce: 10.97 | step: 43.05
[default0]:[2023-08-25 18:06:55,992] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.40
[default0]:[2023-08-25 18:06:55,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.48 | backward_microstep: 116.39 | backward_inner_microstep: 105.25 | backward_allreduce_microstep: 11.05 | step_microstep: 43.61
[default0]:[2023-08-25 18:06:55,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.48 (forward_moe: 20.74, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.30)
[default0]:[2023-08-25 18:06:55,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.39 | backward_inner: 105.25 | backward_allreduce: 11.05 | step: 43.61
[default0]:[2023-08-25 18:06:56,232] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.47
[default0]:[2023-08-25 18:06:56,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 110.52 | backward_inner_microstep: 99.58 | backward_allreduce_microstep: 10.85 | step_microstep: 41.95
[default0]:[2023-08-25 18:06:56,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.00 (forward_moe: 20.14, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.86)
[default0]:[2023-08-25 18:06:56,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.52 | backward_inner: 99.58 | backward_allreduce: 10.85 | step: 41.95
[default0]:[2023-08-25 18:06:56,548] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:56,549] [INFO] [logging.py:96:log_dist] [Rank 0] step=215, skipped=0, lr=[2.3374506666666669e-07, 2.3374506666666669e-07, 2.3374506666666669e-07, 2.3374506666666669e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:56,549] [INFO] [timer.py:215:stop] epoch=0/micro_step=215/global_step=215, RunningAvgSamplesPerSec=4.886949741620718, CurrSamplesPerSec=5.033535268195739, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:56,549] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.93 | backward_microstep: 110.01 | backward_inner_microstep: 99.03 | backward_allreduce_microstep: 10.89 | step_microstep: 42.19
[default0]:[2023-08-25 18:06:56,549] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.93 (forward_moe: 19.93, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.84)
[default0]:[2023-08-25 18:06:56,549] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.01 | backward_inner: 99.04 | backward_allreduce: 10.89 | step: 42.19
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.0842], device='cuda:0'), 'moe loss': tensor([0.3139], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      215/439453125 | consumed samples:          215 | consumed tokens:       440320 | elapsed time per iteration (ms): 262.6 | learning rate: 2.337E-07 | global batch size:     1 | lm loss: 1.041684E+01 | moe loss: 6.278403E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.809 | TFLOPs: 9.46 |
[default0]:[2023-08-25 18:06:56,832] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:06:56,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.93 | backward_microstep: 109.95 | backward_inner_microstep: 98.98 | backward_allreduce_microstep: 10.87 | step_microstep: 43.14
[default0]:[2023-08-25 18:06:56,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.92 (forward_moe: 19.98, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:06:56,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.95 | backward_inner: 98.98 | backward_allreduce: 10.88 | step: 43.14
[default0]:[2023-08-25 18:06:57,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:57,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.89 | backward_microstep: 110.21 | backward_inner_microstep: 99.24 | backward_allreduce_microstep: 10.89 | step_microstep: 41.93
[default0]:[2023-08-25 18:06:57,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.89 (forward_moe: 20.00, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.86)
[default0]:[2023-08-25 18:06:57,097] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.21 | backward_inner: 99.24 | backward_allreduce: 10.89 | step: 41.93
[default0]:[2023-08-25 18:06:57,381] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:57,382] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.14 | backward_microstep: 110.31 | backward_inner_microstep: 99.37 | backward_allreduce_microstep: 10.85 | step_microstep: 42.22
[default0]:[2023-08-25 18:06:57,382] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.14 (forward_moe: 19.94, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:06:57,382] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.31 | backward_inner: 99.37 | backward_allreduce: 10.86 | step: 42.23
[default0]:[2023-08-25 18:06:57,671] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:06:57,672] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.20 | backward_microstep: 110.00 | backward_inner_microstep: 99.08 | backward_allreduce_microstep: 10.83 | step_microstep: 41.83
[default0]:[2023-08-25 18:06:57,672] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.20 (forward_moe: 19.91, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.85)
[default0]:[2023-08-25 18:06:57,672] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.00 | backward_inner: 99.08 | backward_allreduce: 10.84 | step: 41.84
[default0]:[2023-08-25 18:06:57,955] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:06:57,955] [INFO] [logging.py:96:log_dist] [Rank 0] step=220, skipped=0, lr=[2.392064e-07, 2.392064e-07, 2.392064e-07, 2.392064e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:57,955] [INFO] [timer.py:215:stop] epoch=0/micro_step=220/global_step=220, RunningAvgSamplesPerSec=4.889695002852854, CurrSamplesPerSec=4.973502662065858, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:57,955] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.91 | backward_microstep: 111.79 | backward_inner_microstep: 100.74 | backward_allreduce_microstep: 10.96 | step_microstep: 42.81
[default0]:[2023-08-25 18:06:57,955] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.91 (forward_moe: 20.47, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.07)
[default0]:[2023-08-25 18:06:57,955] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.79 | backward_inner: 100.74 | backward_allreduce: 10.96 | step: 42.81
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.7915], device='cuda:0'), 'moe loss': tensor([0.3126], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      220/439453125 | consumed samples:          220 | consumed tokens:       450560 | elapsed time per iteration (ms): 281.1 | learning rate: 2.392E-07 | global batch size:     1 | lm loss: 1.035829E+01 | moe loss: 6.252984E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.557 | TFLOPs: 8.84 |
[default0]:[2023-08-25 18:06:58,241] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:58,244] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.95 | backward_microstep: 112.76 | backward_inner_microstep: 101.64 | backward_allreduce_microstep: 11.02 | step_microstep: 46.67
[default0]:[2023-08-25 18:06:58,245] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.95 (forward_moe: 20.51, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.19)
[default0]:[2023-08-25 18:06:58,245] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.76 | backward_inner: 101.65 | backward_allreduce: 11.03 | step: 46.68
[default0]:[2023-08-25 18:06:58,571] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.06 | optimizer_step: 6.45
[default0]:[2023-08-25 18:06:58,571] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.93 | backward_microstep: 117.57 | backward_inner_microstep: 106.34 | backward_allreduce_microstep: 11.14 | step_microstep: 43.52
[default0]:[2023-08-25 18:06:58,571] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.93 (forward_moe: 21.74, 1st alltoall: 0.93, 2nd alltoall: 0.87, top-k: 8.66)
[default0]:[2023-08-25 18:06:58,572] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.57 | backward_inner: 106.34 | backward_allreduce: 11.14 | step: 43.52
[default0]:[2023-08-25 18:06:58,822] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:58,822] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.38 | backward_microstep: 114.97 | backward_inner_microstep: 103.72 | backward_allreduce_microstep: 11.16 | step_microstep: 43.42
[default0]:[2023-08-25 18:06:58,822] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.38 (forward_moe: 20.99, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.47)
[default0]:[2023-08-25 18:06:58,822] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.97 | backward_inner: 103.73 | backward_allreduce: 11.16 | step: 43.42
[default0]:[2023-08-25 18:06:59,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.47
[default0]:[2023-08-25 18:06:59,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.27 | backward_microstep: 112.98 | backward_inner_microstep: 101.89 | backward_allreduce_microstep: 10.99 | step_microstep: 42.86
[default0]:[2023-08-25 18:06:59,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.27 (forward_moe: 20.63, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.27)
[default0]:[2023-08-25 18:06:59,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.98 | backward_inner: 101.90 | backward_allreduce: 11.00 | step: 42.86
[default0]:[2023-08-25 18:06:59,338] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.40
[default0]:[2023-08-25 18:06:59,338] [INFO] [logging.py:96:log_dist] [Rank 0] step=225, skipped=0, lr=[2.446677333333333e-07, 2.446677333333333e-07, 2.446677333333333e-07, 2.446677333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:06:59,338] [INFO] [timer.py:215:stop] epoch=0/micro_step=225/global_step=225, RunningAvgSamplesPerSec=4.888397448035724, CurrSamplesPerSec=4.877806657944468, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:06:59,338] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.52 | backward_microstep: 113.58 | backward_inner_microstep: 102.41 | backward_allreduce_microstep: 11.07 | step_microstep: 43.35
[default0]:[2023-08-25 18:06:59,339] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.52 (forward_moe: 20.77, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.29)
[default0]:[2023-08-25 18:06:59,339] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.58 | backward_inner: 102.42 | backward_allreduce: 11.07 | step: 43.36
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.0310], device='cuda:0'), 'moe loss': tensor([0.3118], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      225/439453125 | consumed samples:          225 | consumed tokens:       460800 | elapsed time per iteration (ms): 276.5 | learning rate: 2.447E-07 | global batch size:     1 | lm loss: 1.040619E+01 | moe loss: 6.235512E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.617 | TFLOPs: 8.99 |
[default0]:[2023-08-25 18:06:59,590] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:06:59,591] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.23 | backward_microstep: 113.11 | backward_inner_microstep: 102.00 | backward_allreduce_microstep: 11.01 | step_microstep: 43.02
[default0]:[2023-08-25 18:06:59,591] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.23 (forward_moe: 20.64, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:06:59,591] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.11 | backward_inner: 102.01 | backward_allreduce: 11.02 | step: 43.02
[default0]:[2023-08-25 18:06:59,837] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:06:59,838] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.24 | backward_microstep: 112.67 | backward_inner_microstep: 101.61 | backward_allreduce_microstep: 10.96 | step_microstep: 42.67
[default0]:[2023-08-25 18:06:59,838] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.24 (forward_moe: 20.57, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:06:59,838] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.67 | backward_inner: 101.62 | backward_allreduce: 10.96 | step: 42.67
[default0]:[2023-08-25 18:07:00,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:07:00,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.05 | backward_microstep: 112.71 | backward_inner_microstep: 101.64 | backward_allreduce_microstep: 10.97 | step_microstep: 42.85
[default0]:[2023-08-25 18:07:00,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.05 (forward_moe: 20.55, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:07:00,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.71 | backward_inner: 101.65 | backward_allreduce: 10.98 | step: 42.85
[default0]:[2023-08-25 18:07:00,360] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.36
[default0]:[2023-08-25 18:07:00,361] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.27 | backward_microstep: 113.06 | backward_inner_microstep: 101.93 | backward_allreduce_microstep: 11.03 | step_microstep: 42.73
[default0]:[2023-08-25 18:07:00,361] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.27 (forward_moe: 20.73, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.33)
[default0]:[2023-08-25 18:07:00,361] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.05 | backward_inner: 101.93 | backward_allreduce: 11.04 | step: 42.74
[default0]:[2023-08-25 18:07:00,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.36
[default0]:[2023-08-25 18:07:00,633] [INFO] [logging.py:96:log_dist] [Rank 0] step=230, skipped=0, lr=[2.501290666666667e-07, 2.501290666666667e-07, 2.501290666666667e-07, 2.501290666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:00,634] [INFO] [timer.py:215:stop] epoch=0/micro_step=230/global_step=230, RunningAvgSamplesPerSec=4.888837616573925, CurrSamplesPerSec=4.908701722602383, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:00,634] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.09 | backward_microstep: 112.80 | backward_inner_microstep: 101.66 | backward_allreduce_microstep: 11.04 | step_microstep: 43.28
[default0]:[2023-08-25 18:07:00,634] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.09 (forward_moe: 20.76, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:07:00,634] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.80 | backward_inner: 101.67 | backward_allreduce: 11.05 | step: 43.28
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.9650], device='cuda:0'), 'moe loss': tensor([0.3128], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      230/439453125 | consumed samples:          230 | consumed tokens:       471040 | elapsed time per iteration (ms): 259.3 | learning rate: 2.501E-07 | global batch size:     1 | lm loss: 1.039300E+01 | moe loss: 6.256132E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.857 | TFLOPs: 9.58 |
[default0]:[2023-08-25 18:07:00,911] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.38
[default0]:[2023-08-25 18:07:00,911] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.99 | backward_microstep: 112.50 | backward_inner_microstep: 101.38 | backward_allreduce_microstep: 11.02 | step_microstep: 42.76
[default0]:[2023-08-25 18:07:00,911] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.99 (forward_moe: 20.50, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.19)
[default0]:[2023-08-25 18:07:00,911] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.50 | backward_inner: 101.38 | backward_allreduce: 11.03 | step: 42.77
[default0]:[2023-08-25 18:07:01,205] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:01,205] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.19 | backward_microstep: 113.45 | backward_inner_microstep: 102.08 | backward_allreduce_microstep: 11.28 | step_microstep: 42.59
[default0]:[2023-08-25 18:07:01,205] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.19 (forward_moe: 20.87, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:07:01,205] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.45 | backward_inner: 102.09 | backward_allreduce: 11.28 | step: 42.60
[default0]:[2023-08-25 18:07:01,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:01,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.42 | backward_microstep: 111.19 | backward_inner_microstep: 100.25 | backward_allreduce_microstep: 10.85 | step_microstep: 42.16
[default0]:[2023-08-25 18:07:01,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.42 (forward_moe: 20.23, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.01)
[default0]:[2023-08-25 18:07:01,479] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.19 | backward_inner: 100.25 | backward_allreduce: 10.86 | step: 42.17
[default0]:[2023-08-25 18:07:01,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:01,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.66 | backward_microstep: 111.33 | backward_inner_microstep: 100.33 | backward_allreduce_microstep: 10.90 | step_microstep: 42.22
[default0]:[2023-08-25 18:07:01,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.66 (forward_moe: 20.24, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.03)
[default0]:[2023-08-25 18:07:01,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.32 | backward_inner: 100.34 | backward_allreduce: 10.90 | step: 42.23
[default0]:[2023-08-25 18:07:01,996] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:07:01,997] [INFO] [logging.py:96:log_dist] [Rank 0] step=235, skipped=0, lr=[2.555904e-07, 2.555904e-07, 2.555904e-07, 2.555904e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:01,997] [INFO] [timer.py:215:stop] epoch=0/micro_step=235/global_step=235, RunningAvgSamplesPerSec=4.890132447162459, CurrSamplesPerSec=4.966823926182762, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:01,997] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.82 | backward_microstep: 111.42 | backward_inner_microstep: 100.41 | backward_allreduce_microstep: 10.91 | step_microstep: 42.54
[default0]:[2023-08-25 18:07:01,997] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.81 (forward_moe: 20.25, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.03)
[default0]:[2023-08-25 18:07:01,997] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.42 | backward_inner: 100.42 | backward_allreduce: 10.92 | step: 42.55
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.7584], device='cuda:0'), 'moe loss': tensor([0.3124], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      235/439453125 | consumed samples:          235 | consumed tokens:       481280 | elapsed time per iteration (ms): 278.7 | learning rate: 2.556E-07 | global batch size:     1 | lm loss: 1.035169E+01 | moe loss: 6.248358E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.587 | TFLOPs: 8.91 |
[default0]:[2023-08-25 18:07:02,307] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:02,307] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.66 | backward_microstep: 111.77 | backward_inner_microstep: 100.46 | backward_allreduce_microstep: 11.21 | step_microstep: 42.22
[default0]:[2023-08-25 18:07:02,307] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.66 (forward_moe: 20.40, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:07:02,307] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.76 | backward_inner: 100.47 | backward_allreduce: 11.21 | step: 42.23
[default0]:[2023-08-25 18:07:02,548] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.69 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:02,549] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.48 | backward_microstep: 113.03 | backward_inner_microstep: 102.05 | backward_allreduce_microstep: 10.89 | step_microstep: 43.63
[default0]:[2023-08-25 18:07:02,549] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.48 (forward_moe: 20.34, 1st alltoall: 0.87, 2nd alltoall: 0.83, top-k: 8.09)
[default0]:[2023-08-25 18:07:02,550] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.03 | backward_inner: 102.05 | backward_allreduce: 10.90 | step: 43.63
[default0]:[2023-08-25 18:07:02,815] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 9.84
[default0]:[2023-08-25 18:07:02,816] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.59 | backward_microstep: 111.81 | backward_inner_microstep: 100.71 | backward_allreduce_microstep: 10.99 | step_microstep: 45.97
[default0]:[2023-08-25 18:07:02,816] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.59 (forward_moe: 20.34, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.03)
[default0]:[2023-08-25 18:07:02,816] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.81 | backward_inner: 100.72 | backward_allreduce: 11.00 | step: 45.97
[default0]:[2023-08-25 18:07:03,077] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 6.41
[default0]:[2023-08-25 18:07:03,078] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.43 | backward_microstep: 110.58 | backward_inner_microstep: 99.64 | backward_allreduce_microstep: 10.85 | step_microstep: 42.18
[default0]:[2023-08-25 18:07:03,078] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.42 (forward_moe: 20.14, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.94)
[default0]:[2023-08-25 18:07:03,078] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.58 | backward_inner: 99.64 | backward_allreduce: 10.86 | step: 42.18
[default0]:[2023-08-25 18:07:03,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:03,352] [INFO] [logging.py:96:log_dist] [Rank 0] step=240, skipped=0, lr=[2.6105173333333336e-07, 2.6105173333333336e-07, 2.6105173333333336e-07, 2.6105173333333336e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:03,352] [INFO] [timer.py:215:stop] epoch=0/micro_step=240/global_step=240, RunningAvgSamplesPerSec=4.890881918283481, CurrSamplesPerSec=4.968765622519648, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:03,352] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.75 | backward_microstep: 111.53 | backward_inner_microstep: 100.55 | backward_allreduce_microstep: 10.89 | step_microstep: 42.42
[default0]:[2023-08-25 18:07:03,352] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.75 (forward_moe: 20.35, 1st alltoall: 0.86, 2nd alltoall: 0.82, top-k: 7.95)
[default0]:[2023-08-25 18:07:03,352] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.53 | backward_inner: 100.55 | backward_allreduce: 10.89 | step: 42.43
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.8776], device='cuda:0'), 'moe loss': tensor([0.3128], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      240/439453125 | consumed samples:          240 | consumed tokens:       491520 | elapsed time per iteration (ms): 264.9 | learning rate: 2.611E-07 | global batch size:     1 | lm loss: 1.037552E+01 | moe loss: 6.255228E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.775 | TFLOPs: 9.38 |
[default0]:[2023-08-25 18:07:03,607] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:03,607] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.14 | backward_microstep: 110.80 | backward_inner_microstep: 99.79 | backward_allreduce_microstep: 10.91 | step_microstep: 42.14
[default0]:[2023-08-25 18:07:03,608] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.13 (forward_moe: 20.13, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.96)
[default0]:[2023-08-25 18:07:03,608] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.80 | backward_inner: 99.80 | backward_allreduce: 10.91 | step: 42.14
[default0]:[2023-08-25 18:07:03,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.96 | optimizer_step: 6.32
[default0]:[2023-08-25 18:07:03,863] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.30 | backward_microstep: 110.74 | backward_inner_microstep: 99.76 | backward_allreduce_microstep: 10.88 | step_microstep: 41.93
[default0]:[2023-08-25 18:07:03,863] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.30 (forward_moe: 20.19, 1st alltoall: 0.86, 2nd alltoall: 0.90, top-k: 7.93)
[default0]:[2023-08-25 18:07:03,863] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.73 | backward_inner: 99.77 | backward_allreduce: 10.88 | step: 41.94
[default0]:[2023-08-25 18:07:04,203] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.94 | optimizer_step: 6.39
[default0]:[2023-08-25 18:07:04,203] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.20 | backward_microstep: 110.87 | backward_inner_microstep: 99.86 | backward_allreduce_microstep: 10.92 | step_microstep: 42.07
[default0]:[2023-08-25 18:07:04,203] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.20 (forward_moe: 20.12, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.94)
[default0]:[2023-08-25 18:07:04,204] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.87 | backward_inner: 99.86 | backward_allreduce: 10.93 | step: 42.07
[default0]:[2023-08-25 18:07:04,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:04,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.40 | backward_microstep: 110.72 | backward_inner_microstep: 99.75 | backward_allreduce_microstep: 10.87 | step_microstep: 42.93
[default0]:[2023-08-25 18:07:04,668] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.40 (forward_moe: 20.13, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.98)
[default0]:[2023-08-25 18:07:04,668] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.72 | backward_inner: 99.76 | backward_allreduce: 10.88 | step: 42.93
[default0]:[2023-08-25 18:07:04,931] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:07:04,931] [INFO] [logging.py:96:log_dist] [Rank 0] step=245, skipped=0, lr=[2.665130666666667e-07, 2.665130666666667e-07, 2.665130666666667e-07, 2.665130666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:04,931] [INFO] [timer.py:215:stop] epoch=0/micro_step=245/global_step=245, RunningAvgSamplesPerSec=4.892597783802927, CurrSamplesPerSec=4.893753507577534, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:04,931] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.07 | backward_microstep: 113.44 | backward_inner_microstep: 102.28 | backward_allreduce_microstep: 11.07 | step_microstep: 43.33
[default0]:[2023-08-25 18:07:04,932] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.07 (forward_moe: 20.78, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.27)
[default0]:[2023-08-25 18:07:04,932] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.44 | backward_inner: 102.28 | backward_allreduce: 11.07 | step: 43.33
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([52.0050], device='cuda:0'), 'moe loss': tensor([0.3119], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      245/439453125 | consumed samples:          245 | consumed tokens:       501760 | elapsed time per iteration (ms): 315.6 | learning rate: 2.665E-07 | global batch size:     1 | lm loss: 1.040099E+01 | moe loss: 6.237305E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.169 | TFLOPs: 7.87 |
[default0]:[2023-08-25 18:07:05,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.41
[default0]:[2023-08-25 18:07:05,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.72 | backward_microstep: 113.98 | backward_inner_microstep: 102.77 | backward_allreduce_microstep: 11.12 | step_microstep: 43.19
[default0]:[2023-08-25 18:07:05,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.71 (forward_moe: 20.79, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.36)
[default0]:[2023-08-25 18:07:05,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.98 | backward_inner: 102.77 | backward_allreduce: 11.12 | step: 43.19
[default0]:[2023-08-25 18:07:05,441] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.17 | optimizer_step: 6.42
[default0]:[2023-08-25 18:07:05,442] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.12 | backward_microstep: 114.46 | backward_inner_microstep: 103.20 | backward_allreduce_microstep: 11.17 | step_microstep: 43.35
[default0]:[2023-08-25 18:07:05,442] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.12 (forward_moe: 20.87, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.42)
[default0]:[2023-08-25 18:07:05,442] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.46 | backward_inner: 103.20 | backward_allreduce: 11.17 | step: 43.35
[default0]:[2023-08-25 18:07:05,680] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:07:05,681] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.93 | backward_microstep: 110.42 | backward_inner_microstep: 99.49 | backward_allreduce_microstep: 10.84 | step_microstep: 42.29
[default0]:[2023-08-25 18:07:05,681] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.93 (forward_moe: 19.98, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.85)
[default0]:[2023-08-25 18:07:05,681] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.42 | backward_inner: 99.49 | backward_allreduce: 10.84 | step: 42.29
[default0]:[2023-08-25 18:07:05,934] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:07:05,934] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.28 | backward_microstep: 110.05 | backward_inner_microstep: 99.08 | backward_allreduce_microstep: 10.87 | step_microstep: 41.85
[default0]:[2023-08-25 18:07:05,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.28 (forward_moe: 19.96, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.85)
[default0]:[2023-08-25 18:07:05,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.05 | backward_inner: 99.09 | backward_allreduce: 10.87 | step: 41.85
[default0]:[2023-08-25 18:07:06,208] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.33
[default0]:[2023-08-25 18:07:06,208] [INFO] [logging.py:96:log_dist] [Rank 0] step=250, skipped=0, lr=[2.7197440000000005e-07, 2.7197440000000005e-07, 2.7197440000000005e-07, 2.7197440000000005e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:06,209] [INFO] [timer.py:215:stop] epoch=0/micro_step=250/global_step=250, RunningAvgSamplesPerSec=4.893531524420914, CurrSamplesPerSec=4.965136472167538, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:06,209] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.71 | backward_microstep: 110.05 | backward_inner_microstep: 99.16 | backward_allreduce_microstep: 10.80 | step_microstep: 42.09
[default0]:[2023-08-25 18:07:06,209] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.70 (forward_moe: 20.09, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:07:06,209] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.05 | backward_inner: 99.16 | backward_allreduce: 10.81 | step: 42.10
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.9805], device='cuda:0'), 'moe loss': tensor([0.3133], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      250/439453125 | consumed samples:          250 | consumed tokens:       512000 | elapsed time per iteration (ms): 255.9 | learning rate: 2.720E-07 | global batch size:     1 | lm loss: 1.039610E+01 | moe loss: 6.265017E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.908 | TFLOPs: 9.71 |
[default0]:[2023-08-25 18:07:06,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:07:06,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.83 | backward_microstep: 110.11 | backward_inner_microstep: 99.19 | backward_allreduce_microstep: 10.83 | step_microstep: 42.00
[default0]:[2023-08-25 18:07:06,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.83 (forward_moe: 19.99, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.86)
[default0]:[2023-08-25 18:07:06,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.11 | backward_inner: 99.19 | backward_allreduce: 10.83 | step: 42.00
[default0]:[2023-08-25 18:07:06,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:06,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.46 | backward_microstep: 110.18 | backward_inner_microstep: 99.25 | backward_allreduce_microstep: 10.83 | step_microstep: 41.71
[default0]:[2023-08-25 18:07:06,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.46 (forward_moe: 20.01, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.91)
[default0]:[2023-08-25 18:07:06,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.18 | backward_inner: 99.26 | backward_allreduce: 10.84 | step: 41.71
[default0]:[2023-08-25 18:07:06,980] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:06,980] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.39 | backward_microstep: 110.00 | backward_inner_microstep: 99.10 | backward_allreduce_microstep: 10.80 | step_microstep: 41.83
[default0]:[2023-08-25 18:07:06,980] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.39 (forward_moe: 19.97, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:07:06,980] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.00 | backward_inner: 99.11 | backward_allreduce: 10.80 | step: 41.83
[default0]:[2023-08-25 18:07:07,535] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.18 | optimizer_step: 6.53
[default0]:[2023-08-25 18:07:07,536] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.93 | backward_microstep: 117.37 | backward_inner_microstep: 105.97 | backward_allreduce_microstep: 11.30 | step_microstep: 44.52
[default0]:[2023-08-25 18:07:07,536] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.93 (forward_moe: 21.47, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.76)
[default0]:[2023-08-25 18:07:07,536] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.36 | backward_inner: 105.97 | backward_allreduce: 11.31 | step: 44.52
[default0]:[2023-08-25 18:07:07,792] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.18 | optimizer_step: 6.52
[default0]:[2023-08-25 18:07:07,792] [INFO] [logging.py:96:log_dist] [Rank 0] step=255, skipped=0, lr=[2.7743573333333336e-07, 2.7743573333333336e-07, 2.7743573333333336e-07, 2.7743573333333336e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:07,792] [INFO] [timer.py:215:stop] epoch=0/micro_step=255/global_step=255, RunningAvgSamplesPerSec=4.893487664440429, CurrSamplesPerSec=4.703073034753572, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:07,793] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.33 | backward_microstep: 117.76 | backward_inner_microstep: 106.34 | backward_allreduce_microstep: 11.32 | step_microstep: 45.01
[default0]:[2023-08-25 18:07:07,793] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.33 (forward_moe: 21.59, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.84)
[default0]:[2023-08-25 18:07:07,793] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.76 | backward_inner: 106.35 | backward_allreduce: 11.32 | step: 45.01
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.7805], device='cuda:0'), 'moe loss': tensor([0.3121], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      255/439453125 | consumed samples:          255 | consumed tokens:       522240 | elapsed time per iteration (ms): 316.3 | learning rate: 2.774E-07 | global batch size:     1 | lm loss: 1.035609E+01 | moe loss: 6.242920E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.161 | TFLOPs: 7.85 |
[default0]:[2023-08-25 18:07:08,137] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.18 | optimizer_step: 6.55
[default0]:[2023-08-25 18:07:08,138] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.36 | backward_microstep: 117.74 | backward_inner_microstep: 106.34 | backward_allreduce_microstep: 11.30 | step_microstep: 44.49
[default0]:[2023-08-25 18:07:08,138] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.36 (forward_moe: 21.66, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.85)
[default0]:[2023-08-25 18:07:08,138] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.73 | backward_inner: 106.35 | backward_allreduce: 11.30 | step: 44.50
[default0]:[2023-08-25 18:07:08,467] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.17 | optimizer_step: 6.44
[default0]:[2023-08-25 18:07:08,467] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.67 | backward_microstep: 117.66 | backward_inner_microstep: 106.32 | backward_allreduce_microstep: 11.24 | step_microstep: 44.42
[default0]:[2023-08-25 18:07:08,467] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.66 (forward_moe: 21.63, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.91)
[default0]:[2023-08-25 18:07:08,467] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.65 | backward_inner: 106.33 | backward_allreduce: 11.24 | step: 44.42
[default0]:[2023-08-25 18:07:08,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:07:08,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.11 | backward_microstep: 112.66 | backward_inner_microstep: 101.64 | backward_allreduce_microstep: 10.93 | step_microstep: 42.68
[default0]:[2023-08-25 18:07:08,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.11 (forward_moe: 20.62, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.31)
[default0]:[2023-08-25 18:07:08,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.66 | backward_inner: 101.65 | backward_allreduce: 10.93 | step: 42.68
[default0]:[2023-08-25 18:07:08,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:08,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.07 | backward_microstep: 112.63 | backward_inner_microstep: 101.56 | backward_allreduce_microstep: 10.98 | step_microstep: 42.76
[default0]:[2023-08-25 18:07:08,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.07 (forward_moe: 20.56, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.21)
[default0]:[2023-08-25 18:07:08,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.63 | backward_inner: 101.57 | backward_allreduce: 10.98 | step: 42.76
[default0]:[2023-08-25 18:07:09,256] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:07:09,256] [INFO] [logging.py:96:log_dist] [Rank 0] step=260, skipped=0, lr=[2.828970666666667e-07, 2.828970666666667e-07, 2.828970666666667e-07, 2.828970666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:09,256] [INFO] [timer.py:215:stop] epoch=0/micro_step=260/global_step=260, RunningAvgSamplesPerSec=4.8922063192037735, CurrSamplesPerSec=4.901187581286159, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:09,257] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.35 | backward_microstep: 112.90 | backward_inner_microstep: 101.78 | backward_allreduce_microstep: 11.03 | step_microstep: 43.24
[default0]:[2023-08-25 18:07:09,257] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.35 (forward_moe: 20.68, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:07:09,257] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.90 | backward_inner: 101.78 | backward_allreduce: 11.03 | step: 43.24
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.5908], device='cuda:0'), 'moe loss': tensor([0.3122], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      260/439453125 | consumed samples:          260 | consumed tokens:       532480 | elapsed time per iteration (ms): 292.9 | learning rate: 2.829E-07 | global batch size:     1 | lm loss: 1.031816E+01 | moe loss: 6.244240E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.414 | TFLOPs: 8.48 |
[default0]:[2023-08-25 18:07:09,507] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:09,508] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.91 | backward_microstep: 110.00 | backward_inner_microstep: 99.04 | backward_allreduce_microstep: 10.87 | step_microstep: 42.02
[default0]:[2023-08-25 18:07:09,508] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.91 (forward_moe: 20.09, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:07:09,508] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.00 | backward_inner: 99.04 | backward_allreduce: 10.87 | step: 42.02
[default0]:[2023-08-25 18:07:09,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.33
[default0]:[2023-08-25 18:07:09,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.93 | backward_microstep: 110.14 | backward_inner_microstep: 99.21 | backward_allreduce_microstep: 10.84 | step_microstep: 41.87
[default0]:[2023-08-25 18:07:09,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.93 (forward_moe: 20.05, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:07:09,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.14 | backward_inner: 99.21 | backward_allreduce: 10.85 | step: 41.88
[default0]:[2023-08-25 18:07:09,980] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:07:09,980] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.10 | backward_microstep: 110.05 | backward_inner_microstep: 99.15 | backward_allreduce_microstep: 10.80 | step_microstep: 41.91
[default0]:[2023-08-25 18:07:09,980] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.10 (forward_moe: 20.09, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.01)
[default0]:[2023-08-25 18:07:09,981] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.05 | backward_inner: 99.16 | backward_allreduce: 10.80 | step: 41.92
[default0]:[2023-08-25 18:07:10,224] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:10,224] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.88 | backward_microstep: 110.08 | backward_inner_microstep: 99.08 | backward_allreduce_microstep: 10.91 | step_microstep: 41.87
[default0]:[2023-08-25 18:07:10,224] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.88 (forward_moe: 20.04, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.94)
[default0]:[2023-08-25 18:07:10,224] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.08 | backward_inner: 99.08 | backward_allreduce: 10.91 | step: 41.87
[default0]:[2023-08-25 18:07:10,491] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:07:10,492] [INFO] [logging.py:96:log_dist] [Rank 0] step=265, skipped=0, lr=[2.883584e-07, 2.883584e-07, 2.883584e-07, 2.883584e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:10,492] [INFO] [timer.py:215:stop] epoch=0/micro_step=265/global_step=265, RunningAvgSamplesPerSec=4.894728087664314, CurrSamplesPerSec=5.0173501124455715, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:10,492] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.22 | backward_microstep: 110.19 | backward_inner_microstep: 99.20 | backward_allreduce_microstep: 10.89 | step_microstep: 42.40
[default0]:[2023-08-25 18:07:10,492] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.22 (forward_moe: 19.97, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:07:10,493] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.18 | backward_inner: 99.20 | backward_allreduce: 10.90 | step: 42.40
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.7010], device='cuda:0'), 'moe loss': tensor([0.3126], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      265/439453125 | consumed samples:          265 | consumed tokens:       542720 | elapsed time per iteration (ms): 247.5 | learning rate: 2.884E-07 | global batch size:     1 | lm loss: 1.034019E+01 | moe loss: 6.252842E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.040 | TFLOPs: 10.04 |
[default0]:[2023-08-25 18:07:10,755] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:07:10,756] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.90 | backward_microstep: 110.07 | backward_inner_microstep: 99.16 | backward_allreduce_microstep: 10.82 | step_microstep: 41.81
[default0]:[2023-08-25 18:07:10,756] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.90 (forward_moe: 20.06, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.86)
[default0]:[2023-08-25 18:07:10,756] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.07 | backward_inner: 99.16 | backward_allreduce: 10.82 | step: 41.81
[default0]:[2023-08-25 18:07:11,027] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:07:11,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.09 | backward_microstep: 110.03 | backward_inner_microstep: 99.14 | backward_allreduce_microstep: 10.79 | step_microstep: 42.43
[default0]:[2023-08-25 18:07:11,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.08 (forward_moe: 19.94, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:07:11,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.03 | backward_inner: 99.15 | backward_allreduce: 10.79 | step: 42.43
[default0]:[2023-08-25 18:07:11,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 4.05 | optimizer_step: 6.38
[default0]:[2023-08-25 18:07:11,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.35 | backward_microstep: 114.47 | backward_inner_microstep: 103.05 | backward_allreduce_microstep: 11.32 | step_microstep: 43.13
[default0]:[2023-08-25 18:07:11,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.36 (forward_moe: 20.89, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.48)
[default0]:[2023-08-25 18:07:11,289] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.47 | backward_inner: 103.06 | backward_allreduce: 11.32 | step: 43.13
[default0]:[2023-08-25 18:07:11,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:07:11,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 112.63 | backward_inner_microstep: 101.51 | backward_allreduce_microstep: 11.03 | step_microstep: 42.81
[default0]:[2023-08-25 18:07:11,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.02 (forward_moe: 20.49, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.18)
[default0]:[2023-08-25 18:07:11,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.63 | backward_inner: 101.51 | backward_allreduce: 11.03 | step: 42.81
[default0]:[2023-08-25 18:07:11,817] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:11,817] [INFO] [logging.py:96:log_dist] [Rank 0] step=270, skipped=0, lr=[2.9381973333333336e-07, 2.9381973333333336e-07, 2.9381973333333336e-07, 2.9381973333333336e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:11,818] [INFO] [timer.py:215:stop] epoch=0/micro_step=270/global_step=270, RunningAvgSamplesPerSec=4.895554006482073, CurrSamplesPerSec=4.871252171812429, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:11,818] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.25 | backward_microstep: 112.89 | backward_inner_microstep: 101.83 | backward_allreduce_microstep: 10.96 | step_microstep: 44.58
[default0]:[2023-08-25 18:07:11,818] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.25 (forward_moe: 20.82, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.22)
[default0]:[2023-08-25 18:07:11,818] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.89 | backward_inner: 101.84 | backward_allreduce: 10.97 | step: 44.59
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.5885], device='cuda:0'), 'moe loss': tensor([0.3115], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      270/439453125 | consumed samples:          270 | consumed tokens:       552960 | elapsed time per iteration (ms): 264.9 | learning rate: 2.938E-07 | global batch size:     1 | lm loss: 1.031769E+01 | moe loss: 6.229836E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.776 | TFLOPs: 9.38 |
[default0]:[2023-08-25 18:07:12,141] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:07:12,142] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.10 | backward_microstep: 112.68 | backward_inner_microstep: 101.57 | backward_allreduce_microstep: 11.01 | step_microstep: 42.83
[default0]:[2023-08-25 18:07:12,142] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.10 (forward_moe: 20.54, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.22)
[default0]:[2023-08-25 18:07:12,142] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.68 | backward_inner: 101.58 | backward_allreduce: 11.01 | step: 42.83
[default0]:[2023-08-25 18:07:12,451] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.36
[default0]:[2023-08-25 18:07:12,452] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.12 | backward_microstep: 112.69 | backward_inner_microstep: 101.58 | backward_allreduce_microstep: 11.02 | step_microstep: 42.67
[default0]:[2023-08-25 18:07:12,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.11 (forward_moe: 20.58, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.23)
[default0]:[2023-08-25 18:07:12,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.69 | backward_inner: 101.58 | backward_allreduce: 11.02 | step: 42.68
[default0]:[2023-08-25 18:07:12,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:07:12,721] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.81 | backward_microstep: 114.19 | backward_inner_microstep: 103.11 | backward_allreduce_microstep: 10.99 | step_microstep: 42.84
[default0]:[2023-08-25 18:07:12,721] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.81 (forward_moe: 20.53, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.20)
[default0]:[2023-08-25 18:07:12,721] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.19 | backward_inner: 103.11 | backward_allreduce: 11.00 | step: 42.84
[default0]:[2023-08-25 18:07:13,007] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 9.96
[default0]:[2023-08-25 18:07:13,008] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.23 | backward_microstep: 112.80 | backward_inner_microstep: 101.67 | backward_allreduce_microstep: 11.04 | step_microstep: 46.84
[default0]:[2023-08-25 18:07:13,008] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.23 (forward_moe: 20.59, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:07:13,008] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.80 | backward_inner: 101.67 | backward_allreduce: 11.04 | step: 46.84
[default0]:[2023-08-25 18:07:13,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.08 | optimizer_step: 6.44
[default0]:[2023-08-25 18:07:13,273] [INFO] [logging.py:96:log_dist] [Rank 0] step=275, skipped=0, lr=[2.9928106666666667e-07, 2.9928106666666667e-07, 2.9928106666666667e-07, 2.9928106666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:13,273] [INFO] [timer.py:215:stop] epoch=0/micro_step=275/global_step=275, RunningAvgSamplesPerSec=4.894794970545713, CurrSamplesPerSec=4.792241564483769, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:13,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.04 | backward_microstep: 116.13 | backward_inner_microstep: 104.87 | backward_allreduce_microstep: 11.17 | step_microstep: 43.96
[default0]:[2023-08-25 18:07:13,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.03 (forward_moe: 21.43, 1st alltoall: 0.89, 2nd alltoall: 0.85, top-k: 8.52)
[default0]:[2023-08-25 18:07:13,274] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.13 | backward_inner: 104.87 | backward_allreduce: 11.17 | step: 43.96
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.5931], device='cuda:0'), 'moe loss': tensor([0.3110], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      275/439453125 | consumed samples:          275 | consumed tokens:       563200 | elapsed time per iteration (ms): 290.9 | learning rate: 2.993E-07 | global batch size:     1 | lm loss: 1.031862E+01 | moe loss: 6.219363E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.438 | TFLOPs: 8.54 |
[default0]:[2023-08-25 18:07:13,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:13,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.79 | backward_microstep: 112.51 | backward_inner_microstep: 101.46 | backward_allreduce_microstep: 10.95 | step_microstep: 42.62
[default0]:[2023-08-25 18:07:13,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.45, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.17)
[default0]:[2023-08-25 18:07:13,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.51 | backward_inner: 101.47 | backward_allreduce: 10.96 | step: 42.63
[default0]:[2023-08-25 18:07:13,777] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:07:13,777] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 112.29 | backward_inner_microstep: 101.19 | backward_allreduce_microstep: 11.01 | step_microstep: 42.57
[default0]:[2023-08-25 18:07:13,777] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.01 (forward_moe: 20.41, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:07:13,778] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.28 | backward_inner: 101.19 | backward_allreduce: 11.01 | step: 42.57
[default0]:[2023-08-25 18:07:14,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:07:14,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.77 | backward_microstep: 112.27 | backward_inner_microstep: 101.22 | backward_allreduce_microstep: 10.96 | step_microstep: 42.42
[default0]:[2023-08-25 18:07:14,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.77 (forward_moe: 20.46, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.16)
[default0]:[2023-08-25 18:07:14,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.27 | backward_inner: 101.22 | backward_allreduce: 10.97 | step: 42.42
[default0]:[2023-08-25 18:07:14,279] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:07:14,279] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.98 | backward_microstep: 112.05 | backward_inner_microstep: 101.04 | backward_allreduce_microstep: 10.92 | step_microstep: 42.56
[default0]:[2023-08-25 18:07:14,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.98 (forward_moe: 20.44, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:07:14,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.05 | backward_inner: 101.04 | backward_allreduce: 10.92 | step: 42.56
[default0]:[2023-08-25 18:07:14,542] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.33
[default0]:[2023-08-25 18:07:14,542] [INFO] [logging.py:96:log_dist] [Rank 0] step=280, skipped=0, lr=[3.0474240000000004e-07, 3.0474240000000004e-07, 3.0474240000000004e-07, 3.0474240000000004e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:14,543] [INFO] [timer.py:215:stop] epoch=0/micro_step=280/global_step=280, RunningAvgSamplesPerSec=4.8959499281244, CurrSamplesPerSec=5.051333436102976, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:14,543] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 109.65 | backward_inner_microstep: 98.73 | backward_allreduce_microstep: 10.82 | step_microstep: 42.06
[default0]:[2023-08-25 18:07:14,543] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.98, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:07:14,543] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.65 | backward_inner: 98.74 | backward_allreduce: 10.83 | step: 42.06
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.3669], device='cuda:0'), 'moe loss': tensor([0.3097], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      280/439453125 | consumed samples:          280 | consumed tokens:       573440 | elapsed time per iteration (ms): 254.1 | learning rate: 3.047E-07 | global batch size:     1 | lm loss: 1.027338E+01 | moe loss: 6.194104E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.936 | TFLOPs: 9.78 |
[default0]:[2023-08-25 18:07:14,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:14,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.95 | backward_microstep: 109.65 | backward_inner_microstep: 98.73 | backward_allreduce_microstep: 10.83 | step_microstep: 41.68
[default0]:[2023-08-25 18:07:14,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.95 (forward_moe: 19.99, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.92)
[default0]:[2023-08-25 18:07:14,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.65 | backward_inner: 98.73 | backward_allreduce: 10.83 | step: 41.68
[default0]:[2023-08-25 18:07:15,026] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:07:15,026] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.72 | backward_microstep: 109.52 | backward_inner_microstep: 98.65 | backward_allreduce_microstep: 10.78 | step_microstep: 41.59
[default0]:[2023-08-25 18:07:15,026] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.73 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.80)
[default0]:[2023-08-25 18:07:15,026] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.52 | backward_inner: 98.66 | backward_allreduce: 10.78 | step: 41.59
[default0]:[2023-08-25 18:07:15,302] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.90 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:15,302] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.94 | backward_microstep: 109.45 | backward_inner_microstep: 98.49 | backward_allreduce_microstep: 10.86 | step_microstep: 42.00
[default0]:[2023-08-25 18:07:15,303] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.93 (forward_moe: 19.93, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.80)
[default0]:[2023-08-25 18:07:15,303] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.45 | backward_inner: 98.50 | backward_allreduce: 10.87 | step: 42.01
[default0]:[2023-08-25 18:07:15,551] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:07:15,551] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.80 | backward_microstep: 109.67 | backward_inner_microstep: 98.75 | backward_allreduce_microstep: 10.82 | step_microstep: 41.67
[default0]:[2023-08-25 18:07:15,551] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.80 (forward_moe: 20.03, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:07:15,552] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.67 | backward_inner: 98.75 | backward_allreduce: 10.83 | step: 41.67
[default0]:[2023-08-25 18:07:15,802] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:07:15,802] [INFO] [logging.py:96:log_dist] [Rank 0] step=285, skipped=0, lr=[3.1020373333333335e-07, 3.1020373333333335e-07, 3.1020373333333335e-07, 3.1020373333333335e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:15,803] [INFO] [timer.py:215:stop] epoch=0/micro_step=285/global_step=285, RunningAvgSamplesPerSec=4.898573303171574, CurrSamplesPerSec=5.040176693816438, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:15,803] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.95 | backward_microstep: 109.72 | backward_inner_microstep: 98.78 | backward_allreduce_microstep: 10.85 | step_microstep: 42.18
[default0]:[2023-08-25 18:07:15,803] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.95 (forward_moe: 19.85, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:07:15,803] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.71 | backward_inner: 98.78 | backward_allreduce: 10.85 | step: 42.19
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.4509], device='cuda:0'), 'moe loss': tensor([0.3101], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      285/439453125 | consumed samples:          285 | consumed tokens:       583680 | elapsed time per iteration (ms): 251.9 | learning rate: 3.102E-07 | global batch size:     1 | lm loss: 1.029018E+01 | moe loss: 6.202167E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.970 | TFLOPs: 9.86 |
[default0]:[2023-08-25 18:07:16,047] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:16,047] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.74 | backward_microstep: 109.53 | backward_inner_microstep: 98.64 | backward_allreduce_microstep: 10.79 | step_microstep: 41.86
[default0]:[2023-08-25 18:07:16,047] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.73 (forward_moe: 19.90, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.86)
[default0]:[2023-08-25 18:07:16,047] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.53 | backward_inner: 98.65 | backward_allreduce: 10.80 | step: 41.86
[default0]:[2023-08-25 18:07:16,323] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 4.05 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:16,324] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.43 | backward_microstep: 111.67 | backward_inner_microstep: 100.62 | backward_allreduce_microstep: 10.95 | step_microstep: 42.94
[default0]:[2023-08-25 18:07:16,324] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.43 (forward_moe: 20.25, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.03)
[default0]:[2023-08-25 18:07:16,324] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.66 | backward_inner: 100.63 | backward_allreduce: 10.95 | step: 42.94
[default0]:[2023-08-25 18:07:16,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:07:16,571] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.66 | backward_microstep: 111.90 | backward_inner_microstep: 100.84 | backward_allreduce_microstep: 10.97 | step_microstep: 42.64
[default0]:[2023-08-25 18:07:16,571] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.66 (forward_moe: 20.36, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:07:16,571] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.90 | backward_inner: 100.84 | backward_allreduce: 10.97 | step: 42.64
[default0]:[2023-08-25 18:07:16,847] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.36
[default0]:[2023-08-25 18:07:16,847] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.14 | backward_microstep: 112.56 | backward_inner_microstep: 101.43 | backward_allreduce_microstep: 11.04 | step_microstep: 43.95
[default0]:[2023-08-25 18:07:16,847] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.14 (forward_moe: 20.52, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:07:16,847] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.56 | backward_inner: 101.43 | backward_allreduce: 11.04 | step: 43.95
[default0]:[2023-08-25 18:07:17,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.15 | optimizer_step: 6.51
[default0]:[2023-08-25 18:07:17,351] [INFO] [logging.py:96:log_dist] [Rank 0] step=290, skipped=0, lr=[3.1566506666666667e-07, 3.1566506666666667e-07, 3.1566506666666667e-07, 3.1566506666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:17,351] [INFO] [timer.py:215:stop] epoch=0/micro_step=290/global_step=290, RunningAvgSamplesPerSec=4.898528082115446, CurrSamplesPerSec=4.73982999324222, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:17,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.76 | backward_microstep: 116.97 | backward_inner_microstep: 105.53 | backward_allreduce_microstep: 11.34 | step_microstep: 44.69
[default0]:[2023-08-25 18:07:17,352] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.76 (forward_moe: 21.60, 1st alltoall: 0.90, 2nd alltoall: 0.85, top-k: 8.81)
[default0]:[2023-08-25 18:07:17,352] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.97 | backward_inner: 105.54 | backward_allreduce: 11.35 | step: 44.69
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.4202], device='cuda:0'), 'moe loss': tensor([0.3091], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      290/439453125 | consumed samples:          290 | consumed tokens:       593920 | elapsed time per iteration (ms): 309.9 | learning rate: 3.157E-07 | global batch size:     1 | lm loss: 1.028404E+01 | moe loss: 6.181450E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.227 | TFLOPs: 8.02 |
[default0]:[2023-08-25 18:07:17,643] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 6.51
[default0]:[2023-08-25 18:07:17,643] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.26 | backward_microstep: 117.67 | backward_inner_microstep: 106.31 | backward_allreduce_microstep: 11.27 | step_microstep: 44.62
[default0]:[2023-08-25 18:07:17,643] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.26 (forward_moe: 21.57, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.84)
[default0]:[2023-08-25 18:07:17,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.67 | backward_inner: 106.32 | backward_allreduce: 11.27 | step: 44.62
[default0]:[2023-08-25 18:07:17,930] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.47
[default0]:[2023-08-25 18:07:17,930] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 51.26 | backward_microstep: 120.36 | backward_inner_microstep: 108.90 | backward_allreduce_microstep: 11.36 | step_microstep: 44.21
[default0]:[2023-08-25 18:07:17,930] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 51.26 (forward_moe: 22.18, 1st alltoall: 0.95, 2nd alltoall: 0.87, top-k: 8.99)
[default0]:[2023-08-25 18:07:17,931] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 120.35 | backward_inner: 108.91 | backward_allreduce: 11.36 | step: 44.21
[default0]:[2023-08-25 18:07:18,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.45
[default0]:[2023-08-25 18:07:18,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.22 | backward_microstep: 115.34 | backward_inner_microstep: 104.12 | backward_allreduce_microstep: 11.12 | step_microstep: 43.74
[default0]:[2023-08-25 18:07:18,184] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.22 (forward_moe: 21.12, 1st alltoall: 0.90, 2nd alltoall: 0.85, top-k: 8.55)
[default0]:[2023-08-25 18:07:18,184] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.34 | backward_inner: 104.13 | backward_allreduce: 11.12 | step: 43.75
[default0]:[2023-08-25 18:07:18,459] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.10 | optimizer_step: 6.44
[default0]:[2023-08-25 18:07:18,459] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.61 | backward_microstep: 115.99 | backward_inner_microstep: 104.70 | backward_allreduce_microstep: 11.20 | step_microstep: 43.72
[default0]:[2023-08-25 18:07:18,459] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.61 (forward_moe: 21.55, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.57)
[default0]:[2023-08-25 18:07:18,460] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.99 | backward_inner: 104.70 | backward_allreduce: 11.20 | step: 43.73
[default0]:[2023-08-25 18:07:18,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.43
[default0]:[2023-08-25 18:07:18,735] [INFO] [logging.py:96:log_dist] [Rank 0] step=295, skipped=0, lr=[3.2112640000000003e-07, 3.2112640000000003e-07, 3.2112640000000003e-07, 3.2112640000000003e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:18,735] [INFO] [timer.py:215:stop] epoch=0/micro_step=295/global_step=295, RunningAvgSamplesPerSec=4.8957217787797775, CurrSamplesPerSec=4.796993461510749, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:18,735] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.28 | backward_microstep: 115.52 | backward_inner_microstep: 104.29 | backward_allreduce_microstep: 11.13 | step_microstep: 44.13
[default0]:[2023-08-25 18:07:18,735] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.27 (forward_moe: 21.14, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.56)
[default0]:[2023-08-25 18:07:18,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.51 | backward_inner: 104.29 | backward_allreduce: 11.14 | step: 44.13
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.5272], device='cuda:0'), 'moe loss': tensor([0.3090], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      295/439453125 | consumed samples:          295 | consumed tokens:       604160 | elapsed time per iteration (ms): 276.6 | learning rate: 3.211E-07 | global batch size:     1 | lm loss: 1.030545E+01 | moe loss: 6.179039E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.616 | TFLOPs: 8.98 |
[default0]:[2023-08-25 18:07:18,995] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.41
[default0]:[2023-08-25 18:07:18,995] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.79 | backward_microstep: 114.37 | backward_inner_microstep: 103.19 | backward_allreduce_microstep: 11.09 | step_microstep: 43.50
[default0]:[2023-08-25 18:07:18,995] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.79 (forward_moe: 20.91, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.44)
[default0]:[2023-08-25 18:07:18,996] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.37 | backward_inner: 103.19 | backward_allreduce: 11.09 | step: 43.51
[default0]:[2023-08-25 18:07:19,263] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.43
[default0]:[2023-08-25 18:07:19,264] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.01 | backward_microstep: 114.38 | backward_inner_microstep: 103.19 | backward_allreduce_microstep: 11.10 | step_microstep: 43.17
[default0]:[2023-08-25 18:07:19,264] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.01 (forward_moe: 20.99, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.42)
[default0]:[2023-08-25 18:07:19,264] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.38 | backward_inner: 103.19 | backward_allreduce: 11.11 | step: 43.18
[default0]:[2023-08-25 18:07:19,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.41
[default0]:[2023-08-25 18:07:19,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.21 | backward_microstep: 114.51 | backward_inner_microstep: 103.29 | backward_allreduce_microstep: 11.12 | step_microstep: 43.55
[default0]:[2023-08-25 18:07:19,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.21 (forward_moe: 20.90, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.43)
[default0]:[2023-08-25 18:07:19,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.51 | backward_inner: 103.30 | backward_allreduce: 11.13 | step: 43.55
[default0]:[2023-08-25 18:07:19,761] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.02 | optimizer_step: 6.36
[default0]:[2023-08-25 18:07:19,762] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.19 | backward_microstep: 109.93 | backward_inner_microstep: 98.97 | backward_allreduce_microstep: 10.86 | step_microstep: 43.12
[default0]:[2023-08-25 18:07:19,762] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.19 (forward_moe: 19.97, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.87)
[default0]:[2023-08-25 18:07:19,762] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.92 | backward_inner: 98.98 | backward_allreduce: 10.86 | step: 43.12
[default0]:[2023-08-25 18:07:20,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.33
[default0]:[2023-08-25 18:07:20,005] [INFO] [logging.py:96:log_dist] [Rank 0] step=300, skipped=0, lr=[3.2658773333333335e-07, 3.2658773333333335e-07, 3.2658773333333335e-07, 3.2658773333333335e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:20,006] [INFO] [timer.py:215:stop] epoch=0/micro_step=300/global_step=300, RunningAvgSamplesPerSec=4.895895540615365, CurrSamplesPerSec=5.023347170290385, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:20,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.34 | backward_microstep: 110.08 | backward_inner_microstep: 99.15 | backward_allreduce_microstep: 10.84 | step_microstep: 42.24
[default0]:[2023-08-25 18:07:20,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.34 (forward_moe: 20.12, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.87)
[default0]:[2023-08-25 18:07:20,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.08 | backward_inner: 99.15 | backward_allreduce: 10.84 | step: 42.24
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.5674], device='cuda:0'), 'moe loss': tensor([0.3083], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      300/439453125 | consumed samples:          300 | consumed tokens:       614400 | elapsed time per iteration (ms): 254.0 | learning rate: 3.266E-07 | global batch size:     1 | lm loss: 1.031348E+01 | moe loss: 6.165203E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.937 | TFLOPs: 9.78 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 300 | lm loss value: 1.025275E+01 | lm loss PPL: 2.836044E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration     300 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:07:24,212] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step300 is about to be saved!
[default0]:[2023-08-25 18:07:24,214] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,224] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,224] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,233] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,233] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,242] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,242] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,253] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,254] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,263] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,263] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,272] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,272] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,281] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,281] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,290] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,291] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,304] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,304] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,313] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,313] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,322] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,322] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,331] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,332] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,340] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,340] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,349] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,349] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,358] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,358] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,367] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,368] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,377] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,377] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,386] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,386] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,395] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,395] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,405] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,405] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,414] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,414] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,424] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,424] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,433] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,433] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,442] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,442] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:07:24,443] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:07:24,445] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:07:24,445] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:24,722] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:24,723] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:07:28,406] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:07:28,416] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step300/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:07:28,416] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step300 is ready now!
[default0]:  successfully saved checkpoint at iteration     300 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.7, Latency(second): 4.208
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4208.43, 4208.43)
[default0]:[2023-08-25 18:07:28,674] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.16 | optimizer_step: 10.03
[default0]:[2023-08-25 18:07:28,676] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2311.06 | backward_microstep: 117.24 | backward_inner_microstep: 106.00 | backward_allreduce_microstep: 11.14 | step_microstep: 47.80
[default0]:[2023-08-25 18:07:28,677] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2310.95 (forward_moe: 21.45, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.74)
[default0]:[2023-08-25 18:07:28,677] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.24 | backward_inner: 106.01 | backward_allreduce: 11.14 | step: 47.80
[default0]:[2023-08-25 18:07:28,937] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.15 | optimizer_step: 6.51
[default0]:[2023-08-25 18:07:28,938] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.00 | backward_microstep: 116.45 | backward_inner_microstep: 105.35 | backward_allreduce_microstep: 11.00 | step_microstep: 43.71
[default0]:[2023-08-25 18:07:28,938] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.99 (forward_moe: 21.44, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.82)
[default0]:[2023-08-25 18:07:28,938] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.45 | backward_inner: 105.36 | backward_allreduce: 11.01 | step: 43.71
[default0]:[2023-08-25 18:07:29,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.12 | optimizer_step: 6.49
[default0]:[2023-08-25 18:07:29,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.01 | backward_microstep: 116.09 | backward_inner_microstep: 105.01 | backward_allreduce_microstep: 10.99 | step_microstep: 43.86
[default0]:[2023-08-25 18:07:29,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.01 (forward_moe: 21.29, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.68)
[default0]:[2023-08-25 18:07:29,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.09 | backward_inner: 105.02 | backward_allreduce: 10.99 | step: 43.87
[default0]:[2023-08-25 18:07:29,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.15 | optimizer_step: 6.51
[default0]:[2023-08-25 18:07:29,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.85 | backward_microstep: 116.45 | backward_inner_microstep: 105.26 | backward_allreduce_microstep: 11.10 | step_microstep: 44.22
[default0]:[2023-08-25 18:07:29,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.85 (forward_moe: 21.36, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.69)
[default0]:[2023-08-25 18:07:29,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.45 | backward_inner: 105.27 | backward_allreduce: 11.10 | step: 44.22
[default0]:[2023-08-25 18:07:29,754] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.15 | optimizer_step: 6.52
[default0]:[2023-08-25 18:07:29,754] [INFO] [logging.py:96:log_dist] [Rank 0] step=305, skipped=0, lr=[3.3204906666666666e-07, 3.3204906666666666e-07, 3.3204906666666666e-07, 3.3204906666666666e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:29,754] [INFO] [timer.py:215:stop] epoch=0/micro_step=305/global_step=305, RunningAvgSamplesPerSec=4.8927663559186625, CurrSamplesPerSec=4.716903938003187, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:29,754] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.47 | backward_microstep: 117.25 | backward_inner_microstep: 105.92 | backward_allreduce_microstep: 11.23 | step_microstep: 44.72
[default0]:[2023-08-25 18:07:29,754] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.47 (forward_moe: 21.53, 1st alltoall: 0.90, 2nd alltoall: 0.86, top-k: 8.80)
[default0]:[2023-08-25 18:07:29,755] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.24 | backward_inner: 105.92 | backward_allreduce: 11.24 | step: 44.72
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.4668], device='cuda:0'), 'moe loss': tensor([0.3081], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      305/439453125 | consumed samples:          305 | consumed tokens:       624640 | elapsed time per iteration (ms): 1949.9 | learning rate: 3.320E-07 | global batch size:     1 | lm loss: 1.029336E+01 | moe loss: 6.162345E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.513 | TFLOPs: 1.27 |
[default0]:[2023-08-25 18:07:30,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.44
[default0]:[2023-08-25 18:07:30,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.93 | backward_microstep: 114.95 | backward_inner_microstep: 103.75 | backward_allreduce_microstep: 11.11 | step_microstep: 43.95
[default0]:[2023-08-25 18:07:30,026] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.92 (forward_moe: 21.05, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.50)
[default0]:[2023-08-25 18:07:30,026] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.94 | backward_inner: 103.75 | backward_allreduce: 11.11 | step: 43.96
[default0]:[2023-08-25 18:07:30,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.43
[default0]:[2023-08-25 18:07:30,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.86 | backward_microstep: 114.92 | backward_inner_microstep: 103.72 | backward_allreduce_microstep: 11.11 | step_microstep: 43.23
[default0]:[2023-08-25 18:07:30,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.86 (forward_moe: 21.02, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.49)
[default0]:[2023-08-25 18:07:30,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.92 | backward_inner: 103.73 | backward_allreduce: 11.11 | step: 43.23
[default0]:[2023-08-25 18:07:30,561] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.43
[default0]:[2023-08-25 18:07:30,561] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.17 | backward_microstep: 115.04 | backward_inner_microstep: 103.81 | backward_allreduce_microstep: 11.14 | step_microstep: 43.49
[default0]:[2023-08-25 18:07:30,561] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.17 (forward_moe: 21.18, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.50)
[default0]:[2023-08-25 18:07:30,561] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.04 | backward_inner: 103.82 | backward_allreduce: 11.14 | step: 43.49
[default0]:[2023-08-25 18:07:30,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.40
[default0]:[2023-08-25 18:07:30,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.18 | backward_microstep: 113.03 | backward_inner_microstep: 101.94 | backward_allreduce_microstep: 10.99 | step_microstep: 42.88
[default0]:[2023-08-25 18:07:30,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.18 (forward_moe: 20.60, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:07:30,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.03 | backward_inner: 101.95 | backward_allreduce: 10.99 | step: 42.88
[default0]:[2023-08-25 18:07:31,063] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:07:31,063] [INFO] [logging.py:96:log_dist] [Rank 0] step=310, skipped=0, lr=[3.375104e-07, 3.375104e-07, 3.375104e-07, 3.375104e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:31,063] [INFO] [timer.py:215:stop] epoch=0/micro_step=310/global_step=310, RunningAvgSamplesPerSec=4.892049212216093, CurrSamplesPerSec=4.873527532156676, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:31,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.49 | backward_microstep: 114.11 | backward_inner_microstep: 102.84 | backward_allreduce_microstep: 11.17 | step_microstep: 43.09
[default0]:[2023-08-25 18:07:31,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.48 (forward_moe: 20.80, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.27)
[default0]:[2023-08-25 18:07:31,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.11 | backward_inner: 102.84 | backward_allreduce: 11.17 | step: 43.09
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.3174], device='cuda:0'), 'moe loss': tensor([0.3079], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      310/439453125 | consumed samples:          310 | consumed tokens:       634880 | elapsed time per iteration (ms): 261.7 | learning rate: 3.375E-07 | global batch size:     1 | lm loss: 1.026347E+01 | moe loss: 6.157522E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.820 | TFLOPs: 9.49 |
[default0]:[2023-08-25 18:07:31,346] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.40
[default0]:[2023-08-25 18:07:31,346] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.28 | backward_microstep: 113.30 | backward_inner_microstep: 102.23 | backward_allreduce_microstep: 10.97 | step_microstep: 42.99
[default0]:[2023-08-25 18:07:31,346] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.28 (forward_moe: 20.67, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.28)
[default0]:[2023-08-25 18:07:31,346] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.29 | backward_inner: 102.23 | backward_allreduce: 10.98 | step: 43.00
[default0]:[2023-08-25 18:07:31,702] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:07:31,703] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.41 | backward_microstep: 113.22 | backward_inner_microstep: 102.09 | backward_allreduce_microstep: 11.03 | step_microstep: 42.82
[default0]:[2023-08-25 18:07:31,703] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.41 (forward_moe: 20.66, 1st alltoall: 0.87, 2nd alltoall: 0.83, top-k: 8.26)
[default0]:[2023-08-25 18:07:31,703] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.21 | backward_inner: 102.10 | backward_allreduce: 11.03 | step: 42.82
[default0]:[2023-08-25 18:07:31,954] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:07:31,954] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.42 | backward_microstep: 114.63 | backward_inner_microstep: 103.53 | backward_allreduce_microstep: 11.01 | step_microstep: 42.91
[default0]:[2023-08-25 18:07:31,954] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.42 (forward_moe: 20.65, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:07:31,954] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.63 | backward_inner: 103.53 | backward_allreduce: 11.02 | step: 42.92
[default0]:[2023-08-25 18:07:32,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.41
[default0]:[2023-08-25 18:07:32,200] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.59 | backward_microstep: 113.20 | backward_inner_microstep: 102.09 | backward_allreduce_microstep: 11.01 | step_microstep: 42.97
[default0]:[2023-08-25 18:07:32,200] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.59 (forward_moe: 20.67, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.27)
[default0]:[2023-08-25 18:07:32,200] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.20 | backward_inner: 102.09 | backward_allreduce: 11.01 | step: 42.97
[default0]:[2023-08-25 18:07:32,454] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:07:32,454] [INFO] [logging.py:96:log_dist] [Rank 0] step=315, skipped=0, lr=[3.429717333333334e-07, 3.429717333333334e-07, 3.429717333333334e-07, 3.429717333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:32,454] [INFO] [timer.py:215:stop] epoch=0/micro_step=315/global_step=315, RunningAvgSamplesPerSec=4.892053877876307, CurrSamplesPerSec=4.925470375337325, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:32,455] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.98 | backward_microstep: 112.34 | backward_inner_microstep: 101.32 | backward_allreduce_microstep: 10.93 | step_microstep: 43.15
[default0]:[2023-08-25 18:07:32,455] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.98 (forward_moe: 20.57, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:07:32,455] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.34 | backward_inner: 101.32 | backward_allreduce: 10.93 | step: 43.16
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.3909], device='cuda:0'), 'moe loss': tensor([0.3077], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      315/439453125 | consumed samples:          315 | consumed tokens:       645120 | elapsed time per iteration (ms): 278.1 | learning rate: 3.430E-07 | global batch size:     1 | lm loss: 1.027818E+01 | moe loss: 6.153798E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.596 | TFLOPs: 8.94 |
[default0]:[2023-08-25 18:07:32,723] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.35
[default0]:[2023-08-25 18:07:32,724] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.21 | backward_microstep: 112.46 | backward_inner_microstep: 101.36 | backward_allreduce_microstep: 11.01 | step_microstep: 43.16
[default0]:[2023-08-25 18:07:32,724] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.21 (forward_moe: 20.42, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:07:32,724] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.46 | backward_inner: 101.37 | backward_allreduce: 11.01 | step: 43.16
[default0]:[2023-08-25 18:07:32,982] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.35
[default0]:[2023-08-25 18:07:32,982] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.88 | backward_microstep: 112.48 | backward_inner_microstep: 101.38 | backward_allreduce_microstep: 11.01 | step_microstep: 42.68
[default0]:[2023-08-25 18:07:32,983] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.88 (forward_moe: 20.48, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.17)
[default0]:[2023-08-25 18:07:32,983] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.48 | backward_inner: 101.39 | backward_allreduce: 11.01 | step: 42.69
[default0]:[2023-08-25 18:07:33,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:07:33,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.06 | backward_microstep: 110.22 | backward_inner_microstep: 99.28 | backward_allreduce_microstep: 10.85 | step_microstep: 42.68
[default0]:[2023-08-25 18:07:33,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.06 (forward_moe: 19.97, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:07:33,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.22 | backward_inner: 99.28 | backward_allreduce: 10.85 | step: 42.68
[default0]:[2023-08-25 18:07:33,496] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:33,497] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.62 | backward_microstep: 112.31 | backward_inner_microstep: 101.29 | backward_allreduce_microstep: 10.93 | step_microstep: 41.85
[default0]:[2023-08-25 18:07:33,497] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.62 (forward_moe: 20.04, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.84)
[default0]:[2023-08-25 18:07:33,497] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.31 | backward_inner: 101.30 | backward_allreduce: 10.93 | step: 41.85
[default0]:[2023-08-25 18:07:33,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:33,736] [INFO] [logging.py:96:log_dist] [Rank 0] step=320, skipped=0, lr=[3.484330666666667e-07, 3.484330666666667e-07, 3.484330666666667e-07, 3.484330666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:33,737] [INFO] [timer.py:215:stop] epoch=0/micro_step=320/global_step=320, RunningAvgSamplesPerSec=4.893024210583463, CurrSamplesPerSec=5.020094482006647, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:33,737] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.99 | backward_microstep: 110.39 | backward_inner_microstep: 99.45 | backward_allreduce_microstep: 10.85 | step_microstep: 42.27
[default0]:[2023-08-25 18:07:33,737] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.99 (forward_moe: 20.10, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.84)
[default0]:[2023-08-25 18:07:33,737] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.39 | backward_inner: 99.46 | backward_allreduce: 10.85 | step: 42.28
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.2643], device='cuda:0'), 'moe loss': tensor([0.3078], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      320/439453125 | consumed samples:          320 | consumed tokens:       655360 | elapsed time per iteration (ms): 256.5 | learning rate: 3.484E-07 | global batch size:     1 | lm loss: 1.025286E+01 | moe loss: 6.156690E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.899 | TFLOPs: 9.69 |
[default0]:[2023-08-25 18:07:33,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:33,992] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.21 | backward_microstep: 110.01 | backward_inner_microstep: 99.11 | backward_allreduce_microstep: 10.81 | step_microstep: 41.76
[default0]:[2023-08-25 18:07:33,992] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.21 (forward_moe: 19.96, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:07:33,992] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.01 | backward_inner: 99.11 | backward_allreduce: 10.81 | step: 41.76
[default0]:[2023-08-25 18:07:34,239] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:34,240] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 109.07 | backward_inner_microstep: 98.22 | backward_allreduce_microstep: 10.75 | step_microstep: 41.85
[default0]:[2023-08-25 18:07:34,242] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:07:34,242] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.07 | backward_inner: 98.23 | backward_allreduce: 10.76 | step: 41.86
[default0]:[2023-08-25 18:07:34,494] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:07:34,496] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.00 | backward_microstep: 111.67 | backward_inner_microstep: 100.76 | backward_allreduce_microstep: 10.82 | step_microstep: 43.94
[default0]:[2023-08-25 18:07:34,496] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.00 (forward_moe: 20.42, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 7.89)
[default0]:[2023-08-25 18:07:34,496] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.67 | backward_inner: 100.76 | backward_allreduce: 10.82 | step: 43.94
[default0]:[2023-08-25 18:07:34,772] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:07:34,773] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 109.09 | backward_inner_microstep: 98.19 | backward_allreduce_microstep: 10.81 | step_microstep: 41.53
[default0]:[2023-08-25 18:07:34,773] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.89, 1st alltoall: 0.86, 2nd alltoall: 0.85, top-k: 7.71)
[default0]:[2023-08-25 18:07:34,773] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.09 | backward_inner: 98.20 | backward_allreduce: 10.81 | step: 41.53
[default0]:[2023-08-25 18:07:35,020] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.28
[default0]:[2023-08-25 18:07:35,020] [INFO] [logging.py:96:log_dist] [Rank 0] step=325, skipped=0, lr=[3.538944e-07, 3.538944e-07, 3.538944e-07, 3.538944e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:35,021] [INFO] [timer.py:215:stop] epoch=0/micro_step=325/global_step=325, RunningAvgSamplesPerSec=4.895024322080906, CurrSamplesPerSec=5.075306081455541, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:35,021] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 109.01 | backward_inner_microstep: 98.11 | backward_allreduce_microstep: 10.80 | step_microstep: 41.87
[default0]:[2023-08-25 18:07:35,021] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.90, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:07:35,021] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.12 | backward_allreduce: 10.80 | step: 41.87
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.3814], device='cuda:0'), 'moe loss': tensor([0.3074], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      325/439453125 | consumed samples:          325 | consumed tokens:       665600 | elapsed time per iteration (ms): 257.0 | learning rate: 3.539E-07 | global batch size:     1 | lm loss: 1.027628E+01 | moe loss: 6.148223E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.890 | TFLOPs: 9.67 |
[default0]:[2023-08-25 18:07:35,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:07:35,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 109.03 | backward_inner_microstep: 98.15 | backward_allreduce_microstep: 10.79 | step_microstep: 41.60
[default0]:[2023-08-25 18:07:35,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:07:35,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.15 | backward_allreduce: 10.79 | step: 41.60
[default0]:[2023-08-25 18:07:35,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:35,513] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 108.96 | backward_inner_microstep: 98.07 | backward_allreduce_microstep: 10.80 | step_microstep: 41.66
[default0]:[2023-08-25 18:07:35,513] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.51 (forward_moe: 19.81, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:07:35,513] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.95 | backward_inner: 98.07 | backward_allreduce: 10.80 | step: 41.66
[default0]:[2023-08-25 18:07:35,772] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.01 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:35,772] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.85 | backward_microstep: 109.41 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 11.23 | step_microstep: 46.21
[default0]:[2023-08-25 18:07:35,772] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.85 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:07:35,773] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.40 | backward_inner: 98.09 | backward_allreduce: 11.23 | step: 46.21
[default0]:[2023-08-25 18:07:36,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:36,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.04 | backward_microstep: 111.94 | backward_inner_microstep: 100.92 | backward_allreduce_microstep: 10.93 | step_microstep: 42.44
[default0]:[2023-08-25 18:07:36,013] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.04 (forward_moe: 20.50, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:07:36,013] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.94 | backward_inner: 100.92 | backward_allreduce: 10.93 | step: 42.44
[default0]:[2023-08-25 18:07:36,271] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:07:36,272] [INFO] [logging.py:96:log_dist] [Rank 0] step=330, skipped=0, lr=[3.5935573333333334e-07, 3.5935573333333334e-07, 3.5935573333333334e-07, 3.5935573333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:36,272] [INFO] [timer.py:215:stop] epoch=0/micro_step=330/global_step=330, RunningAvgSamplesPerSec=4.896909760946435, CurrSamplesPerSec=5.071550350291285, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:36,272] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.62 | backward_microstep: 109.07 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.80 | step_microstep: 41.95
[default0]:[2023-08-25 18:07:36,272] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:07:36,272] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.07 | backward_inner: 98.18 | backward_allreduce: 10.80 | step: 41.95
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.1309], device='cuda:0'), 'moe loss': tensor([0.3064], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      330/439453125 | consumed samples:          330 | consumed tokens:       675840 | elapsed time per iteration (ms): 250.0 | learning rate: 3.594E-07 | global batch size:     1 | lm loss: 1.022617E+01 | moe loss: 6.128737E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.000 | TFLOPs: 9.94 |
[default0]:[2023-08-25 18:07:36,515] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:36,515] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 109.00 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.81 | step_microstep: 41.57
[default0]:[2023-08-25 18:07:36,515] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.84, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.79)
[default0]:[2023-08-25 18:07:36,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.11 | backward_allreduce: 10.81 | step: 41.57
[default0]:[2023-08-25 18:07:36,761] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:07:36,761] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.80 | backward_microstep: 109.00 | backward_inner_microstep: 98.15 | backward_allreduce_microstep: 10.76 | step_microstep: 41.33
[default0]:[2023-08-25 18:07:36,762] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.80 (forward_moe: 19.83, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:07:36,762] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.16 | backward_allreduce: 10.76 | step: 41.34
[default0]:[2023-08-25 18:07:37,031] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:07:37,032] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.44 | backward_microstep: 110.69 | backward_inner_microstep: 99.76 | backward_allreduce_microstep: 10.85 | step_microstep: 41.51
[default0]:[2023-08-25 18:07:37,032] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.44 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:07:37,032] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.69 | backward_inner: 99.76 | backward_allreduce: 10.85 | step: 41.52
[default0]:[2023-08-25 18:07:37,297] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.88 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:37,297] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.78 | backward_microstep: 109.12 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.76 | step_microstep: 41.53
[default0]:[2023-08-25 18:07:37,297] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.77 (forward_moe: 19.83, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:07:37,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.26 | backward_allreduce: 10.77 | step: 41.53
[default0]:[2023-08-25 18:07:37,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.38
[default0]:[2023-08-25 18:07:37,529] [INFO] [logging.py:96:log_dist] [Rank 0] step=335, skipped=0, lr=[3.6481706666666666e-07, 3.6481706666666666e-07, 3.6481706666666666e-07, 3.6481706666666666e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:37,529] [INFO] [timer.py:215:stop] epoch=0/micro_step=335/global_step=335, RunningAvgSamplesPerSec=4.899094915091484, CurrSamplesPerSec=5.071531953534882, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:37,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.53 | backward_microstep: 108.93 | backward_inner_microstep: 98.03 | backward_allreduce_microstep: 10.81 | step_microstep: 42.18
[default0]:[2023-08-25 18:07:37,530] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.53 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:07:37,530] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.93 | backward_inner: 98.03 | backward_allreduce: 10.81 | step: 42.18
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.3169], device='cuda:0'), 'moe loss': tensor([0.3071], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      335/439453125 | consumed samples:          335 | consumed tokens:       686080 | elapsed time per iteration (ms): 251.5 | learning rate: 3.648E-07 | global batch size:     1 | lm loss: 1.026338E+01 | moe loss: 6.142229E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.976 | TFLOPs: 9.88 |
[default0]:[2023-08-25 18:07:37,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:07:37,788] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 109.14 | backward_inner_microstep: 98.28 | backward_allreduce_microstep: 10.77 | step_microstep: 41.41
[default0]:[2023-08-25 18:07:37,788] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 19.79, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:07:37,788] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.14 | backward_inner: 98.29 | backward_allreduce: 10.77 | step: 41.42
[default0]:[2023-08-25 18:07:38,037] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:38,037] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.53 | backward_microstep: 111.47 | backward_inner_microstep: 100.46 | backward_allreduce_microstep: 10.92 | step_microstep: 42.34
[default0]:[2023-08-25 18:07:38,037] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.54 (forward_moe: 20.33, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.08)
[default0]:[2023-08-25 18:07:38,037] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.47 | backward_inner: 100.46 | backward_allreduce: 10.92 | step: 42.35
[default0]:[2023-08-25 18:07:38,300] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:38,300] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.93 | backward_microstep: 111.56 | backward_inner_microstep: 100.51 | backward_allreduce_microstep: 10.96 | step_microstep: 42.40
[default0]:[2023-08-25 18:07:38,300] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.93 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:07:38,300] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.56 | backward_inner: 100.52 | backward_allreduce: 10.96 | step: 42.41
[default0]:[2023-08-25 18:07:38,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.05 | optimizer_step: 6.38
[default0]:[2023-08-25 18:07:38,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.76 | backward_microstep: 113.92 | backward_inner_microstep: 102.74 | backward_allreduce_microstep: 11.08 | step_microstep: 43.97
[default0]:[2023-08-25 18:07:38,637] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.76 (forward_moe: 20.74, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:07:38,637] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.92 | backward_inner: 102.74 | backward_allreduce: 11.09 | step: 43.98
[default0]:[2023-08-25 18:07:38,904] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 9.92
[default0]:[2023-08-25 18:07:38,904] [INFO] [logging.py:96:log_dist] [Rank 0] step=340, skipped=0, lr=[3.7027839999999997e-07, 3.7027839999999997e-07, 3.7027839999999997e-07, 3.7027839999999997e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:38,905] [INFO] [timer.py:215:stop] epoch=0/micro_step=340/global_step=340, RunningAvgSamplesPerSec=4.89970448072735, CurrSamplesPerSec=4.861692891709409, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:38,905] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.72 | backward_microstep: 111.65 | backward_inner_microstep: 100.62 | backward_allreduce_microstep: 10.94 | step_microstep: 46.76
[default0]:[2023-08-25 18:07:38,905] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.72 (forward_moe: 20.47, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.04)
[default0]:[2023-08-25 18:07:38,905] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.65 | backward_inner: 100.62 | backward_allreduce: 10.94 | step: 46.76
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.2747], device='cuda:0'), 'moe loss': tensor([0.3065], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      340/439453125 | consumed samples:          340 | consumed tokens:       696320 | elapsed time per iteration (ms): 275.3 | learning rate: 3.703E-07 | global batch size:     1 | lm loss: 1.025494E+01 | moe loss: 6.130626E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.633 | TFLOPs: 9.03 |
[default0]:[2023-08-25 18:07:39,176] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:07:39,176] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.38 | backward_microstep: 111.54 | backward_inner_microstep: 100.53 | backward_allreduce_microstep: 10.91 | step_microstep: 42.30
[default0]:[2023-08-25 18:07:39,176] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.38 (forward_moe: 20.34, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.04)
[default0]:[2023-08-25 18:07:39,176] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.53 | backward_inner: 100.54 | backward_allreduce: 10.91 | step: 42.30
[default0]:[2023-08-25 18:07:39,428] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:39,428] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.70 | backward_microstep: 111.43 | backward_inner_microstep: 100.40 | backward_allreduce_microstep: 10.93 | step_microstep: 42.22
[default0]:[2023-08-25 18:07:39,429] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.70 (forward_moe: 20.40, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.03)
[default0]:[2023-08-25 18:07:39,429] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.43 | backward_inner: 100.41 | backward_allreduce: 10.94 | step: 42.23
[default0]:[2023-08-25 18:07:39,672] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.29
[default0]:[2023-08-25 18:07:39,672] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.62 | backward_microstep: 109.07 | backward_inner_microstep: 98.22 | backward_allreduce_microstep: 10.75 | step_microstep: 41.53
[default0]:[2023-08-25 18:07:39,672] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:07:39,672] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.07 | backward_inner: 98.23 | backward_allreduce: 10.76 | step: 41.53
[default0]:[2023-08-25 18:07:39,908] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:07:39,908] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 109.08 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.81 | step_microstep: 41.50
[default0]:[2023-08-25 18:07:39,908] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:07:39,908] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.18 | backward_allreduce: 10.81 | step: 41.50
[default0]:[2023-08-25 18:07:40,177] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:07:40,177] [INFO] [logging.py:96:log_dist] [Rank 0] step=345, skipped=0, lr=[3.7573973333333334e-07, 3.7573973333333334e-07, 3.7573973333333334e-07, 3.7573973333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:40,178] [INFO] [timer.py:215:stop] epoch=0/micro_step=345/global_step=345, RunningAvgSamplesPerSec=4.901623121345815, CurrSamplesPerSec=5.08385079240023, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:40,178] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 108.95 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.75 | step_microstep: 41.79
[default0]:[2023-08-25 18:07:40,178] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.41 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:07:40,178] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.95 | backward_inner: 98.11 | backward_allreduce: 10.75 | step: 41.80
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.4555], device='cuda:0'), 'moe loss': tensor([0.3061], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      345/439453125 | consumed samples:          345 | consumed tokens:       706560 | elapsed time per iteration (ms): 254.3 | learning rate: 3.757E-07 | global batch size:     1 | lm loss: 1.029110E+01 | moe loss: 6.122398E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.932 | TFLOPs: 9.77 |
[default0]:[2023-08-25 18:07:40,433] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:40,433] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.48 | backward_microstep: 108.91 | backward_inner_microstep: 98.05 | backward_allreduce_microstep: 10.76 | step_microstep: 41.54
[default0]:[2023-08-25 18:07:40,433] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.71)
[default0]:[2023-08-25 18:07:40,433] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.91 | backward_inner: 98.05 | backward_allreduce: 10.77 | step: 41.54
[default0]:[2023-08-25 18:07:40,666] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:40,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 109.61 | backward_inner_microstep: 98.65 | backward_allreduce_microstep: 10.87 | step_microstep: 41.75
[default0]:[2023-08-25 18:07:40,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:07:40,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.61 | backward_inner: 98.65 | backward_allreduce: 10.88 | step: 41.76
[default0]:[2023-08-25 18:07:40,913] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:40,913] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 108.90 | backward_inner_microstep: 98.08 | backward_allreduce_microstep: 10.73 | step_microstep: 41.41
[default0]:[2023-08-25 18:07:40,914] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:07:40,914] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 98.09 | backward_allreduce: 10.73 | step: 41.41
[default0]:[2023-08-25 18:07:41,173] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.91 | optimizer_step: 6.36
[default0]:[2023-08-25 18:07:41,173] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.31 | backward_microstep: 109.44 | backward_inner_microstep: 98.36 | backward_allreduce_microstep: 10.98 | step_microstep: 42.55
[default0]:[2023-08-25 18:07:41,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.31 (forward_moe: 19.78, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.76)
[default0]:[2023-08-25 18:07:41,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.44 | backward_inner: 98.37 | backward_allreduce: 10.99 | step: 42.55
[default0]:[2023-08-25 18:07:41,431] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.88 | optimizer_step: 6.28
[default0]:[2023-08-25 18:07:41,431] [INFO] [logging.py:96:log_dist] [Rank 0] step=350, skipped=0, lr=[3.8120106666666665e-07, 3.8120106666666665e-07, 3.8120106666666665e-07, 3.8120106666666665e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:41,431] [INFO] [timer.py:215:stop] epoch=0/micro_step=350/global_step=350, RunningAvgSamplesPerSec=4.903869775340861, CurrSamplesPerSec=5.0640922240306, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:41,431] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.88 | backward_microstep: 109.24 | backward_inner_microstep: 98.39 | backward_allreduce_microstep: 10.76 | step_microstep: 41.78
[default0]:[2023-08-25 18:07:41,431] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.88 (forward_moe: 20.15, 1st alltoall: 0.87, 2nd alltoall: 0.97, top-k: 7.71)
[default0]:[2023-08-25 18:07:41,432] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.24 | backward_inner: 98.40 | backward_allreduce: 10.76 | step: 41.79
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.6764], device='cuda:0'), 'moe loss': tensor([0.3054], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      350/439453125 | consumed samples:          350 | consumed tokens:       716800 | elapsed time per iteration (ms): 250.7 | learning rate: 3.812E-07 | global batch size:     1 | lm loss: 1.033527E+01 | moe loss: 6.108930E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.989 | TFLOPs: 9.91 |
[default0]:[2023-08-25 18:07:41,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:07:41,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.39 | backward_microstep: 109.27 | backward_inner_microstep: 98.37 | backward_allreduce_microstep: 10.81 | step_microstep: 41.64
[default0]:[2023-08-25 18:07:41,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.39 (forward_moe: 19.77, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:07:41,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.26 | backward_inner: 98.37 | backward_allreduce: 10.81 | step: 41.64
[default0]:[2023-08-25 18:07:41,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:07:41,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.58 | backward_microstep: 108.96 | backward_inner_microstep: 98.07 | backward_allreduce_microstep: 10.79 | step_microstep: 41.35
[default0]:[2023-08-25 18:07:41,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.58 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:07:41,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.08 | backward_allreduce: 10.79 | step: 41.36
[default0]:[2023-08-25 18:07:42,195] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:07:42,195] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 109.01 | backward_inner_microstep: 98.14 | backward_allreduce_microstep: 10.78 | step_microstep: 41.45
[default0]:[2023-08-25 18:07:42,196] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:07:42,196] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.01 | backward_inner: 98.14 | backward_allreduce: 10.78 | step: 41.45
[default0]:[2023-08-25 18:07:42,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.88 | optimizer_step: 6.35
[default0]:[2023-08-25 18:07:42,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 109.01 | backward_inner_microstep: 98.12 | backward_allreduce_microstep: 10.80 | step_microstep: 41.53
[default0]:[2023-08-25 18:07:42,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.74)
[default0]:[2023-08-25 18:07:42,457] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.01 | backward_inner: 98.12 | backward_allreduce: 10.80 | step: 41.53
[default0]:[2023-08-25 18:07:42,705] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.98 | optimizer_step: 6.29
[default0]:[2023-08-25 18:07:42,706] [INFO] [logging.py:96:log_dist] [Rank 0] step=355, skipped=0, lr=[3.866624e-07, 3.866624e-07, 3.866624e-07, 3.866624e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:42,706] [INFO] [timer.py:215:stop] epoch=0/micro_step=355/global_step=355, RunningAvgSamplesPerSec=4.906260949779182, CurrSamplesPerSec=5.074397322886849, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:42,706] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.53 | backward_microstep: 109.04 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.81 | step_microstep: 41.95
[default0]:[2023-08-25 18:07:42,706] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.53 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:07:42,706] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.04 | backward_inner: 98.14 | backward_allreduce: 10.82 | step: 41.96
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.2894], device='cuda:0'), 'moe loss': tensor([0.3044], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      355/439453125 | consumed samples:          355 | consumed tokens:       727040 | elapsed time per iteration (ms): 255.2 | learning rate: 3.867E-07 | global batch size:     1 | lm loss: 1.025789E+01 | moe loss: 6.087847E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.919 | TFLOPs: 9.74 |
[default0]:[2023-08-25 18:07:42,973] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:07:42,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.41 | backward_microstep: 109.00 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.77 | step_microstep: 42.69
[default0]:[2023-08-25 18:07:42,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.41 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.73)
[default0]:[2023-08-25 18:07:42,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.99 | backward_inner: 98.13 | backward_allreduce: 10.78 | step: 42.69
[default0]:[2023-08-25 18:07:43,215] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:07:43,215] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.29 | backward_microstep: 109.02 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.77 | step_microstep: 41.92
[default0]:[2023-08-25 18:07:43,216] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.29 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:07:43,216] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.02 | backward_inner: 98.16 | backward_allreduce: 10.78 | step: 41.92
[default0]:[2023-08-25 18:07:43,472] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:43,473] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.65 | backward_microstep: 111.40 | backward_inner_microstep: 100.34 | backward_allreduce_microstep: 10.96 | step_microstep: 42.30
[default0]:[2023-08-25 18:07:43,473] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.65 (forward_moe: 20.26, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.04)
[default0]:[2023-08-25 18:07:43,473] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.39 | backward_inner: 100.35 | backward_allreduce: 10.96 | step: 42.30
[default0]:[2023-08-25 18:07:43,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:07:43,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.80 | backward_microstep: 111.98 | backward_inner_microstep: 100.95 | backward_allreduce_microstep: 10.93 | step_microstep: 42.55
[default0]:[2023-08-25 18:07:43,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.80 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:07:43,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.98 | backward_inner: 100.96 | backward_allreduce: 10.94 | step: 42.56
[default0]:[2023-08-25 18:07:44,015] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:44,016] [INFO] [logging.py:96:log_dist] [Rank 0] step=360, skipped=0, lr=[3.9212373333333333e-07, 3.9212373333333333e-07, 3.9212373333333333e-07, 3.9212373333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:44,016] [INFO] [timer.py:215:stop] epoch=0/micro_step=360/global_step=360, RunningAvgSamplesPerSec=4.907108015683103, CurrSamplesPerSec=4.896855918648501, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:44,016] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.17 | backward_microstep: 113.27 | backward_inner_microstep: 102.16 | backward_allreduce_microstep: 11.01 | step_microstep: 43.21
[default0]:[2023-08-25 18:07:44,016] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.17 (forward_moe: 20.78, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.24)
[default0]:[2023-08-25 18:07:44,016] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.26 | backward_inner: 102.17 | backward_allreduce: 11.01 | step: 43.22
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.2341], device='cuda:0'), 'moe loss': tensor([0.3042], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      360/439453125 | consumed samples:          360 | consumed tokens:       737280 | elapsed time per iteration (ms): 261.8 | learning rate: 3.921E-07 | global batch size:     1 | lm loss: 1.024681E+01 | moe loss: 6.083146E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.820 | TFLOPs: 9.49 |
[default0]:[2023-08-25 18:07:44,307] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:07:44,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.56 | backward_microstep: 113.31 | backward_inner_microstep: 102.15 | backward_allreduce_microstep: 11.06 | step_microstep: 43.00
[default0]:[2023-08-25 18:07:44,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.56 (forward_moe: 20.65, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.27)
[default0]:[2023-08-25 18:07:44,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.30 | backward_inner: 102.16 | backward_allreduce: 11.06 | step: 43.01
[default0]:[2023-08-25 18:07:44,561] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.05 | optimizer_step: 6.40
[default0]:[2023-08-25 18:07:44,561] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.48 | backward_microstep: 113.81 | backward_inner_microstep: 102.62 | backward_allreduce_microstep: 11.09 | step_microstep: 43.20
[default0]:[2023-08-25 18:07:44,561] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.48 (forward_moe: 20.88, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.33)
[default0]:[2023-08-25 18:07:44,562] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.80 | backward_inner: 102.62 | backward_allreduce: 11.10 | step: 43.21
[default0]:[2023-08-25 18:07:44,803] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.10 | optimizer_step: 6.41
[default0]:[2023-08-25 18:07:44,803] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.01 | backward_microstep: 114.21 | backward_inner_microstep: 102.97 | backward_allreduce_microstep: 11.14 | step_microstep: 43.08
[default0]:[2023-08-25 18:07:44,803] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.01 (forward_moe: 21.00, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.46)
[default0]:[2023-08-25 18:07:44,803] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.20 | backward_inner: 102.98 | backward_allreduce: 11.14 | step: 43.09
[default0]:[2023-08-25 18:07:45,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:07:45,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.00 | backward_microstep: 114.99 | backward_inner_microstep: 103.63 | backward_allreduce_microstep: 11.27 | step_microstep: 43.25
[default0]:[2023-08-25 18:07:45,086] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.00 (forward_moe: 21.00, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.48)
[default0]:[2023-08-25 18:07:45,086] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.99 | backward_inner: 103.64 | backward_allreduce: 11.27 | step: 43.25
[default0]:[2023-08-25 18:07:45,336] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.44
[default0]:[2023-08-25 18:07:45,336] [INFO] [logging.py:96:log_dist] [Rank 0] step=365, skipped=0, lr=[3.975850666666667e-07, 3.975850666666667e-07, 3.975850666666667e-07, 3.975850666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:45,336] [INFO] [timer.py:215:stop] epoch=0/micro_step=365/global_step=365, RunningAvgSamplesPerSec=4.906367082041029, CurrSamplesPerSec=4.832949245036043, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:45,336] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.13 | backward_microstep: 114.49 | backward_inner_microstep: 103.28 | backward_allreduce_microstep: 11.12 | step_microstep: 43.72
[default0]:[2023-08-25 18:07:45,336] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.13 (forward_moe: 20.94, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.48)
[default0]:[2023-08-25 18:07:45,336] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.49 | backward_inner: 103.29 | backward_allreduce: 11.12 | step: 43.73
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.4858], device='cuda:0'), 'moe loss': tensor([0.3036], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      365/439453125 | consumed samples:          365 | consumed tokens:       747520 | elapsed time per iteration (ms): 264.4 | learning rate: 3.976E-07 | global batch size:     1 | lm loss: 1.029717E+01 | moe loss: 6.071048E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.782 | TFLOPs: 9.40 |
[default0]:[2023-08-25 18:07:45,583] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.41
[default0]:[2023-08-25 18:07:45,583] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.96 | backward_microstep: 114.61 | backward_inner_microstep: 103.41 | backward_allreduce_microstep: 11.10 | step_microstep: 43.33
[default0]:[2023-08-25 18:07:45,583] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.95 (forward_moe: 20.89, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.40)
[default0]:[2023-08-25 18:07:45,583] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.60 | backward_inner: 103.42 | backward_allreduce: 11.10 | step: 43.33
[default0]:[2023-08-25 18:07:45,867] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.43
[default0]:[2023-08-25 18:07:45,868] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.87 | backward_microstep: 114.66 | backward_inner_microstep: 103.45 | backward_allreduce_microstep: 11.12 | step_microstep: 43.44
[default0]:[2023-08-25 18:07:45,868] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.86 (forward_moe: 20.89, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.41)
[default0]:[2023-08-25 18:07:45,868] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.66 | backward_inner: 103.45 | backward_allreduce: 11.13 | step: 43.45
[default0]:[2023-08-25 18:07:46,172] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:07:46,172] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 109.91 | backward_inner_microstep: 98.92 | backward_allreduce_microstep: 10.90 | step_microstep: 41.93
[default0]:[2023-08-25 18:07:46,172] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.00 (forward_moe: 19.97, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.86)
[default0]:[2023-08-25 18:07:46,172] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.91 | backward_inner: 98.92 | backward_allreduce: 10.91 | step: 41.94
[default0]:[2023-08-25 18:07:46,437] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:07:46,437] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.11 | backward_microstep: 110.24 | backward_inner_microstep: 99.32 | backward_allreduce_microstep: 10.83 | step_microstep: 41.61
[default0]:[2023-08-25 18:07:46,437] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.10 (forward_moe: 19.96, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:07:46,438] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.24 | backward_inner: 99.33 | backward_allreduce: 10.83 | step: 41.61
[default0]:[2023-08-25 18:07:46,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:46,694] [INFO] [logging.py:96:log_dist] [Rank 0] step=370, skipped=0, lr=[4.030464e-07, 4.030464e-07, 4.030464e-07, 4.030464e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:46,694] [INFO] [timer.py:215:stop] epoch=0/micro_step=370/global_step=370, RunningAvgSamplesPerSec=4.906746591471147, CurrSamplesPerSec=4.942901487359039, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:46,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.95 | backward_microstep: 113.16 | backward_inner_microstep: 101.65 | backward_allreduce_microstep: 11.40 | step_microstep: 42.65
[default0]:[2023-08-25 18:07:46,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.95 (forward_moe: 20.80, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 7.96)
[default0]:[2023-08-25 18:07:46,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.16 | backward_inner: 101.66 | backward_allreduce: 11.41 | step: 42.66
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.1992], device='cuda:0'), 'moe loss': tensor([0.3033], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      370/439453125 | consumed samples:          370 | consumed tokens:       757760 | elapsed time per iteration (ms): 271.8 | learning rate: 4.030E-07 | global batch size:     1 | lm loss: 1.023984E+01 | moe loss: 6.066872E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.679 | TFLOPs: 9.14 |
[default0]:[2023-08-25 18:07:47,051] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.33
[default0]:[2023-08-25 18:07:47,052] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.64 | backward_microstep: 114.20 | backward_inner_microstep: 103.27 | backward_allreduce_microstep: 10.84 | step_microstep: 42.35
[default0]:[2023-08-25 18:07:47,052] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.64 (forward_moe: 20.28, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 7.92)
[default0]:[2023-08-25 18:07:47,052] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.20 | backward_inner: 103.27 | backward_allreduce: 10.84 | step: 42.35
[default0]:[2023-08-25 18:07:47,304] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:07:47,304] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.10 | backward_microstep: 110.06 | backward_inner_microstep: 99.10 | backward_allreduce_microstep: 10.87 | step_microstep: 41.82
[default0]:[2023-08-25 18:07:47,304] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.10 (forward_moe: 20.10, 1st alltoall: 0.87, 2nd alltoall: 0.85, top-k: 7.86)
[default0]:[2023-08-25 18:07:47,304] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.06 | backward_inner: 99.10 | backward_allreduce: 10.87 | step: 41.83
[default0]:[2023-08-25 18:07:47,555] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:07:47,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.06 | backward_microstep: 109.99 | backward_inner_microstep: 99.01 | backward_allreduce_microstep: 10.88 | step_microstep: 41.79
[default0]:[2023-08-25 18:07:47,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.06 (forward_moe: 19.99, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:07:47,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.99 | backward_inner: 99.02 | backward_allreduce: 10.89 | step: 41.79
[default0]:[2023-08-25 18:07:47,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.04 | optimizer_step: 6.39
[default0]:[2023-08-25 18:07:47,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.02 | backward_microstep: 115.63 | backward_inner_microstep: 103.94 | backward_allreduce_microstep: 11.60 | step_microstep: 43.93
[default0]:[2023-08-25 18:07:47,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.02 (forward_moe: 21.10, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.26)
[default0]:[2023-08-25 18:07:47,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.63 | backward_inner: 103.94 | backward_allreduce: 11.60 | step: 43.93
[default0]:[2023-08-25 18:07:48,054] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:48,055] [INFO] [logging.py:96:log_dist] [Rank 0] step=375, skipped=0, lr=[4.085077333333334e-07, 4.085077333333334e-07, 4.085077333333334e-07, 4.085077333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:48,055] [INFO] [timer.py:215:stop] epoch=0/micro_step=375/global_step=375, RunningAvgSamplesPerSec=4.9071237709249464, CurrSamplesPerSec=4.919214155613702, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:48,055] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.37 | backward_microstep: 112.33 | backward_inner_microstep: 101.23 | backward_allreduce_microstep: 11.00 | step_microstep: 43.04
[default0]:[2023-08-25 18:07:48,055] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.37 (forward_moe: 20.46, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.14)
[default0]:[2023-08-25 18:07:48,055] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.33 | backward_inner: 101.23 | backward_allreduce: 11.01 | step: 43.04
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.9948], device='cuda:0'), 'moe loss': tensor([0.3037], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      375/439453125 | consumed samples:          375 | consumed tokens:       768000 | elapsed time per iteration (ms): 271.7 | learning rate: 4.085E-07 | global batch size:     1 | lm loss: 1.019895E+01 | moe loss: 6.074783E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.681 | TFLOPs: 9.15 |
[default0]:[2023-08-25 18:07:48,306] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:07:48,306] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.16 | backward_microstep: 112.24 | backward_inner_microstep: 101.14 | backward_allreduce_microstep: 11.01 | step_microstep: 42.57
[default0]:[2023-08-25 18:07:48,306] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.16 (forward_moe: 20.46, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:07:48,306] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.24 | backward_inner: 101.14 | backward_allreduce: 11.01 | step: 42.58
[default0]:[2023-08-25 18:07:48,595] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:48,595] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.00 | backward_microstep: 112.33 | backward_inner_microstep: 101.24 | backward_allreduce_microstep: 11.00 | step_microstep: 42.59
[default0]:[2023-08-25 18:07:48,595] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.99 (forward_moe: 20.43, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:07:48,595] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.33 | backward_inner: 101.25 | backward_allreduce: 11.00 | step: 42.59
[default0]:[2023-08-25 18:07:48,852] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:07:48,853] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.95 | backward_microstep: 112.55 | backward_inner_microstep: 101.47 | backward_allreduce_microstep: 10.99 | step_microstep: 43.09
[default0]:[2023-08-25 18:07:48,853] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.95 (forward_moe: 20.48, 1st alltoall: 0.92, 2nd alltoall: 0.81, top-k: 8.16)
[default0]:[2023-08-25 18:07:48,853] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.55 | backward_inner: 101.48 | backward_allreduce: 10.99 | step: 43.09
[default0]:[2023-08-25 18:07:49,249] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 10.42
[default0]:[2023-08-25 18:07:49,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.18 | backward_microstep: 112.25 | backward_inner_microstep: 101.17 | backward_allreduce_microstep: 10.99 | step_microstep: 46.93
[default0]:[2023-08-25 18:07:49,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.18 (forward_moe: 20.46, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:07:49,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.25 | backward_inner: 101.18 | backward_allreduce: 10.99 | step: 46.93
[default0]:[2023-08-25 18:07:49,511] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:07:49,511] [INFO] [logging.py:96:log_dist] [Rank 0] step=380, skipped=0, lr=[4.139690666666667e-07, 4.139690666666667e-07, 4.139690666666667e-07, 4.139690666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:49,512] [INFO] [timer.py:215:stop] epoch=0/micro_step=380/global_step=380, RunningAvgSamplesPerSec=4.9071118455982425, CurrSamplesPerSec=4.926696909115256, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:49,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.01 | backward_microstep: 112.41 | backward_inner_microstep: 101.34 | backward_allreduce_microstep: 10.98 | step_microstep: 43.00
[default0]:[2023-08-25 18:07:49,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.01 (forward_moe: 20.66, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.19)
[default0]:[2023-08-25 18:07:49,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.41 | backward_inner: 101.34 | backward_allreduce: 10.98 | step: 43.01
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.2403], device='cuda:0'), 'moe loss': tensor([0.3039], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      380/439453125 | consumed samples:          380 | consumed tokens:       778240 | elapsed time per iteration (ms): 291.2 | learning rate: 4.140E-07 | global batch size:     1 | lm loss: 1.024806E+01 | moe loss: 6.077247E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.434 | TFLOPs: 8.53 |
[default0]:[2023-08-25 18:07:49,753] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.05 | optimizer_step: 6.40
[default0]:[2023-08-25 18:07:49,753] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.16 | backward_microstep: 112.41 | backward_inner_microstep: 101.35 | backward_allreduce_microstep: 10.97 | step_microstep: 43.38
[default0]:[2023-08-25 18:07:49,753] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.16 (forward_moe: 20.45, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.16)
[default0]:[2023-08-25 18:07:49,753] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.41 | backward_inner: 101.36 | backward_allreduce: 10.97 | step: 43.38
[default0]:[2023-08-25 18:07:50,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:07:50,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.93 | backward_microstep: 114.02 | backward_inner_microstep: 102.81 | backward_allreduce_microstep: 11.12 | step_microstep: 43.33
[default0]:[2023-08-25 18:07:50,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.92 (forward_moe: 20.80, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.35)
[default0]:[2023-08-25 18:07:50,039] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.02 | backward_inner: 102.82 | backward_allreduce: 11.12 | step: 43.33
[default0]:[2023-08-25 18:07:50,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 6.42
[default0]:[2023-08-25 18:07:50,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.02 | backward_microstep: 114.88 | backward_inner_microstep: 103.63 | backward_allreduce_microstep: 11.16 | step_microstep: 43.44
[default0]:[2023-08-25 18:07:50,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.02 (forward_moe: 21.04, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.50)
[default0]:[2023-08-25 18:07:50,310] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.88 | backward_inner: 103.63 | backward_allreduce: 11.16 | step: 43.44
[default0]:[2023-08-25 18:07:50,573] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:07:50,574] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.95 | backward_microstep: 114.48 | backward_inner_microstep: 103.16 | backward_allreduce_microstep: 11.23 | step_microstep: 43.31
[default0]:[2023-08-25 18:07:50,574] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.94 (forward_moe: 20.89, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.42)
[default0]:[2023-08-25 18:07:50,574] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.48 | backward_inner: 103.16 | backward_allreduce: 11.23 | step: 43.32
[default0]:[2023-08-25 18:07:50,831] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.41
[default0]:[2023-08-25 18:07:50,831] [INFO] [logging.py:96:log_dist] [Rank 0] step=385, skipped=0, lr=[4.194304e-07, 4.194304e-07, 4.194304e-07, 4.194304e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:50,832] [INFO] [timer.py:215:stop] epoch=0/micro_step=385/global_step=385, RunningAvgSamplesPerSec=4.906440041909142, CurrSamplesPerSec=4.8304556929370355, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:50,832] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.09 | backward_microstep: 114.35 | backward_inner_microstep: 103.14 | backward_allreduce_microstep: 11.11 | step_microstep: 44.03
[default0]:[2023-08-25 18:07:50,832] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.09 (forward_moe: 20.90, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.41)
[default0]:[2023-08-25 18:07:50,832] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.34 | backward_inner: 103.14 | backward_allreduce: 11.11 | step: 44.04
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.9532], device='cuda:0'), 'moe loss': tensor([0.3046], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      385/439453125 | consumed samples:          385 | consumed tokens:       788480 | elapsed time per iteration (ms): 264.0 | learning rate: 4.194E-07 | global batch size:     1 | lm loss: 1.019063E+01 | moe loss: 6.092272E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.788 | TFLOPs: 9.41 |
[default0]:[2023-08-25 18:07:51,088] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.43
[default0]:[2023-08-25 18:07:51,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.16 | backward_microstep: 115.10 | backward_inner_microstep: 103.90 | backward_allreduce_microstep: 11.10 | step_microstep: 43.24
[default0]:[2023-08-25 18:07:51,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.16 (forward_moe: 21.28, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.42)
[default0]:[2023-08-25 18:07:51,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.10 | backward_inner: 103.90 | backward_allreduce: 11.11 | step: 43.24
[default0]:[2023-08-25 18:07:51,334] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.35
[default0]:[2023-08-25 18:07:51,334] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.13 | backward_microstep: 110.30 | backward_inner_microstep: 99.25 | backward_allreduce_microstep: 10.96 | step_microstep: 42.03
[default0]:[2023-08-25 18:07:51,335] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.13 (forward_moe: 20.02, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.90)
[default0]:[2023-08-25 18:07:51,335] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.30 | backward_inner: 99.25 | backward_allreduce: 10.96 | step: 42.03
[default0]:[2023-08-25 18:07:51,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:51,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.46 | backward_microstep: 110.39 | backward_inner_microstep: 99.40 | backward_allreduce_microstep: 10.89 | step_microstep: 41.86
[default0]:[2023-08-25 18:07:51,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.45 (forward_moe: 20.20, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.92)
[default0]:[2023-08-25 18:07:51,580] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.39 | backward_inner: 99.41 | backward_allreduce: 10.90 | step: 41.86
[default0]:[2023-08-25 18:07:51,832] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:51,832] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 110.30 | backward_inner_microstep: 99.34 | backward_allreduce_microstep: 10.87 | step_microstep: 42.19
[default0]:[2023-08-25 18:07:51,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.00 (forward_moe: 20.13, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.90)
[default0]:[2023-08-25 18:07:51,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.30 | backward_inner: 99.35 | backward_allreduce: 10.87 | step: 42.19
[default0]:[2023-08-25 18:07:52,072] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:52,073] [INFO] [logging.py:96:log_dist] [Rank 0] step=390, skipped=0, lr=[4.248917333333334e-07, 4.248917333333334e-07, 4.248917333333334e-07, 4.248917333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:52,073] [INFO] [timer.py:215:stop] epoch=0/micro_step=390/global_step=390, RunningAvgSamplesPerSec=4.907224278420388, CurrSamplesPerSec=4.975006968537794, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:52,073] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.07 | backward_microstep: 112.05 | backward_inner_microstep: 101.07 | backward_allreduce_microstep: 10.89 | step_microstep: 42.31
[default0]:[2023-08-25 18:07:52,073] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.07 (forward_moe: 20.35, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.97)
[default0]:[2023-08-25 18:07:52,073] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.05 | backward_inner: 101.07 | backward_allreduce: 10.89 | step: 42.31
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.1301], device='cuda:0'), 'moe loss': tensor([0.3048], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      390/439453125 | consumed samples:          390 | consumed tokens:       798720 | elapsed time per iteration (ms): 249.3 | learning rate: 4.249E-07 | global batch size:     1 | lm loss: 1.022601E+01 | moe loss: 6.095591E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.011 | TFLOPs: 9.97 |
[default0]:[2023-08-25 18:07:52,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:07:52,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.18 | backward_microstep: 110.28 | backward_inner_microstep: 99.37 | backward_allreduce_microstep: 10.82 | step_microstep: 42.00
[default0]:[2023-08-25 18:07:52,404] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.17 (forward_moe: 20.01, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.89)
[default0]:[2023-08-25 18:07:52,404] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.28 | backward_inner: 99.38 | backward_allreduce: 10.82 | step: 42.00
[default0]:[2023-08-25 18:07:52,652] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.33
[default0]:[2023-08-25 18:07:52,652] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.14 | backward_microstep: 110.41 | backward_inner_microstep: 99.42 | backward_allreduce_microstep: 10.90 | step_microstep: 41.96
[default0]:[2023-08-25 18:07:52,652] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.14 (forward_moe: 20.03, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.91)
[default0]:[2023-08-25 18:07:52,653] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.41 | backward_inner: 99.43 | backward_allreduce: 10.90 | step: 41.96
[default0]:[2023-08-25 18:07:53,049] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.11 | optimizer_step: 6.49
[default0]:[2023-08-25 18:07:53,049] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.81 | backward_microstep: 115.02 | backward_inner_microstep: 103.75 | backward_allreduce_microstep: 11.17 | step_microstep: 44.34
[default0]:[2023-08-25 18:07:53,050] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.81 (forward_moe: 21.01, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.47)
[default0]:[2023-08-25 18:07:53,050] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.01 | backward_inner: 103.76 | backward_allreduce: 11.17 | step: 44.34
[default0]:[2023-08-25 18:07:53,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.12 | optimizer_step: 6.42
[default0]:[2023-08-25 18:07:53,310] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.71 | backward_microstep: 117.30 | backward_inner_microstep: 105.86 | backward_allreduce_microstep: 11.34 | step_microstep: 43.82
[default0]:[2023-08-25 18:07:53,310] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.71 (forward_moe: 21.28, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.65)
[default0]:[2023-08-25 18:07:53,310] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.30 | backward_inner: 105.87 | backward_allreduce: 11.34 | step: 43.82
[default0]:[2023-08-25 18:07:53,562] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:07:53,562] [INFO] [logging.py:96:log_dist] [Rank 0] step=395, skipped=0, lr=[4.303530666666667e-07, 4.303530666666667e-07, 4.303530666666667e-07, 4.303530666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:53,563] [INFO] [timer.py:215:stop] epoch=0/micro_step=395/global_step=395, RunningAvgSamplesPerSec=4.907204750532914, CurrSamplesPerSec=4.9507662272206305, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:53,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.92 | backward_microstep: 111.80 | backward_inner_microstep: 100.81 | backward_allreduce_microstep: 10.90 | step_microstep: 42.72
[default0]:[2023-08-25 18:07:53,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.92 (forward_moe: 20.38, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:07:53,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.80 | backward_inner: 100.81 | backward_allreduce: 10.91 | step: 42.72
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.1432], device='cuda:0'), 'moe loss': tensor([0.3042], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      395/439453125 | consumed samples:          395 | consumed tokens:       808960 | elapsed time per iteration (ms): 297.2 | learning rate: 4.304E-07 | global batch size:     1 | lm loss: 1.022865E+01 | moe loss: 6.084446E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.365 | TFLOPs: 8.36 |
[default0]:[2023-08-25 18:07:53,825] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.44
[default0]:[2023-08-25 18:07:53,826] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.80 | backward_microstep: 112.34 | backward_inner_microstep: 101.13 | backward_allreduce_microstep: 11.12 | step_microstep: 42.47
[default0]:[2023-08-25 18:07:53,826] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.80 (forward_moe: 20.40, 1st alltoall: 0.87, 2nd alltoall: 0.83, top-k: 8.12)
[default0]:[2023-08-25 18:07:53,826] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.34 | backward_inner: 101.13 | backward_allreduce: 11.12 | step: 42.47
[default0]:[2023-08-25 18:07:54,116] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.33
[default0]:[2023-08-25 18:07:54,116] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.62 | backward_microstep: 111.95 | backward_inner_microstep: 100.84 | backward_allreduce_microstep: 11.02 | step_microstep: 42.45
[default0]:[2023-08-25 18:07:54,116] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.62 (forward_moe: 20.42, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.17)
[default0]:[2023-08-25 18:07:54,116] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.95 | backward_inner: 100.84 | backward_allreduce: 11.02 | step: 42.45
[default0]:[2023-08-25 18:07:54,381] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:07:54,382] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.33 | backward_microstep: 110.37 | backward_inner_microstep: 99.44 | backward_allreduce_microstep: 10.83 | step_microstep: 41.74
[default0]:[2023-08-25 18:07:54,382] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.33 (forward_moe: 20.04, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:07:54,382] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.36 | backward_inner: 99.44 | backward_allreduce: 10.84 | step: 41.74
[default0]:[2023-08-25 18:07:54,631] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.30
[default0]:[2023-08-25 18:07:54,632] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.93 | backward_microstep: 110.38 | backward_inner_microstep: 99.38 | backward_allreduce_microstep: 10.91 | step_microstep: 42.25
[default0]:[2023-08-25 18:07:54,632] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.93 (forward_moe: 20.05, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.91)
[default0]:[2023-08-25 18:07:54,632] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.38 | backward_inner: 99.39 | backward_allreduce: 10.91 | step: 42.25
[default0]:[2023-08-25 18:07:55,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.35
[default0]:[2023-08-25 18:07:55,034] [INFO] [logging.py:96:log_dist] [Rank 0] step=400, skipped=0, lr=[4.3581440000000006e-07, 4.3581440000000006e-07, 4.3581440000000006e-07, 4.3581440000000006e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:07:55,035] [INFO] [timer.py:215:stop] epoch=0/micro_step=400/global_step=400, RunningAvgSamplesPerSec=4.908033037627517, CurrSamplesPerSec=4.9917987620189015, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:07:55,035] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.22 | backward_microstep: 110.57 | backward_inner_microstep: 99.61 | backward_allreduce_microstep: 10.86 | step_microstep: 43.00
[default0]:[2023-08-25 18:07:55,035] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.22 (forward_moe: 20.17, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.89)
[default0]:[2023-08-25 18:07:55,035] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.57 | backward_inner: 99.62 | backward_allreduce: 10.86 | step: 43.01
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.1466], device='cuda:0'), 'moe loss': tensor([0.3036], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      400/439453125 | consumed samples:          400 | consumed tokens:       819200 | elapsed time per iteration (ms): 295.6 | learning rate: 4.358E-07 | global batch size:     1 | lm loss: 1.022932E+01 | moe loss: 6.072048E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.382 | TFLOPs: 8.40 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 400 | lm loss value: 1.021375E+01 | lm loss PPL: 2.727568E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration     400 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:07:58,943] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step400 is about to be saved!
[default0]:[2023-08-25 18:07:58,945] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:58,955] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:58,955] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:58,964] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:58,964] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:58,973] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:58,974] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:58,982] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:58,983] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:58,992] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:58,992] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,000] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,001] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,009] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,009] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,018] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,019] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,029] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,029] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,038] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,038] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,046] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,047] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,055] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,056] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,065] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,065] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,074] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,074] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,084] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,084] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,093] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,094] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,103] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,103] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,112] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,113] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,121] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,121] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,130] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,131] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,139] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,140] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,148] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,149] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,157] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,158] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,166] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,167] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:07:59,168] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:07:59,170] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:07:59,170] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:07:59,446] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:07:59,448] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:08:03,107] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:08:03,115] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step400/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:08:03,115] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step400 is ready now!
[default0]:  successfully saved checkpoint at iteration     400 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.71, Latency(second): 4.175
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4175.30, 4175.30)
[default0]:[2023-08-25 18:08:03,491] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.16 | optimizer_step: 10.00
[default0]:[2023-08-25 18:08:03,492] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2314.87 | backward_microstep: 117.98 | backward_inner_microstep: 106.69 | backward_allreduce_microstep: 11.19 | step_microstep: 47.77
[default0]:[2023-08-25 18:08:03,493] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2314.77 (forward_moe: 21.47, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.77)
[default0]:[2023-08-25 18:08:03,493] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.98 | backward_inner: 106.70 | backward_allreduce: 11.19 | step: 47.77
[default0]:[2023-08-25 18:08:03,757] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.14 | optimizer_step: 6.49
[default0]:[2023-08-25 18:08:03,757] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.33 | backward_microstep: 116.84 | backward_inner_microstep: 105.73 | backward_allreduce_microstep: 11.03 | step_microstep: 43.54
[default0]:[2023-08-25 18:08:03,757] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.33 (forward_moe: 21.36, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.72)
[default0]:[2023-08-25 18:08:03,757] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.84 | backward_inner: 105.73 | backward_allreduce: 11.03 | step: 43.54
[default0]:[2023-08-25 18:08:04,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:08:04,029] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.52 | backward_microstep: 113.70 | backward_inner_microstep: 102.88 | backward_allreduce_microstep: 10.74 | step_microstep: 42.10
[default0]:[2023-08-25 18:08:04,029] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.51 (forward_moe: 20.09, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.97)
[default0]:[2023-08-25 18:08:04,029] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.70 | backward_inner: 102.88 | backward_allreduce: 10.74 | step: 42.10
[default0]:[2023-08-25 18:08:04,278] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.98 | optimizer_step: 6.38
[default0]:[2023-08-25 18:08:04,278] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.57 | backward_microstep: 111.89 | backward_inner_microstep: 100.87 | backward_allreduce_microstep: 10.92 | step_microstep: 42.48
[default0]:[2023-08-25 18:08:04,278] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.56 (forward_moe: 20.48, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.21)
[default0]:[2023-08-25 18:08:04,278] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.89 | backward_inner: 100.87 | backward_allreduce: 10.93 | step: 42.48
[default0]:[2023-08-25 18:08:04,585] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.35
[default0]:[2023-08-25 18:08:04,586] [INFO] [logging.py:96:log_dist] [Rank 0] step=405, skipped=0, lr=[4.412757333333334e-07, 4.412757333333334e-07, 4.412757333333334e-07, 4.412757333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:04,586] [INFO] [timer.py:215:stop] epoch=0/micro_step=405/global_step=405, RunningAvgSamplesPerSec=4.907037270400265, CurrSamplesPerSec=4.948050415964741, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:04,586] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.82 | backward_microstep: 111.90 | backward_inner_microstep: 100.85 | backward_allreduce_microstep: 10.96 | step_microstep: 42.84
[default0]:[2023-08-25 18:08:04,586] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.81 (forward_moe: 20.36, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.09)
[default0]:[2023-08-25 18:08:04,586] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.90 | backward_inner: 100.85 | backward_allreduce: 10.96 | step: 42.85
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.0312], device='cuda:0'), 'moe loss': tensor([0.3034], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      405/439453125 | consumed samples:          405 | consumed tokens:       829440 | elapsed time per iteration (ms): 1909.1 | learning rate: 4.413E-07 | global batch size:     1 | lm loss: 1.020625E+01 | moe loss: 6.068487E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.524 | TFLOPs: 1.30 |
[default0]:[2023-08-25 18:08:04,853] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:08:04,853] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.72 | backward_microstep: 111.97 | backward_inner_microstep: 100.91 | backward_allreduce_microstep: 10.97 | step_microstep: 42.57
[default0]:[2023-08-25 18:08:04,854] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.72 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.11)
[default0]:[2023-08-25 18:08:04,854] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.97 | backward_inner: 100.92 | backward_allreduce: 10.97 | step: 42.57
[default0]:[2023-08-25 18:08:05,103] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:05,103] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.86 | backward_microstep: 111.94 | backward_inner_microstep: 100.91 | backward_allreduce_microstep: 10.94 | step_microstep: 42.61
[default0]:[2023-08-25 18:08:05,103] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.86 (forward_moe: 20.39, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.09)
[default0]:[2023-08-25 18:08:05,103] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.94 | backward_inner: 100.92 | backward_allreduce: 10.94 | step: 42.61
[default0]:[2023-08-25 18:08:05,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:08:05,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.83 | backward_microstep: 111.93 | backward_inner_microstep: 100.89 | backward_allreduce_microstep: 10.95 | step_microstep: 42.62
[default0]:[2023-08-25 18:08:05,378] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.83 (forward_moe: 20.46, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.11)
[default0]:[2023-08-25 18:08:05,378] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.93 | backward_inner: 100.90 | backward_allreduce: 10.95 | step: 42.63
[default0]:[2023-08-25 18:08:05,629] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:08:05,629] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.67 | backward_microstep: 111.05 | backward_inner_microstep: 100.06 | backward_allreduce_microstep: 10.90 | step_microstep: 42.05
[default0]:[2023-08-25 18:08:05,629] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.67 (forward_moe: 20.16, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.99)
[default0]:[2023-08-25 18:08:05,630] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.04 | backward_inner: 100.06 | backward_allreduce: 10.90 | step: 42.06
[default0]:[2023-08-25 18:08:05,874] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:08:05,874] [INFO] [logging.py:96:log_dist] [Rank 0] step=410, skipped=0, lr=[4.4673706666666664e-07, 4.4673706666666664e-07, 4.4673706666666664e-07, 4.4673706666666664e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:05,875] [INFO] [timer.py:215:stop] epoch=0/micro_step=410/global_step=410, RunningAvgSamplesPerSec=4.907681377437085, CurrSamplesPerSec=4.977787905113197, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:05,875] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.54 | backward_microstep: 111.20 | backward_inner_microstep: 100.18 | backward_allreduce_microstep: 10.93 | step_microstep: 42.74
[default0]:[2023-08-25 18:08:05,875] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.54 (forward_moe: 20.33, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.97)
[default0]:[2023-08-25 18:08:05,875] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.20 | backward_inner: 100.18 | backward_allreduce: 10.93 | step: 42.75
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.1113], device='cuda:0'), 'moe loss': tensor([0.3036], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      410/439453125 | consumed samples:          410 | consumed tokens:       839680 | elapsed time per iteration (ms): 257.6 | learning rate: 4.467E-07 | global batch size:     1 | lm loss: 1.022227E+01 | moe loss: 6.072834E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.881 | TFLOPs: 9.64 |
[default0]:[2023-08-25 18:08:06,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:08:06,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.48 | backward_microstep: 111.22 | backward_inner_microstep: 100.20 | backward_allreduce_microstep: 10.92 | step_microstep: 42.24
[default0]:[2023-08-25 18:08:06,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.48 (forward_moe: 20.19, 1st alltoall: 0.86, 2nd alltoall: 0.83, top-k: 8.00)
[default0]:[2023-08-25 18:08:06,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.22 | backward_inner: 100.20 | backward_allreduce: 10.93 | step: 42.24
[default0]:[2023-08-25 18:08:06,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:06,404] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.39 | backward_microstep: 111.34 | backward_inner_microstep: 100.36 | backward_allreduce_microstep: 10.88 | step_microstep: 42.25
[default0]:[2023-08-25 18:08:06,404] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.39 (forward_moe: 20.13, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.97)
[default0]:[2023-08-25 18:08:06,404] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.34 | backward_inner: 100.37 | backward_allreduce: 10.89 | step: 42.25
[default0]:[2023-08-25 18:08:06,655] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:06,656] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.75 | backward_microstep: 111.15 | backward_inner_microstep: 100.15 | backward_allreduce_microstep: 10.90 | step_microstep: 42.15
[default0]:[2023-08-25 18:08:06,656] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.75 (forward_moe: 20.16, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.99)
[default0]:[2023-08-25 18:08:06,656] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.15 | backward_inner: 100.16 | backward_allreduce: 10.91 | step: 42.15
[default0]:[2023-08-25 18:08:06,919] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:06,919] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.52 | backward_microstep: 111.11 | backward_inner_microstep: 100.09 | backward_allreduce_microstep: 10.93 | step_microstep: 42.66
[default0]:[2023-08-25 18:08:06,919] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.51 (forward_moe: 20.29, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 8.03)
[default0]:[2023-08-25 18:08:06,920] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.11 | backward_inner: 100.10 | backward_allreduce: 10.93 | step: 42.66
[default0]:[2023-08-25 18:08:07,247] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:08:07,247] [INFO] [logging.py:96:log_dist] [Rank 0] step=415, skipped=0, lr=[4.521984e-07, 4.521984e-07, 4.521984e-07, 4.521984e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:07,247] [INFO] [timer.py:215:stop] epoch=0/micro_step=415/global_step=415, RunningAvgSamplesPerSec=4.9084366702745035, CurrSamplesPerSec=4.942977214927322, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:07,247] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.36 | backward_microstep: 111.55 | backward_inner_microstep: 100.36 | backward_allreduce_microstep: 11.10 | step_microstep: 43.85
[default0]:[2023-08-25 18:08:07,247] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.36 (forward_moe: 20.18, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.96)
[default0]:[2023-08-25 18:08:07,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.55 | backward_inner: 100.37 | backward_allreduce: 11.10 | step: 43.85
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.3467], device='cuda:0'), 'moe loss': tensor([0.3029], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      415/439453125 | consumed samples:          415 | consumed tokens:       849920 | elapsed time per iteration (ms): 274.3 | learning rate: 4.522E-07 | global batch size:     1 | lm loss: 1.026935E+01 | moe loss: 6.057907E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.645 | TFLOPs: 9.06 |
[default0]:[2023-08-25 18:08:07,501] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.42
[default0]:[2023-08-25 18:08:07,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.09 | backward_microstep: 117.65 | backward_inner_microstep: 106.46 | backward_allreduce_microstep: 11.10 | step_microstep: 43.63
[default0]:[2023-08-25 18:08:07,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.09 (forward_moe: 20.94, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.46)
[default0]:[2023-08-25 18:08:07,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.65 | backward_inner: 106.47 | backward_allreduce: 11.10 | step: 43.63
[default0]:[2023-08-25 18:08:07,746] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.14 | optimizer_step: 6.48
[default0]:[2023-08-25 18:08:07,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.06 | backward_microstep: 115.39 | backward_inner_microstep: 104.10 | backward_allreduce_microstep: 11.20 | step_microstep: 44.38
[default0]:[2023-08-25 18:08:07,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.06 (forward_moe: 21.18, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.53)
[default0]:[2023-08-25 18:08:07,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.39 | backward_inner: 104.11 | backward_allreduce: 11.20 | step: 44.38
[default0]:[2023-08-25 18:08:08,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.10 | optimizer_step: 6.47
[default0]:[2023-08-25 18:08:08,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.54 | backward_microstep: 115.64 | backward_inner_microstep: 104.32 | backward_allreduce_microstep: 11.22 | step_microstep: 43.67
[default0]:[2023-08-25 18:08:08,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.54 (forward_moe: 21.35, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.56)
[default0]:[2023-08-25 18:08:08,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.63 | backward_inner: 104.33 | backward_allreduce: 11.23 | step: 43.67
[default0]:[2023-08-25 18:08:08,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.10 | optimizer_step: 6.43
[default0]:[2023-08-25 18:08:08,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.36 | backward_microstep: 115.39 | backward_inner_microstep: 104.15 | backward_allreduce_microstep: 11.15 | step_microstep: 43.67
[default0]:[2023-08-25 18:08:08,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.36 (forward_moe: 21.13, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.56)
[default0]:[2023-08-25 18:08:08,269] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.39 | backward_inner: 104.15 | backward_allreduce: 11.15 | step: 43.67
[default0]:[2023-08-25 18:08:08,528] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.10 | optimizer_step: 6.47
[default0]:[2023-08-25 18:08:08,528] [INFO] [logging.py:96:log_dist] [Rank 0] step=420, skipped=0, lr=[4.576597333333333e-07, 4.576597333333333e-07, 4.576597333333333e-07, 4.576597333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:08,528] [INFO] [timer.py:215:stop] epoch=0/micro_step=420/global_step=420, RunningAvgSamplesPerSec=4.906935261521845, CurrSamplesPerSec=4.786078700983049, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:08,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.63 | backward_microstep: 115.67 | backward_inner_microstep: 104.40 | backward_allreduce_microstep: 11.17 | step_microstep: 44.08
[default0]:[2023-08-25 18:08:08,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.63 (forward_moe: 21.33, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.62)
[default0]:[2023-08-25 18:08:08,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.66 | backward_inner: 104.41 | backward_allreduce: 11.17 | step: 44.08
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.0609], device='cuda:0'), 'moe loss': tensor([0.3028], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      420/439453125 | consumed samples:          420 | consumed tokens:       860160 | elapsed time per iteration (ms): 256.1 | learning rate: 4.577E-07 | global batch size:     1 | lm loss: 1.021219E+01 | moe loss: 6.056317E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.904 | TFLOPs: 9.70 |
[default0]:[2023-08-25 18:08:09,133] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.69 | optimizer_gradients: 4.24 | optimizer_step: 6.57
[default0]:[2023-08-25 18:08:09,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.54 | backward_microstep: 119.50 | backward_inner_microstep: 107.51 | backward_allreduce_microstep: 11.89 | step_microstep: 48.47
[default0]:[2023-08-25 18:08:09,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.54 (forward_moe: 21.84, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.87)
[default0]:[2023-08-25 18:08:09,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 119.50 | backward_inner: 107.51 | backward_allreduce: 11.90 | step: 48.48
[default0]:[2023-08-25 18:08:09,446] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.18 | optimizer_step: 6.53
[default0]:[2023-08-25 18:08:09,447] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.52 | backward_microstep: 117.85 | backward_inner_microstep: 106.44 | backward_allreduce_microstep: 11.31 | step_microstep: 44.42
[default0]:[2023-08-25 18:08:09,447] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.52 (forward_moe: 21.57, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.82)
[default0]:[2023-08-25 18:08:09,447] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.85 | backward_inner: 106.45 | backward_allreduce: 11.32 | step: 44.42
[default0]:[2023-08-25 18:08:09,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 6.52
[default0]:[2023-08-25 18:08:09,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.36 | backward_microstep: 117.83 | backward_inner_microstep: 106.38 | backward_allreduce_microstep: 11.35 | step_microstep: 44.65
[default0]:[2023-08-25 18:08:09,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.36 (forward_moe: 21.58, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.83)
[default0]:[2023-08-25 18:08:09,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.83 | backward_inner: 106.39 | backward_allreduce: 11.36 | step: 44.66
[default0]:[2023-08-25 18:08:09,985] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 4.18 | optimizer_step: 6.55
[default0]:[2023-08-25 18:08:09,985] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.64 | backward_microstep: 118.30 | backward_inner_microstep: 106.87 | backward_allreduce_microstep: 11.34 | step_microstep: 44.62
[default0]:[2023-08-25 18:08:09,985] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.64 (forward_moe: 21.64, 1st alltoall: 0.92, 2nd alltoall: 0.84, top-k: 8.83)
[default0]:[2023-08-25 18:08:09,986] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 118.30 | backward_inner: 106.87 | backward_allreduce: 11.34 | step: 44.62
[default0]:[2023-08-25 18:08:10,264] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:10,264] [INFO] [logging.py:96:log_dist] [Rank 0] step=425, skipped=0, lr=[4.631210666666667e-07, 4.631210666666667e-07, 4.631210666666667e-07, 4.631210666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:10,264] [INFO] [timer.py:215:stop] epoch=0/micro_step=425/global_step=425, RunningAvgSamplesPerSec=4.904479942203015, CurrSamplesPerSec=4.900592024321252, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:10,264] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.30 | backward_microstep: 113.20 | backward_inner_microstep: 102.05 | backward_allreduce_microstep: 11.06 | step_microstep: 43.01
[default0]:[2023-08-25 18:08:10,264] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.30 (forward_moe: 20.63, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.23)
[default0]:[2023-08-25 18:08:10,264] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.20 | backward_inner: 102.05 | backward_allreduce: 11.06 | step: 43.02
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.9674], device='cuda:0'), 'moe loss': tensor([0.3022], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      425/439453125 | consumed samples:          425 | consumed tokens:       870400 | elapsed time per iteration (ms): 347.2 | learning rate: 4.631E-07 | global batch size:     1 | lm loss: 1.019347E+01 | moe loss: 6.044309E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.880 | TFLOPs: 7.16 |
[default0]:[2023-08-25 18:08:10,514] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:10,515] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.20 | backward_microstep: 113.13 | backward_inner_microstep: 102.01 | backward_allreduce_microstep: 11.02 | step_microstep: 42.93
[default0]:[2023-08-25 18:08:10,515] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.20 (forward_moe: 20.72, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.35)
[default0]:[2023-08-25 18:08:10,515] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.13 | backward_inner: 102.02 | backward_allreduce: 11.02 | step: 42.94
[default0]:[2023-08-25 18:08:10,756] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:08:10,757] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.53 | backward_microstep: 113.25 | backward_inner_microstep: 102.16 | backward_allreduce_microstep: 11.00 | step_microstep: 42.93
[default0]:[2023-08-25 18:08:10,757] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.53 (forward_moe: 20.65, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.29)
[default0]:[2023-08-25 18:08:10,757] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.25 | backward_inner: 102.16 | backward_allreduce: 11.00 | step: 42.93
[default0]:[2023-08-25 18:08:11,002] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.05 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:11,002] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.55 | backward_microstep: 113.36 | backward_inner_microstep: 102.13 | backward_allreduce_microstep: 11.13 | step_microstep: 43.20
[default0]:[2023-08-25 18:08:11,002] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.55 (forward_moe: 20.66, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:08:11,002] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.36 | backward_inner: 102.14 | backward_allreduce: 11.13 | step: 43.20
[default0]:[2023-08-25 18:08:11,436] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:11,436] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.15 | backward_microstep: 110.28 | backward_inner_microstep: 99.35 | backward_allreduce_microstep: 10.83 | step_microstep: 41.92
[default0]:[2023-08-25 18:08:11,436] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.15 (forward_moe: 20.11, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.97)
[default0]:[2023-08-25 18:08:11,436] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.28 | backward_inner: 99.35 | backward_allreduce: 10.84 | step: 41.93
[default0]:[2023-08-25 18:08:11,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:11,748] [INFO] [logging.py:96:log_dist] [Rank 0] step=430, skipped=0, lr=[4.685824e-07, 4.685824e-07, 4.685824e-07, 4.685824e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:11,749] [INFO] [timer.py:215:stop] epoch=0/micro_step=430/global_step=430, RunningAvgSamplesPerSec=4.904921269406645, CurrSamplesPerSec=5.028134654092046, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:11,749] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.02 | backward_microstep: 110.01 | backward_inner_microstep: 99.10 | backward_allreduce_microstep: 10.82 | step_microstep: 42.30
[default0]:[2023-08-25 18:08:11,749] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.02 (forward_moe: 20.06, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.84)
[default0]:[2023-08-25 18:08:11,749] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.01 | backward_inner: 99.10 | backward_allreduce: 10.82 | step: 42.31
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.1350], device='cuda:0'), 'moe loss': tensor([0.3039], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      430/439453125 | consumed samples:          430 | consumed tokens:       880640 | elapsed time per iteration (ms): 296.9 | learning rate: 4.686E-07 | global batch size:     1 | lm loss: 1.022699E+01 | moe loss: 6.078099E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.368 | TFLOPs: 8.37 |
[default0]:[2023-08-25 18:08:11,990] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.72 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:11,990] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.99 | backward_microstep: 109.92 | backward_inner_microstep: 99.01 | backward_allreduce_microstep: 10.82 | step_microstep: 42.08
[default0]:[2023-08-25 18:08:11,990] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.99 (forward_moe: 19.96, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.88)
[default0]:[2023-08-25 18:08:11,990] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.92 | backward_inner: 99.02 | backward_allreduce: 10.82 | step: 42.08
[default0]:[2023-08-25 18:08:12,236] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:12,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.79 | backward_microstep: 109.08 | backward_inner_microstep: 98.24 | backward_allreduce_microstep: 10.75 | step_microstep: 41.53
[default0]:[2023-08-25 18:08:12,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.79 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:08:12,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.24 | backward_allreduce: 10.76 | step: 41.53
[default0]:[2023-08-25 18:08:12,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:08:12,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 108.93 | backward_inner_microstep: 98.08 | backward_allreduce_microstep: 10.75 | step_microstep: 41.40
[default0]:[2023-08-25 18:08:12,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.64 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:08:12,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.93 | backward_inner: 98.09 | backward_allreduce: 10.76 | step: 41.41
[default0]:[2023-08-25 18:08:12,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:12,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.48 | backward_microstep: 108.90 | backward_inner_microstep: 97.99 | backward_allreduce_microstep: 10.81 | step_microstep: 41.47
[default0]:[2023-08-25 18:08:12,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:08:12,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 97.99 | backward_allreduce: 10.82 | step: 41.48
[default0]:[2023-08-25 18:08:12,987] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:12,987] [INFO] [logging.py:96:log_dist] [Rank 0] step=435, skipped=0, lr=[4.7404373333333337e-07, 4.7404373333333337e-07, 4.7404373333333337e-07, 4.7404373333333337e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:12,987] [INFO] [timer.py:215:stop] epoch=0/micro_step=435/global_step=435, RunningAvgSamplesPerSec=4.906749698613054, CurrSamplesPerSec=5.075901863328481, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:12,987] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.37 | backward_microstep: 109.06 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.77 | step_microstep: 42.04
[default0]:[2023-08-25 18:08:12,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.37 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:08:12,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.19 | backward_allreduce: 10.78 | step: 42.04
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.2761], device='cuda:0'), 'moe loss': tensor([0.3031], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      435/439453125 | consumed samples:          435 | consumed tokens:       890880 | elapsed time per iteration (ms): 247.6 | learning rate: 4.740E-07 | global batch size:     1 | lm loss: 1.025523E+01 | moe loss: 6.061466E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.039 | TFLOPs: 10.04 |
[default0]:[2023-08-25 18:08:13,282] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:13,284] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.48 | backward_microstep: 111.57 | backward_inner_microstep: 100.56 | backward_allreduce_microstep: 10.91 | step_microstep: 43.41
[default0]:[2023-08-25 18:08:13,284] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:08:13,285] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.57 | backward_inner: 100.57 | backward_allreduce: 10.91 | step: 43.41
[default0]:[2023-08-25 18:08:13,551] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 10.00
[default0]:[2023-08-25 18:08:13,552] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.69 | backward_microstep: 109.27 | backward_inner_microstep: 98.39 | backward_allreduce_microstep: 10.78 | step_microstep: 45.31
[default0]:[2023-08-25 18:08:13,552] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:08:13,552] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.26 | backward_inner: 98.40 | backward_allreduce: 10.78 | step: 45.32
[default0]:[2023-08-25 18:08:13,841] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:13,842] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 109.04 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.84 | step_microstep: 41.51
[default0]:[2023-08-25 18:08:13,842] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.41 (forward_moe: 19.74, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:08:13,842] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.04 | backward_inner: 98.11 | backward_allreduce: 10.85 | step: 41.52
[default0]:[2023-08-25 18:08:14,094] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.40
[default0]:[2023-08-25 18:08:14,094] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.58 | backward_microstep: 112.71 | backward_inner_microstep: 101.55 | backward_allreduce_microstep: 11.06 | step_microstep: 42.58
[default0]:[2023-08-25 18:08:14,094] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.58 (forward_moe: 20.47, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.18)
[default0]:[2023-08-25 18:08:14,094] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.71 | backward_inner: 101.56 | backward_allreduce: 11.06 | step: 42.59
[default0]:[2023-08-25 18:08:14,356] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.40
[default0]:[2023-08-25 18:08:14,357] [INFO] [logging.py:96:log_dist] [Rank 0] step=440, skipped=0, lr=[4.795050666666667e-07, 4.795050666666667e-07, 4.795050666666667e-07, 4.795050666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:14,357] [INFO] [timer.py:215:stop] epoch=0/micro_step=440/global_step=440, RunningAvgSamplesPerSec=4.907298220508761, CurrSamplesPerSec=4.897221839512602, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:14,357] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.14 | backward_microstep: 113.21 | backward_inner_microstep: 102.04 | backward_allreduce_microstep: 11.07 | step_microstep: 43.28
[default0]:[2023-08-25 18:08:14,357] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.14 (forward_moe: 20.82, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:08:14,357] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.21 | backward_inner: 102.05 | backward_allreduce: 11.07 | step: 43.28
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.9235], device='cuda:0'), 'moe loss': tensor([0.3029], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      440/439453125 | consumed samples:          440 | consumed tokens:       901120 | elapsed time per iteration (ms): 274.0 | learning rate: 4.795E-07 | global batch size:     1 | lm loss: 1.018469E+01 | moe loss: 6.058584E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.649 | TFLOPs: 9.07 |
[default0]:[2023-08-25 18:08:14,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.40
[default0]:[2023-08-25 18:08:14,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.59 | backward_microstep: 113.95 | backward_inner_microstep: 102.75 | backward_allreduce_microstep: 11.10 | step_microstep: 43.20
[default0]:[2023-08-25 18:08:14,634] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.59 (forward_moe: 20.90, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.37)
[default0]:[2023-08-25 18:08:14,634] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.95 | backward_inner: 102.76 | backward_allreduce: 11.11 | step: 43.20
[default0]:[2023-08-25 18:08:14,880] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:08:14,880] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.26 | backward_microstep: 113.57 | backward_inner_microstep: 102.47 | backward_allreduce_microstep: 11.01 | step_microstep: 43.04
[default0]:[2023-08-25 18:08:14,880] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.26 (forward_moe: 20.65, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.28)
[default0]:[2023-08-25 18:08:14,880] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.56 | backward_inner: 102.47 | backward_allreduce: 11.01 | step: 43.04
[default0]:[2023-08-25 18:08:15,128] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:08:15,129] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.53 | backward_microstep: 113.31 | backward_inner_microstep: 102.18 | backward_allreduce_microstep: 11.03 | step_microstep: 42.89
[default0]:[2023-08-25 18:08:15,129] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.53 (forward_moe: 20.83, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.26)
[default0]:[2023-08-25 18:08:15,129] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.30 | backward_inner: 102.18 | backward_allreduce: 11.03 | step: 42.89
[default0]:[2023-08-25 18:08:15,391] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.38
[default0]:[2023-08-25 18:08:15,391] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.38 | backward_microstep: 113.30 | backward_inner_microstep: 102.20 | backward_allreduce_microstep: 11.01 | step_microstep: 42.94
[default0]:[2023-08-25 18:08:15,392] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.37 (forward_moe: 20.71, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:08:15,392] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.30 | backward_inner: 102.20 | backward_allreduce: 11.01 | step: 42.95
[default0]:[2023-08-25 18:08:15,656] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.41
[default0]:[2023-08-25 18:08:15,656] [INFO] [logging.py:96:log_dist] [Rank 0] step=445, skipped=0, lr=[4.849664e-07, 4.849664e-07, 4.849664e-07, 4.849664e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:15,657] [INFO] [timer.py:215:stop] epoch=0/micro_step=445/global_step=445, RunningAvgSamplesPerSec=4.907029070546927, CurrSamplesPerSec=4.887708548674856, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:15,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.39 | backward_microstep: 113.35 | backward_inner_microstep: 102.21 | backward_allreduce_microstep: 11.04 | step_microstep: 43.30
[default0]:[2023-08-25 18:08:15,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.39 (forward_moe: 20.66, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.27)
[default0]:[2023-08-25 18:08:15,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.35 | backward_inner: 102.22 | backward_allreduce: 11.04 | step: 43.30
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.0565], device='cuda:0'), 'moe loss': tensor([0.3038], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      445/439453125 | consumed samples:          445 | consumed tokens:       911360 | elapsed time per iteration (ms): 260.7 | learning rate: 4.850E-07 | global batch size:     1 | lm loss: 1.021130E+01 | moe loss: 6.075797E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.836 | TFLOPs: 9.53 |
[default0]:[2023-08-25 18:08:16,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 6.53
[default0]:[2023-08-25 18:08:16,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.63 | backward_microstep: 117.76 | backward_inner_microstep: 106.33 | backward_allreduce_microstep: 11.33 | step_microstep: 44.64
[default0]:[2023-08-25 18:08:16,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.63 (forward_moe: 21.56, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.83)
[default0]:[2023-08-25 18:08:16,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.76 | backward_inner: 106.34 | backward_allreduce: 11.33 | step: 44.64
[default0]:[2023-08-25 18:08:17,084] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:17,084] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.93 | backward_microstep: 113.53 | backward_inner_microstep: 102.48 | backward_allreduce_microstep: 10.96 | step_microstep: 42.88
[default0]:[2023-08-25 18:08:17,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.93 (forward_moe: 20.43, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:08:17,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.53 | backward_inner: 102.49 | backward_allreduce: 10.96 | step: 42.88
[default0]:[2023-08-25 18:08:17,328] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:17,329] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.84 | backward_microstep: 112.39 | backward_inner_microstep: 101.28 | backward_allreduce_microstep: 11.02 | step_microstep: 42.58
[default0]:[2023-08-25 18:08:17,329] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.84 (forward_moe: 20.42, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:08:17,329] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.39 | backward_inner: 101.28 | backward_allreduce: 11.02 | step: 42.58
[default0]:[2023-08-25 18:08:17,589] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.38
[default0]:[2023-08-25 18:08:17,590] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.88 | backward_microstep: 119.09 | backward_inner_microstep: 108.05 | backward_allreduce_microstep: 10.95 | step_microstep: 43.15
[default0]:[2023-08-25 18:08:17,590] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.88 (forward_moe: 20.44, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:08:17,590] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 119.09 | backward_inner: 108.05 | backward_allreduce: 10.95 | step: 43.16
[default0]:[2023-08-25 18:08:17,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:17,858] [INFO] [logging.py:96:log_dist] [Rank 0] step=450, skipped=0, lr=[4.904277333333333e-07, 4.904277333333333e-07, 4.904277333333333e-07, 4.904277333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:17,858] [INFO] [timer.py:215:stop] epoch=0/micro_step=450/global_step=450, RunningAvgSamplesPerSec=4.906155067991521, CurrSamplesPerSec=4.888318069615606, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:17,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.09 | backward_microstep: 113.84 | backward_inner_microstep: 102.75 | backward_allreduce_microstep: 10.99 | step_microstep: 43.09
[default0]:[2023-08-25 18:08:17,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.09 (forward_moe: 20.95, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.21)
[default0]:[2023-08-25 18:08:17,859] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.83 | backward_inner: 102.75 | backward_allreduce: 11.00 | step: 43.09
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.9216], device='cuda:0'), 'moe loss': tensor([0.3040], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      450/439453125 | consumed samples:          450 | consumed tokens:       921600 | elapsed time per iteration (ms): 439.5 | learning rate: 4.904E-07 | global batch size:     1 | lm loss: 1.018431E+01 | moe loss: 6.080415E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.276 | TFLOPs: 5.65 |
[default0]:[2023-08-25 18:08:18,106] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:18,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.97 | backward_microstep: 112.28 | backward_inner_microstep: 101.20 | backward_allreduce_microstep: 10.98 | step_microstep: 42.81
[default0]:[2023-08-25 18:08:18,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.96 (forward_moe: 20.42, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:08:18,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.27 | backward_inner: 101.20 | backward_allreduce: 10.99 | step: 42.82
[default0]:[2023-08-25 18:08:18,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:18,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.95 | backward_microstep: 112.55 | backward_inner_microstep: 101.34 | backward_allreduce_microstep: 11.11 | step_microstep: 42.57
[default0]:[2023-08-25 18:08:18,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.95 (forward_moe: 20.41, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.12)
[default0]:[2023-08-25 18:08:18,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.54 | backward_inner: 101.35 | backward_allreduce: 11.12 | step: 42.57
[default0]:[2023-08-25 18:08:18,601] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.38
[default0]:[2023-08-25 18:08:18,601] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.20 | backward_microstep: 112.16 | backward_inner_microstep: 101.13 | backward_allreduce_microstep: 10.94 | step_microstep: 42.51
[default0]:[2023-08-25 18:08:18,601] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.20 (forward_moe: 20.43, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:08:18,601] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.16 | backward_inner: 101.14 | backward_allreduce: 10.94 | step: 42.51
[default0]:[2023-08-25 18:08:18,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.43
[default0]:[2023-08-25 18:08:18,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.21 | backward_microstep: 114.61 | backward_inner_microstep: 103.36 | backward_allreduce_microstep: 11.16 | step_microstep: 43.25
[default0]:[2023-08-25 18:08:18,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.22 (forward_moe: 20.94, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.44)
[default0]:[2023-08-25 18:08:18,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.61 | backward_inner: 103.36 | backward_allreduce: 11.16 | step: 43.25
[default0]:[2023-08-25 18:08:19,117] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:08:19,117] [INFO] [logging.py:96:log_dist] [Rank 0] step=455, skipped=0, lr=[4.958890666666667e-07, 4.958890666666667e-07, 4.958890666666667e-07, 4.958890666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:19,118] [INFO] [timer.py:215:stop] epoch=0/micro_step=455/global_step=455, RunningAvgSamplesPerSec=4.906092621363085, CurrSamplesPerSec=4.879895102657686, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:19,118] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.49 | backward_microstep: 113.59 | backward_inner_microstep: 102.09 | backward_allreduce_microstep: 11.40 | step_microstep: 43.33
[default0]:[2023-08-25 18:08:19,118] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.48 (forward_moe: 20.64, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.28)
[default0]:[2023-08-25 18:08:19,118] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.59 | backward_inner: 102.10 | backward_allreduce: 11.41 | step: 43.33
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.0426], device='cuda:0'), 'moe loss': tensor([0.3034], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      455/439453125 | consumed samples:          455 | consumed tokens:       931840 | elapsed time per iteration (ms): 252.4 | learning rate: 4.959E-07 | global batch size:     1 | lm loss: 1.020852E+01 | moe loss: 6.068565E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.962 | TFLOPs: 9.85 |
[default0]:[2023-08-25 18:08:19,384] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:19,385] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.44 | backward_microstep: 113.45 | backward_inner_microstep: 102.32 | backward_allreduce_microstep: 11.04 | step_microstep: 42.90
[default0]:[2023-08-25 18:08:19,385] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.44 (forward_moe: 20.66, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.28)
[default0]:[2023-08-25 18:08:19,385] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.45 | backward_inner: 102.33 | backward_allreduce: 11.04 | step: 42.91
[default0]:[2023-08-25 18:08:19,639] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:08:19,639] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.26 | backward_microstep: 113.14 | backward_inner_microstep: 101.97 | backward_allreduce_microstep: 11.06 | step_microstep: 42.81
[default0]:[2023-08-25 18:08:19,640] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.26 (forward_moe: 20.60, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.23)
[default0]:[2023-08-25 18:08:19,640] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.13 | backward_inner: 101.98 | backward_allreduce: 11.06 | step: 42.81
[default0]:[2023-08-25 18:08:19,891] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:19,891] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.45 | backward_microstep: 114.74 | backward_inner_microstep: 103.29 | backward_allreduce_microstep: 11.35 | step_microstep: 42.98
[default0]:[2023-08-25 18:08:19,892] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.45 (forward_moe: 20.88, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.09)
[default0]:[2023-08-25 18:08:19,892] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.74 | backward_inner: 103.30 | backward_allreduce: 11.35 | step: 42.98
[default0]:[2023-08-25 18:08:20,148] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.35
[default0]:[2023-08-25 18:08:20,148] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.82 | backward_microstep: 109.79 | backward_inner_microstep: 98.73 | backward_allreduce_microstep: 10.96 | step_microstep: 41.89
[default0]:[2023-08-25 18:08:20,148] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.82 (forward_moe: 19.99, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.92)
[default0]:[2023-08-25 18:08:20,148] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.79 | backward_inner: 98.74 | backward_allreduce: 10.96 | step: 41.89
[default0]:[2023-08-25 18:08:20,386] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:20,386] [INFO] [logging.py:96:log_dist] [Rank 0] step=460, skipped=0, lr=[5.013504e-07, 5.013504e-07, 5.013504e-07, 5.013504e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:20,386] [INFO] [timer.py:215:stop] epoch=0/micro_step=460/global_step=460, RunningAvgSamplesPerSec=4.906499099192282, CurrSamplesPerSec=5.040297829488292, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:20,386] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.75 | backward_microstep: 109.94 | backward_inner_microstep: 98.99 | backward_allreduce_microstep: 10.85 | step_microstep: 42.17
[default0]:[2023-08-25 18:08:20,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.75 (forward_moe: 20.08, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.82)
[default0]:[2023-08-25 18:08:20,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.93 | backward_inner: 99.00 | backward_allreduce: 10.85 | step: 42.17
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.1874], device='cuda:0'), 'moe loss': tensor([0.3032], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      460/439453125 | consumed samples:          460 | consumed tokens:       942080 | elapsed time per iteration (ms): 253.3 | learning rate: 5.014E-07 | global batch size:     1 | lm loss: 1.023748E+01 | moe loss: 6.063754E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.947 | TFLOPs: 9.81 |
[default0]:[2023-08-25 18:08:20,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:08:20,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.09 | backward_microstep: 109.64 | backward_inner_microstep: 98.75 | backward_allreduce_microstep: 10.79 | step_microstep: 41.66
[default0]:[2023-08-25 18:08:20,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.09 (forward_moe: 20.00, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.91)
[default0]:[2023-08-25 18:08:20,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.64 | backward_inner: 98.76 | backward_allreduce: 10.79 | step: 41.66
[default0]:[2023-08-25 18:08:20,893] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:20,893] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.51 | backward_microstep: 108.98 | backward_inner_microstep: 98.11 | backward_allreduce_microstep: 10.77 | step_microstep: 41.68
[default0]:[2023-08-25 18:08:20,893] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.51 (forward_moe: 19.77, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:08:20,893] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.97 | backward_inner: 98.11 | backward_allreduce: 10.78 | step: 41.68
[default0]:[2023-08-25 18:08:21,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.04 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:21,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 109.43 | backward_inner_microstep: 98.47 | backward_allreduce_microstep: 10.85 | step_microstep: 41.92
[default0]:[2023-08-25 18:08:21,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.74)
[default0]:[2023-08-25 18:08:21,146] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.42 | backward_inner: 98.48 | backward_allreduce: 10.85 | step: 41.93
[default0]:[2023-08-25 18:08:21,468] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:21,468] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.74 | backward_microstep: 109.22 | backward_inner_microstep: 98.32 | backward_allreduce_microstep: 10.80 | step_microstep: 41.39
[default0]:[2023-08-25 18:08:21,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.74 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:08:21,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.22 | backward_inner: 98.33 | backward_allreduce: 10.81 | step: 41.39
[default0]:[2023-08-25 18:08:21,818] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:21,818] [INFO] [logging.py:96:log_dist] [Rank 0] step=465, skipped=0, lr=[5.068117333333334e-07, 5.068117333333334e-07, 5.068117333333334e-07, 5.068117333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:21,819] [INFO] [timer.py:215:stop] epoch=0/micro_step=465/global_step=465, RunningAvgSamplesPerSec=4.908146378148663, CurrSamplesPerSec=5.079916285559259, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:21,819] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.32 | backward_microstep: 109.08 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.82 | step_microstep: 41.91
[default0]:[2023-08-25 18:08:21,819] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.32 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:08:21,819] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.17 | backward_allreduce: 10.83 | step: 41.92
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.2938], device='cuda:0'), 'moe loss': tensor([0.3029], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      465/439453125 | consumed samples:          465 | consumed tokens:       952320 | elapsed time per iteration (ms): 286.6 | learning rate: 5.068E-07 | global batch size:     1 | lm loss: 1.025876E+01 | moe loss: 6.058907E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.489 | TFLOPs: 8.67 |
[default0]:[2023-08-25 18:08:22,087] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:08:22,087] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.67 | backward_microstep: 109.53 | backward_inner_microstep: 98.31 | backward_allreduce_microstep: 11.13 | step_microstep: 42.77
[default0]:[2023-08-25 18:08:22,087] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.67 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.75)
[default0]:[2023-08-25 18:08:22,087] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.53 | backward_inner: 98.32 | backward_allreduce: 11.13 | step: 42.77
[default0]:[2023-08-25 18:08:22,333] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:22,334] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.56 | backward_microstep: 109.27 | backward_inner_microstep: 98.32 | backward_allreduce_microstep: 10.85 | step_microstep: 41.56
[default0]:[2023-08-25 18:08:22,334] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.56 (forward_moe: 19.81, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:08:22,334] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.27 | backward_inner: 98.33 | backward_allreduce: 10.86 | step: 41.57
[default0]:[2023-08-25 18:08:22,591] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:22,591] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.78 | backward_microstep: 111.52 | backward_inner_microstep: 100.46 | backward_allreduce_microstep: 10.97 | step_microstep: 42.65
[default0]:[2023-08-25 18:08:22,591] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.78 (forward_moe: 20.32, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.03)
[default0]:[2023-08-25 18:08:22,592] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.52 | backward_inner: 100.47 | backward_allreduce: 10.97 | step: 42.65
[default0]:[2023-08-25 18:08:22,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.39
[default0]:[2023-08-25 18:08:22,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.27 | backward_microstep: 112.95 | backward_inner_microstep: 101.86 | backward_allreduce_microstep: 11.00 | step_microstep: 42.96
[default0]:[2023-08-25 18:08:22,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.27 (forward_moe: 20.70, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:08:22,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.95 | backward_inner: 101.87 | backward_allreduce: 11.00 | step: 42.97
[default0]:[2023-08-25 18:08:23,138] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.71 | optimizer_gradients: 4.04 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:23,139] [INFO] [logging.py:96:log_dist] [Rank 0] step=470, skipped=0, lr=[5.122730666666667e-07, 5.122730666666667e-07, 5.122730666666667e-07, 5.122730666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:23,139] [INFO] [timer.py:215:stop] epoch=0/micro_step=470/global_step=470, RunningAvgSamplesPerSec=4.90911053209455, CurrSamplesPerSec=5.021074053678742, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:23,139] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.93 | backward_microstep: 110.23 | backward_inner_microstep: 99.29 | backward_allreduce_microstep: 10.85 | step_microstep: 42.50
[default0]:[2023-08-25 18:08:23,139] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.93 (forward_moe: 20.07, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:08:23,139] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.23 | backward_inner: 99.29 | backward_allreduce: 10.85 | step: 42.51
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.8982], device='cuda:0'), 'moe loss': tensor([0.3021], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      470/439453125 | consumed samples:          470 | consumed tokens:       962560 | elapsed time per iteration (ms): 264.2 | learning rate: 5.123E-07 | global batch size:     1 | lm loss: 1.017963E+01 | moe loss: 6.041071E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.785 | TFLOPs: 9.41 |
[default0]:[2023-08-25 18:08:23,386] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:23,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.89 | backward_microstep: 112.69 | backward_inner_microstep: 101.75 | backward_allreduce_microstep: 10.85 | step_microstep: 42.57
[default0]:[2023-08-25 18:08:23,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.89 (forward_moe: 20.01, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.88)
[default0]:[2023-08-25 18:08:23,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.69 | backward_inner: 101.75 | backward_allreduce: 10.85 | step: 42.57
[default0]:[2023-08-25 18:08:23,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.95 | optimizer_step: 9.95
[default0]:[2023-08-25 18:08:23,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.12 | backward_microstep: 110.31 | backward_inner_microstep: 99.41 | backward_allreduce_microstep: 10.81 | step_microstep: 45.57
[default0]:[2023-08-25 18:08:23,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.11 (forward_moe: 20.16, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.85)
[default0]:[2023-08-25 18:08:23,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.31 | backward_inner: 99.41 | backward_allreduce: 10.81 | step: 45.57
[default0]:[2023-08-25 18:08:23,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.39
[default0]:[2023-08-25 18:08:23,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.91 | backward_microstep: 110.02 | backward_inner_microstep: 99.08 | backward_allreduce_microstep: 10.85 | step_microstep: 41.85
[default0]:[2023-08-25 18:08:23,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.91 (forward_moe: 19.95, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.86)
[default0]:[2023-08-25 18:08:23,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.01 | backward_inner: 99.08 | backward_allreduce: 10.85 | step: 41.85
[default0]:[2023-08-25 18:08:24,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:08:24,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.29 | backward_microstep: 110.14 | backward_inner_microstep: 99.17 | backward_allreduce_microstep: 10.87 | step_microstep: 41.73
[default0]:[2023-08-25 18:08:24,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.29 (forward_moe: 19.95, 1st alltoall: 0.89, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:08:24,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.13 | backward_inner: 99.18 | backward_allreduce: 10.87 | step: 41.73
[default0]:[2023-08-25 18:08:24,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:24,401] [INFO] [logging.py:96:log_dist] [Rank 0] step=475, skipped=0, lr=[5.177344000000001e-07, 5.177344000000001e-07, 5.177344000000001e-07, 5.177344000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:24,401] [INFO] [timer.py:215:stop] epoch=0/micro_step=475/global_step=475, RunningAvgSamplesPerSec=4.9099042914475035, CurrSamplesPerSec=5.033535268195739, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:24,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.87 | backward_microstep: 110.02 | backward_inner_microstep: 99.06 | backward_allreduce_microstep: 10.86 | step_microstep: 42.23
[default0]:[2023-08-25 18:08:24,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.86 (forward_moe: 19.95, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.85)
[default0]:[2023-08-25 18:08:24,402] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.02 | backward_inner: 99.06 | backward_allreduce: 10.87 | step: 42.24
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.9034], device='cuda:0'), 'moe loss': tensor([0.3017], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      475/439453125 | consumed samples:          475 | consumed tokens:       972800 | elapsed time per iteration (ms): 252.3 | learning rate: 5.177E-07 | global batch size:     1 | lm loss: 1.018067E+01 | moe loss: 6.033224E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.964 | TFLOPs: 9.85 |
[default0]:[2023-08-25 18:08:24,666] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:24,666] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.01 | backward_microstep: 110.07 | backward_inner_microstep: 99.11 | backward_allreduce_microstep: 10.86 | step_microstep: 41.73
[default0]:[2023-08-25 18:08:24,666] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.01 (forward_moe: 19.93, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:08:24,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.07 | backward_inner: 99.12 | backward_allreduce: 10.87 | step: 41.73
[default0]:[2023-08-25 18:08:25,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:25,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.50 | backward_microstep: 109.12 | backward_inner_microstep: 98.24 | backward_allreduce_microstep: 10.78 | step_microstep: 41.60
[default0]:[2023-08-25 18:08:25,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.50 (forward_moe: 19.76, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:08:25,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.24 | backward_allreduce: 10.78 | step: 41.60
[default0]:[2023-08-25 18:08:25,270] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:25,270] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.89 | backward_microstep: 109.27 | backward_inner_microstep: 98.36 | backward_allreduce_microstep: 10.81 | step_microstep: 41.54
[default0]:[2023-08-25 18:08:25,270] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.89 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:08:25,270] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.26 | backward_inner: 98.36 | backward_allreduce: 10.81 | step: 41.55
[default0]:[2023-08-25 18:08:25,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:25,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 109.00 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.78 | step_microstep: 41.45
[default0]:[2023-08-25 18:08:25,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.75)
[default0]:[2023-08-25 18:08:25,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.14 | backward_allreduce: 10.78 | step: 41.45
[default0]:[2023-08-25 18:08:25,761] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.33
[default0]:[2023-08-25 18:08:25,761] [INFO] [logging.py:96:log_dist] [Rank 0] step=480, skipped=0, lr=[5.231957333333334e-07, 5.231957333333334e-07, 5.231957333333334e-07, 5.231957333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:25,761] [INFO] [timer.py:215:stop] epoch=0/micro_step=480/global_step=480, RunningAvgSamplesPerSec=4.911465374998471, CurrSamplesPerSec=5.06561513052615, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:25,761] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.67 | backward_microstep: 109.28 | backward_inner_microstep: 98.41 | backward_allreduce_microstep: 10.79 | step_microstep: 41.94
[default0]:[2023-08-25 18:08:25,762] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.67 (forward_moe: 19.99, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:08:25,762] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.28 | backward_inner: 98.41 | backward_allreduce: 10.79 | step: 41.94
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.8876], device='cuda:0'), 'moe loss': tensor([0.3020], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      480/439453125 | consumed samples:          480 | consumed tokens:       983040 | elapsed time per iteration (ms): 271.9 | learning rate: 5.232E-07 | global batch size:     1 | lm loss: 1.017752E+01 | moe loss: 6.040829E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.678 | TFLOPs: 9.14 |
[default0]:[2023-08-25 18:08:26,003] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:26,003] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 109.32 | backward_inner_microstep: 98.42 | backward_allreduce_microstep: 10.80 | step_microstep: 41.64
[default0]:[2023-08-25 18:08:26,003] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.75)
[default0]:[2023-08-25 18:08:26,004] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.31 | backward_inner: 98.43 | backward_allreduce: 10.81 | step: 41.64
[default0]:[2023-08-25 18:08:26,239] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.29
[default0]:[2023-08-25 18:08:26,240] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 109.33 | backward_inner_microstep: 98.45 | backward_allreduce_microstep: 10.78 | step_microstep: 41.58
[default0]:[2023-08-25 18:08:26,240] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.85, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:08:26,240] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.33 | backward_inner: 98.45 | backward_allreduce: 10.79 | step: 41.58
[default0]:[2023-08-25 18:08:26,479] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.28
[default0]:[2023-08-25 18:08:26,479] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.62 | backward_microstep: 109.32 | backward_inner_microstep: 98.41 | backward_allreduce_microstep: 10.81 | step_microstep: 41.50
[default0]:[2023-08-25 18:08:26,479] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.86)
[default0]:[2023-08-25 18:08:26,479] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.32 | backward_inner: 98.42 | backward_allreduce: 10.82 | step: 41.51
[default0]:[2023-08-25 18:08:26,961] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:26,961] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.31 | backward_microstep: 108.96 | backward_inner_microstep: 98.07 | backward_allreduce_microstep: 10.79 | step_microstep: 41.56
[default0]:[2023-08-25 18:08:26,962] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.31 (forward_moe: 19.75, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:08:26,962] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.07 | backward_allreduce: 10.80 | step: 41.56
[default0]:[2023-08-25 18:08:27,222] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:27,222] [INFO] [logging.py:96:log_dist] [Rank 0] step=485, skipped=0, lr=[5.286570666666667e-07, 5.286570666666667e-07, 5.286570666666667e-07, 5.286570666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:27,223] [INFO] [timer.py:215:stop] epoch=0/micro_step=485/global_step=485, RunningAvgSamplesPerSec=4.912997102024845, CurrSamplesPerSec=5.029461104842394, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:27,223] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.97 | backward_microstep: 110.51 | backward_inner_microstep: 99.45 | backward_allreduce_microstep: 10.96 | step_microstep: 41.82
[default0]:[2023-08-25 18:08:27,223] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.97 (forward_moe: 19.78, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:08:27,223] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.50 | backward_inner: 99.46 | backward_allreduce: 10.96 | step: 41.83
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.5458], device='cuda:0'), 'moe loss': tensor([0.3035], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      485/439453125 | consumed samples:          485 | consumed tokens:       993280 | elapsed time per iteration (ms): 292.2 | learning rate: 5.287E-07 | global batch size:     1 | lm loss: 1.010916E+01 | moe loss: 6.070692E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.423 | TFLOPs: 8.50 |
[default0]:[2023-08-25 18:08:27,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:27,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.42 | backward_microstep: 109.08 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.77 | step_microstep: 41.54
[default0]:[2023-08-25 18:08:27,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.42 (forward_moe: 19.86, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:08:27,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.22 | backward_allreduce: 10.78 | step: 41.55
[default0]:[2023-08-25 18:08:27,731] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:27,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.58 | backward_microstep: 109.18 | backward_inner_microstep: 98.33 | backward_allreduce_microstep: 10.75 | step_microstep: 41.91
[default0]:[2023-08-25 18:08:27,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.59 (forward_moe: 19.93, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:08:27,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.17 | backward_inner: 98.33 | backward_allreduce: 10.75 | step: 41.91
[default0]:[2023-08-25 18:08:27,973] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:08:27,973] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.43 | backward_microstep: 109.05 | backward_inner_microstep: 98.14 | backward_allreduce_microstep: 10.82 | step_microstep: 41.47
[default0]:[2023-08-25 18:08:27,973] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.42 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:08:27,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.14 | backward_allreduce: 10.82 | step: 41.48
[default0]:[2023-08-25 18:08:28,224] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:28,224] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.54 | backward_microstep: 109.20 | backward_inner_microstep: 98.06 | backward_allreduce_microstep: 11.04 | step_microstep: 41.41
[default0]:[2023-08-25 18:08:28,224] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.54 (forward_moe: 19.71, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:08:28,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.19 | backward_inner: 98.06 | backward_allreduce: 11.05 | step: 41.41
[default0]:[2023-08-25 18:08:28,528] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.35
[default0]:[2023-08-25 18:08:28,528] [INFO] [logging.py:96:log_dist] [Rank 0] step=490, skipped=0, lr=[5.341184e-07, 5.341184e-07, 5.341184e-07, 5.341184e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:28,529] [INFO] [timer.py:215:stop] epoch=0/micro_step=490/global_step=490, RunningAvgSamplesPerSec=4.914162046118607, CurrSamplesPerSec=4.947997881268455, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:28,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.77 | backward_microstep: 111.98 | backward_inner_microstep: 100.91 | backward_allreduce_microstep: 10.97 | step_microstep: 42.81
[default0]:[2023-08-25 18:08:28,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.77 (forward_moe: 20.49, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.09)
[default0]:[2023-08-25 18:08:28,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.97 | backward_inner: 100.92 | backward_allreduce: 10.97 | step: 42.81
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.8555], device='cuda:0'), 'moe loss': tensor([0.3034], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      490/439453125 | consumed samples:          490 | consumed tokens:      1003520 | elapsed time per iteration (ms): 261.8 | learning rate: 5.341E-07 | global batch size:     1 | lm loss: 1.017109E+01 | moe loss: 6.068326E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.819 | TFLOPs: 9.49 |
[default0]:[2023-08-25 18:08:28,784] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:28,784] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.99 | backward_microstep: 112.34 | backward_inner_microstep: 101.26 | backward_allreduce_microstep: 10.98 | step_microstep: 42.66
[default0]:[2023-08-25 18:08:28,784] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.99 (forward_moe: 20.44, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.16)
[default0]:[2023-08-25 18:08:28,784] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.34 | backward_inner: 101.26 | backward_allreduce: 10.99 | step: 42.66
[default0]:[2023-08-25 18:08:29,061] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:08:29,061] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.19 | backward_microstep: 113.64 | backward_inner_microstep: 102.51 | backward_allreduce_microstep: 11.04 | step_microstep: 43.13
[default0]:[2023-08-25 18:08:29,062] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.19 (forward_moe: 20.74, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.35)
[default0]:[2023-08-25 18:08:29,062] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.64 | backward_inner: 102.51 | backward_allreduce: 11.04 | step: 43.14
[default0]:[2023-08-25 18:08:29,311] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:08:29,311] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.72 | backward_microstep: 114.48 | backward_inner_microstep: 103.32 | backward_allreduce_microstep: 11.07 | step_microstep: 43.23
[default0]:[2023-08-25 18:08:29,312] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.72 (forward_moe: 20.82, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.37)
[default0]:[2023-08-25 18:08:29,312] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.48 | backward_inner: 103.32 | backward_allreduce: 11.07 | step: 43.24
[default0]:[2023-08-25 18:08:29,554] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:08:29,555] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.14 | backward_microstep: 112.71 | backward_inner_microstep: 101.65 | backward_allreduce_microstep: 10.97 | step_microstep: 42.60
[default0]:[2023-08-25 18:08:29,555] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.13 (forward_moe: 20.56, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:08:29,555] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.71 | backward_inner: 101.66 | backward_allreduce: 10.97 | step: 42.60
[default0]:[2023-08-25 18:08:29,837] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:08:29,837] [INFO] [logging.py:96:log_dist] [Rank 0] step=495, skipped=0, lr=[5.395797333333334e-07, 5.395797333333334e-07, 5.395797333333334e-07, 5.395797333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:29,837] [INFO] [timer.py:215:stop] epoch=0/micro_step=495/global_step=495, RunningAvgSamplesPerSec=4.913994555178523, CurrSamplesPerSec=4.911501025789952, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:29,837] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.21 | backward_microstep: 112.66 | backward_inner_microstep: 101.50 | backward_allreduce_microstep: 11.07 | step_microstep: 43.17
[default0]:[2023-08-25 18:08:29,837] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.21 (forward_moe: 20.55, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:08:29,838] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.66 | backward_inner: 101.51 | backward_allreduce: 11.07 | step: 43.18
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.6728], device='cuda:0'), 'moe loss': tensor([0.3042], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      495/439453125 | consumed samples:          495 | consumed tokens:      1013760 | elapsed time per iteration (ms): 261.1 | learning rate: 5.396E-07 | global batch size:     1 | lm loss: 1.013455E+01 | moe loss: 6.084016E-02 | loss scale: 2048.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.831 | TFLOPs: 9.52 |
[default0]:[2023-08-25 18:08:30,126] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:08:30,126] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.08 | backward_microstep: 112.80 | backward_inner_microstep: 101.68 | backward_allreduce_microstep: 11.03 | step_microstep: 42.86
[default0]:[2023-08-25 18:08:30,126] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.08 (forward_moe: 20.52, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.19)
[default0]:[2023-08-25 18:08:30,127] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.79 | backward_inner: 101.68 | backward_allreduce: 11.03 | step: 42.87
[default0]:[2023-08-25 18:08:30,363] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.41
[default0]:[2023-08-25 18:08:30,363] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.46 | backward_microstep: 112.93 | backward_inner_microstep: 101.82 | backward_allreduce_microstep: 11.01 | step_microstep: 42.81
[default0]:[2023-08-25 18:08:30,363] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.46 (forward_moe: 20.51, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:08:30,363] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.93 | backward_inner: 101.83 | backward_allreduce: 11.02 | step: 42.81
[default0]:[2023-08-25 18:08:30,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:30,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.10 | backward_microstep: 112.66 | backward_inner_microstep: 101.54 | backward_allreduce_microstep: 11.02 | step_microstep: 42.89
[default0]:[2023-08-25 18:08:30,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.10 (forward_moe: 20.51, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.19)
[default0]:[2023-08-25 18:08:30,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.66 | backward_inner: 101.55 | backward_allreduce: 11.02 | step: 42.89
[default0]:[2023-08-25 18:08:30,900] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:08:30,901] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.27 | backward_microstep: 112.60 | backward_inner_microstep: 101.51 | backward_allreduce_microstep: 10.99 | step_microstep: 42.72
[default0]:[2023-08-25 18:08:30,901] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.27 (forward_moe: 20.50, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:08:30,901] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.60 | backward_inner: 101.52 | backward_allreduce: 11.00 | step: 42.73
[default0]:[2023-08-25 18:08:31,165] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.92 | optimizer_step: 6.60
[default0]:[2023-08-25 18:08:31,165] [INFO] [logging.py:96:log_dist] [Rank 0] step=500, skipped=0, lr=[5.450410666666667e-07, 5.450410666666667e-07, 5.450410666666667e-07, 5.450410666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:31,166] [INFO] [timer.py:215:stop] epoch=0/micro_step=500/global_step=500, RunningAvgSamplesPerSec=4.914160112099396, CurrSamplesPerSec=5.009123013185913, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:31,166] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.30 | backward_microstep: 109.96 | backward_inner_microstep: 98.79 | backward_allreduce_microstep: 11.08 | step_microstep: 42.83
[default0]:[2023-08-25 18:08:31,166] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.30 (forward_moe: 20.01, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.81)
[default0]:[2023-08-25 18:08:31,166] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.96 | backward_inner: 98.80 | backward_allreduce: 11.08 | step: 42.83
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.7740], device='cuda:0'), 'moe loss': tensor([0.3033], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      500/439453125 | consumed samples:          500 | consumed tokens:      1024000 | elapsed time per iteration (ms): 266.0 | learning rate: 5.450E-07 | global batch size:     1 | lm loss: 1.015480E+01 | moe loss: 6.066029E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.759 | TFLOPs: 9.34 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 500 | lm loss value: 1.010623E+01 | lm loss PPL: 2.449518E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration     500 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:08:35,003] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step500 is about to be saved!
[default0]:[2023-08-25 18:08:35,005] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,015] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,015] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,024] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,024] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,033] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,033] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,042] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,043] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,052] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,052] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,062] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,062] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,070] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,071] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,080] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,081] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,089] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,089] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,098] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,098] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,107] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,107] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,115] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,116] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,125] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,125] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,134] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,134] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,143] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,143] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,152] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,153] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,161] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,161] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,170] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,170] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,179] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,179] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,188] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,189] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,197] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,197] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,206] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,206] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,215] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,215] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,224] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,224] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:08:35,226] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:08:35,227] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:08:35,227] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:08:35,499] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:08:35,501] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:08:39,143] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:08:39,151] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step500/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:08:39,152] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
[default0]:  successfully saved checkpoint at iteration     500 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.71, Latency(second): 4.152
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4152.44, 4152.44)
[default0]:[2023-08-25 18:08:39,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.19 | optimizer_step: 10.17
[default0]:[2023-08-25 18:08:39,428] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2278.59 | backward_microstep: 117.40 | backward_inner_microstep: 106.21 | backward_allreduce_microstep: 11.09 | step_microstep: 47.52
[default0]:[2023-08-25 18:08:39,428] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2278.51 (forward_moe: 21.61, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.78)
[default0]:[2023-08-25 18:08:39,429] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.39 | backward_inner: 106.21 | backward_allreduce: 11.10 | step: 47.52
[default0]:[2023-08-25 18:08:39,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.14 | optimizer_step: 6.51
[default0]:[2023-08-25 18:08:39,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.93 | backward_microstep: 116.82 | backward_inner_microstep: 105.67 | backward_allreduce_microstep: 11.07 | step_microstep: 43.64
[default0]:[2023-08-25 18:08:39,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.93 (forward_moe: 21.51, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.75)
[default0]:[2023-08-25 18:08:39,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.82 | backward_inner: 105.67 | backward_allreduce: 11.07 | step: 43.64
[default0]:[2023-08-25 18:08:39,944] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.24 | optimizer_step: 6.51
[default0]:[2023-08-25 18:08:39,944] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.07 | backward_microstep: 116.68 | backward_inner_microstep: 105.54 | backward_allreduce_microstep: 11.05 | step_microstep: 43.68
[default0]:[2023-08-25 18:08:39,944] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.07 (forward_moe: 21.37, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.73)
[default0]:[2023-08-25 18:08:39,944] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.68 | backward_inner: 105.54 | backward_allreduce: 11.05 | step: 43.68
[default0]:[2023-08-25 18:08:40,202] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.45
[default0]:[2023-08-25 18:08:40,203] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.85 | backward_microstep: 114.14 | backward_inner_microstep: 102.99 | backward_allreduce_microstep: 11.05 | step_microstep: 43.33
[default0]:[2023-08-25 18:08:40,203] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.85 (forward_moe: 20.83, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.42)
[default0]:[2023-08-25 18:08:40,203] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.14 | backward_inner: 103.00 | backward_allreduce: 11.05 | step: 43.34
[default0]:[2023-08-25 18:08:40,477] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.10 | optimizer_step: 6.47
[default0]:[2023-08-25 18:08:40,478] [INFO] [logging.py:96:log_dist] [Rank 0] step=505, skipped=0, lr=[5.505024e-07, 5.505024e-07, 5.505024e-07, 5.505024e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:40,478] [INFO] [timer.py:215:stop] epoch=0/micro_step=505/global_step=505, RunningAvgSamplesPerSec=4.912350403395157, CurrSamplesPerSec=4.790522898958588, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:40,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.50 | backward_microstep: 115.54 | backward_inner_microstep: 104.27 | backward_allreduce_microstep: 11.17 | step_microstep: 44.16
[default0]:[2023-08-25 18:08:40,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.49 (forward_moe: 21.25, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.56)
[default0]:[2023-08-25 18:08:40,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.54 | backward_inner: 104.28 | backward_allreduce: 11.17 | step: 44.16
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.9637], device='cuda:0'), 'moe loss': tensor([0.3028], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      505/439453125 | consumed samples:          505 | consumed tokens:      1034240 | elapsed time per iteration (ms): 1862.2 | learning rate: 5.505E-07 | global batch size:     1 | lm loss: 1.019273E+01 | moe loss: 6.055931E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.537 | TFLOPs: 1.33 |
[default0]:[2023-08-25 18:08:40,759] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.45
[default0]:[2023-08-25 18:08:40,760] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.41 | backward_microstep: 115.26 | backward_inner_microstep: 104.03 | backward_allreduce_microstep: 11.13 | step_microstep: 43.71
[default0]:[2023-08-25 18:08:40,760] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.41 (forward_moe: 21.18, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.56)
[default0]:[2023-08-25 18:08:40,760] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.26 | backward_inner: 104.04 | backward_allreduce: 11.14 | step: 43.71
[default0]:[2023-08-25 18:08:41,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:41,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.97 | backward_microstep: 112.30 | backward_inner_microstep: 101.22 | backward_allreduce_microstep: 10.99 | step_microstep: 43.39
[default0]:[2023-08-25 18:08:41,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.97 (forward_moe: 20.54, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.16)
[default0]:[2023-08-25 18:08:41,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.30 | backward_inner: 101.22 | backward_allreduce: 10.99 | step: 43.40
[default0]:[2023-08-25 18:08:41,293] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:08:41,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.30 | backward_microstep: 112.74 | backward_inner_microstep: 101.69 | backward_allreduce_microstep: 10.95 | step_microstep: 42.66
[default0]:[2023-08-25 18:08:41,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.29 (forward_moe: 20.73, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.43)
[default0]:[2023-08-25 18:08:41,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.74 | backward_inner: 101.70 | backward_allreduce: 10.95 | step: 42.66
[default0]:[2023-08-25 18:08:41,537] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:08:41,537] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.82 | backward_microstep: 112.33 | backward_inner_microstep: 101.28 | backward_allreduce_microstep: 10.95 | step_microstep: 42.66
[default0]:[2023-08-25 18:08:41,537] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.82 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:08:41,537] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.33 | backward_inner: 101.28 | backward_allreduce: 10.95 | step: 42.66
[default0]:[2023-08-25 18:08:41,796] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:08:41,796] [INFO] [logging.py:96:log_dist] [Rank 0] step=510, skipped=0, lr=[5.559637333333333e-07, 5.559637333333333e-07, 5.559637333333333e-07, 5.559637333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:41,796] [INFO] [timer.py:215:stop] epoch=0/micro_step=510/global_step=510, RunningAvgSamplesPerSec=4.912202868040478, CurrSamplesPerSec=4.927680891758658, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:41,796] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.20 | backward_microstep: 112.28 | backward_inner_microstep: 101.23 | backward_allreduce_microstep: 10.96 | step_microstep: 42.95
[default0]:[2023-08-25 18:08:41,796] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.20 (forward_moe: 20.54, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:08:41,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.27 | backward_inner: 101.23 | backward_allreduce: 10.96 | step: 42.95
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.3590], device='cuda:0'), 'moe loss': tensor([0.3026], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      510/439453125 | consumed samples:          510 | consumed tokens:      1044480 | elapsed time per iteration (ms): 263.7 | learning rate: 5.560E-07 | global batch size:     1 | lm loss: 1.007180E+01 | moe loss: 6.052836E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.792 | TFLOPs: 9.42 |
[default0]:[2023-08-25 18:08:42,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.52
[default0]:[2023-08-25 18:08:42,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.89 | backward_microstep: 112.33 | backward_inner_microstep: 101.26 | backward_allreduce_microstep: 10.97 | step_microstep: 42.72
[default0]:[2023-08-25 18:08:42,156] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.89 (forward_moe: 20.46, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.16)
[default0]:[2023-08-25 18:08:42,156] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.33 | backward_inner: 101.27 | backward_allreduce: 10.98 | step: 42.72
[default0]:[2023-08-25 18:08:42,407] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.39
[default0]:[2023-08-25 18:08:42,407] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.03 | backward_microstep: 112.42 | backward_inner_microstep: 101.36 | backward_allreduce_microstep: 10.97 | step_microstep: 42.56
[default0]:[2023-08-25 18:08:42,407] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.03 (forward_moe: 20.48, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.16)
[default0]:[2023-08-25 18:08:42,408] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.42 | backward_inner: 101.37 | backward_allreduce: 10.97 | step: 42.56
[default0]:[2023-08-25 18:08:42,666] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:42,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.75 | backward_microstep: 112.46 | backward_inner_microstep: 101.23 | backward_allreduce_microstep: 11.14 | step_microstep: 42.60
[default0]:[2023-08-25 18:08:42,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.75 (forward_moe: 20.46, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:08:42,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.46 | backward_inner: 101.23 | backward_allreduce: 11.14 | step: 42.60
[default0]:[2023-08-25 18:08:42,929] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.34
[default0]:[2023-08-25 18:08:42,929] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.95 | backward_microstep: 112.25 | backward_inner_microstep: 101.21 | backward_allreduce_microstep: 10.95 | step_microstep: 42.56
[default0]:[2023-08-25 18:08:42,929] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.95 (forward_moe: 20.41, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.13)
[default0]:[2023-08-25 18:08:42,929] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.25 | backward_inner: 101.21 | backward_allreduce: 10.95 | step: 42.56
[default0]:[2023-08-25 18:08:43,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:43,174] [INFO] [logging.py:96:log_dist] [Rank 0] step=515, skipped=0, lr=[5.614250666666667e-07, 5.614250666666667e-07, 5.614250666666667e-07, 5.614250666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:43,174] [INFO] [timer.py:215:stop] epoch=0/micro_step=515/global_step=515, RunningAvgSamplesPerSec=4.912392745297116, CurrSamplesPerSec=4.924140392399951, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:43,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.06 | backward_microstep: 112.43 | backward_inner_microstep: 101.35 | backward_allreduce_microstep: 10.98 | step_microstep: 43.04
[default0]:[2023-08-25 18:08:43,175] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.06 (forward_moe: 20.47, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.17)
[default0]:[2023-08-25 18:08:43,175] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.42 | backward_inner: 101.35 | backward_allreduce: 10.99 | step: 43.04
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.7366], device='cuda:0'), 'moe loss': tensor([0.3023], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      515/439453125 | consumed samples:          515 | consumed tokens:      1054720 | elapsed time per iteration (ms): 275.6 | learning rate: 5.614E-07 | global batch size:     1 | lm loss: 1.014731E+01 | moe loss: 6.046854E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.629 | TFLOPs: 9.02 |
[default0]:[2023-08-25 18:08:43,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.34
[default0]:[2023-08-25 18:08:43,513] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 53.26 | backward_microstep: 110.12 | backward_inner_microstep: 99.19 | backward_allreduce_microstep: 10.84 | step_microstep: 42.23
[default0]:[2023-08-25 18:08:43,513] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 53.26 (forward_moe: 19.97, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:08:43,513] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.12 | backward_inner: 99.19 | backward_allreduce: 10.84 | step: 42.23
[default0]:[2023-08-25 18:08:43,765] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:43,765] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.72 | backward_microstep: 110.04 | backward_inner_microstep: 99.07 | backward_allreduce_microstep: 10.88 | step_microstep: 41.78
[default0]:[2023-08-25 18:08:43,765] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.72 (forward_moe: 19.91, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.84)
[default0]:[2023-08-25 18:08:43,765] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.04 | backward_inner: 99.07 | backward_allreduce: 10.89 | step: 41.78
[default0]:[2023-08-25 18:08:44,011] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:08:44,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.83 | backward_microstep: 109.99 | backward_inner_microstep: 99.00 | backward_allreduce_microstep: 10.89 | step_microstep: 41.90
[default0]:[2023-08-25 18:08:44,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.83 (forward_moe: 19.96, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.86)
[default0]:[2023-08-25 18:08:44,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.99 | backward_inner: 99.00 | backward_allreduce: 10.90 | step: 41.90
[default0]:[2023-08-25 18:08:44,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:44,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.35 | backward_microstep: 110.04 | backward_inner_microstep: 99.05 | backward_allreduce_microstep: 10.90 | step_microstep: 41.62
[default0]:[2023-08-25 18:08:44,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.35 (forward_moe: 19.96, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:08:44,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.04 | backward_inner: 99.05 | backward_allreduce: 10.90 | step: 41.62
[default0]:[2023-08-25 18:08:44,501] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.42
[default0]:[2023-08-25 18:08:44,501] [INFO] [logging.py:96:log_dist] [Rank 0] step=520, skipped=0, lr=[5.668864e-07, 5.668864e-07, 5.668864e-07, 5.668864e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:44,501] [INFO] [timer.py:215:stop] epoch=0/micro_step=520/global_step=520, RunningAvgSamplesPerSec=4.913070719876258, CurrSamplesPerSec=5.0213686008828065, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:44,501] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.17 | backward_microstep: 110.13 | backward_inner_microstep: 99.19 | backward_allreduce_microstep: 10.84 | step_microstep: 42.28
[default0]:[2023-08-25 18:08:44,501] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.17 (forward_moe: 20.11, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.85)
[default0]:[2023-08-25 18:08:44,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.12 | backward_inner: 99.20 | backward_allreduce: 10.84 | step: 42.29
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.7231], device='cuda:0'), 'moe loss': tensor([0.3025], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      520/439453125 | consumed samples:          520 | consumed tokens:      1064960 | elapsed time per iteration (ms): 266.3 | learning rate: 5.669E-07 | global batch size:     1 | lm loss: 1.014462E+01 | moe loss: 6.049137E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.755 | TFLOPs: 9.33 |
[default0]:[2023-08-25 18:08:44,761] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:08:44,762] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.91 | backward_microstep: 112.41 | backward_inner_microstep: 101.42 | backward_allreduce_microstep: 10.89 | step_microstep: 41.78
[default0]:[2023-08-25 18:08:44,762] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.91 (forward_moe: 20.21, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.89)
[default0]:[2023-08-25 18:08:44,762] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.41 | backward_inner: 101.43 | backward_allreduce: 10.90 | step: 41.79
[default0]:[2023-08-25 18:08:45,043] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:45,044] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.88 | backward_microstep: 110.11 | backward_inner_microstep: 99.05 | backward_allreduce_microstep: 10.97 | step_microstep: 43.55
[default0]:[2023-08-25 18:08:45,047] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.88 (forward_moe: 19.95, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.88)
[default0]:[2023-08-25 18:08:45,047] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.11 | backward_inner: 99.05 | backward_allreduce: 10.97 | step: 43.56
[default0]:[2023-08-25 18:08:45,355] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:08:45,357] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.28 | backward_microstep: 119.20 | backward_inner_microstep: 107.42 | backward_allreduce_microstep: 11.67 | step_microstep: 45.05
[default0]:[2023-08-25 18:08:45,357] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.28 (forward_moe: 21.94, 1st alltoall: 0.93, 2nd alltoall: 0.87, top-k: 8.65)
[default0]:[2023-08-25 18:08:45,357] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 119.19 | backward_inner: 107.43 | backward_allreduce: 11.67 | step: 45.05
[default0]:[2023-08-25 18:08:45,629] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.06 | optimizer_step: 6.44
[default0]:[2023-08-25 18:08:45,630] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.39 | backward_microstep: 114.48 | backward_inner_microstep: 103.23 | backward_allreduce_microstep: 11.15 | step_microstep: 43.30
[default0]:[2023-08-25 18:08:45,630] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.39 (forward_moe: 21.03, 1st alltoall: 0.98, 2nd alltoall: 0.83, top-k: 8.43)
[default0]:[2023-08-25 18:08:45,630] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.48 | backward_inner: 103.24 | backward_allreduce: 11.16 | step: 43.30
[default0]:[2023-08-25 18:08:46,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 4.18 | optimizer_step: 6.51
[default0]:[2023-08-25 18:08:46,136] [INFO] [logging.py:96:log_dist] [Rank 0] step=525, skipped=0, lr=[5.723477333333333e-07, 5.723477333333333e-07, 5.723477333333333e-07, 5.723477333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:46,137] [INFO] [timer.py:215:stop] epoch=0/micro_step=525/global_step=525, RunningAvgSamplesPerSec=4.912175311028682, CurrSamplesPerSec=4.708378937537115, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:46,137] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.17 | backward_microstep: 117.73 | backward_inner_microstep: 106.35 | backward_allreduce_microstep: 11.28 | step_microstep: 44.94
[default0]:[2023-08-25 18:08:46,137] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.17 (forward_moe: 21.63, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.84)
[default0]:[2023-08-25 18:08:46,137] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.73 | backward_inner: 106.35 | backward_allreduce: 11.29 | step: 44.94
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.4120], device='cuda:0'), 'moe loss': tensor([0.3024], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      525/439453125 | consumed samples:          525 | consumed tokens:      1075200 | elapsed time per iteration (ms): 326.2 | learning rate: 5.723E-07 | global batch size:     1 | lm loss: 1.008241E+01 | moe loss: 6.047735E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.065 | TFLOPs: 7.62 |
[default0]:[2023-08-25 18:08:46,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 6.55
[default0]:[2023-08-25 18:08:46,394] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.31 | backward_microstep: 118.13 | backward_inner_microstep: 106.45 | backward_allreduce_microstep: 11.58 | step_microstep: 44.39
[default0]:[2023-08-25 18:08:46,394] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.31 (forward_moe: 21.60, 1st alltoall: 0.91, 2nd alltoall: 0.86, top-k: 8.86)
[default0]:[2023-08-25 18:08:46,394] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 118.13 | backward_inner: 106.46 | backward_allreduce: 11.58 | step: 44.40
[default0]:[2023-08-25 18:08:46,652] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.69 | optimizer_gradients: 4.08 | optimizer_step: 6.43
[default0]:[2023-08-25 18:08:46,652] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.31 | backward_microstep: 113.95 | backward_inner_microstep: 102.23 | backward_allreduce_microstep: 11.62 | step_microstep: 44.49
[default0]:[2023-08-25 18:08:46,652] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.31 (forward_moe: 20.63, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.23)
[default0]:[2023-08-25 18:08:46,652] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.94 | backward_inner: 102.23 | backward_allreduce: 11.62 | step: 44.49
[default0]:[2023-08-25 18:08:46,902] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:46,902] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.37 | backward_microstep: 113.21 | backward_inner_microstep: 101.98 | backward_allreduce_microstep: 11.14 | step_microstep: 42.82
[default0]:[2023-08-25 18:08:46,902] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.37 (forward_moe: 20.63, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:08:46,902] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.21 | backward_inner: 101.98 | backward_allreduce: 11.14 | step: 42.82
[default0]:[2023-08-25 18:08:47,162] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.80 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:08:47,162] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.66 | backward_microstep: 113.23 | backward_inner_microstep: 102.05 | backward_allreduce_microstep: 11.08 | step_microstep: 43.10
[default0]:[2023-08-25 18:08:47,162] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.66 (forward_moe: 20.72, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.29)
[default0]:[2023-08-25 18:08:47,162] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.23 | backward_inner: 102.05 | backward_allreduce: 11.09 | step: 43.10
[default0]:[2023-08-25 18:08:47,417] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:08:47,418] [INFO] [logging.py:96:log_dist] [Rank 0] step=530, skipped=0, lr=[5.778090666666667e-07, 5.778090666666667e-07, 5.778090666666667e-07, 5.778090666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:47,418] [INFO] [timer.py:215:stop] epoch=0/micro_step=530/global_step=530, RunningAvgSamplesPerSec=4.911486113759545, CurrSamplesPerSec=4.884498257243242, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:47,418] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.28 | backward_microstep: 113.70 | backward_inner_microstep: 102.50 | backward_allreduce_microstep: 11.11 | step_microstep: 43.16
[default0]:[2023-08-25 18:08:47,418] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.28 (forward_moe: 20.98, 1st alltoall: 1.07, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:08:47,418] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.70 | backward_inner: 102.51 | backward_allreduce: 11.11 | step: 43.16
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.5683], device='cuda:0'), 'moe loss': tensor([0.3020], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      530/439453125 | consumed samples:          530 | consumed tokens:      1085440 | elapsed time per iteration (ms): 256.2 | learning rate: 5.778E-07 | global batch size:     1 | lm loss: 1.011367E+01 | moe loss: 6.039300E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.903 | TFLOPs: 9.70 |
[default0]:[2023-08-25 18:08:47,685] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.45
[default0]:[2023-08-25 18:08:47,685] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.82 | backward_microstep: 112.17 | backward_inner_microstep: 101.14 | backward_allreduce_microstep: 10.93 | step_microstep: 42.99
[default0]:[2023-08-25 18:08:47,685] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.82 (forward_moe: 20.41, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:08:47,685] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.17 | backward_inner: 101.14 | backward_allreduce: 10.94 | step: 43.00
[default0]:[2023-08-25 18:08:47,936] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:47,936] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.15 | backward_microstep: 112.37 | backward_inner_microstep: 101.32 | backward_allreduce_microstep: 10.96 | step_microstep: 42.41
[default0]:[2023-08-25 18:08:47,936] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.14 (forward_moe: 20.47, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:08:47,936] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.36 | backward_inner: 101.32 | backward_allreduce: 10.96 | step: 42.41
[default0]:[2023-08-25 18:08:48,220] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:08:48,220] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.38 | backward_microstep: 112.48 | backward_inner_microstep: 101.36 | backward_allreduce_microstep: 11.02 | step_microstep: 42.81
[default0]:[2023-08-25 18:08:48,221] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.38 (forward_moe: 20.46, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:08:48,221] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.48 | backward_inner: 101.36 | backward_allreduce: 11.03 | step: 42.82
[default0]:[2023-08-25 18:08:48,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.38
[default0]:[2023-08-25 18:08:48,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.67 | backward_microstep: 112.80 | backward_inner_microstep: 101.78 | backward_allreduce_microstep: 10.92 | step_microstep: 42.39
[default0]:[2023-08-25 18:08:48,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.67 (forward_moe: 20.55, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.17)
[default0]:[2023-08-25 18:08:48,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.79 | backward_inner: 101.79 | backward_allreduce: 10.92 | step: 42.39
[default0]:[2023-08-25 18:08:48,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.70 | optimizer_gradients: 4.08 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:48,737] [INFO] [logging.py:96:log_dist] [Rank 0] step=535, skipped=0, lr=[5.832704000000001e-07, 5.832704000000001e-07, 5.832704000000001e-07, 5.832704000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:48,737] [INFO] [timer.py:215:stop] epoch=0/micro_step=535/global_step=535, RunningAvgSamplesPerSec=4.911512215558675, CurrSamplesPerSec=4.908741936389937, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:48,737] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.63 | backward_microstep: 112.21 | backward_inner_microstep: 100.64 | backward_allreduce_microstep: 11.47 | step_microstep: 44.35
[default0]:[2023-08-25 18:08:48,737] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.63 (forward_moe: 20.36, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.04)
[default0]:[2023-08-25 18:08:48,737] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.21 | backward_inner: 100.65 | backward_allreduce: 11.47 | step: 44.35
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.2942], device='cuda:0'), 'moe loss': tensor([0.3026], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      535/439453125 | consumed samples:          535 | consumed tokens:      1095680 | elapsed time per iteration (ms): 265.8 | learning rate: 5.833E-07 | global batch size:     1 | lm loss: 1.005884E+01 | moe loss: 6.051114E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.762 | TFLOPs: 9.35 |
[default0]:[2023-08-25 18:08:48,998] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:48,998] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.74 | backward_microstep: 111.69 | backward_inner_microstep: 100.67 | backward_allreduce_microstep: 10.93 | step_microstep: 42.35
[default0]:[2023-08-25 18:08:48,998] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.74 (forward_moe: 20.49, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.09)
[default0]:[2023-08-25 18:08:48,998] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.69 | backward_inner: 100.67 | backward_allreduce: 10.93 | step: 42.35
[default0]:[2023-08-25 18:08:49,258] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:08:49,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.36 | backward_microstep: 110.78 | backward_inner_microstep: 99.75 | backward_allreduce_microstep: 10.94 | step_microstep: 42.53
[default0]:[2023-08-25 18:08:49,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.37 (forward_moe: 20.15, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 7.99)
[default0]:[2023-08-25 18:08:49,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.78 | backward_inner: 99.76 | backward_allreduce: 10.94 | step: 42.53
[default0]:[2023-08-25 18:08:49,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 10.25
[default0]:[2023-08-25 18:08:49,517] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.49 | backward_microstep: 110.97 | backward_inner_microstep: 100.02 | backward_allreduce_microstep: 10.85 | step_microstep: 46.08
[default0]:[2023-08-25 18:08:49,517] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.48 (forward_moe: 20.46, 1st alltoall: 1.05, 2nd alltoall: 0.80, top-k: 8.10)
[default0]:[2023-08-25 18:08:49,517] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.97 | backward_inner: 100.02 | backward_allreduce: 10.86 | step: 46.09
[default0]:[2023-08-25 18:08:50,132] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:08:50,133] [INFO] [logging.py:96:log_dist] [Rank 0] step=540, skipped=0, lr=[5.887317333333334e-07, 5.887317333333334e-07, 5.887317333333334e-07, 5.887317333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:50,133] [INFO] [timer.py:215:stop] epoch=0/micro_step=540/global_step=540, RunningAvgSamplesPerSec=4.911892297318632, CurrSamplesPerSec=5.0000464920552234, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:50,133] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.39 | backward_microstep: 110.88 | backward_inner_microstep: 99.82 | backward_allreduce_microstep: 10.97 | step_microstep: 42.17
[default0]:[2023-08-25 18:08:50,133] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.39 (forward_moe: 20.24, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.93)
[default0]:[2023-08-25 18:08:50,133] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.88 | backward_inner: 99.83 | backward_allreduce: 10.97 | step: 42.18
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.8699], device='cuda:0'), 'moe loss': tensor([0.3032], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      540/439453125 | consumed samples:          540 | consumed tokens:      1105920 | elapsed time per iteration (ms): 277.0 | learning rate: 5.887E-07 | global batch size:     1 | lm loss: 1.017398E+01 | moe loss: 6.064081E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.610 | TFLOPs: 8.97 |
[default0]:[2023-08-25 18:08:50,430] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:50,430] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.30 | backward_microstep: 110.71 | backward_inner_microstep: 99.74 | backward_allreduce_microstep: 10.88 | step_microstep: 42.43
[default0]:[2023-08-25 18:08:50,430] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.30 (forward_moe: 20.19, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.95)
[default0]:[2023-08-25 18:08:50,430] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.71 | backward_inner: 99.74 | backward_allreduce: 10.88 | step: 42.43
[default0]:[2023-08-25 18:08:50,701] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:08:50,702] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.92 | backward_microstep: 110.38 | backward_inner_microstep: 99.41 | backward_allreduce_microstep: 10.87 | step_microstep: 41.99
[default0]:[2023-08-25 18:08:50,702] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.92 (forward_moe: 20.06, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.90)
[default0]:[2023-08-25 18:08:50,702] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.38 | backward_inner: 99.42 | backward_allreduce: 10.87 | step: 42.00
[default0]:[2023-08-25 18:08:50,939] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.34
[default0]:[2023-08-25 18:08:50,939] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.40 | backward_microstep: 110.52 | backward_inner_microstep: 99.58 | backward_allreduce_microstep: 10.85 | step_microstep: 41.99
[default0]:[2023-08-25 18:08:50,940] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.40 (forward_moe: 20.17, 1st alltoall: 0.86, 2nd alltoall: 0.86, top-k: 7.92)
[default0]:[2023-08-25 18:08:50,940] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.52 | backward_inner: 99.59 | backward_allreduce: 10.85 | step: 42.00
[default0]:[2023-08-25 18:08:51,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:51,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 110.97 | backward_inner_microstep: 99.89 | backward_allreduce_microstep: 10.98 | step_microstep: 42.21
[default0]:[2023-08-25 18:08:51,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.02 (forward_moe: 20.26, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:08:51,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.97 | backward_inner: 99.90 | backward_allreduce: 10.99 | step: 42.21
[default0]:[2023-08-25 18:08:52,050] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:08:52,051] [INFO] [logging.py:96:log_dist] [Rank 0] step=545, skipped=0, lr=[5.941930666666667e-07, 5.941930666666667e-07, 5.941930666666667e-07, 5.941930666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:52,051] [INFO] [timer.py:215:stop] epoch=0/micro_step=545/global_step=545, RunningAvgSamplesPerSec=4.91272769014654, CurrSamplesPerSec=5.025580194370656, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:52,051] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.03 | backward_microstep: 110.20 | backward_inner_microstep: 99.30 | backward_allreduce_microstep: 10.81 | step_microstep: 42.19
[default0]:[2023-08-25 18:08:52,051] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.03 (forward_moe: 19.99, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.89)
[default0]:[2023-08-25 18:08:52,051] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.20 | backward_inner: 99.30 | backward_allreduce: 10.81 | step: 42.19
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.7774], device='cuda:0'), 'moe loss': tensor([0.3024], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      545/439453125 | consumed samples:          545 | consumed tokens:      1116160 | elapsed time per iteration (ms): 383.6 | learning rate: 5.942E-07 | global batch size:     1 | lm loss: 1.015547E+01 | moe loss: 6.048239E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.607 | TFLOPs: 6.48 |
[default0]:[2023-08-25 18:08:52,307] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:52,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.13 | backward_microstep: 112.36 | backward_inner_microstep: 101.20 | backward_allreduce_microstep: 11.06 | step_microstep: 42.68
[default0]:[2023-08-25 18:08:52,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.13 (forward_moe: 20.16, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.98)
[default0]:[2023-08-25 18:08:52,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.36 | backward_inner: 101.21 | backward_allreduce: 11.06 | step: 42.68
[default0]:[2023-08-25 18:08:52,596] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.40
[default0]:[2023-08-25 18:08:52,597] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.32 | backward_microstep: 113.45 | backward_inner_microstep: 102.30 | backward_allreduce_microstep: 11.06 | step_microstep: 43.02
[default0]:[2023-08-25 18:08:52,597] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.33 (forward_moe: 20.67, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.30)
[default0]:[2023-08-25 18:08:52,597] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.45 | backward_inner: 102.30 | backward_allreduce: 11.06 | step: 43.02
[default0]:[2023-08-25 18:08:52,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.40
[default0]:[2023-08-25 18:08:52,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.74 | backward_microstep: 113.92 | backward_inner_microstep: 102.62 | backward_allreduce_microstep: 11.20 | step_microstep: 43.11
[default0]:[2023-08-25 18:08:52,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.74 (forward_moe: 20.80, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.36)
[default0]:[2023-08-25 18:08:52,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.91 | backward_inner: 102.63 | backward_allreduce: 11.20 | step: 43.11
[default0]:[2023-08-25 18:08:53,160] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.45
[default0]:[2023-08-25 18:08:53,160] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.84 | backward_microstep: 114.72 | backward_inner_microstep: 103.48 | backward_allreduce_microstep: 11.15 | step_microstep: 43.50
[default0]:[2023-08-25 18:08:53,160] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.84 (forward_moe: 20.98, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.45)
[default0]:[2023-08-25 18:08:53,161] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.72 | backward_inner: 103.49 | backward_allreduce: 11.16 | step: 43.50
[default0]:[2023-08-25 18:08:53,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.47
[default0]:[2023-08-25 18:08:53,421] [INFO] [logging.py:96:log_dist] [Rank 0] step=550, skipped=0, lr=[5.996544e-07, 5.996544e-07, 5.996544e-07, 5.996544e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:53,421] [INFO] [timer.py:215:stop] epoch=0/micro_step=550/global_step=550, RunningAvgSamplesPerSec=4.912296927338737, CurrSamplesPerSec=4.797564103004037, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:53,422] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.39 | backward_microstep: 115.57 | backward_inner_microstep: 104.29 | backward_allreduce_microstep: 11.19 | step_microstep: 43.92
[default0]:[2023-08-25 18:08:53,422] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.39 (forward_moe: 21.26, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.54)
[default0]:[2023-08-25 18:08:53,422] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.57 | backward_inner: 104.30 | backward_allreduce: 11.19 | step: 43.92
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.5876], device='cuda:0'), 'moe loss': tensor([0.3019], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      550/439453125 | consumed samples:          550 | consumed tokens:      1126400 | elapsed time per iteration (ms): 274.3 | learning rate: 5.997E-07 | global batch size:     1 | lm loss: 1.011752E+01 | moe loss: 6.037301E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.646 | TFLOPs: 9.06 |
[default0]:[2023-08-25 18:08:53,690] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.43
[default0]:[2023-08-25 18:08:53,690] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.53 | backward_microstep: 114.90 | backward_inner_microstep: 103.69 | backward_allreduce_microstep: 11.12 | step_microstep: 43.33
[default0]:[2023-08-25 18:08:53,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.53 (forward_moe: 20.61, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:08:53,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.90 | backward_inner: 103.70 | backward_allreduce: 11.12 | step: 43.34
[default0]:[2023-08-25 18:08:53,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.37
[default0]:[2023-08-25 18:08:53,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.37 | backward_microstep: 113.20 | backward_inner_microstep: 102.03 | backward_allreduce_microstep: 11.07 | step_microstep: 42.90
[default0]:[2023-08-25 18:08:53,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.37 (forward_moe: 20.65, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.24)
[default0]:[2023-08-25 18:08:53,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.20 | backward_inner: 102.04 | backward_allreduce: 11.07 | step: 42.91
[default0]:[2023-08-25 18:08:54,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.41
[default0]:[2023-08-25 18:08:54,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.66 | backward_microstep: 113.17 | backward_inner_microstep: 102.07 | backward_allreduce_microstep: 11.01 | step_microstep: 42.82
[default0]:[2023-08-25 18:08:54,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.66 (forward_moe: 20.77, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.29)
[default0]:[2023-08-25 18:08:54,234] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.17 | backward_inner: 102.07 | backward_allreduce: 11.02 | step: 42.82
[default0]:[2023-08-25 18:08:54,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:08:54,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.04 | backward_microstep: 110.50 | backward_inner_microstep: 99.33 | backward_allreduce_microstep: 11.07 | step_microstep: 41.98
[default0]:[2023-08-25 18:08:54,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.04 (forward_moe: 20.15, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.92)
[default0]:[2023-08-25 18:08:54,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.49 | backward_inner: 99.34 | backward_allreduce: 11.08 | step: 41.97
[default0]:[2023-08-25 18:08:54,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:08:54,741] [INFO] [logging.py:96:log_dist] [Rank 0] step=555, skipped=0, lr=[6.051157333333333e-07, 6.051157333333333e-07, 6.051157333333333e-07, 6.051157333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:54,741] [INFO] [timer.py:215:stop] epoch=0/micro_step=555/global_step=555, RunningAvgSamplesPerSec=4.912368996140051, CurrSamplesPerSec=4.962557531442634, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:54,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.31 | backward_microstep: 112.32 | backward_inner_microstep: 101.42 | backward_allreduce_microstep: 10.81 | step_microstep: 42.34
[default0]:[2023-08-25 18:08:54,742] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.30 (forward_moe: 20.08, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.91)
[default0]:[2023-08-25 18:08:54,742] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.32 | backward_inner: 101.42 | backward_allreduce: 10.81 | step: 42.34
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.5250], device='cuda:0'), 'moe loss': tensor([0.3028], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      555/439453125 | consumed samples:          555 | consumed tokens:      1136640 | elapsed time per iteration (ms): 264.1 | learning rate: 6.051E-07 | global batch size:     1 | lm loss: 1.010501E+01 | moe loss: 6.055965E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.786 | TFLOPs: 9.41 |
[default0]:[2023-08-25 18:08:55,073] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.32
[default0]:[2023-08-25 18:08:55,073] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.96 | backward_microstep: 110.49 | backward_inner_microstep: 99.55 | backward_allreduce_microstep: 10.84 | step_microstep: 42.00
[default0]:[2023-08-25 18:08:55,073] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.96 (forward_moe: 20.06, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.93)
[default0]:[2023-08-25 18:08:55,073] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.49 | backward_inner: 99.56 | backward_allreduce: 10.85 | step: 42.00
[default0]:[2023-08-25 18:08:55,332] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 6.34
[default0]:[2023-08-25 18:08:55,333] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.19 | backward_microstep: 110.50 | backward_inner_microstep: 99.50 | backward_allreduce_microstep: 10.90 | step_microstep: 41.93
[default0]:[2023-08-25 18:08:55,333] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.19 (forward_moe: 20.22, 1st alltoall: 0.86, 2nd alltoall: 0.89, top-k: 7.90)
[default0]:[2023-08-25 18:08:55,333] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.50 | backward_inner: 99.51 | backward_allreduce: 10.91 | step: 41.93
[default0]:[2023-08-25 18:08:55,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:55,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.42 | backward_microstep: 110.37 | backward_inner_microstep: 99.44 | backward_allreduce_microstep: 10.83 | step_microstep: 41.94
[default0]:[2023-08-25 18:08:55,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.42 (forward_moe: 20.03, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:08:55,605] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.37 | backward_inner: 99.44 | backward_allreduce: 10.84 | step: 41.94
[default0]:[2023-08-25 18:08:55,838] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:08:55,839] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.54 | backward_microstep: 110.35 | backward_inner_microstep: 99.41 | backward_allreduce_microstep: 10.85 | step_microstep: 42.56
[default0]:[2023-08-25 18:08:55,839] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.54 (forward_moe: 20.08, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.91)
[default0]:[2023-08-25 18:08:55,839] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.35 | backward_inner: 99.42 | backward_allreduce: 10.85 | step: 42.57
[default0]:[2023-08-25 18:08:56,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:56,075] [INFO] [logging.py:96:log_dist] [Rank 0] step=560, skipped=0, lr=[6.105770666666668e-07, 6.105770666666668e-07, 6.105770666666668e-07, 6.105770666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:56,075] [INFO] [timer.py:215:stop] epoch=0/micro_step=560/global_step=560, RunningAvgSamplesPerSec=4.913318563031603, CurrSamplesPerSec=5.0668818586401345, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:56,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 109.12 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.76 | step_microstep: 41.91
[default0]:[2023-08-25 18:08:56,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:08:56,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.27 | backward_allreduce: 10.77 | step: 41.92
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.3170], device='cuda:0'), 'moe loss': tensor([0.3025], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      560/439453125 | consumed samples:          560 | consumed tokens:      1146880 | elapsed time per iteration (ms): 267.0 | learning rate: 6.106E-07 | global batch size:     1 | lm loss: 1.006340E+01 | moe loss: 6.049680E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.745 | TFLOPs: 9.30 |
[default0]:[2023-08-25 18:08:56,340] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:08:56,340] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.33 | backward_microstep: 108.92 | backward_inner_microstep: 98.04 | backward_allreduce_microstep: 10.79 | step_microstep: 41.63
[default0]:[2023-08-25 18:08:56,340] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.33 (forward_moe: 19.75, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.75)
[default0]:[2023-08-25 18:08:56,340] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.05 | backward_allreduce: 10.79 | step: 41.64
[default0]:[2023-08-25 18:08:56,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:08:56,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 108.96 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.77 | step_microstep: 41.50
[default0]:[2023-08-25 18:08:56,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.89, top-k: 7.72)
[default0]:[2023-08-25 18:08:56,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.09 | backward_allreduce: 10.78 | step: 41.50
[default0]:[2023-08-25 18:08:56,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.33
[default0]:[2023-08-25 18:08:56,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.40 | backward_microstep: 108.93 | backward_inner_microstep: 98.11 | backward_allreduce_microstep: 10.72 | step_microstep: 41.55
[default0]:[2023-08-25 18:08:56,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.40 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:08:56,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.12 | backward_allreduce: 10.73 | step: 41.55
[default0]:[2023-08-25 18:08:57,149] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.95 | optimizer_step: 6.28
[default0]:[2023-08-25 18:08:57,150] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 109.22 | backward_inner_microstep: 98.31 | backward_allreduce_microstep: 10.81 | step_microstep: 41.60
[default0]:[2023-08-25 18:08:57,150] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.76)
[default0]:[2023-08-25 18:08:57,150] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.21 | backward_inner: 98.32 | backward_allreduce: 10.81 | step: 41.60
[default0]:[2023-08-25 18:08:57,385] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:08:57,385] [INFO] [logging.py:96:log_dist] [Rank 0] step=565, skipped=0, lr=[6.160384000000001e-07, 6.160384000000001e-07, 6.160384000000001e-07, 6.160384000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:57,386] [INFO] [timer.py:215:stop] epoch=0/micro_step=565/global_step=565, RunningAvgSamplesPerSec=4.914740917340863, CurrSamplesPerSec=5.0757605828109496, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:57,386] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 109.03 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.77 | step_microstep: 41.85
[default0]:[2023-08-25 18:08:57,386] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.76)
[default0]:[2023-08-25 18:08:57,386] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.17 | backward_allreduce: 10.77 | step: 41.85
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.1522], device='cuda:0'), 'moe loss': tensor([0.3028], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      565/439453125 | consumed samples:          565 | consumed tokens:      1157120 | elapsed time per iteration (ms): 261.6 | learning rate: 6.160E-07 | global batch size:     1 | lm loss: 1.023043E+01 | moe loss: 6.055311E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.822 | TFLOPs: 9.50 |
[default0]:[2023-08-25 18:08:57,637] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:08:57,637] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.88 | backward_microstep: 109.26 | backward_inner_microstep: 98.37 | backward_allreduce_microstep: 10.79 | step_microstep: 41.54
[default0]:[2023-08-25 18:08:57,637] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.88 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:08:57,638] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.25 | backward_inner: 98.37 | backward_allreduce: 10.80 | step: 41.54
[default0]:[2023-08-25 18:08:57,895] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:08:57,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 109.79 | backward_inner_microstep: 98.85 | backward_allreduce_microstep: 10.84 | step_microstep: 42.07
[default0]:[2023-08-25 18:08:57,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:08:57,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.79 | backward_inner: 98.86 | backward_allreduce: 10.85 | step: 42.07
[default0]:[2023-08-25 18:08:58,173] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.44
[default0]:[2023-08-25 18:08:58,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.02 | backward_microstep: 113.58 | backward_inner_microstep: 102.61 | backward_allreduce_microstep: 10.87 | step_microstep: 42.83
[default0]:[2023-08-25 18:08:58,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.02 (forward_moe: 20.12, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.94)
[default0]:[2023-08-25 18:08:58,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.58 | backward_inner: 102.62 | backward_allreduce: 10.88 | step: 42.84
[default0]:[2023-08-25 18:08:58,438] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:08:58,439] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.90 | backward_microstep: 111.77 | backward_inner_microstep: 100.76 | backward_allreduce_microstep: 10.91 | step_microstep: 42.35
[default0]:[2023-08-25 18:08:58,439] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.89 (forward_moe: 20.39, 1st alltoall: 0.92, 2nd alltoall: 0.83, top-k: 8.08)
[default0]:[2023-08-25 18:08:58,439] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.77 | backward_inner: 100.76 | backward_allreduce: 10.92 | step: 42.35
[default0]:[2023-08-25 18:08:58,690] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.38
[default0]:[2023-08-25 18:08:58,690] [INFO] [logging.py:96:log_dist] [Rank 0] step=570, skipped=0, lr=[6.214997333333334e-07, 6.214997333333334e-07, 6.214997333333334e-07, 6.214997333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:08:58,690] [INFO] [timer.py:215:stop] epoch=0/micro_step=570/global_step=570, RunningAvgSamplesPerSec=4.915330752773931, CurrSamplesPerSec=4.938821456999807, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:08:58,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.75 | backward_microstep: 112.31 | backward_inner_microstep: 101.28 | backward_allreduce_microstep: 10.94 | step_microstep: 42.86
[default0]:[2023-08-25 18:08:58,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.74 (forward_moe: 20.49, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.08)
[default0]:[2023-08-25 18:08:58,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.31 | backward_inner: 101.28 | backward_allreduce: 10.94 | step: 42.86
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.8733], device='cuda:0'), 'moe loss': tensor([0.3152], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      570/439453125 | consumed samples:          570 | consumed tokens:      1167360 | elapsed time per iteration (ms): 261.1 | learning rate: 6.215E-07 | global batch size:     1 | lm loss: 9.974663E+00 | moe loss: 6.303211E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.830 | TFLOPs: 9.52 |
[default0]:[2023-08-25 18:08:58,972] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:08:58,973] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.99 | backward_microstep: 112.19 | backward_inner_microstep: 101.14 | backward_allreduce_microstep: 10.95 | step_microstep: 42.64
[default0]:[2023-08-25 18:08:58,973] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.98 (forward_moe: 20.42, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:08:58,973] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.19 | backward_inner: 101.15 | backward_allreduce: 10.95 | step: 42.64
[default0]:[2023-08-25 18:08:59,244] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:08:59,244] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.24 | backward_microstep: 113.78 | backward_inner_microstep: 102.62 | backward_allreduce_microstep: 11.06 | step_microstep: 43.00
[default0]:[2023-08-25 18:08:59,244] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.24 (forward_moe: 20.75, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.35)
[default0]:[2023-08-25 18:08:59,244] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.77 | backward_inner: 102.62 | backward_allreduce: 11.06 | step: 43.00
[default0]:[2023-08-25 18:08:59,536] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.42
[default0]:[2023-08-25 18:08:59,537] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.37 | backward_microstep: 113.48 | backward_inner_microstep: 102.31 | backward_allreduce_microstep: 11.08 | step_microstep: 43.80
[default0]:[2023-08-25 18:08:59,538] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.37 (forward_moe: 20.77, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.30)
[default0]:[2023-08-25 18:08:59,538] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.48 | backward_inner: 102.31 | backward_allreduce: 11.08 | step: 43.80
[default0]:[2023-08-25 18:08:59,804] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 10.09
[default0]:[2023-08-25 18:08:59,804] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.85 | backward_microstep: 113.52 | backward_inner_microstep: 102.37 | backward_allreduce_microstep: 11.05 | step_microstep: 46.71
[default0]:[2023-08-25 18:08:59,804] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.85 (forward_moe: 20.72, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.32)
[default0]:[2023-08-25 18:08:59,805] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.51 | backward_inner: 102.37 | backward_allreduce: 11.06 | step: 46.71
[default0]:[2023-08-25 18:09:00,055] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.41
[default0]:[2023-08-25 18:09:00,055] [INFO] [logging.py:96:log_dist] [Rank 0] step=575, skipped=0, lr=[6.269610666666667e-07, 6.269610666666667e-07, 6.269610666666667e-07, 6.269610666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:00,055] [INFO] [timer.py:215:stop] epoch=0/micro_step=575/global_step=575, RunningAvgSamplesPerSec=4.914920670953605, CurrSamplesPerSec=4.875997740044688, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:00,056] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.48 | backward_microstep: 113.67 | backward_inner_microstep: 102.52 | backward_allreduce_microstep: 11.06 | step_microstep: 43.42
[default0]:[2023-08-25 18:09:00,056] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.48 (forward_moe: 20.75, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.33)
[default0]:[2023-08-25 18:09:00,056] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.67 | backward_inner: 102.53 | backward_allreduce: 11.06 | step: 43.42
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.1758], device='cuda:0'), 'moe loss': tensor([0.3036], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      575/439453125 | consumed samples:          575 | consumed tokens:      1177600 | elapsed time per iteration (ms): 273.3 | learning rate: 6.270E-07 | global batch size:     1 | lm loss: 1.023516E+01 | moe loss: 6.072383E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.659 | TFLOPs: 9.09 |
[default0]:[2023-08-25 18:09:00,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:09:00,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.95 | backward_microstep: 112.13 | backward_inner_microstep: 101.08 | backward_allreduce_microstep: 10.95 | step_microstep: 42.57
[default0]:[2023-08-25 18:09:00,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.94 (forward_moe: 20.42, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:09:00,302] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.13 | backward_inner: 101.08 | backward_allreduce: 10.96 | step: 42.57
[default0]:[2023-08-25 18:09:00,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:09:00,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.75 | backward_microstep: 112.29 | backward_inner_microstep: 101.24 | backward_allreduce_microstep: 10.96 | step_microstep: 43.06
[default0]:[2023-08-25 18:09:00,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.75 (forward_moe: 20.54, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:09:00,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.29 | backward_inner: 101.24 | backward_allreduce: 10.97 | step: 43.06
[default0]:[2023-08-25 18:09:00,821] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:09:00,821] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.00 | backward_microstep: 112.28 | backward_inner_microstep: 101.23 | backward_allreduce_microstep: 10.96 | step_microstep: 42.54
[default0]:[2023-08-25 18:09:00,821] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.00 (forward_moe: 20.44, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.16)
[default0]:[2023-08-25 18:09:00,821] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.28 | backward_inner: 101.24 | backward_allreduce: 10.96 | step: 42.54
[default0]:[2023-08-25 18:09:01,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:09:01,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.90 | backward_microstep: 112.87 | backward_inner_microstep: 101.78 | backward_allreduce_microstep: 11.00 | step_microstep: 42.54
[default0]:[2023-08-25 18:09:01,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.89 (forward_moe: 20.77, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.16)
[default0]:[2023-08-25 18:09:01,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.87 | backward_inner: 101.78 | backward_allreduce: 11.00 | step: 42.55
[default0]:[2023-08-25 18:09:01,320] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:01,320] [INFO] [logging.py:96:log_dist] [Rank 0] step=580, skipped=0, lr=[6.324224e-07, 6.324224e-07, 6.324224e-07, 6.324224e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:01,321] [INFO] [timer.py:215:stop] epoch=0/micro_step=580/global_step=580, RunningAvgSamplesPerSec=4.915166842022993, CurrSamplesPerSec=4.992190894018256, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:01,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.49 | backward_microstep: 110.90 | backward_inner_microstep: 99.87 | backward_allreduce_microstep: 10.94 | step_microstep: 42.38
[default0]:[2023-08-25 18:09:01,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.49 (forward_moe: 20.30, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.94)
[default0]:[2023-08-25 18:09:01,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.90 | backward_inner: 99.88 | backward_allreduce: 10.94 | step: 42.38
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.4031], device='cuda:0'), 'moe loss': tensor([0.3018], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      580/439453125 | consumed samples:          580 | consumed tokens:      1187840 | elapsed time per iteration (ms): 252.5 | learning rate: 6.324E-07 | global batch size:     1 | lm loss: 1.008061E+01 | moe loss: 6.035234E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.960 | TFLOPs: 9.84 |
[default0]:[2023-08-25 18:09:01,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.96 | optimizer_step: 6.41
[default0]:[2023-08-25 18:09:01,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.41 | backward_microstep: 110.78 | backward_inner_microstep: 99.77 | backward_allreduce_microstep: 10.92 | step_microstep: 42.24
[default0]:[2023-08-25 18:09:01,571] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.41 (forward_moe: 20.11, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.95)
[default0]:[2023-08-25 18:09:01,571] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.78 | backward_inner: 99.78 | backward_allreduce: 10.92 | step: 42.25
[default0]:[2023-08-25 18:09:01,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:01,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.37 | backward_microstep: 110.91 | backward_inner_microstep: 99.88 | backward_allreduce_microstep: 10.93 | step_microstep: 42.18
[default0]:[2023-08-25 18:09:01,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.37 (forward_moe: 20.23, 1st alltoall: 0.87, 2nd alltoall: 0.94, top-k: 7.93)
[default0]:[2023-08-25 18:09:01,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.90 | backward_inner: 99.89 | backward_allreduce: 10.93 | step: 42.19
[default0]:[2023-08-25 18:09:02,100] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:02,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.34 | backward_microstep: 110.66 | backward_inner_microstep: 99.64 | backward_allreduce_microstep: 10.93 | step_microstep: 42.08
[default0]:[2023-08-25 18:09:02,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.34 (forward_moe: 20.15, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.93)
[default0]:[2023-08-25 18:09:02,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.66 | backward_inner: 99.65 | backward_allreduce: 10.93 | step: 42.09
[default0]:[2023-08-25 18:09:02,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.94 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:02,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.81 | backward_microstep: 110.84 | backward_inner_microstep: 99.85 | backward_allreduce_microstep: 10.90 | step_microstep: 42.11
[default0]:[2023-08-25 18:09:02,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.81 (forward_moe: 20.20, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 8.04)
[default0]:[2023-08-25 18:09:02,343] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.84 | backward_inner: 99.85 | backward_allreduce: 10.91 | step: 42.12
[default0]:[2023-08-25 18:09:02,695] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:02,695] [INFO] [logging.py:96:log_dist] [Rank 0] step=585, skipped=0, lr=[6.378837333333333e-07, 6.378837333333333e-07, 6.378837333333333e-07, 6.378837333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:02,695] [INFO] [timer.py:215:stop] epoch=0/micro_step=585/global_step=585, RunningAvgSamplesPerSec=4.915791655155579, CurrSamplesPerSec=4.996252486628786, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:02,696] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.35 | backward_microstep: 110.91 | backward_inner_microstep: 99.95 | backward_allreduce_microstep: 10.87 | step_microstep: 42.36
[default0]:[2023-08-25 18:09:02,696] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.35 (forward_moe: 20.12, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.96)
[default0]:[2023-08-25 18:09:02,696] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.91 | backward_inner: 99.95 | backward_allreduce: 10.87 | step: 42.36
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.6646], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      585/439453125 | consumed samples:          585 | consumed tokens:      1198080 | elapsed time per iteration (ms): 275.0 | learning rate: 6.379E-07 | global batch size:     1 | lm loss: 1.013293E+01 | moe loss: 6.020151E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.637 | TFLOPs: 9.04 |
[default0]:[2023-08-25 18:09:02,944] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:02,944] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.01 | backward_microstep: 110.20 | backward_inner_microstep: 99.26 | backward_allreduce_microstep: 10.84 | step_microstep: 42.03
[default0]:[2023-08-25 18:09:02,944] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.00 (forward_moe: 20.12, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.88)
[default0]:[2023-08-25 18:09:02,944] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.19 | backward_inner: 99.27 | backward_allreduce: 10.84 | step: 42.03
[default0]:[2023-08-25 18:09:03,213] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:03,213] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.24 | backward_microstep: 109.96 | backward_inner_microstep: 99.06 | backward_allreduce_microstep: 10.80 | step_microstep: 42.75
[default0]:[2023-08-25 18:09:03,213] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.24 (forward_moe: 19.98, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.83)
[default0]:[2023-08-25 18:09:03,213] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.95 | backward_inner: 99.06 | backward_allreduce: 10.80 | step: 42.75
[default0]:[2023-08-25 18:09:03,463] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:03,463] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.04 | backward_microstep: 109.94 | backward_inner_microstep: 99.02 | backward_allreduce_microstep: 10.82 | step_microstep: 41.88
[default0]:[2023-08-25 18:09:03,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.04 (forward_moe: 19.95, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.87)
[default0]:[2023-08-25 18:09:03,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.94 | backward_inner: 99.03 | backward_allreduce: 10.82 | step: 41.89
[default0]:[2023-08-25 18:09:03,710] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.71 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:03,712] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.06 | backward_microstep: 112.23 | backward_inner_microstep: 101.24 | backward_allreduce_microstep: 10.89 | step_microstep: 43.01
[default0]:[2023-08-25 18:09:03,712] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.06 (forward_moe: 19.98, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:09:03,712] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.23 | backward_inner: 101.25 | backward_allreduce: 10.89 | step: 43.01
[default0]:[2023-08-25 18:09:03,976] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:03,976] [INFO] [logging.py:96:log_dist] [Rank 0] step=590, skipped=0, lr=[6.433450666666666e-07, 6.433450666666666e-07, 6.433450666666666e-07, 6.433450666666666e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:03,976] [INFO] [timer.py:215:stop] epoch=0/micro_step=590/global_step=590, RunningAvgSamplesPerSec=4.916552110622099, CurrSamplesPerSec=5.023954885903162, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:03,976] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.98 | backward_microstep: 110.23 | backward_inner_microstep: 99.29 | backward_allreduce_microstep: 10.86 | step_microstep: 42.29
[default0]:[2023-08-25 18:09:03,977] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.97 (forward_moe: 20.14, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:09:03,977] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.23 | backward_inner: 99.29 | backward_allreduce: 10.86 | step: 42.29
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.6399], device='cuda:0'), 'moe loss': tensor([0.3027], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      590/439453125 | consumed samples:          590 | consumed tokens:      1208320 | elapsed time per iteration (ms): 256.1 | learning rate: 6.433E-07 | global batch size:     1 | lm loss: 1.012797E+01 | moe loss: 6.054941E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.904 | TFLOPs: 9.70 |
[default0]:[2023-08-25 18:09:04,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:04,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.20 | backward_microstep: 110.26 | backward_inner_microstep: 99.29 | backward_allreduce_microstep: 10.87 | step_microstep: 41.84
[default0]:[2023-08-25 18:09:04,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.19 (forward_moe: 19.99, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:09:04,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.26 | backward_inner: 99.30 | backward_allreduce: 10.87 | step: 41.84
[default0]:[2023-08-25 18:09:04,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.34
[default0]:[2023-08-25 18:09:04,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.82 | backward_microstep: 109.79 | backward_inner_microstep: 98.91 | backward_allreduce_microstep: 10.79 | step_microstep: 41.97
[default0]:[2023-08-25 18:09:04,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.82 (forward_moe: 19.93, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:09:04,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.79 | backward_inner: 98.91 | backward_allreduce: 10.80 | step: 41.97
[default0]:[2023-08-25 18:09:04,789] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:09:04,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.10 | backward_microstep: 114.44 | backward_inner_microstep: 103.34 | backward_allreduce_microstep: 11.01 | step_microstep: 42.78
[default0]:[2023-08-25 18:09:04,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.10 (forward_moe: 20.51, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.16)
[default0]:[2023-08-25 18:09:04,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.44 | backward_inner: 103.35 | backward_allreduce: 11.01 | step: 42.78
[default0]:[2023-08-25 18:09:05,110] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:09:05,110] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.81 | backward_microstep: 114.34 | backward_inner_microstep: 103.15 | backward_allreduce_microstep: 11.10 | step_microstep: 43.54
[default0]:[2023-08-25 18:09:05,111] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.81 (forward_moe: 21.04, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.55)
[default0]:[2023-08-25 18:09:05,111] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.34 | backward_inner: 103.16 | backward_allreduce: 11.10 | step: 43.54
[default0]:[2023-08-25 18:09:05,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:09:05,377] [INFO] [logging.py:96:log_dist] [Rank 0] step=595, skipped=0, lr=[6.488064000000001e-07, 6.488064000000001e-07, 6.488064000000001e-07, 6.488064000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:05,378] [INFO] [timer.py:215:stop] epoch=0/micro_step=595/global_step=595, RunningAvgSamplesPerSec=4.916781105540825, CurrSamplesPerSec=4.945500851899234, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:05,378] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.79 | backward_microstep: 111.92 | backward_inner_microstep: 100.87 | backward_allreduce_microstep: 10.96 | step_microstep: 42.91
[default0]:[2023-08-25 18:09:05,378] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.37, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.10)
[default0]:[2023-08-25 18:09:05,378] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.92 | backward_inner: 100.87 | backward_allreduce: 10.96 | step: 42.92
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.4256], device='cuda:0'), 'moe loss': tensor([0.3021], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      595/439453125 | consumed samples:          595 | consumed tokens:      1218560 | elapsed time per iteration (ms): 280.2 | learning rate: 6.488E-07 | global batch size:     1 | lm loss: 1.008511E+01 | moe loss: 6.042095E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.569 | TFLOPs: 8.87 |
[default0]:[2023-08-25 18:09:05,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:09:05,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.71 | backward_microstep: 112.01 | backward_inner_microstep: 100.94 | backward_allreduce_microstep: 10.97 | step_microstep: 42.62
[default0]:[2023-08-25 18:09:05,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.70 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.10)
[default0]:[2023-08-25 18:09:05,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.00 | backward_inner: 100.94 | backward_allreduce: 10.97 | step: 42.62
[default0]:[2023-08-25 18:09:05,873] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.34
[default0]:[2023-08-25 18:09:05,874] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.15 | backward_microstep: 111.87 | backward_inner_microstep: 100.83 | backward_allreduce_microstep: 10.95 | step_microstep: 42.93
[default0]:[2023-08-25 18:09:05,874] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.15 (forward_moe: 20.35, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:09:05,874] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.87 | backward_inner: 100.83 | backward_allreduce: 10.95 | step: 42.94
[default0]:[2023-08-25 18:09:06,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:09:06,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.68 | backward_microstep: 111.81 | backward_inner_microstep: 100.76 | backward_allreduce_microstep: 10.95 | step_microstep: 42.54
[default0]:[2023-08-25 18:09:06,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.68 (forward_moe: 20.36, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.10)
[default0]:[2023-08-25 18:09:06,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.81 | backward_inner: 100.77 | backward_allreduce: 10.95 | step: 42.54
[default0]:[2023-08-25 18:09:06,372] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:09:06,372] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.00 | backward_microstep: 112.03 | backward_inner_microstep: 101.01 | backward_allreduce_microstep: 10.91 | step_microstep: 42.49
[default0]:[2023-08-25 18:09:06,372] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.00 (forward_moe: 20.49, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.11)
[default0]:[2023-08-25 18:09:06,373] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.03 | backward_inner: 101.02 | backward_allreduce: 10.92 | step: 42.50
[default0]:[2023-08-25 18:09:06,851] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:06,851] [INFO] [logging.py:96:log_dist] [Rank 0] step=600, skipped=0, lr=[6.542677333333334e-07, 6.542677333333334e-07, 6.542677333333334e-07, 6.542677333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:06,852] [INFO] [timer.py:215:stop] epoch=0/micro_step=600/global_step=600, RunningAvgSamplesPerSec=4.916990425861591, CurrSamplesPerSec=4.938001608207273, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:06,852] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.83 | backward_microstep: 112.05 | backward_inner_microstep: 101.01 | backward_allreduce_microstep: 10.95 | step_microstep: 43.06
[default0]:[2023-08-25 18:09:06,852] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.83 (forward_moe: 20.51, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.10)
[default0]:[2023-08-25 18:09:06,852] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.05 | backward_inner: 101.01 | backward_allreduce: 10.95 | step: 43.06
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.6035], device='cuda:0'), 'moe loss': tensor([0.3019], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      600/439453125 | consumed samples:          600 | consumed tokens:      1228800 | elapsed time per iteration (ms): 296.0 | learning rate: 6.543E-07 | global batch size:     1 | lm loss: 1.012069E+01 | moe loss: 6.037769E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.378 | TFLOPs: 8.39 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 600 | lm loss value: 1.008225E+01 | lm loss PPL: 2.391470E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration     600 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:09:10,594] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step600 is about to be saved!
[default0]:[2023-08-25 18:09:10,596] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,606] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,606] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,616] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,616] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,626] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,626] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,635] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,635] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,644] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,644] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,654] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,654] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,662] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,663] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,671] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,672] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,681] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,681] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,689] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,690] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,699] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,699] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,708] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,709] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,717] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,717] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,727] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,727] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,737] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,737] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,746] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,747] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,756] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,756] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,770] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,770] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,781] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,781] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,790] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,791] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,800] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,800] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,809] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,809] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,818] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,818] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:10,827] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:10,827] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:09:10,828] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:09:10,830] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:09:10,830] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:11,106] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:11,108] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:09:14,770] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:09:14,782] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step600/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:09:14,782] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step600 is ready now!
[default0]:  successfully saved checkpoint at iteration     600 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.7, Latency(second): 4.192
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4191.62, 4191.62)
[default0]:[2023-08-25 18:09:15,152] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.16 | optimizer_step: 10.28
[default0]:[2023-08-25 18:09:15,153] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2355.73 | backward_microstep: 117.14 | backward_inner_microstep: 105.89 | backward_allreduce_microstep: 11.15 | step_microstep: 47.65
[default0]:[2023-08-25 18:09:15,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2355.66 (forward_moe: 21.42, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.73)
[default0]:[2023-08-25 18:09:15,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.13 | backward_inner: 105.89 | backward_allreduce: 11.16 | step: 47.65
[default0]:[2023-08-25 18:09:15,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:09:15,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.53 | backward_microstep: 111.02 | backward_inner_microstep: 100.19 | backward_allreduce_microstep: 10.74 | step_microstep: 41.80
[default0]:[2023-08-25 18:09:15,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.53 (forward_moe: 20.23, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 8.08)
[default0]:[2023-08-25 18:09:15,404] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.02 | backward_inner: 100.19 | backward_allreduce: 10.75 | step: 41.80
[default0]:[2023-08-25 18:09:15,639] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:09:15,639] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.50 | backward_microstep: 111.11 | backward_inner_microstep: 100.27 | backward_allreduce_microstep: 10.76 | step_microstep: 41.65
[default0]:[2023-08-25 18:09:15,639] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.49 (forward_moe: 20.18, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 8.02)
[default0]:[2023-08-25 18:09:15,639] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.11 | backward_inner: 100.27 | backward_allreduce: 10.76 | step: 41.65
[default0]:[2023-08-25 18:09:15,877] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.38
[default0]:[2023-08-25 18:09:15,878] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.82 | backward_microstep: 111.58 | backward_inner_microstep: 100.52 | backward_allreduce_microstep: 10.97 | step_microstep: 43.21
[default0]:[2023-08-25 18:09:15,879] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.82 (forward_moe: 20.29, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 8.08)
[default0]:[2023-08-25 18:09:15,879] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.58 | backward_inner: 100.52 | backward_allreduce: 10.97 | step: 43.22
[default0]:[2023-08-25 18:09:16,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:09:16,137] [INFO] [logging.py:96:log_dist] [Rank 0] step=605, skipped=0, lr=[6.597290666666667e-07, 6.597290666666667e-07, 6.597290666666667e-07, 6.597290666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:16,137] [INFO] [timer.py:215:stop] epoch=0/micro_step=605/global_step=605, RunningAvgSamplesPerSec=4.916089847038758, CurrSamplesPerSec=4.919646899580324, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:16,137] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.97 | backward_microstep: 112.30 | backward_inner_microstep: 101.19 | backward_allreduce_microstep: 11.02 | step_microstep: 43.46
[default0]:[2023-08-25 18:09:16,138] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.96 (forward_moe: 20.46, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.16)
[default0]:[2023-08-25 18:09:16,138] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.30 | backward_inner: 101.19 | backward_allreduce: 11.02 | step: 43.46
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.0665], device='cuda:0'), 'moe loss': tensor([0.3025], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      605/439453125 | consumed samples:          605 | consumed tokens:      1239040 | elapsed time per iteration (ms): 1857.9 | learning rate: 6.597E-07 | global batch size:     1 | lm loss: 1.001329E+01 | moe loss: 6.050338E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.538 | TFLOPs: 1.34 |
[default0]:[2023-08-25 18:09:16,415] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.34
[default0]:[2023-08-25 18:09:16,416] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.80 | backward_microstep: 111.86 | backward_inner_microstep: 100.82 | backward_allreduce_microstep: 10.95 | step_microstep: 42.29
[default0]:[2023-08-25 18:09:16,416] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.11)
[default0]:[2023-08-25 18:09:16,416] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.86 | backward_inner: 100.82 | backward_allreduce: 10.95 | step: 42.30
[default0]:[2023-08-25 18:09:16,662] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.06 | optimizer_step: 6.39
[default0]:[2023-08-25 18:09:16,663] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.64 | backward_microstep: 113.49 | backward_inner_microstep: 101.87 | backward_allreduce_microstep: 11.52 | step_microstep: 43.96
[default0]:[2023-08-25 18:09:16,663] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.64 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:09:16,663] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.49 | backward_inner: 101.88 | backward_allreduce: 11.53 | step: 43.97
[default0]:[2023-08-25 18:09:16,920] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:09:16,920] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.94 | backward_microstep: 111.86 | backward_inner_microstep: 100.76 | backward_allreduce_microstep: 11.00 | step_microstep: 42.43
[default0]:[2023-08-25 18:09:16,920] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.94 (forward_moe: 20.41, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:09:16,921] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.86 | backward_inner: 100.77 | backward_allreduce: 11.01 | step: 42.44
[default0]:[2023-08-25 18:09:17,185] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:09:17,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.63 | backward_microstep: 111.97 | backward_inner_microstep: 100.92 | backward_allreduce_microstep: 10.96 | step_microstep: 42.54
[default0]:[2023-08-25 18:09:17,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.63 (forward_moe: 20.44, 1st alltoall: 0.87, 2nd alltoall: 0.83, top-k: 8.14)
[default0]:[2023-08-25 18:09:17,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.97 | backward_inner: 100.92 | backward_allreduce: 10.96 | step: 42.55
[default0]:[2023-08-25 18:09:17,518] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:17,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=610, skipped=0, lr=[6.651904e-07, 6.651904e-07, 6.651904e-07, 6.651904e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:17,518] [INFO] [timer.py:215:stop] epoch=0/micro_step=610/global_step=610, RunningAvgSamplesPerSec=4.916260378184495, CurrSamplesPerSec=4.9491655820747935, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:17,518] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.91 | backward_microstep: 111.99 | backward_inner_microstep: 100.89 | backward_allreduce_microstep: 11.00 | step_microstep: 42.60
[default0]:[2023-08-25 18:09:17,518] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.91 (forward_moe: 20.59, 1st alltoall: 0.87, 2nd alltoall: 0.83, top-k: 8.20)
[default0]:[2023-08-25 18:09:17,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.99 | backward_inner: 100.90 | backward_allreduce: 11.00 | step: 42.61
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.4809], device='cuda:0'), 'moe loss': tensor([0.3024], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      610/439453125 | consumed samples:          610 | consumed tokens:      1249280 | elapsed time per iteration (ms): 274.0 | learning rate: 6.652E-07 | global batch size:     1 | lm loss: 1.009618E+01 | moe loss: 6.048287E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.650 | TFLOPs: 9.07 |
[default0]:[2023-08-25 18:09:17,782] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.05 | optimizer_step: 6.39
[default0]:[2023-08-25 18:09:17,783] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.58 | backward_microstep: 115.37 | backward_inner_microstep: 103.70 | backward_allreduce_microstep: 11.57 | step_microstep: 44.10
[default0]:[2023-08-25 18:09:17,783] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.58 (forward_moe: 20.87, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.23)
[default0]:[2023-08-25 18:09:17,783] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.37 | backward_inner: 103.71 | backward_allreduce: 11.57 | step: 44.10
[default0]:[2023-08-25 18:09:18,039] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:09:18,039] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.73 | backward_microstep: 112.07 | backward_inner_microstep: 100.94 | backward_allreduce_microstep: 11.03 | step_microstep: 42.65
[default0]:[2023-08-25 18:09:18,039] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.73 (forward_moe: 20.40, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.13)
[default0]:[2023-08-25 18:09:18,039] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.07 | backward_inner: 100.94 | backward_allreduce: 11.03 | step: 42.65
[default0]:[2023-08-25 18:09:18,289] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.39
[default0]:[2023-08-25 18:09:18,290] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 115.95 | backward_inner_microstep: 104.87 | backward_allreduce_microstep: 10.99 | step_microstep: 43.31
[default0]:[2023-08-25 18:09:18,290] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.02 (forward_moe: 20.63, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.22)
[default0]:[2023-08-25 18:09:18,290] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.95 | backward_inner: 104.88 | backward_allreduce: 10.99 | step: 43.31
[default0]:[2023-08-25 18:09:18,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.41
[default0]:[2023-08-25 18:09:18,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.32 | backward_microstep: 114.11 | backward_inner_microstep: 102.92 | backward_allreduce_microstep: 11.10 | step_microstep: 43.12
[default0]:[2023-08-25 18:09:18,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.32 (forward_moe: 20.88, 1st alltoall: 0.89, 2nd alltoall: 0.88, top-k: 8.36)
[default0]:[2023-08-25 18:09:18,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.11 | backward_inner: 102.92 | backward_allreduce: 11.10 | step: 43.12
[default0]:[2023-08-25 18:09:18,838] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:18,838] [INFO] [logging.py:96:log_dist] [Rank 0] step=615, skipped=0, lr=[6.706517333333333e-07, 6.706517333333333e-07, 6.706517333333333e-07, 6.706517333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:18,838] [INFO] [timer.py:215:stop] epoch=0/micro_step=615/global_step=615, RunningAvgSamplesPerSec=4.916076252498432, CurrSamplesPerSec=5.048712815988117, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:18,838] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 109.83 | backward_inner_microstep: 98.91 | backward_allreduce_microstep: 10.82 | step_microstep: 42.01
[default0]:[2023-08-25 18:09:18,838] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.79)
[default0]:[2023-08-25 18:09:18,839] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.83 | backward_inner: 98.92 | backward_allreduce: 10.82 | step: 42.01
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([51.0131], device='cuda:0'), 'moe loss': tensor([0.3026], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      615/439453125 | consumed samples:          615 | consumed tokens:      1259520 | elapsed time per iteration (ms): 264.4 | learning rate: 6.707E-07 | global batch size:     1 | lm loss: 1.020263E+01 | moe loss: 6.052861E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.783 | TFLOPs: 9.40 |
[default0]:[2023-08-25 18:09:19,098] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:19,098] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.76 | backward_microstep: 109.77 | backward_inner_microstep: 98.86 | backward_allreduce_microstep: 10.81 | step_microstep: 41.75
[default0]:[2023-08-25 18:09:19,098] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.76 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:09:19,098] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.77 | backward_inner: 98.87 | backward_allreduce: 10.81 | step: 41.75
[default0]:[2023-08-25 18:09:19,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:19,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.94 | backward_microstep: 109.78 | backward_inner_microstep: 98.87 | backward_allreduce_microstep: 10.82 | step_microstep: 41.69
[default0]:[2023-08-25 18:09:19,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.94 (forward_moe: 19.95, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:09:19,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.78 | backward_inner: 98.88 | backward_allreduce: 10.82 | step: 41.69
[default0]:[2023-08-25 18:09:19,646] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:19,646] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.51 | backward_microstep: 109.09 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.78 | step_microstep: 41.47
[default0]:[2023-08-25 18:09:19,646] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.51 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:09:19,646] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.09 | backward_inner: 98.22 | backward_allreduce: 10.79 | step: 41.47
[default0]:[2023-08-25 18:09:19,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:19,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.58 | backward_microstep: 111.34 | backward_inner_microstep: 100.45 | backward_allreduce_microstep: 10.79 | step_microstep: 41.51
[default0]:[2023-08-25 18:09:19,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.58 (forward_moe: 20.26, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 7.88)
[default0]:[2023-08-25 18:09:19,908] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.33 | backward_inner: 100.44 | backward_allreduce: 10.80 | step: 41.52
[default0]:[2023-08-25 18:09:20,169] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:20,170] [INFO] [logging.py:96:log_dist] [Rank 0] step=620, skipped=0, lr=[6.761130666666667e-07, 6.761130666666667e-07, 6.761130666666667e-07, 6.761130666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:20,170] [INFO] [timer.py:215:stop] epoch=0/micro_step=620/global_step=620, RunningAvgSamplesPerSec=4.917099716477803, CurrSamplesPerSec=5.0662025198725935, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:20,170] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.79 | backward_microstep: 109.12 | backward_inner_microstep: 98.20 | backward_allreduce_microstep: 10.82 | step_microstep: 41.92
[default0]:[2023-08-25 18:09:20,170] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.79 (forward_moe: 19.91, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:09:20,170] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.21 | backward_allreduce: 10.83 | step: 41.93
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.4883], device='cuda:0'), 'moe loss': tensor([0.3020], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      620/439453125 | consumed samples:          620 | consumed tokens:      1269760 | elapsed time per iteration (ms): 267.5 | learning rate: 6.761E-07 | global batch size:     1 | lm loss: 1.009767E+01 | moe loss: 6.040370E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.738 | TFLOPs: 9.29 |
[default0]:[2023-08-25 18:09:20,448] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:20,448] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 109.12 | backward_inner_microstep: 98.20 | backward_allreduce_microstep: 10.82 | step_microstep: 41.59
[default0]:[2023-08-25 18:09:20,448] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.41 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:09:20,448] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.21 | backward_allreduce: 10.82 | step: 41.60
[default0]:[2023-08-25 18:09:20,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:21,078] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.59 | backward_microstep: 109.00 | backward_inner_microstep: 98.12 | backward_allreduce_microstep: 10.78 | step_microstep: 388.06
[default0]:[2023-08-25 18:09:21,079] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.59 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:09:21,079] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.13 | backward_allreduce: 10.78 | step: 388.06
[default0]:[2023-08-25 18:09:21,337] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:21,338] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.40 | backward_microstep: 109.42 | backward_inner_microstep: 98.52 | backward_allreduce_microstep: 10.81 | step_microstep: 41.40
[default0]:[2023-08-25 18:09:21,338] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.40 (forward_moe: 19.86, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:09:21,338] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.42 | backward_inner: 98.53 | backward_allreduce: 10.81 | step: 41.40
[default0]:[2023-08-25 18:09:21,577] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:21,577] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.40 | backward_microstep: 109.28 | backward_inner_microstep: 98.38 | backward_allreduce_microstep: 10.80 | step_microstep: 41.49
[default0]:[2023-08-25 18:09:21,577] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.40 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:09:21,577] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.28 | backward_inner: 98.39 | backward_allreduce: 10.81 | step: 41.49
[default0]:[2023-08-25 18:09:21,823] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:21,823] [INFO] [logging.py:96:log_dist] [Rank 0] step=625, skipped=0, lr=[6.815744000000001e-07, 6.815744000000001e-07, 6.815744000000001e-07, 6.815744000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:21,823] [INFO] [timer.py:215:stop] epoch=0/micro_step=625/global_step=625, RunningAvgSamplesPerSec=4.904842404609641, CurrSamplesPerSec=5.072494896428951, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:21,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 109.10 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.82 | step_microstep: 41.95
[default0]:[2023-08-25 18:09:21,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.86, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:09:21,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.09 | backward_inner: 98.19 | backward_allreduce: 10.82 | step: 41.96
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.1704], device='cuda:0'), 'moe loss': tensor([0.3022], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      625/439453125 | consumed samples:          625 | consumed tokens:      1280000 | elapsed time per iteration (ms): 329.2 | learning rate: 6.816E-07 | global batch size:     1 | lm loss: 1.003407E+01 | moe loss: 6.043006E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.037 | TFLOPs: 7.55 |
[default0]:[2023-08-25 18:09:22,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:22,086] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.71 | backward_microstep: 108.99 | backward_inner_microstep: 98.05 | backward_allreduce_microstep: 10.85 | step_microstep: 41.46
[default0]:[2023-08-25 18:09:22,086] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.71 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.75)
[default0]:[2023-08-25 18:09:22,086] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.99 | backward_inner: 98.06 | backward_allreduce: 10.85 | step: 41.46
[default0]:[2023-08-25 18:09:22,348] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:22,349] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 110.48 | backward_inner_microstep: 99.61 | backward_allreduce_microstep: 10.78 | step_microstep: 41.58
[default0]:[2023-08-25 18:09:22,349] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.91, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:09:22,349] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.48 | backward_inner: 99.62 | backward_allreduce: 10.78 | step: 41.58
[default0]:[2023-08-25 18:09:22,585] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:22,586] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 109.00 | backward_inner_microstep: 98.14 | backward_allreduce_microstep: 10.77 | step_microstep: 41.54
[default0]:[2023-08-25 18:09:22,586] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.75, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:09:22,586] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.14 | backward_allreduce: 10.77 | step: 41.54
[default0]:[2023-08-25 18:09:22,844] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:22,845] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.39 | backward_microstep: 109.14 | backward_inner_microstep: 98.27 | backward_allreduce_microstep: 10.78 | step_microstep: 41.45
[default0]:[2023-08-25 18:09:22,845] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.39 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:09:22,845] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.14 | backward_inner: 98.28 | backward_allreduce: 10.78 | step: 41.45
[default0]:[2023-08-25 18:09:23,100] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:23,101] [INFO] [logging.py:96:log_dist] [Rank 0] step=630, skipped=0, lr=[6.870357333333333e-07, 6.870357333333333e-07, 6.870357333333333e-07, 6.870357333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:23,101] [INFO] [timer.py:215:stop] epoch=0/micro_step=630/global_step=630, RunningAvgSamplesPerSec=4.906118371097339, CurrSamplesPerSec=5.071446103769695, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:23,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 109.24 | backward_inner_microstep: 98.35 | backward_allreduce_microstep: 10.80 | step_microstep: 41.94
[default0]:[2023-08-25 18:09:23,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:09:23,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.24 | backward_inner: 98.36 | backward_allreduce: 10.80 | step: 41.94
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.3228], device='cuda:0'), 'moe loss': tensor([0.3020], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      630/439453125 | consumed samples:          630 | consumed tokens:      1290240 | elapsed time per iteration (ms): 255.5 | learning rate: 6.870E-07 | global batch size:     1 | lm loss: 1.006456E+01 | moe loss: 6.039967E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.914 | TFLOPs: 9.72 |
[default0]:[2023-08-25 18:09:23,348] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:23,349] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.27 | backward_microstep: 109.38 | backward_inner_microstep: 98.50 | backward_allreduce_microstep: 10.79 | step_microstep: 41.57
[default0]:[2023-08-25 18:09:23,349] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.27 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:09:23,349] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.38 | backward_inner: 98.50 | backward_allreduce: 10.79 | step: 41.57
[default0]:[2023-08-25 18:09:23,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:23,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.42 | backward_microstep: 109.13 | backward_inner_microstep: 98.23 | backward_allreduce_microstep: 10.80 | step_microstep: 41.62
[default0]:[2023-08-25 18:09:23,695] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.42 (forward_moe: 19.84, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:09:23,695] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.24 | backward_allreduce: 10.80 | step: 41.63
[default0]:[2023-08-25 18:09:24,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:24,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.48 | backward_microstep: 109.01 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.82 | step_microstep: 41.40
[default0]:[2023-08-25 18:09:24,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:09:24,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.01 | backward_inner: 98.11 | backward_allreduce: 10.82 | step: 41.41
[default0]:[2023-08-25 18:09:24,276] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:24,277] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.48 | backward_microstep: 109.16 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.86 | step_microstep: 41.39
[default0]:[2023-08-25 18:09:24,277] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:09:24,277] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.16 | backward_inner: 98.21 | backward_allreduce: 10.86 | step: 41.39
[default0]:[2023-08-25 18:09:24,527] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:09:24,528] [INFO] [logging.py:96:log_dist] [Rank 0] step=635, skipped=0, lr=[6.924970666666667e-07, 6.924970666666667e-07, 6.924970666666667e-07, 6.924970666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:24,528] [INFO] [timer.py:215:stop] epoch=0/micro_step=635/global_step=635, RunningAvgSamplesPerSec=4.907258564641086, CurrSamplesPerSec=4.985343392046136, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:24,528] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 111.26 | backward_inner_microstep: 100.19 | backward_allreduce_microstep: 10.97 | step_microstep: 43.25
[default0]:[2023-08-25 18:09:24,528] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 20.23, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.02)
[default0]:[2023-08-25 18:09:24,528] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.25 | backward_inner: 100.20 | backward_allreduce: 10.97 | step: 43.26
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.5269], device='cuda:0'), 'moe loss': tensor([0.3023], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      635/439453125 | consumed samples:          635 | consumed tokens:      1300480 | elapsed time per iteration (ms): 285.3 | learning rate: 6.925E-07 | global batch size:     1 | lm loss: 1.010537E+01 | moe loss: 6.046477E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.505 | TFLOPs: 8.71 |
[default0]:[2023-08-25 18:09:24,781] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:09:24,781] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.26 | backward_microstep: 112.54 | backward_inner_microstep: 101.48 | backward_allreduce_microstep: 10.96 | step_microstep: 42.68
[default0]:[2023-08-25 18:09:24,782] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.26 (forward_moe: 20.61, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:09:24,782] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.54 | backward_inner: 101.49 | backward_allreduce: 10.97 | step: 42.69
[default0]:[2023-08-25 18:09:25,044] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.44
[default0]:[2023-08-25 18:09:25,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.82 | backward_microstep: 112.75 | backward_inner_microstep: 101.63 | backward_allreduce_microstep: 11.02 | step_microstep: 44.25
[default0]:[2023-08-25 18:09:25,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.82 (forward_moe: 20.67, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.32)
[default0]:[2023-08-25 18:09:25,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.74 | backward_inner: 101.64 | backward_allreduce: 11.02 | step: 44.26
[default0]:[2023-08-25 18:09:25,316] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 10.00
[default0]:[2023-08-25 18:09:25,316] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.54 | backward_microstep: 113.67 | backward_inner_microstep: 102.53 | backward_allreduce_microstep: 11.05 | step_microstep: 46.73
[default0]:[2023-08-25 18:09:25,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.54 (forward_moe: 20.76, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.35)
[default0]:[2023-08-25 18:09:25,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.67 | backward_inner: 102.53 | backward_allreduce: 11.06 | step: 46.73
[default0]:[2023-08-25 18:09:25,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.41
[default0]:[2023-08-25 18:09:25,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.47 | backward_microstep: 113.91 | backward_inner_microstep: 102.76 | backward_allreduce_microstep: 11.07 | step_microstep: 43.25
[default0]:[2023-08-25 18:09:25,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.47 (forward_moe: 20.93, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.37)
[default0]:[2023-08-25 18:09:25,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.91 | backward_inner: 102.76 | backward_allreduce: 11.07 | step: 43.26
[default0]:[2023-08-25 18:09:25,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.44
[default0]:[2023-08-25 18:09:25,834] [INFO] [logging.py:96:log_dist] [Rank 0] step=640, skipped=0, lr=[6.979584e-07, 6.979584e-07, 6.979584e-07, 6.979584e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:25,834] [INFO] [timer.py:215:stop] epoch=0/micro_step=640/global_step=640, RunningAvgSamplesPerSec=4.906789987041014, CurrSamplesPerSec=4.827547946829461, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:25,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.09 | backward_microstep: 114.78 | backward_inner_microstep: 103.37 | backward_allreduce_microstep: 11.32 | step_microstep: 43.68
[default0]:[2023-08-25 18:09:25,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.09 (forward_moe: 21.05, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.43)
[default0]:[2023-08-25 18:09:25,835] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.78 | backward_inner: 103.37 | backward_allreduce: 11.33 | step: 43.69
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.3563], device='cuda:0'), 'moe loss': tensor([0.3024], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      640/439453125 | consumed samples:          640 | consumed tokens:      1310720 | elapsed time per iteration (ms): 261.3 | learning rate: 6.980E-07 | global batch size:     1 | lm loss: 1.007126E+01 | moe loss: 6.047133E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.826 | TFLOPs: 9.51 |
[default0]:[2023-08-25 18:09:26,092] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.39
[default0]:[2023-08-25 18:09:26,093] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.80 | backward_microstep: 114.58 | backward_inner_microstep: 103.31 | backward_allreduce_microstep: 11.18 | step_microstep: 43.89
[default0]:[2023-08-25 18:09:26,093] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.80 (forward_moe: 20.94, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.42)
[default0]:[2023-08-25 18:09:26,093] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.58 | backward_inner: 103.32 | backward_allreduce: 11.18 | step: 43.90
[default0]:[2023-08-25 18:09:26,349] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.40
[default0]:[2023-08-25 18:09:26,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.94 | backward_microstep: 114.33 | backward_inner_microstep: 103.14 | backward_allreduce_microstep: 11.10 | step_microstep: 43.31
[default0]:[2023-08-25 18:09:26,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.94 (forward_moe: 20.90, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.42)
[default0]:[2023-08-25 18:09:26,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.33 | backward_inner: 103.15 | backward_allreduce: 11.10 | step: 43.31
[default0]:[2023-08-25 18:09:26,605] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:09:26,606] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.84 | backward_microstep: 114.53 | backward_inner_microstep: 103.35 | backward_allreduce_microstep: 11.08 | step_microstep: 43.24
[default0]:[2023-08-25 18:09:26,606] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.84 (forward_moe: 20.90, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.43)
[default0]:[2023-08-25 18:09:26,606] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.53 | backward_inner: 103.36 | backward_allreduce: 11.09 | step: 43.24
[default0]:[2023-08-25 18:09:26,842] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:26,843] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.49 | backward_microstep: 111.37 | backward_inner_microstep: 100.12 | backward_allreduce_microstep: 11.16 | step_microstep: 42.19
[default0]:[2023-08-25 18:09:26,843] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.49 (forward_moe: 20.28, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 8.08)
[default0]:[2023-08-25 18:09:26,843] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.37 | backward_inner: 100.12 | backward_allreduce: 11.16 | step: 42.19
[default0]:[2023-08-25 18:09:27,079] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.43
[default0]:[2023-08-25 18:09:27,079] [INFO] [logging.py:96:log_dist] [Rank 0] step=645, skipped=0, lr=[7.034197333333333e-07, 7.034197333333333e-07, 7.034197333333333e-07, 7.034197333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:27,080] [INFO] [timer.py:215:stop] epoch=0/micro_step=645/global_step=645, RunningAvgSamplesPerSec=4.906696220423816, CurrSamplesPerSec=4.9834183249133845, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:27,080] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.39 | backward_microstep: 111.11 | backward_inner_microstep: 100.12 | backward_allreduce_microstep: 10.89 | step_microstep: 42.67
[default0]:[2023-08-25 18:09:27,080] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.39 (forward_moe: 20.17, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.97)
[default0]:[2023-08-25 18:09:27,080] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.10 | backward_inner: 100.12 | backward_allreduce: 10.89 | step: 42.68
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.6703], device='cuda:0'), 'moe loss': tensor([0.3015], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      645/439453125 | consumed samples:          645 | consumed tokens:      1320960 | elapsed time per iteration (ms): 249.0 | learning rate: 7.034E-07 | global batch size:     1 | lm loss: 9.934064E+00 | moe loss: 6.030872E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.016 | TFLOPs: 9.98 |
[default0]:[2023-08-25 18:09:27,335] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.36
[default0]:[2023-08-25 18:09:27,335] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.45 | backward_microstep: 112.83 | backward_inner_microstep: 101.71 | backward_allreduce_microstep: 11.02 | step_microstep: 42.15
[default0]:[2023-08-25 18:09:27,335] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.45 (forward_moe: 20.26, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.02)
[default0]:[2023-08-25 18:09:27,336] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.83 | backward_inner: 101.71 | backward_allreduce: 11.02 | step: 42.15
[default0]:[2023-08-25 18:09:27,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:09:27,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.36 | backward_microstep: 111.15 | backward_inner_microstep: 100.17 | backward_allreduce_microstep: 10.89 | step_microstep: 42.17
[default0]:[2023-08-25 18:09:27,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.35 (forward_moe: 20.19, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.97)
[default0]:[2023-08-25 18:09:27,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.15 | backward_inner: 100.17 | backward_allreduce: 10.89 | step: 42.18
[default0]:[2023-08-25 18:09:27,864] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.34
[default0]:[2023-08-25 18:09:27,864] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 109.19 | backward_inner_microstep: 98.28 | backward_allreduce_microstep: 10.81 | step_microstep: 41.58
[default0]:[2023-08-25 18:09:27,864] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:09:27,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.19 | backward_inner: 98.29 | backward_allreduce: 10.82 | step: 41.58
[default0]:[2023-08-25 18:09:28,102] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:28,102] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 108.86 | backward_inner_microstep: 97.97 | backward_allreduce_microstep: 10.80 | step_microstep: 41.49
[default0]:[2023-08-25 18:09:28,102] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.71, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:09:28,102] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.86 | backward_inner: 97.97 | backward_allreduce: 10.81 | step: 41.49
[default0]:[2023-08-25 18:09:28,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:28,343] [INFO] [logging.py:96:log_dist] [Rank 0] step=650, skipped=0, lr=[7.088810666666666e-07, 7.088810666666666e-07, 7.088810666666666e-07, 7.088810666666666e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:28,343] [INFO] [timer.py:215:stop] epoch=0/micro_step=650/global_step=650, RunningAvgSamplesPerSec=4.90751623501988, CurrSamplesPerSec=4.992315676210971, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:28,343] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 112.08 | backward_inner_microstep: 101.16 | backward_allreduce_microstep: 10.83 | step_microstep: 42.22
[default0]:[2023-08-25 18:09:28,343] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:09:28,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.08 | backward_inner: 101.17 | backward_allreduce: 10.83 | step: 42.23
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.3942], device='cuda:0'), 'moe loss': tensor([0.3019], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      650/439453125 | consumed samples:          650 | consumed tokens:      1331200 | elapsed time per iteration (ms): 253.5 | learning rate: 7.089E-07 | global batch size:     1 | lm loss: 1.007883E+01 | moe loss: 6.038064E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.945 | TFLOPs: 9.80 |
[default0]:[2023-08-25 18:09:28,592] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:28,593] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.54 | backward_microstep: 108.91 | backward_inner_microstep: 97.97 | backward_allreduce_microstep: 10.84 | step_microstep: 41.46
[default0]:[2023-08-25 18:09:28,593] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.54 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:09:28,593] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 97.98 | backward_allreduce: 10.84 | step: 41.46
[default0]:[2023-08-25 18:09:28,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:28,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 110.39 | backward_inner_microstep: 99.47 | backward_allreduce_microstep: 10.83 | step_microstep: 41.57
[default0]:[2023-08-25 18:09:28,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.40 (forward_moe: 20.11, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.79)
[default0]:[2023-08-25 18:09:28,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.39 | backward_inner: 99.47 | backward_allreduce: 10.83 | step: 41.58
[default0]:[2023-08-25 18:09:29,098] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:29,098] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.66 | backward_microstep: 108.96 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.78 | step_microstep: 41.36
[default0]:[2023-08-25 18:09:29,099] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:09:29,099] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.95 | backward_inner: 98.09 | backward_allreduce: 10.78 | step: 41.36
[default0]:[2023-08-25 18:09:29,355] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:29,356] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.38 | backward_microstep: 109.05 | backward_inner_microstep: 98.15 | backward_allreduce_microstep: 10.80 | step_microstep: 41.37
[default0]:[2023-08-25 18:09:29,356] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.38 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.76)
[default0]:[2023-08-25 18:09:29,356] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.16 | backward_allreduce: 10.81 | step: 41.37
[default0]:[2023-08-25 18:09:29,668] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:09:29,669] [INFO] [logging.py:96:log_dist] [Rank 0] step=655, skipped=0, lr=[7.143424e-07, 7.143424e-07, 7.143424e-07, 7.143424e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:29,669] [INFO] [timer.py:215:stop] epoch=0/micro_step=655/global_step=655, RunningAvgSamplesPerSec=4.908520746719619, CurrSamplesPerSec=4.919139154400985, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:29,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.91 | backward_microstep: 112.57 | backward_inner_microstep: 101.43 | backward_allreduce_microstep: 11.04 | step_microstep: 43.25
[default0]:[2023-08-25 18:09:29,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.91 (forward_moe: 20.62, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.22)
[default0]:[2023-08-25 18:09:29,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.57 | backward_inner: 101.44 | backward_allreduce: 11.05 | step: 43.26
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.6707], device='cuda:0'), 'moe loss': tensor([0.3019], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      655/439453125 | consumed samples:          655 | consumed tokens:      1341440 | elapsed time per iteration (ms): 264.3 | learning rate: 7.143E-07 | global batch size:     1 | lm loss: 1.013415E+01 | moe loss: 6.037145E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.783 | TFLOPs: 9.40 |
[default0]:[2023-08-25 18:09:29,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.40
[default0]:[2023-08-25 18:09:29,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.37 | backward_microstep: 113.61 | backward_inner_microstep: 102.46 | backward_allreduce_microstep: 11.05 | step_microstep: 43.25
[default0]:[2023-08-25 18:09:29,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.37 (forward_moe: 20.77, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:09:29,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.61 | backward_inner: 102.47 | backward_allreduce: 11.06 | step: 43.25
[default0]:[2023-08-25 18:09:30,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.15 | optimizer_step: 6.50
[default0]:[2023-08-25 18:09:30,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.93 | backward_microstep: 117.36 | backward_inner_microstep: 105.97 | backward_allreduce_microstep: 11.29 | step_microstep: 44.34
[default0]:[2023-08-25 18:09:30,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.92 (forward_moe: 21.50, 1st alltoall: 0.91, 2nd alltoall: 0.86, top-k: 8.79)
[default0]:[2023-08-25 18:09:30,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.36 | backward_inner: 105.98 | backward_allreduce: 11.30 | step: 44.34
[default0]:[2023-08-25 18:09:30,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.43
[default0]:[2023-08-25 18:09:30,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.23 | backward_microstep: 117.31 | backward_inner_microstep: 105.99 | backward_allreduce_microstep: 11.22 | step_microstep: 43.98
[default0]:[2023-08-25 18:09:30,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.23 (forward_moe: 21.55, 1st alltoall: 0.93, 2nd alltoall: 0.85, top-k: 8.76)
[default0]:[2023-08-25 18:09:30,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.31 | backward_inner: 106.00 | backward_allreduce: 11.23 | step: 43.98
[default0]:[2023-08-25 18:09:30,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:09:30,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.26 | backward_microstep: 115.43 | backward_inner_microstep: 104.25 | backward_allreduce_microstep: 11.08 | step_microstep: 43.65
[default0]:[2023-08-25 18:09:30,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.26 (forward_moe: 21.07, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.54)
[default0]:[2023-08-25 18:09:30,911] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.43 | backward_inner: 104.25 | backward_allreduce: 11.08 | step: 43.65
[default0]:[2023-08-25 18:09:31,179] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.10 | optimizer_step: 6.48
[default0]:[2023-08-25 18:09:31,180] [INFO] [logging.py:96:log_dist] [Rank 0] step=660, skipped=0, lr=[7.198037333333334e-07, 7.198037333333334e-07, 7.198037333333334e-07, 7.198037333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:31,180] [INFO] [timer.py:215:stop] epoch=0/micro_step=660/global_step=660, RunningAvgSamplesPerSec=4.9075601564257, CurrSamplesPerSec=4.765810458570906, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:31,180] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.78 | backward_microstep: 116.08 | backward_inner_microstep: 104.57 | backward_allreduce_microstep: 11.41 | step_microstep: 44.41
[default0]:[2023-08-25 18:09:31,180] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.78 (forward_moe: 21.24, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.53)
[default0]:[2023-08-25 18:09:31,180] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.07 | backward_inner: 104.57 | backward_allreduce: 11.42 | step: 44.41
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.0957], device='cuda:0'), 'moe loss': tensor([0.3052], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      660/439453125 | consumed samples:          660 | consumed tokens:      1351680 | elapsed time per iteration (ms): 302.8 | learning rate: 7.198E-07 | global batch size:     1 | lm loss: 1.001914E+01 | moe loss: 6.103676E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.303 | TFLOPs: 8.21 |
[default0]:[2023-08-25 18:09:31,451] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.38
[default0]:[2023-08-25 18:09:31,451] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.32 | backward_microstep: 115.58 | backward_inner_microstep: 104.34 | backward_allreduce_microstep: 11.15 | step_microstep: 43.59
[default0]:[2023-08-25 18:09:31,451] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.32 (forward_moe: 21.22, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.67)
[default0]:[2023-08-25 18:09:31,451] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.58 | backward_inner: 104.35 | backward_allreduce: 11.15 | step: 43.59
[default0]:[2023-08-25 18:09:31,788] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.40
[default0]:[2023-08-25 18:09:31,788] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.77 | backward_microstep: 112.18 | backward_inner_microstep: 101.13 | backward_allreduce_microstep: 10.96 | step_microstep: 42.66
[default0]:[2023-08-25 18:09:31,788] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.77 (forward_moe: 20.44, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:09:31,789] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.18 | backward_inner: 101.14 | backward_allreduce: 10.96 | step: 42.66
[default0]:[2023-08-25 18:09:32,099] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.35
[default0]:[2023-08-25 18:09:32,099] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.76 | backward_microstep: 112.34 | backward_inner_microstep: 101.26 | backward_allreduce_microstep: 10.99 | step_microstep: 42.88
[default0]:[2023-08-25 18:09:32,099] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.76 (forward_moe: 20.61, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.14)
[default0]:[2023-08-25 18:09:32,099] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.34 | backward_inner: 101.27 | backward_allreduce: 10.99 | step: 42.89
[default0]:[2023-08-25 18:09:32,353] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:09:32,353] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.14 | backward_microstep: 113.60 | backward_inner_microstep: 102.55 | backward_allreduce_microstep: 10.96 | step_microstep: 42.43
[default0]:[2023-08-25 18:09:32,353] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.14 (forward_moe: 20.46, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.12)
[default0]:[2023-08-25 18:09:32,353] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.60 | backward_inner: 102.56 | backward_allreduce: 10.96 | step: 42.43
[default0]:[2023-08-25 18:09:32,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:09:32,604] [INFO] [logging.py:96:log_dist] [Rank 0] step=665, skipped=0, lr=[7.252650666666667e-07, 7.252650666666667e-07, 7.252650666666667e-07, 7.252650666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:32,605] [INFO] [timer.py:215:stop] epoch=0/micro_step=665/global_step=665, RunningAvgSamplesPerSec=4.907443496533619, CurrSamplesPerSec=4.93817020735515, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:32,605] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.79 | backward_microstep: 112.14 | backward_inner_microstep: 101.10 | backward_allreduce_microstep: 10.94 | step_microstep: 43.01
[default0]:[2023-08-25 18:09:32,605] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.56, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:09:32,605] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.14 | backward_inner: 101.10 | backward_allreduce: 10.95 | step: 43.02
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.6390], device='cuda:0'), 'moe loss': tensor([0.3030], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      665/439453125 | consumed samples:          665 | consumed tokens:      1361920 | elapsed time per iteration (ms): 284.8 | learning rate: 7.253E-07 | global batch size:     1 | lm loss: 1.012780E+01 | moe loss: 6.060545E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.512 | TFLOPs: 8.73 |
[default0]:[2023-08-25 18:09:32,851] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:09:32,851] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.89 | backward_microstep: 112.63 | backward_inner_microstep: 101.21 | backward_allreduce_microstep: 11.33 | step_microstep: 42.61
[default0]:[2023-08-25 18:09:32,851] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.89 (forward_moe: 20.41, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:09:32,851] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.63 | backward_inner: 101.21 | backward_allreduce: 11.33 | step: 42.61
[default0]:[2023-08-25 18:09:33,202] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.50
[default0]:[2023-08-25 18:09:33,203] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.54 | backward_microstep: 108.97 | backward_inner_microstep: 98.07 | backward_allreduce_microstep: 10.80 | step_microstep: 42.10
[default0]:[2023-08-25 18:09:33,203] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.53 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:09:33,203] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.97 | backward_inner: 98.08 | backward_allreduce: 10.80 | step: 42.10
[default0]:[2023-08-25 18:09:33,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:33,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 109.04 | backward_inner_microstep: 98.03 | backward_allreduce_microstep: 10.82 | step_microstep: 41.42
[default0]:[2023-08-25 18:09:33,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:09:33,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.04 | backward_inner: 98.03 | backward_allreduce: 10.83 | step: 41.42
[default0]:[2023-08-25 18:09:33,767] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:33,767] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.43 | backward_microstep: 108.92 | backward_inner_microstep: 98.04 | backward_allreduce_microstep: 10.79 | step_microstep: 41.42
[default0]:[2023-08-25 18:09:33,768] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.43 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:09:33,768] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.05 | backward_allreduce: 10.79 | step: 41.42
[default0]:[2023-08-25 18:09:34,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:09:34,005] [INFO] [logging.py:96:log_dist] [Rank 0] step=670, skipped=0, lr=[7.307264e-07, 7.307264e-07, 7.307264e-07, 7.307264e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:34,006] [INFO] [timer.py:215:stop] epoch=0/micro_step=670/global_step=670, RunningAvgSamplesPerSec=4.908441329335086, CurrSamplesPerSec=5.0636214704202835, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:34,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.92 | backward_microstep: 109.12 | backward_inner_microstep: 98.22 | backward_allreduce_microstep: 10.80 | step_microstep: 41.90
[default0]:[2023-08-25 18:09:34,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.92 (forward_moe: 19.89, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:09:34,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.23 | backward_allreduce: 10.81 | step: 41.90
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.6519], device='cuda:0'), 'moe loss': tensor([0.3027], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      670/439453125 | consumed samples:          670 | consumed tokens:      1372160 | elapsed time per iteration (ms): 280.0 | learning rate: 7.307E-07 | global batch size:     1 | lm loss: 9.930380E+00 | moe loss: 6.053763E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.572 | TFLOPs: 8.88 |
[default0]:[2023-08-25 18:09:34,266] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:34,267] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 108.97 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.78 | step_microstep: 41.42
[default0]:[2023-08-25 18:09:34,267] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.75, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:09:34,267] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.10 | backward_allreduce: 10.78 | step: 41.43
[default0]:[2023-08-25 18:09:34,515] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:34,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 108.96 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.78 | step_microstep: 41.35
[default0]:[2023-08-25 18:09:34,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:09:34,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.09 | backward_allreduce: 10.78 | step: 41.36
[default0]:[2023-08-25 18:09:34,745] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.37
[default0]:[2023-08-25 18:09:34,746] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.50 | backward_microstep: 108.81 | backward_inner_microstep: 97.95 | backward_allreduce_microstep: 10.77 | step_microstep: 41.48
[default0]:[2023-08-25 18:09:34,746] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.50 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:09:34,746] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.81 | backward_inner: 97.95 | backward_allreduce: 10.77 | step: 41.48
[default0]:[2023-08-25 18:09:35,021] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:35,023] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.86 | backward_microstep: 109.09 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.81 | step_microstep: 42.68
[default0]:[2023-08-25 18:09:35,023] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.86 (forward_moe: 19.76, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:09:35,023] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.19 | backward_allreduce: 10.81 | step: 42.68
[default0]:[2023-08-25 18:09:35,286] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:09:35,287] [INFO] [logging.py:96:log_dist] [Rank 0] step=675, skipped=0, lr=[7.361877333333333e-07, 7.361877333333333e-07, 7.361877333333333e-07, 7.361877333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:35,287] [INFO] [timer.py:215:stop] epoch=0/micro_step=675/global_step=675, RunningAvgSamplesPerSec=4.909550056465886, CurrSamplesPerSec=5.070244512166375, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:35,287] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 108.85 | backward_inner_microstep: 97.99 | backward_allreduce_microstep: 10.77 | step_microstep: 42.41
[default0]:[2023-08-25 18:09:35,287] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:09:35,287] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.85 | backward_inner: 97.99 | backward_allreduce: 10.77 | step: 42.42
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.0670], device='cuda:0'), 'moe loss': tensor([0.3018], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      675/439453125 | consumed samples:          675 | consumed tokens:      1382400 | elapsed time per iteration (ms): 256.4 | learning rate: 7.362E-07 | global batch size:     1 | lm loss: 1.001340E+01 | moe loss: 6.036986E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.900 | TFLOPs: 9.69 |
[default0]:[2023-08-25 18:09:35,578] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 10.03
[default0]:[2023-08-25 18:09:35,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.62 | backward_microstep: 112.49 | backward_inner_microstep: 101.39 | backward_allreduce_microstep: 11.01 | step_microstep: 46.98
[default0]:[2023-08-25 18:09:35,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.62 (forward_moe: 20.63, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.19)
[default0]:[2023-08-25 18:09:35,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.49 | backward_inner: 101.39 | backward_allreduce: 11.01 | step: 46.98
[default0]:[2023-08-25 18:09:35,829] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.40
[default0]:[2023-08-25 18:09:35,830] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.08 | backward_microstep: 118.31 | backward_inner_microstep: 106.61 | backward_allreduce_microstep: 11.59 | step_microstep: 42.80
[default0]:[2023-08-25 18:09:35,830] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.08 (forward_moe: 21.49, 1st alltoall: 0.91, 2nd alltoall: 0.86, top-k: 8.59)
[default0]:[2023-08-25 18:09:35,830] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 118.30 | backward_inner: 106.62 | backward_allreduce: 11.60 | step: 42.80
[default0]:[2023-08-25 18:09:36,087] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.41
[default0]:[2023-08-25 18:09:36,088] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.52 | backward_microstep: 113.61 | backward_inner_microstep: 102.44 | backward_allreduce_microstep: 11.08 | step_microstep: 43.15
[default0]:[2023-08-25 18:09:36,088] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.52 (forward_moe: 20.83, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:09:36,088] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.61 | backward_inner: 102.45 | backward_allreduce: 11.08 | step: 43.16
[default0]:[2023-08-25 18:09:36,337] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:09:36,337] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.76 | backward_microstep: 113.63 | backward_inner_microstep: 102.46 | backward_allreduce_microstep: 11.08 | step_microstep: 42.90
[default0]:[2023-08-25 18:09:36,337] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.76 (forward_moe: 20.75, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:09:36,337] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.63 | backward_inner: 102.46 | backward_allreduce: 11.08 | step: 42.90
[default0]:[2023-08-25 18:09:36,588] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.41
[default0]:[2023-08-25 18:09:36,588] [INFO] [logging.py:96:log_dist] [Rank 0] step=680, skipped=0, lr=[7.416490666666667e-07, 7.416490666666667e-07, 7.416490666666667e-07, 7.416490666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:36,588] [INFO] [timer.py:215:stop] epoch=0/micro_step=680/global_step=680, RunningAvgSamplesPerSec=4.909066873728219, CurrSamplesPerSec=4.857942693403105, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:36,588] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.63 | backward_microstep: 114.18 | backward_inner_microstep: 103.06 | backward_allreduce_microstep: 11.02 | step_microstep: 43.48
[default0]:[2023-08-25 18:09:36,589] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.63 (forward_moe: 20.97, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.33)
[default0]:[2023-08-25 18:09:36,589] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.18 | backward_inner: 103.07 | backward_allreduce: 11.02 | step: 43.48
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.2211], device='cuda:0'), 'moe loss': tensor([0.3015], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      680/439453125 | consumed samples:          680 | consumed tokens:      1392640 | elapsed time per iteration (ms): 260.2 | learning rate: 7.416E-07 | global batch size:     1 | lm loss: 1.004422E+01 | moe loss: 6.029903E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.844 | TFLOPs: 9.55 |
[default0]:[2023-08-25 18:09:36,839] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.41
[default0]:[2023-08-25 18:09:36,839] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.65 | backward_microstep: 114.57 | backward_inner_microstep: 103.36 | backward_allreduce_microstep: 11.11 | step_microstep: 43.40
[default0]:[2023-08-25 18:09:36,839] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.65 (forward_moe: 20.89, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.42)
[default0]:[2023-08-25 18:09:36,840] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.56 | backward_inner: 103.36 | backward_allreduce: 11.12 | step: 43.41
[default0]:[2023-08-25 18:09:37,106] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.42
[default0]:[2023-08-25 18:09:37,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.79 | backward_microstep: 114.48 | backward_inner_microstep: 103.23 | backward_allreduce_microstep: 11.15 | step_microstep: 43.41
[default0]:[2023-08-25 18:09:37,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.79 (forward_moe: 20.89, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.43)
[default0]:[2023-08-25 18:09:37,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.48 | backward_inner: 103.24 | backward_allreduce: 11.15 | step: 43.41
[default0]:[2023-08-25 18:09:37,347] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.29 | optimizer_step: 6.43
[default0]:[2023-08-25 18:09:37,347] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.88 | backward_microstep: 115.02 | backward_inner_microstep: 103.67 | backward_allreduce_microstep: 11.25 | step_microstep: 43.62
[default0]:[2023-08-25 18:09:37,347] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.88 (forward_moe: 20.94, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.43)
[default0]:[2023-08-25 18:09:37,348] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.01 | backward_inner: 103.67 | backward_allreduce: 11.26 | step: 43.62
[default0]:[2023-08-25 18:09:37,603] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.44
[default0]:[2023-08-25 18:09:37,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.08 | backward_microstep: 114.80 | backward_inner_microstep: 103.55 | backward_allreduce_microstep: 11.14 | step_microstep: 43.48
[default0]:[2023-08-25 18:09:37,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.08 (forward_moe: 20.96, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.46)
[default0]:[2023-08-25 18:09:37,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.79 | backward_inner: 103.56 | backward_allreduce: 11.15 | step: 43.48
[default0]:[2023-08-25 18:09:37,876] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.12 | optimizer_step: 6.48
[default0]:[2023-08-25 18:09:37,877] [INFO] [logging.py:96:log_dist] [Rank 0] step=685, skipped=0, lr=[7.471104e-07, 7.471104e-07, 7.471104e-07, 7.471104e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:37,877] [INFO] [timer.py:215:stop] epoch=0/micro_step=685/global_step=685, RunningAvgSamplesPerSec=4.908414777956806, CurrSamplesPerSec=4.772730272665412, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:37,877] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.39 | backward_microstep: 115.77 | backward_inner_microstep: 104.46 | backward_allreduce_microstep: 11.21 | step_microstep: 44.81
[default0]:[2023-08-25 18:09:37,878] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.39 (forward_moe: 21.17, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.61)
[default0]:[2023-08-25 18:09:37,878] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.76 | backward_inner: 104.47 | backward_allreduce: 11.21 | step: 44.82
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.6762], device='cuda:0'), 'moe loss': tensor([0.3023], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      685/439453125 | consumed samples:          685 | consumed tokens:      1402880 | elapsed time per iteration (ms): 257.7 | learning rate: 7.471E-07 | global batch size:     1 | lm loss: 9.935233E+00 | moe loss: 6.045626E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.881 | TFLOPs: 9.64 |
[default0]:[2023-08-25 18:09:38,129] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.95 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:38,129] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.15 | backward_microstep: 110.74 | backward_inner_microstep: 99.75 | backward_allreduce_microstep: 10.89 | step_microstep: 42.10
[default0]:[2023-08-25 18:09:38,129] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.16 (forward_moe: 20.08, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.92)
[default0]:[2023-08-25 18:09:38,129] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.74 | backward_inner: 99.76 | backward_allreduce: 10.90 | step: 42.11
[default0]:[2023-08-25 18:09:38,515] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:38,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.91 | backward_microstep: 110.70 | backward_inner_microstep: 99.68 | backward_allreduce_microstep: 10.93 | step_microstep: 42.40
[default0]:[2023-08-25 18:09:38,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.91 (forward_moe: 20.11, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.95)
[default0]:[2023-08-25 18:09:38,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.70 | backward_inner: 99.69 | backward_allreduce: 10.93 | step: 42.40
[default0]:[2023-08-25 18:09:38,775] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:38,775] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.62 | backward_microstep: 110.80 | backward_inner_microstep: 99.83 | backward_allreduce_microstep: 10.87 | step_microstep: 42.11
[default0]:[2023-08-25 18:09:38,776] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.62 (forward_moe: 20.15, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.98)
[default0]:[2023-08-25 18:09:38,776] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.80 | backward_inner: 99.83 | backward_allreduce: 10.87 | step: 42.11
[default0]:[2023-08-25 18:09:39,050] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.97 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:39,051] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.06 | backward_microstep: 110.82 | backward_inner_microstep: 99.83 | backward_allreduce_microstep: 10.89 | step_microstep: 42.47
[default0]:[2023-08-25 18:09:39,051] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.06 (forward_moe: 20.26, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.97)
[default0]:[2023-08-25 18:09:39,051] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.81 | backward_inner: 99.84 | backward_allreduce: 10.89 | step: 42.47
[default0]:[2023-08-25 18:09:39,291] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:39,291] [INFO] [logging.py:96:log_dist] [Rank 0] step=690, skipped=0, lr=[7.525717333333334e-07, 7.525717333333334e-07, 7.525717333333334e-07, 7.525717333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:39,291] [INFO] [timer.py:215:stop] epoch=0/micro_step=690/global_step=690, RunningAvgSamplesPerSec=4.908949545539081, CurrSamplesPerSec=4.994497401120525, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:39,291] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.15 | backward_microstep: 111.15 | backward_inner_microstep: 100.19 | backward_allreduce_microstep: 10.87 | step_microstep: 42.40
[default0]:[2023-08-25 18:09:39,291] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.15 (forward_moe: 20.25, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.94)
[default0]:[2023-08-25 18:09:39,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.15 | backward_inner: 100.20 | backward_allreduce: 10.87 | step: 42.41
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.9099], device='cuda:0'), 'moe loss': tensor([0.3029], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      690/439453125 | consumed samples:          690 | consumed tokens:      1413120 | elapsed time per iteration (ms): 282.9 | learning rate: 7.526E-07 | global batch size:     1 | lm loss: 9.981975E+00 | moe loss: 6.057012E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.535 | TFLOPs: 8.78 |
[default0]:[2023-08-25 18:09:39,553] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:39,554] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.81 | backward_microstep: 110.09 | backward_inner_microstep: 99.16 | backward_allreduce_microstep: 10.84 | step_microstep: 42.01
[default0]:[2023-08-25 18:09:39,554] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.81 (forward_moe: 19.94, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.83)
[default0]:[2023-08-25 18:09:39,554] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.09 | backward_inner: 99.16 | backward_allreduce: 10.85 | step: 42.01
[default0]:[2023-08-25 18:09:39,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:39,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.09 | backward_microstep: 110.09 | backward_inner_microstep: 99.10 | backward_allreduce_microstep: 10.89 | step_microstep: 41.62
[default0]:[2023-08-25 18:09:39,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.09 (forward_moe: 20.07, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:09:39,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.08 | backward_inner: 99.11 | backward_allreduce: 10.89 | step: 41.63
[default0]:[2023-08-25 18:09:40,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.35
[default0]:[2023-08-25 18:09:40,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.85 | backward_microstep: 110.06 | backward_inner_microstep: 99.12 | backward_allreduce_microstep: 10.84 | step_microstep: 41.95
[default0]:[2023-08-25 18:09:40,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.85 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.85)
[default0]:[2023-08-25 18:09:40,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.06 | backward_inner: 99.12 | backward_allreduce: 10.85 | step: 41.96
[default0]:[2023-08-25 18:09:40,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:40,322] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 109.22 | backward_inner_microstep: 98.32 | backward_allreduce_microstep: 10.81 | step_microstep: 41.31
[default0]:[2023-08-25 18:09:40,322] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:09:40,322] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.22 | backward_inner: 98.32 | backward_allreduce: 10.81 | step: 41.32
[default0]:[2023-08-25 18:09:40,560] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.29
[default0]:[2023-08-25 18:09:40,560] [INFO] [logging.py:96:log_dist] [Rank 0] step=695, skipped=0, lr=[7.580330666666667e-07, 7.580330666666667e-07, 7.580330666666667e-07, 7.580330666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:40,561] [INFO] [timer.py:215:stop] epoch=0/micro_step=695/global_step=695, RunningAvgSamplesPerSec=4.909943240540741, CurrSamplesPerSec=5.069000606689049, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:40,561] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.66 | backward_microstep: 109.16 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.85 | step_microstep: 41.90
[default0]:[2023-08-25 18:09:40,561] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:09:40,561] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.16 | backward_inner: 98.22 | backward_allreduce: 10.85 | step: 41.91
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.0204], device='cuda:0'), 'moe loss': tensor([0.3022], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      695/439453125 | consumed samples:          695 | consumed tokens:      1423360 | elapsed time per iteration (ms): 253.6 | learning rate: 7.580E-07 | global batch size:     1 | lm loss: 1.000408E+01 | moe loss: 6.044321E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.943 | TFLOPs: 9.80 |
[default0]:[2023-08-25 18:09:40,917] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:40,918] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.32 | backward_microstep: 109.17 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.82 | step_microstep: 41.61
[default0]:[2023-08-25 18:09:40,918] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.32 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:09:40,918] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.17 | backward_inner: 98.27 | backward_allreduce: 10.82 | step: 41.61
[default0]:[2023-08-25 18:09:41,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:41,156] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.16 | backward_microstep: 109.25 | backward_inner_microstep: 98.33 | backward_allreduce_microstep: 10.82 | step_microstep: 41.99
[default0]:[2023-08-25 18:09:41,156] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.16 (forward_moe: 19.84, 1st alltoall: 0.88, 2nd alltoall: 0.79, top-k: 7.78)
[default0]:[2023-08-25 18:09:41,156] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.25 | backward_inner: 98.34 | backward_allreduce: 10.82 | step: 41.99
[default0]:[2023-08-25 18:09:41,419] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:41,419] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.56 | backward_microstep: 108.96 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.77 | step_microstep: 41.57
[default0]:[2023-08-25 18:09:41,419] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.56 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:09:41,420] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.95 | backward_inner: 98.09 | backward_allreduce: 10.78 | step: 41.57
[default0]:[2023-08-25 18:09:41,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:41,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.67 | backward_microstep: 109.08 | backward_inner_microstep: 98.24 | backward_allreduce_microstep: 10.75 | step_microstep: 41.53
[default0]:[2023-08-25 18:09:41,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.67 (forward_moe: 19.77, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:09:41,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.24 | backward_allreduce: 10.76 | step: 41.53
[default0]:[2023-08-25 18:09:41,922] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:41,922] [INFO] [logging.py:96:log_dist] [Rank 0] step=700, skipped=0, lr=[7.634944e-07, 7.634944e-07, 7.634944e-07, 7.634944e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:41,923] [INFO] [timer.py:215:stop] epoch=0/micro_step=700/global_step=700, RunningAvgSamplesPerSec=4.9109572883184756, CurrSamplesPerSec=5.054961795261166, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:41,923] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.35 | backward_microstep: 109.31 | backward_inner_microstep: 98.40 | backward_allreduce_microstep: 10.81 | step_microstep: 42.63
[default0]:[2023-08-25 18:09:41,923] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.35 (forward_moe: 20.01, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:09:41,923] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.30 | backward_inner: 98.40 | backward_allreduce: 10.81 | step: 42.64
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.6303], device='cuda:0'), 'moe loss': tensor([0.3032], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      700/439453125 | consumed samples:          700 | consumed tokens:      1433600 | elapsed time per iteration (ms): 272.5 | learning rate: 7.635E-07 | global batch size:     1 | lm loss: 9.926065E+00 | moe loss: 6.063886E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.670 | TFLOPs: 9.12 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 700 | lm loss value: 9.994078E+00 | lm loss PPL: 2.189640E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration     700 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:09:45,587] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step700 is about to be saved!
[default0]:[2023-08-25 18:09:45,589] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,599] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,599] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,609] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,609] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,620] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,620] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,629] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,630] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,639] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,639] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,648] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,648] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,658] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,658] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,668] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,669] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,678] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,678] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,687] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,687] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,695] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,696] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,705] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,706] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,715] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,715] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,724] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,724] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,733] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,733] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,745] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,746] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,756] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,756] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,765] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,765] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,775] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,775] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,784] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,785] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,794] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,794] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,803] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,803] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,812] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,812] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:45,826] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:45,826] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:09:45,831] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:09:45,832] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:09:45,832] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:09:46,111] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:09:46,112] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:09:49,800] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:09:49,815] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step700/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:09:49,815] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step700 is ready now!
[default0]:  successfully saved checkpoint at iteration     700 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.7, Latency(second): 4.235
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4234.69, 4234.69)
[default0]:[2023-08-25 18:09:50,073] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.18 | optimizer_step: 10.15
[default0]:[2023-08-25 18:09:50,074] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2316.93 | backward_microstep: 117.44 | backward_inner_microstep: 106.20 | backward_allreduce_microstep: 11.15 | step_microstep: 47.58
[default0]:[2023-08-25 18:09:50,074] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2316.90 (forward_moe: 21.66, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.82)
[default0]:[2023-08-25 18:09:50,074] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.43 | backward_inner: 106.20 | backward_allreduce: 11.15 | step: 47.58
[default0]:[2023-08-25 18:09:50,330] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.13 | optimizer_step: 6.51
[default0]:[2023-08-25 18:09:50,331] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.27 | backward_microstep: 116.71 | backward_inner_microstep: 105.53 | backward_allreduce_microstep: 11.08 | step_microstep: 43.58
[default0]:[2023-08-25 18:09:50,331] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.27 (forward_moe: 21.43, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.73)
[default0]:[2023-08-25 18:09:50,331] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.71 | backward_inner: 105.54 | backward_allreduce: 11.09 | step: 43.58
[default0]:[2023-08-25 18:09:50,597] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:09:50,598] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.07 | backward_microstep: 114.80 | backward_inner_microstep: 103.68 | backward_allreduce_microstep: 11.02 | step_microstep: 43.04
[default0]:[2023-08-25 18:09:50,598] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.07 (forward_moe: 20.98, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.49)
[default0]:[2023-08-25 18:09:50,598] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.79 | backward_inner: 103.69 | backward_allreduce: 11.02 | step: 43.04
[default0]:[2023-08-25 18:09:50,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.10 | optimizer_step: 6.48
[default0]:[2023-08-25 18:09:50,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.26 | backward_microstep: 114.38 | backward_inner_microstep: 103.37 | backward_allreduce_microstep: 10.92 | step_microstep: 43.53
[default0]:[2023-08-25 18:09:50,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.26 (forward_moe: 20.92, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.47)
[default0]:[2023-08-25 18:09:50,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.37 | backward_inner: 103.37 | backward_allreduce: 10.92 | step: 43.54
[default0]:[2023-08-25 18:09:51,109] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.10 | optimizer_step: 6.48
[default0]:[2023-08-25 18:09:51,110] [INFO] [logging.py:96:log_dist] [Rank 0] step=705, skipped=0, lr=[7.689557333333334e-07, 7.689557333333334e-07, 7.689557333333334e-07, 7.689557333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:51,110] [INFO] [timer.py:215:stop] epoch=0/micro_step=705/global_step=705, RunningAvgSamplesPerSec=4.909749890622782, CurrSamplesPerSec=4.743839901917983, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:51,110] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.42 | backward_microstep: 116.95 | backward_inner_microstep: 105.63 | backward_allreduce_microstep: 11.22 | step_microstep: 44.89
[default0]:[2023-08-25 18:09:51,110] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.42 (forward_moe: 21.60, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.93)
[default0]:[2023-08-25 18:09:51,111] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.94 | backward_inner: 105.64 | backward_allreduce: 11.22 | step: 44.90
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.4883], device='cuda:0'), 'moe loss': tensor([0.3024], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      705/439453125 | consumed samples:          705 | consumed tokens:      1443840 | elapsed time per iteration (ms): 1837.7 | learning rate: 7.690E-07 | global batch size:     1 | lm loss: 9.897652E+00 | moe loss: 6.047153E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.544 | TFLOPs: 1.35 |
[default0]:[2023-08-25 18:09:51,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.47
[default0]:[2023-08-25 18:09:51,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.78 | backward_microstep: 116.08 | backward_inner_microstep: 104.83 | backward_allreduce_microstep: 11.16 | step_microstep: 44.03
[default0]:[2023-08-25 18:09:51,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.78 (forward_moe: 21.20, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.60)
[default0]:[2023-08-25 18:09:51,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.08 | backward_inner: 104.84 | backward_allreduce: 11.16 | step: 44.03
[default0]:[2023-08-25 18:09:51,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:09:51,618] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.52 | backward_microstep: 111.73 | backward_inner_microstep: 100.70 | backward_allreduce_microstep: 10.94 | step_microstep: 42.95
[default0]:[2023-08-25 18:09:51,618] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.52 (forward_moe: 20.38, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.16)
[default0]:[2023-08-25 18:09:51,618] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.73 | backward_inner: 100.70 | backward_allreduce: 10.95 | step: 42.95
[default0]:[2023-08-25 18:09:51,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:09:51,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.96 | backward_microstep: 114.27 | backward_inner_microstep: 103.19 | backward_allreduce_microstep: 10.97 | step_microstep: 42.88
[default0]:[2023-08-25 18:09:51,866] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.96 (forward_moe: 20.54, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.11)
[default0]:[2023-08-25 18:09:51,866] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.26 | backward_inner: 103.20 | backward_allreduce: 10.98 | step: 42.88
[default0]:[2023-08-25 18:09:52,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:09:52,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.59 | backward_microstep: 111.74 | backward_inner_microstep: 100.68 | backward_allreduce_microstep: 10.97 | step_microstep: 42.27
[default0]:[2023-08-25 18:09:52,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.59 (forward_moe: 20.33, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.03)
[default0]:[2023-08-25 18:09:52,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.74 | backward_inner: 100.69 | backward_allreduce: 10.97 | step: 42.28
[default0]:[2023-08-25 18:09:52,399] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:09:52,399] [INFO] [logging.py:96:log_dist] [Rank 0] step=710, skipped=0, lr=[7.744170666666667e-07, 7.744170666666667e-07, 7.744170666666667e-07, 7.744170666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:52,399] [INFO] [timer.py:215:stop] epoch=0/micro_step=710/global_step=710, RunningAvgSamplesPerSec=4.9096753393907155, CurrSamplesPerSec=4.9397172057877885, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:52,399] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.35 | backward_microstep: 111.44 | backward_inner_microstep: 100.42 | backward_allreduce_microstep: 10.92 | step_microstep: 44.11
[default0]:[2023-08-25 18:09:52,400] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.35 (forward_moe: 20.28, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.99)
[default0]:[2023-08-25 18:09:52,400] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.44 | backward_inner: 100.42 | backward_allreduce: 10.93 | step: 44.11
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.9035], device='cuda:0'), 'moe loss': tensor([0.3020], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      710/439453125 | consumed samples:          710 | consumed tokens:      1454080 | elapsed time per iteration (ms): 257.8 | learning rate: 7.744E-07 | global batch size:     1 | lm loss: 9.980705E+00 | moe loss: 6.039115E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.879 | TFLOPs: 9.64 |
[default0]:[2023-08-25 18:09:52,871] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:52,872] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.43 | backward_microstep: 111.16 | backward_inner_microstep: 100.16 | backward_allreduce_microstep: 10.91 | step_microstep: 42.17
[default0]:[2023-08-25 18:09:52,872] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.43 (forward_moe: 20.33, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 8.01)
[default0]:[2023-08-25 18:09:52,872] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.16 | backward_inner: 100.16 | backward_allreduce: 10.92 | step: 42.17
[default0]:[2023-08-25 18:09:53,141] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:09:53,141] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.73 | backward_microstep: 111.27 | backward_inner_microstep: 100.29 | backward_allreduce_microstep: 10.89 | step_microstep: 42.11
[default0]:[2023-08-25 18:09:53,142] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.73 (forward_moe: 20.28, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.97)
[default0]:[2023-08-25 18:09:53,142] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.27 | backward_inner: 100.30 | backward_allreduce: 10.89 | step: 42.11
[default0]:[2023-08-25 18:09:53,411] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:09:53,411] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.61 | backward_microstep: 111.13 | backward_inner_microstep: 100.12 | backward_allreduce_microstep: 10.91 | step_microstep: 42.32
[default0]:[2023-08-25 18:09:53,411] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.61 (forward_moe: 20.27, 1st alltoall: 0.86, 2nd alltoall: 0.91, top-k: 7.98)
[default0]:[2023-08-25 18:09:53,411] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.13 | backward_inner: 100.12 | backward_allreduce: 10.92 | step: 42.32
[default0]:[2023-08-25 18:09:53,658] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:53,658] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.53 | backward_microstep: 111.12 | backward_inner_microstep: 100.16 | backward_allreduce_microstep: 10.85 | step_microstep: 42.25
[default0]:[2023-08-25 18:09:53,658] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.52 (forward_moe: 20.26, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.00)
[default0]:[2023-08-25 18:09:53,658] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.12 | backward_inner: 100.17 | backward_allreduce: 10.86 | step: 42.25
[default0]:[2023-08-25 18:09:53,899] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:09:53,900] [INFO] [logging.py:96:log_dist] [Rank 0] step=715, skipped=0, lr=[7.798784e-07, 7.798784e-07, 7.798784e-07, 7.798784e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:53,900] [INFO] [timer.py:215:stop] epoch=0/micro_step=715/global_step=715, RunningAvgSamplesPerSec=4.910168521843748, CurrSamplesPerSec=4.98277893936514, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:53,900] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.48 | backward_microstep: 111.06 | backward_inner_microstep: 100.05 | backward_allreduce_microstep: 10.91 | step_microstep: 42.62
[default0]:[2023-08-25 18:09:53,900] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.48 (forward_moe: 20.26, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.07)
[default0]:[2023-08-25 18:09:53,900] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.06 | backward_inner: 100.05 | backward_allreduce: 10.92 | step: 42.62
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.5832], device='cuda:0'), 'moe loss': tensor([0.3017], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      715/439453125 | consumed samples:          715 | consumed tokens:      1464320 | elapsed time per iteration (ms): 300.0 | learning rate: 7.799E-07 | global batch size:     1 | lm loss: 9.916631E+00 | moe loss: 6.033977E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.333 | TFLOPs: 8.28 |
[default0]:[2023-08-25 18:09:54,168] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.38
[default0]:[2023-08-25 18:09:54,168] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.15 | backward_microstep: 114.09 | backward_inner_microstep: 102.96 | backward_allreduce_microstep: 11.04 | step_microstep: 43.11
[default0]:[2023-08-25 18:09:54,168] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.15 (forward_moe: 20.85, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.41)
[default0]:[2023-08-25 18:09:54,168] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.09 | backward_inner: 102.97 | backward_allreduce: 11.04 | step: 43.12
[default0]:[2023-08-25 18:09:54,425] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.36
[default0]:[2023-08-25 18:09:54,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.30 | backward_microstep: 110.50 | backward_inner_microstep: 99.49 | backward_allreduce_microstep: 10.91 | step_microstep: 42.02
[default0]:[2023-08-25 18:09:54,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.29 (forward_moe: 20.05, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.88)
[default0]:[2023-08-25 18:09:54,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.50 | backward_inner: 99.50 | backward_allreduce: 10.91 | step: 42.02
[default0]:[2023-08-25 18:09:54,665] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:54,666] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.18 | backward_microstep: 110.54 | backward_inner_microstep: 99.55 | backward_allreduce_microstep: 10.89 | step_microstep: 42.30
[default0]:[2023-08-25 18:09:54,666] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.18 (forward_moe: 20.02, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.89)
[default0]:[2023-08-25 18:09:54,666] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.54 | backward_inner: 99.56 | backward_allreduce: 10.89 | step: 42.30
[default0]:[2023-08-25 18:09:54,906] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:54,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.43 | backward_microstep: 110.45 | backward_inner_microstep: 99.41 | backward_allreduce_microstep: 10.90 | step_microstep: 41.98
[default0]:[2023-08-25 18:09:54,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.43 (forward_moe: 20.02, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.89)
[default0]:[2023-08-25 18:09:54,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.45 | backward_inner: 99.42 | backward_allreduce: 10.95 | step: 41.98
[default0]:[2023-08-25 18:09:55,153] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:55,153] [INFO] [logging.py:96:log_dist] [Rank 0] step=720, skipped=0, lr=[7.853397333333334e-07, 7.853397333333334e-07, 7.853397333333334e-07, 7.853397333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:55,153] [INFO] [timer.py:215:stop] epoch=0/micro_step=720/global_step=720, RunningAvgSamplesPerSec=4.9105672364141775, CurrSamplesPerSec=4.948424028201849, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:55,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.12 | backward_microstep: 111.03 | backward_inner_microstep: 99.89 | backward_allreduce_microstep: 11.05 | step_microstep: 42.38
[default0]:[2023-08-25 18:09:55,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.12 (forward_moe: 20.17, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.90)
[default0]:[2023-08-25 18:09:55,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.03 | backward_inner: 99.89 | backward_allreduce: 11.06 | step: 42.38
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.8365], device='cuda:0'), 'moe loss': tensor([0.3019], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      720/439453125 | consumed samples:          720 | consumed tokens:      1474560 | elapsed time per iteration (ms): 250.4 | learning rate: 7.853E-07 | global batch size:     1 | lm loss: 9.967295E+00 | moe loss: 6.037489E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.994 | TFLOPs: 9.92 |
[default0]:[2023-08-25 18:09:55,400] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:55,400] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.30 | backward_microstep: 110.80 | backward_inner_microstep: 99.85 | backward_allreduce_microstep: 10.86 | step_microstep: 42.11
[default0]:[2023-08-25 18:09:55,400] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.30 (forward_moe: 20.18, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.94)
[default0]:[2023-08-25 18:09:55,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.80 | backward_inner: 99.86 | backward_allreduce: 10.86 | step: 42.11
[default0]:[2023-08-25 18:09:55,643] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:55,643] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.30 | backward_microstep: 110.42 | backward_inner_microstep: 99.46 | backward_allreduce_microstep: 10.87 | step_microstep: 42.04
[default0]:[2023-08-25 18:09:55,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.30 (forward_moe: 20.06, 1st alltoall: 0.86, 2nd alltoall: 0.82, top-k: 7.91)
[default0]:[2023-08-25 18:09:55,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.42 | backward_inner: 99.46 | backward_allreduce: 10.88 | step: 42.04
[default0]:[2023-08-25 18:09:56,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.40
[default0]:[2023-08-25 18:09:56,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.99 | backward_microstep: 114.74 | backward_inner_microstep: 103.55 | backward_allreduce_microstep: 11.08 | step_microstep: 45.35
[default0]:[2023-08-25 18:09:56,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.99 (forward_moe: 21.07, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.20)
[default0]:[2023-08-25 18:09:56,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.73 | backward_inner: 103.56 | backward_allreduce: 11.08 | step: 45.35
[default0]:[2023-08-25 18:09:56,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:09:56,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.96 | backward_microstep: 114.15 | backward_inner_microstep: 103.01 | backward_allreduce_microstep: 11.05 | step_microstep: 43.28
[default0]:[2023-08-25 18:09:56,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.95 (forward_moe: 20.97, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.38)
[default0]:[2023-08-25 18:09:56,295] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.15 | backward_inner: 103.01 | backward_allreduce: 11.06 | step: 43.28
[default0]:[2023-08-25 18:09:56,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.47
[default0]:[2023-08-25 18:09:56,563] [INFO] [logging.py:96:log_dist] [Rank 0] step=725, skipped=0, lr=[7.908010666666668e-07, 7.908010666666668e-07, 7.908010666666668e-07, 7.908010666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:56,564] [INFO] [timer.py:215:stop] epoch=0/micro_step=725/global_step=725, RunningAvgSamplesPerSec=4.910403816238816, CurrSamplesPerSec=4.799611847796733, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:56,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.26 | backward_microstep: 115.52 | backward_inner_microstep: 104.27 | backward_allreduce_microstep: 11.15 | step_microstep: 44.05
[default0]:[2023-08-25 18:09:56,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.26 (forward_moe: 21.08, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.54)
[default0]:[2023-08-25 18:09:56,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.52 | backward_inner: 104.28 | backward_allreduce: 11.16 | step: 44.06
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.7608], device='cuda:0'), 'moe loss': tensor([0.3022], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      725/439453125 | consumed samples:          725 | consumed tokens:      1484800 | elapsed time per iteration (ms): 282.2 | learning rate: 7.908E-07 | global batch size:     1 | lm loss: 9.952151E+00 | moe loss: 6.043670E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.544 | TFLOPs: 8.81 |
[default0]:[2023-08-25 18:09:56,851] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.41
[default0]:[2023-08-25 18:09:56,851] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.88 | backward_microstep: 114.51 | backward_inner_microstep: 103.30 | backward_allreduce_microstep: 11.12 | step_microstep: 43.31
[default0]:[2023-08-25 18:09:56,851] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.88 (forward_moe: 20.91, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.43)
[default0]:[2023-08-25 18:09:56,852] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.51 | backward_inner: 103.30 | backward_allreduce: 11.12 | step: 43.31
[default0]:[2023-08-25 18:09:57,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.44
[default0]:[2023-08-25 18:09:57,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.15 | backward_microstep: 114.33 | backward_inner_microstep: 103.13 | backward_allreduce_microstep: 11.10 | step_microstep: 43.35
[default0]:[2023-08-25 18:09:57,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.15 (forward_moe: 20.91, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.41)
[default0]:[2023-08-25 18:09:57,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.32 | backward_inner: 103.13 | backward_allreduce: 11.11 | step: 43.36
[default0]:[2023-08-25 18:09:57,347] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.43
[default0]:[2023-08-25 18:09:57,348] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.96 | backward_microstep: 114.57 | backward_inner_microstep: 103.39 | backward_allreduce_microstep: 11.08 | step_microstep: 43.36
[default0]:[2023-08-25 18:09:57,348] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.96 (forward_moe: 20.96, 1st alltoall: 0.91, 2nd alltoall: 0.83, top-k: 8.43)
[default0]:[2023-08-25 18:09:57,348] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.57 | backward_inner: 103.39 | backward_allreduce: 11.09 | step: 43.36
[default0]:[2023-08-25 18:09:57,591] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:09:57,591] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.26 | backward_microstep: 114.42 | backward_inner_microstep: 103.23 | backward_allreduce_microstep: 11.10 | step_microstep: 43.20
[default0]:[2023-08-25 18:09:57,591] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.26 (forward_moe: 20.90, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.41)
[default0]:[2023-08-25 18:09:57,591] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.42 | backward_inner: 103.24 | backward_allreduce: 11.10 | step: 43.21
[default0]:[2023-08-25 18:09:57,826] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:57,826] [INFO] [logging.py:96:log_dist] [Rank 0] step=730, skipped=0, lr=[7.962624000000001e-07, 7.962624000000001e-07, 7.962624000000001e-07, 7.962624000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:57,827] [INFO] [timer.py:215:stop] epoch=0/micro_step=730/global_step=730, RunningAvgSamplesPerSec=4.910170331854373, CurrSamplesPerSec=5.031904811035317, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:57,827] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.11 | backward_microstep: 110.16 | backward_inner_microstep: 99.17 | backward_allreduce_microstep: 10.90 | step_microstep: 41.90
[default0]:[2023-08-25 18:09:57,827] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.11 (forward_moe: 20.07, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.84)
[default0]:[2023-08-25 18:09:57,827] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.16 | backward_inner: 99.18 | backward_allreduce: 10.90 | step: 41.90
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.7109], device='cuda:0'), 'moe loss': tensor([0.3022], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      730/439453125 | consumed samples:          730 | consumed tokens:      1495040 | elapsed time per iteration (ms): 252.6 | learning rate: 7.963E-07 | global batch size:     1 | lm loss: 9.942178E+00 | moe loss: 6.043397E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.959 | TFLOPs: 9.84 |
[default0]:[2023-08-25 18:09:58,071] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.33
[default0]:[2023-08-25 18:09:58,072] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 110.21 | backward_inner_microstep: 99.31 | backward_allreduce_microstep: 10.81 | step_microstep: 41.96
[default0]:[2023-08-25 18:09:58,072] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.78 (forward_moe: 20.05, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.96)
[default0]:[2023-08-25 18:09:58,072] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.21 | backward_inner: 99.32 | backward_allreduce: 10.81 | step: 41.96
[default0]:[2023-08-25 18:09:58,333] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:58,333] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.27 | backward_microstep: 109.97 | backward_inner_microstep: 99.04 | backward_allreduce_microstep: 10.84 | step_microstep: 41.66
[default0]:[2023-08-25 18:09:58,333] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.27 (forward_moe: 19.92, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:09:58,333] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.97 | backward_inner: 99.05 | backward_allreduce: 10.85 | step: 41.66
[default0]:[2023-08-25 18:09:58,578] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:09:58,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.98 | backward_microstep: 109.92 | backward_inner_microstep: 99.04 | backward_allreduce_microstep: 10.79 | step_microstep: 41.80
[default0]:[2023-08-25 18:09:58,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.98 (forward_moe: 19.97, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:09:58,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.92 | backward_inner: 99.04 | backward_allreduce: 10.79 | step: 41.80
[default0]:[2023-08-25 18:09:58,841] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:09:58,841] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.06 | backward_microstep: 109.97 | backward_inner_microstep: 99.03 | backward_allreduce_microstep: 10.85 | step_microstep: 41.52
[default0]:[2023-08-25 18:09:58,841] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.06 (forward_moe: 19.95, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:09:58,841] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.96 | backward_inner: 99.03 | backward_allreduce: 10.85 | step: 41.52
[default0]:[2023-08-25 18:09:59,177] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:59,178] [INFO] [logging.py:96:log_dist] [Rank 0] step=735, skipped=0, lr=[8.017237333333334e-07, 8.017237333333334e-07, 8.017237333333334e-07, 8.017237333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:09:59,179] [INFO] [timer.py:215:stop] epoch=0/micro_step=735/global_step=735, RunningAvgSamplesPerSec=4.908957703898863, CurrSamplesPerSec=3.8343645325961355, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:09:59,179] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.91 | backward_microstep: 171.56 | backward_inner_microstep: 160.62 | backward_allreduce_microstep: 10.84 | step_microstep: 42.81
[default0]:[2023-08-25 18:09:59,179] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.91 (forward_moe: 19.95, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.84)
[default0]:[2023-08-25 18:09:59,179] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 171.55 | backward_inner: 160.63 | backward_allreduce: 10.84 | step: 42.82
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.2194], device='cuda:0'), 'moe loss': tensor([0.3020], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      735/439453125 | consumed samples:          735 | consumed tokens:      1505280 | elapsed time per iteration (ms): 271.0 | learning rate: 8.017E-07 | global batch size:     1 | lm loss: 1.004388E+01 | moe loss: 6.039745E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.690 | TFLOPs: 9.17 |
[default0]:[2023-08-25 18:09:59,543] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:59,544] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.93 | backward_microstep: 110.12 | backward_inner_microstep: 99.15 | backward_allreduce_microstep: 10.87 | step_microstep: 41.77
[default0]:[2023-08-25 18:09:59,544] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.92 (forward_moe: 19.97, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.85)
[default0]:[2023-08-25 18:09:59,544] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.12 | backward_inner: 99.16 | backward_allreduce: 10.88 | step: 41.77
[default0]:[2023-08-25 18:09:59,796] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:09:59,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.86 | backward_microstep: 110.32 | backward_inner_microstep: 99.37 | backward_allreduce_microstep: 10.86 | step_microstep: 42.04
[default0]:[2023-08-25 18:09:59,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.86 (forward_moe: 20.02, 1st alltoall: 0.90, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:09:59,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.32 | backward_inner: 99.37 | backward_allreduce: 10.86 | step: 42.04
[default0]:[2023-08-25 18:10:00,114] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 27.88
[default0]:[2023-08-25 18:10:00,116] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.54 | backward_microstep: 109.03 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.77 | step_microstep: 64.23
[default0]:[2023-08-25 18:10:00,116] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.54 (forward_moe: 19.74, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:10:00,116] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.02 | backward_inner: 98.16 | backward_allreduce: 10.78 | step: 64.23
[default0]:[2023-08-25 18:10:00,374] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:00,375] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 109.05 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.77 | step_microstep: 41.29
[default0]:[2023-08-25 18:10:00,375] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:10:00,375] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.19 | backward_allreduce: 10.78 | step: 41.29
[default0]:[2023-08-25 18:10:00,683] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:00,683] [INFO] [logging.py:96:log_dist] [Rank 0] step=740, skipped=0, lr=[8.071850666666667e-07, 8.071850666666667e-07, 8.071850666666667e-07, 8.071850666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:00,683] [INFO] [timer.py:215:stop] epoch=0/micro_step=740/global_step=740, RunningAvgSamplesPerSec=4.9092058826914995, CurrSamplesPerSec=5.079565615988936, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:00,684] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 109.02 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.77 | step_microstep: 41.84
[default0]:[2023-08-25 18:10:00,684] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.70)
[default0]:[2023-08-25 18:10:00,684] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.02 | backward_inner: 98.17 | backward_allreduce: 10.77 | step: 41.84
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.7692], device='cuda:0'), 'moe loss': tensor([0.3022], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      740/439453125 | consumed samples:          740 | consumed tokens:      1515520 | elapsed time per iteration (ms): 300.5 | learning rate: 8.072E-07 | global batch size:     1 | lm loss: 9.953846E+00 | moe loss: 6.043325E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.327 | TFLOPs: 8.27 |
[default0]:[2023-08-25 18:10:00,940] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:10:00,941] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.34 | backward_microstep: 109.08 | backward_inner_microstep: 98.20 | backward_allreduce_microstep: 10.79 | step_microstep: 41.49
[default0]:[2023-08-25 18:10:00,941] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.34 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:10:00,941] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.20 | backward_allreduce: 10.80 | step: 41.49
[default0]:[2023-08-25 18:10:01,196] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:10:01,197] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 109.98 | backward_inner_microstep: 98.93 | backward_allreduce_microstep: 10.96 | step_microstep: 41.44
[default0]:[2023-08-25 18:10:01,197] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.70 (forward_moe: 20.17, 1st alltoall: 0.86, 2nd alltoall: 1.19, top-k: 7.73)
[default0]:[2023-08-25 18:10:01,197] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.98 | backward_inner: 98.93 | backward_allreduce: 10.96 | step: 41.44
[default0]:[2023-08-25 18:10:01,432] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.28
[default0]:[2023-08-25 18:10:01,433] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.43 | backward_microstep: 109.08 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.89 | step_microstep: 41.48
[default0]:[2023-08-25 18:10:01,433] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.43 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:10:01,433] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.10 | backward_allreduce: 10.89 | step: 41.48
[default0]:[2023-08-25 18:10:01,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:01,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 108.89 | backward_inner_microstep: 98.01 | backward_allreduce_microstep: 10.78 | step_microstep: 41.54
[default0]:[2023-08-25 18:10:01,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.41 (forward_moe: 19.72, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:10:01,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.88 | backward_inner: 98.02 | backward_allreduce: 10.79 | step: 41.55
[default0]:[2023-08-25 18:10:02,120] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:10:02,120] [INFO] [logging.py:96:log_dist] [Rank 0] step=745, skipped=0, lr=[8.126464000000001e-07, 8.126464000000001e-07, 8.126464000000001e-07, 8.126464000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:02,121] [INFO] [timer.py:215:stop] epoch=0/micro_step=745/global_step=745, RunningAvgSamplesPerSec=4.910216824862183, CurrSamplesPerSec=5.019523742277985, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:02,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.67 | backward_microstep: 109.06 | backward_inner_microstep: 98.20 | backward_allreduce_microstep: 10.77 | step_microstep: 41.98
[default0]:[2023-08-25 18:10:02,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.65 (forward_moe: 19.76, 1st alltoall: 0.89, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:10:02,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.06 | backward_inner: 98.21 | backward_allreduce: 10.77 | step: 41.98
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.7273], device='cuda:0'), 'moe loss': tensor([0.3017], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      745/439453125 | consumed samples:          745 | consumed tokens:      1525760 | elapsed time per iteration (ms): 288.1 | learning rate: 8.126E-07 | global batch size:     1 | lm loss: 9.945468E+00 | moe loss: 6.034008E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.471 | TFLOPs: 8.62 |
[default0]:[2023-08-25 18:10:02,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 5.13 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:02,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.59 | backward_microstep: 108.93 | backward_inner_microstep: 98.04 | backward_allreduce_microstep: 10.80 | step_microstep: 42.69
[default0]:[2023-08-25 18:10:02,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:10:02,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.93 | backward_inner: 98.05 | backward_allreduce: 10.80 | step: 42.69
[default0]:[2023-08-25 18:10:02,641] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:02,641] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 109.07 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.80 | step_microstep: 41.57
[default0]:[2023-08-25 18:10:02,641] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:10:02,641] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.07 | backward_inner: 98.18 | backward_allreduce: 10.81 | step: 41.57
[default0]:[2023-08-25 18:10:02,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:02,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.71 | backward_microstep: 108.88 | backward_inner_microstep: 97.99 | backward_allreduce_microstep: 10.79 | step_microstep: 41.44
[default0]:[2023-08-25 18:10:02,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.71 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:10:02,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.88 | backward_inner: 98.00 | backward_allreduce: 10.80 | step: 41.45
[default0]:[2023-08-25 18:10:03,178] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:10:03,178] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.48 | backward_microstep: 112.35 | backward_inner_microstep: 101.05 | backward_allreduce_microstep: 11.20 | step_microstep: 42.61
[default0]:[2023-08-25 18:10:03,178] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 20.39, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.12)
[default0]:[2023-08-25 18:10:03,179] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.34 | backward_inner: 101.05 | backward_allreduce: 11.21 | step: 42.61
[default0]:[2023-08-25 18:10:03,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:10:03,470] [INFO] [logging.py:96:log_dist] [Rank 0] step=750, skipped=0, lr=[8.181077333333335e-07, 8.181077333333335e-07, 8.181077333333335e-07, 8.181077333333335e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:03,471] [INFO] [timer.py:215:stop] epoch=0/micro_step=750/global_step=750, RunningAvgSamplesPerSec=4.910900553856316, CurrSamplesPerSec=4.902877689432107, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:03,471] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.12 | backward_microstep: 112.85 | backward_inner_microstep: 101.71 | backward_allreduce_microstep: 11.04 | step_microstep: 43.42
[default0]:[2023-08-25 18:10:03,471] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.12 (forward_moe: 20.76, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.19)
[default0]:[2023-08-25 18:10:03,471] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.85 | backward_inner: 101.72 | backward_allreduce: 11.04 | step: 43.43
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.0733], device='cuda:0'), 'moe loss': tensor([0.3016], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      750/439453125 | consumed samples:          750 | consumed tokens:      1536000 | elapsed time per iteration (ms): 269.1 | learning rate: 8.181E-07 | global batch size:     1 | lm loss: 1.001465E+01 | moe loss: 6.032602E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.716 | TFLOPs: 9.23 |
[default0]:[2023-08-25 18:10:03,725] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.42
[default0]:[2023-08-25 18:10:03,725] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.40 | backward_microstep: 113.36 | backward_inner_microstep: 102.20 | backward_allreduce_microstep: 11.06 | step_microstep: 43.02
[default0]:[2023-08-25 18:10:03,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.40 (forward_moe: 20.69, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.28)
[default0]:[2023-08-25 18:10:03,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.36 | backward_inner: 102.21 | backward_allreduce: 11.07 | step: 43.02
[default0]:[2023-08-25 18:10:03,971] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.40
[default0]:[2023-08-25 18:10:03,972] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.59 | backward_microstep: 113.51 | backward_inner_microstep: 102.35 | backward_allreduce_microstep: 11.06 | step_microstep: 43.09
[default0]:[2023-08-25 18:10:03,972] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.59 (forward_moe: 20.74, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.31)
[default0]:[2023-08-25 18:10:03,972] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.50 | backward_inner: 102.35 | backward_allreduce: 11.07 | step: 43.09
[default0]:[2023-08-25 18:10:04,229] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.44
[default0]:[2023-08-25 18:10:04,230] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.82 | backward_microstep: 114.58 | backward_inner_microstep: 103.37 | backward_allreduce_microstep: 11.12 | step_microstep: 43.34
[default0]:[2023-08-25 18:10:04,230] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.82 (forward_moe: 20.96, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.41)
[default0]:[2023-08-25 18:10:04,230] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.58 | backward_inner: 103.38 | backward_allreduce: 11.12 | step: 43.34
[default0]:[2023-08-25 18:10:04,476] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:04,477] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.10 | backward_microstep: 110.03 | backward_inner_microstep: 99.05 | backward_allreduce_microstep: 10.88 | step_microstep: 41.84
[default0]:[2023-08-25 18:10:04,477] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.10 (forward_moe: 20.00, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:10:04,477] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.02 | backward_inner: 99.06 | backward_allreduce: 10.89 | step: 41.85
[default0]:[2023-08-25 18:10:04,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.33
[default0]:[2023-08-25 18:10:04,733] [INFO] [logging.py:96:log_dist] [Rank 0] step=755, skipped=0, lr=[8.235690666666668e-07, 8.235690666666668e-07, 8.235690666666668e-07, 8.235690666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:04,734] [INFO] [timer.py:215:stop] epoch=0/micro_step=755/global_step=755, RunningAvgSamplesPerSec=4.911033371553002, CurrSamplesPerSec=5.025447722477364, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:04,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.12 | backward_microstep: 110.04 | backward_inner_microstep: 99.14 | backward_allreduce_microstep: 10.80 | step_microstep: 42.29
[default0]:[2023-08-25 18:10:04,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.12 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:10:04,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.04 | backward_inner: 99.15 | backward_allreduce: 10.81 | step: 42.29
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.3662], device='cuda:0'), 'moe loss': tensor([0.3009], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      755/439453125 | consumed samples:          755 | consumed tokens:      1546240 | elapsed time per iteration (ms): 252.6 | learning rate: 8.236E-07 | global batch size:     1 | lm loss: 9.873232E+00 | moe loss: 6.017790E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.960 | TFLOPs: 9.84 |
[default0]:[2023-08-25 18:10:04,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:04,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.22 | backward_microstep: 110.05 | backward_inner_microstep: 99.11 | backward_allreduce_microstep: 10.84 | step_microstep: 42.04
[default0]:[2023-08-25 18:10:04,989] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.21 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:10:04,989] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.05 | backward_inner: 99.12 | backward_allreduce: 10.84 | step: 42.04
[default0]:[2023-08-25 18:10:05,260] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:05,260] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.00 | backward_microstep: 110.32 | backward_inner_microstep: 99.36 | backward_allreduce_microstep: 10.87 | step_microstep: 41.92
[default0]:[2023-08-25 18:10:05,260] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.00 (forward_moe: 20.00, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.89)
[default0]:[2023-08-25 18:10:05,260] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.32 | backward_inner: 99.36 | backward_allreduce: 10.88 | step: 41.93
[default0]:[2023-08-25 18:10:05,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:05,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.97 | backward_microstep: 110.04 | backward_inner_microstep: 99.09 | backward_allreduce_microstep: 10.85 | step_microstep: 41.85
[default0]:[2023-08-25 18:10:05,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.96 (forward_moe: 19.95, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.85)
[default0]:[2023-08-25 18:10:05,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.03 | backward_inner: 99.09 | backward_allreduce: 10.86 | step: 41.85
[default0]:[2023-08-25 18:10:05,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:10:05,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.27 | backward_microstep: 110.06 | backward_inner_microstep: 99.14 | backward_allreduce_microstep: 10.83 | step_microstep: 41.85
[default0]:[2023-08-25 18:10:05,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.27 (forward_moe: 20.07, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.94)
[default0]:[2023-08-25 18:10:05,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.06 | backward_inner: 99.14 | backward_allreduce: 10.83 | step: 41.85
[default0]:[2023-08-25 18:10:06,055] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:10:06,055] [INFO] [logging.py:96:log_dist] [Rank 0] step=760, skipped=0, lr=[8.290304000000001e-07, 8.290304000000001e-07, 8.290304000000001e-07, 8.290304000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:06,055] [INFO] [timer.py:215:stop] epoch=0/micro_step=760/global_step=760, RunningAvgSamplesPerSec=4.91170890964371, CurrSamplesPerSec=5.023605882726348, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:06,056] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.95 | backward_microstep: 110.24 | backward_inner_microstep: 99.18 | backward_allreduce_microstep: 10.97 | step_microstep: 42.33
[default0]:[2023-08-25 18:10:06,056] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.95 (forward_moe: 20.11, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.88)
[default0]:[2023-08-25 18:10:06,056] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.24 | backward_inner: 99.18 | backward_allreduce: 10.98 | step: 42.34
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.4155], device='cuda:0'), 'moe loss': tensor([0.3025], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      760/439453125 | consumed samples:          760 | consumed tokens:      1556480 | elapsed time per iteration (ms): 264.5 | learning rate: 8.290E-07 | global batch size:     1 | lm loss: 9.883098E+00 | moe loss: 6.049021E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.781 | TFLOPs: 9.39 |
[default0]:[2023-08-25 18:10:06,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:10:06,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.13 | backward_microstep: 111.66 | backward_inner_microstep: 100.59 | backward_allreduce_microstep: 10.98 | step_microstep: 42.48
[default0]:[2023-08-25 18:10:06,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.13 (forward_moe: 20.31, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.05)
[default0]:[2023-08-25 18:10:06,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.66 | backward_inner: 100.59 | backward_allreduce: 10.98 | step: 42.49
[default0]:[2023-08-25 18:10:06,607] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:10:06,607] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.93 | backward_microstep: 113.34 | backward_inner_microstep: 102.24 | backward_allreduce_microstep: 11.01 | step_microstep: 42.80
[default0]:[2023-08-25 18:10:06,607] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.92 (forward_moe: 20.62, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:10:06,607] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.34 | backward_inner: 102.24 | backward_allreduce: 11.02 | step: 42.81
[default0]:[2023-08-25 18:10:06,867] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:10:06,868] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.48 | backward_microstep: 113.37 | backward_inner_microstep: 102.21 | backward_allreduce_microstep: 11.06 | step_microstep: 43.07
[default0]:[2023-08-25 18:10:06,868] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.48 (forward_moe: 20.70, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:10:06,868] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.36 | backward_inner: 102.22 | backward_allreduce: 11.06 | step: 43.08
[default0]:[2023-08-25 18:10:07,132] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.40
[default0]:[2023-08-25 18:10:07,132] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.66 | backward_microstep: 113.85 | backward_inner_microstep: 102.68 | backward_allreduce_microstep: 11.07 | step_microstep: 43.13
[default0]:[2023-08-25 18:10:07,133] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.66 (forward_moe: 20.91, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.35)
[default0]:[2023-08-25 18:10:07,133] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.85 | backward_inner: 102.69 | backward_allreduce: 11.08 | step: 43.13
[default0]:[2023-08-25 18:10:07,385] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 3.03 | optimizer_gradients: 4.07 | optimizer_step: 6.42
[default0]:[2023-08-25 18:10:07,385] [INFO] [logging.py:96:log_dist] [Rank 0] step=765, skipped=0, lr=[8.344917333333334e-07, 8.344917333333334e-07, 8.344917333333334e-07, 8.344917333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:07,385] [INFO] [timer.py:215:stop] epoch=0/micro_step=765/global_step=765, RunningAvgSamplesPerSec=4.911520978401212, CurrSamplesPerSec=4.813763105191578, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:07,385] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.70 | backward_microstep: 114.43 | backward_inner_microstep: 103.25 | backward_allreduce_microstep: 11.08 | step_microstep: 45.10
[default0]:[2023-08-25 18:10:07,385] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.69 (forward_moe: 21.02, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.42)
[default0]:[2023-08-25 18:10:07,386] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.43 | backward_inner: 103.26 | backward_allreduce: 11.09 | step: 45.11
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.4764], device='cuda:0'), 'moe loss': tensor([0.3016], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      765/439453125 | consumed samples:          765 | consumed tokens:      1566720 | elapsed time per iteration (ms): 265.9 | learning rate: 8.345E-07 | global batch size:     1 | lm loss: 9.895287E+00 | moe loss: 6.032297E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.760 | TFLOPs: 9.34 |
[default0]:[2023-08-25 18:10:07,651] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.10 | optimizer_step: 6.42
[default0]:[2023-08-25 18:10:07,651] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.11 | backward_microstep: 114.79 | backward_inner_microstep: 103.61 | backward_allreduce_microstep: 11.10 | step_microstep: 43.50
[default0]:[2023-08-25 18:10:07,651] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.11 (forward_moe: 21.01, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.47)
[default0]:[2023-08-25 18:10:07,651] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.79 | backward_inner: 103.61 | backward_allreduce: 11.10 | step: 43.50
[default0]:[2023-08-25 18:10:07,929] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:10:07,929] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.41 | backward_microstep: 110.74 | backward_inner_microstep: 99.80 | backward_allreduce_microstep: 10.84 | step_microstep: 41.94
[default0]:[2023-08-25 18:10:07,929] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.41 (forward_moe: 20.24, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 8.09)
[default0]:[2023-08-25 18:10:07,929] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.74 | backward_inner: 99.81 | backward_allreduce: 10.85 | step: 41.94
[default0]:[2023-08-25 18:10:08,176] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.33
[default0]:[2023-08-25 18:10:08,176] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.41 | backward_microstep: 110.76 | backward_inner_microstep: 99.76 | backward_allreduce_microstep: 10.90 | step_microstep: 42.21
[default0]:[2023-08-25 18:10:08,176] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.41 (forward_moe: 20.24, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.94)
[default0]:[2023-08-25 18:10:08,176] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.76 | backward_inner: 99.77 | backward_allreduce: 10.91 | step: 42.21
[default0]:[2023-08-25 18:10:08,434] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:08,434] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.38 | backward_microstep: 110.74 | backward_inner_microstep: 99.75 | backward_allreduce_microstep: 10.89 | step_microstep: 42.03
[default0]:[2023-08-25 18:10:08,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.38 (forward_moe: 20.23, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 8.07)
[default0]:[2023-08-25 18:10:08,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.74 | backward_inner: 99.76 | backward_allreduce: 10.89 | step: 42.04
[default0]:[2023-08-25 18:10:08,699] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:08,699] [INFO] [logging.py:96:log_dist] [Rank 0] step=770, skipped=0, lr=[8.399530666666668e-07, 8.399530666666668e-07, 8.399530666666668e-07, 8.399530666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:08,699] [INFO] [timer.py:215:stop] epoch=0/micro_step=770/global_step=770, RunningAvgSamplesPerSec=4.911897300694375, CurrSamplesPerSec=5.029955688270883, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:08,699] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.88 | backward_microstep: 110.04 | backward_inner_microstep: 99.11 | backward_allreduce_microstep: 10.83 | step_microstep: 42.34
[default0]:[2023-08-25 18:10:08,699] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.87 (forward_moe: 20.16, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:10:08,700] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.03 | backward_inner: 99.12 | backward_allreduce: 10.83 | step: 42.35
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.3236], device='cuda:0'), 'moe loss': tensor([0.3045], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      770/439453125 | consumed samples:          770 | consumed tokens:      1576960 | elapsed time per iteration (ms): 262.7 | learning rate: 8.400E-07 | global batch size:     1 | lm loss: 1.006473E+01 | moe loss: 6.089705E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.806 | TFLOPs: 9.46 |
[default0]:[2023-08-25 18:10:08,964] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:10:08,965] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.90 | backward_microstep: 109.98 | backward_inner_microstep: 99.07 | backward_allreduce_microstep: 10.82 | step_microstep: 41.80
[default0]:[2023-08-25 18:10:08,965] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.90 (forward_moe: 20.02, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.87)
[default0]:[2023-08-25 18:10:08,965] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.98 | backward_inner: 99.07 | backward_allreduce: 10.83 | step: 41.80
[default0]:[2023-08-25 18:10:09,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:09,234] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.09 | backward_microstep: 113.85 | backward_inner_microstep: 102.86 | backward_allreduce_microstep: 10.89 | step_microstep: 41.94
[default0]:[2023-08-25 18:10:09,234] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.09 (forward_moe: 20.14, 1st alltoall: 1.05, 2nd alltoall: 0.81, top-k: 7.85)
[default0]:[2023-08-25 18:10:09,234] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.84 | backward_inner: 102.86 | backward_allreduce: 10.90 | step: 41.94
[default0]:[2023-08-25 18:10:09,475] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:09,476] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.10 | backward_microstep: 109.86 | backward_inner_microstep: 98.95 | backward_allreduce_microstep: 10.81 | step_microstep: 42.12
[default0]:[2023-08-25 18:10:09,476] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.10 (forward_moe: 19.92, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.85)
[default0]:[2023-08-25 18:10:09,476] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.85 | backward_inner: 98.96 | backward_allreduce: 10.81 | step: 42.12
[default0]:[2023-08-25 18:10:09,735] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:09,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.92 | backward_microstep: 110.09 | backward_inner_microstep: 99.13 | backward_allreduce_microstep: 10.86 | step_microstep: 41.87
[default0]:[2023-08-25 18:10:09,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.92 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.84)
[default0]:[2023-08-25 18:10:09,736] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.09 | backward_inner: 99.14 | backward_allreduce: 10.87 | step: 41.87
[default0]:[2023-08-25 18:10:10,067] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.33
[default0]:[2023-08-25 18:10:10,084] [INFO] [logging.py:96:log_dist] [Rank 0] step=775, skipped=0, lr=[8.454144000000001e-07, 8.454144000000001e-07, 8.454144000000001e-07, 8.454144000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:10,084] [INFO] [timer.py:215:stop] epoch=0/micro_step=775/global_step=775, RunningAvgSamplesPerSec=4.912030168298609, CurrSamplesPerSec=4.653280302652089, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:10,084] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.02 | backward_microstep: 110.09 | backward_inner_microstep: 99.04 | backward_allreduce_microstep: 10.96 | step_microstep: 58.25
[default0]:[2023-08-25 18:10:10,084] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.02 (forward_moe: 19.97, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:10:10,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.08 | backward_inner: 99.04 | backward_allreduce: 10.96 | step: 58.26
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.7048], device='cuda:0'), 'moe loss': tensor([0.3012], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      775/439453125 | consumed samples:          775 | consumed tokens:      1587200 | elapsed time per iteration (ms): 277.4 | learning rate: 8.454E-07 | global batch size:     1 | lm loss: 9.940958E+00 | moe loss: 6.024548E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.604 | TFLOPs: 8.96 |
[default0]:[2023-08-25 18:10:10,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 63.35
[default0]:[2023-08-25 18:10:10,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.10 | backward_microstep: 110.36 | backward_inner_microstep: 99.33 | backward_allreduce_microstep: 10.94 | step_microstep: 99.09
[default0]:[2023-08-25 18:10:10,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.10 (forward_moe: 19.99, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.87)
[default0]:[2023-08-25 18:10:10,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.36 | backward_inner: 99.34 | backward_allreduce: 10.94 | step: 99.09
[default0]:[2023-08-25 18:10:10,651] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:10:10,652] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.87 | backward_microstep: 112.69 | backward_inner_microstep: 101.64 | backward_allreduce_microstep: 10.95 | step_microstep: 42.69
[default0]:[2023-08-25 18:10:10,652] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.87 (forward_moe: 20.52, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.20)
[default0]:[2023-08-25 18:10:10,652] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.69 | backward_inner: 101.65 | backward_allreduce: 10.96 | step: 42.69
[default0]:[2023-08-25 18:10:10,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:10,897] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.31 | backward_microstep: 110.18 | backward_inner_microstep: 99.24 | backward_allreduce_microstep: 10.84 | step_microstep: 41.99
[default0]:[2023-08-25 18:10:10,897] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.30 (forward_moe: 20.07, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.94)
[default0]:[2023-08-25 18:10:10,897] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.18 | backward_inner: 99.24 | backward_allreduce: 10.85 | step: 42.00
[default0]:[2023-08-25 18:10:11,159] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:11,160] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.32 | backward_microstep: 110.66 | backward_inner_microstep: 99.48 | backward_allreduce_microstep: 11.08 | step_microstep: 42.47
[default0]:[2023-08-25 18:10:11,160] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.32 (forward_moe: 20.04, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.89)
[default0]:[2023-08-25 18:10:11,160] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.65 | backward_inner: 99.48 | backward_allreduce: 11.09 | step: 42.47
[default0]:[2023-08-25 18:10:11,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.34
[default0]:[2023-08-25 18:10:11,435] [INFO] [logging.py:96:log_dist] [Rank 0] step=780, skipped=0, lr=[8.508757333333333e-07, 8.508757333333333e-07, 8.508757333333333e-07, 8.508757333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:11,435] [INFO] [timer.py:215:stop] epoch=0/micro_step=780/global_step=780, RunningAvgSamplesPerSec=4.910751611255469, CurrSamplesPerSec=5.004102971582239, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:11,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.32 | backward_microstep: 110.61 | backward_inner_microstep: 99.63 | backward_allreduce_microstep: 10.88 | step_microstep: 42.36
[default0]:[2023-08-25 18:10:11,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.32 (forward_moe: 20.15, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.89)
[default0]:[2023-08-25 18:10:11,436] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.61 | backward_inner: 99.64 | backward_allreduce: 10.89 | step: 42.36
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.0039], device='cuda:0'), 'moe loss': tensor([0.3012], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      780/439453125 | consumed samples:          780 | consumed tokens:      1597440 | elapsed time per iteration (ms): 270.1 | learning rate: 8.509E-07 | global batch size:     1 | lm loss: 9.800790E+00 | moe loss: 6.023206E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.702 | TFLOPs: 9.20 |
[default0]:[2023-08-25 18:10:11,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:11,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.16 | backward_microstep: 110.33 | backward_inner_microstep: 99.40 | backward_allreduce_microstep: 10.84 | step_microstep: 41.91
[default0]:[2023-08-25 18:10:11,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.15 (forward_moe: 20.02, 1st alltoall: 0.86, 2nd alltoall: 0.82, top-k: 7.90)
[default0]:[2023-08-25 18:10:11,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.33 | backward_inner: 99.40 | backward_allreduce: 10.85 | step: 41.91
[default0]:[2023-08-25 18:10:11,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:10:11,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.24 | backward_microstep: 110.40 | backward_inner_microstep: 99.43 | backward_allreduce_microstep: 10.88 | step_microstep: 41.85
[default0]:[2023-08-25 18:10:11,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.24 (forward_moe: 20.15, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.00)
[default0]:[2023-08-25 18:10:11,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.40 | backward_inner: 99.44 | backward_allreduce: 10.88 | step: 41.85
[default0]:[2023-08-25 18:10:12,371] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:12,371] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.08 | backward_microstep: 110.37 | backward_inner_microstep: 99.38 | backward_allreduce_microstep: 10.90 | step_microstep: 42.02
[default0]:[2023-08-25 18:10:12,372] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.09 (forward_moe: 20.02, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.89)
[default0]:[2023-08-25 18:10:12,372] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.37 | backward_inner: 99.38 | backward_allreduce: 10.90 | step: 42.03
[default0]:[2023-08-25 18:10:12,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:10:12,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.18 | backward_microstep: 112.43 | backward_inner_microstep: 101.28 | backward_allreduce_microstep: 11.05 | step_microstep: 42.79
[default0]:[2023-08-25 18:10:12,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.18 (forward_moe: 20.49, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:10:12,611] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.43 | backward_inner: 101.29 | backward_allreduce: 11.05 | step: 42.79
[default0]:[2023-08-25 18:10:12,854] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.38
[default0]:[2023-08-25 18:10:12,854] [INFO] [logging.py:96:log_dist] [Rank 0] step=785, skipped=0, lr=[8.563370666666667e-07, 8.563370666666667e-07, 8.563370666666667e-07, 8.563370666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:12,854] [INFO] [timer.py:215:stop] epoch=0/micro_step=785/global_step=785, RunningAvgSamplesPerSec=4.911113263727293, CurrSamplesPerSec=4.892937136031058, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:12,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.48 | backward_microstep: 113.07 | backward_inner_microstep: 101.94 | backward_allreduce_microstep: 11.03 | step_microstep: 43.28
[default0]:[2023-08-25 18:10:12,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.49 (forward_moe: 20.59, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.23)
[default0]:[2023-08-25 18:10:12,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.07 | backward_inner: 101.95 | backward_allreduce: 11.04 | step: 43.29
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.2954], device='cuda:0'), 'moe loss': tensor([0.3017], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      785/439453125 | consumed samples:          785 | consumed tokens:      1607680 | elapsed time per iteration (ms): 283.5 | learning rate: 8.563E-07 | global batch size:     1 | lm loss: 9.859086E+00 | moe loss: 6.033456E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.528 | TFLOPs: 8.77 |
[default0]:[2023-08-25 18:10:13,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.04 | optimizer_step: 6.35
[default0]:[2023-08-25 18:10:13,101] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.67 | backward_microstep: 112.02 | backward_inner_microstep: 100.96 | backward_allreduce_microstep: 10.96 | step_microstep: 43.02
[default0]:[2023-08-25 18:10:13,102] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.67 (forward_moe: 20.43, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:10:13,102] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.02 | backward_inner: 100.97 | backward_allreduce: 10.97 | step: 43.03
[default0]:[2023-08-25 18:10:13,364] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:10:13,365] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.94 | backward_microstep: 112.25 | backward_inner_microstep: 101.19 | backward_allreduce_microstep: 10.96 | step_microstep: 42.42
[default0]:[2023-08-25 18:10:13,365] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.94 (forward_moe: 20.51, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.25)
[default0]:[2023-08-25 18:10:13,365] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.25 | backward_inner: 101.19 | backward_allreduce: 10.97 | step: 42.43
[default0]:[2023-08-25 18:10:13,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:10:13,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.76 | backward_microstep: 112.00 | backward_inner_microstep: 100.93 | backward_allreduce_microstep: 10.97 | step_microstep: 42.47
[default0]:[2023-08-25 18:10:13,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.76 (forward_moe: 20.41, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.11)
[default0]:[2023-08-25 18:10:13,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.00 | backward_inner: 100.94 | backward_allreduce: 10.98 | step: 42.47
[default0]:[2023-08-25 18:10:13,890] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:10:13,891] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.15 | backward_microstep: 111.83 | backward_inner_microstep: 100.79 | backward_allreduce_microstep: 10.94 | step_microstep: 42.58
[default0]:[2023-08-25 18:10:13,891] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.15 (forward_moe: 20.45, 1st alltoall: 0.87, 2nd alltoall: 0.83, top-k: 8.09)
[default0]:[2023-08-25 18:10:13,891] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.83 | backward_inner: 100.80 | backward_allreduce: 10.94 | step: 42.58
[default0]:[2023-08-25 18:10:14,133] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.37
[default0]:[2023-08-25 18:10:14,133] [INFO] [logging.py:96:log_dist] [Rank 0] step=790, skipped=0, lr=[8.617984e-07, 8.617984e-07, 8.617984e-07, 8.617984e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:14,133] [INFO] [timer.py:215:stop] epoch=0/micro_step=790/global_step=790, RunningAvgSamplesPerSec=4.911276887272803, CurrSamplesPerSec=4.942225867154019, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:14,133] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.82 | backward_microstep: 111.99 | backward_inner_microstep: 100.95 | backward_allreduce_microstep: 10.95 | step_microstep: 42.96
[default0]:[2023-08-25 18:10:14,133] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.82 (forward_moe: 20.47, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.08)
[default0]:[2023-08-25 18:10:14,134] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.99 | backward_inner: 100.95 | backward_allreduce: 10.95 | step: 42.97
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.8370], device='cuda:0'), 'moe loss': tensor([0.3018], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      790/439453125 | consumed samples:          790 | consumed tokens:      1617920 | elapsed time per iteration (ms): 255.7 | learning rate: 8.618E-07 | global batch size:     1 | lm loss: 9.967397E+00 | moe loss: 6.036375E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.910 | TFLOPs: 9.72 |
[default0]:[2023-08-25 18:10:14,402] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.33
[default0]:[2023-08-25 18:10:14,402] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.16 | backward_microstep: 111.83 | backward_inner_microstep: 100.77 | backward_allreduce_microstep: 10.97 | step_microstep: 42.45
[default0]:[2023-08-25 18:10:14,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.16 (forward_moe: 20.39, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:10:14,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.83 | backward_inner: 100.78 | backward_allreduce: 10.97 | step: 42.46
[default0]:[2023-08-25 18:10:14,652] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:10:14,652] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.73 | backward_microstep: 111.86 | backward_inner_microstep: 100.82 | backward_allreduce_microstep: 10.95 | step_microstep: 42.50
[default0]:[2023-08-25 18:10:14,653] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.73 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.09)
[default0]:[2023-08-25 18:10:14,653] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.86 | backward_inner: 100.82 | backward_allreduce: 10.95 | step: 42.51
[default0]:[2023-08-25 18:10:14,924] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.39
[default0]:[2023-08-25 18:10:14,924] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.33 | backward_microstep: 112.94 | backward_inner_microstep: 101.77 | backward_allreduce_microstep: 11.07 | step_microstep: 42.85
[default0]:[2023-08-25 18:10:14,924] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.33 (forward_moe: 20.60, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.24)
[default0]:[2023-08-25 18:10:14,924] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.93 | backward_inner: 101.77 | backward_allreduce: 11.08 | step: 42.85
[default0]:[2023-08-25 18:10:15,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.39
[default0]:[2023-08-25 18:10:15,184] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.28 | backward_microstep: 115.70 | backward_inner_microstep: 104.59 | backward_allreduce_microstep: 11.02 | step_microstep: 43.39
[default0]:[2023-08-25 18:10:15,184] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.28 (forward_moe: 20.65, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.30)
[default0]:[2023-08-25 18:10:15,184] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.70 | backward_inner: 104.60 | backward_allreduce: 11.02 | step: 43.39
[default0]:[2023-08-25 18:10:15,451] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:10:15,451] [INFO] [logging.py:96:log_dist] [Rank 0] step=795, skipped=0, lr=[8.672597333333333e-07, 8.672597333333333e-07, 8.672597333333333e-07, 8.672597333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:15,451] [INFO] [timer.py:215:stop] epoch=0/micro_step=795/global_step=795, RunningAvgSamplesPerSec=4.911170444259584, CurrSamplesPerSec=4.848547621910055, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:15,451] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.48 | backward_microstep: 114.41 | backward_inner_microstep: 103.19 | backward_allreduce_microstep: 11.13 | step_microstep: 43.81
[default0]:[2023-08-25 18:10:15,452] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.47 (forward_moe: 20.91, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.45)
[default0]:[2023-08-25 18:10:15,452] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.41 | backward_inner: 103.20 | backward_allreduce: 11.13 | step: 43.82
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.3885], device='cuda:0'), 'moe loss': tensor([0.3006], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      795/439453125 | consumed samples:          795 | consumed tokens:      1628160 | elapsed time per iteration (ms): 263.7 | learning rate: 8.673E-07 | global batch size:     1 | lm loss: 9.877705E+00 | moe loss: 6.012996E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.792 | TFLOPs: 9.42 |
[default0]:[2023-08-25 18:10:15,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.48
[default0]:[2023-08-25 18:10:15,745] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.86 | backward_microstep: 114.54 | backward_inner_microstep: 103.30 | backward_allreduce_microstep: 11.15 | step_microstep: 43.59
[default0]:[2023-08-25 18:10:15,745] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.85 (forward_moe: 20.91, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.41)
[default0]:[2023-08-25 18:10:15,745] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.54 | backward_inner: 103.30 | backward_allreduce: 11.16 | step: 43.59
[default0]:[2023-08-25 18:10:16,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.47
[default0]:[2023-08-25 18:10:16,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.33 | backward_microstep: 115.45 | backward_inner_microstep: 104.14 | backward_allreduce_microstep: 11.21 | step_microstep: 43.71
[default0]:[2023-08-25 18:10:16,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.33 (forward_moe: 21.11, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.55)
[default0]:[2023-08-25 18:10:16,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.45 | backward_inner: 104.15 | backward_allreduce: 11.21 | step: 43.72
[default0]:[2023-08-25 18:10:16,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 4.15 | optimizer_step: 6.46
[default0]:[2023-08-25 18:10:16,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.37 | backward_microstep: 117.94 | backward_inner_microstep: 106.49 | backward_allreduce_microstep: 11.35 | step_microstep: 44.98
[default0]:[2023-08-25 18:10:16,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.36 (forward_moe: 21.57, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.82)
[default0]:[2023-08-25 18:10:16,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.94 | backward_inner: 106.50 | backward_allreduce: 11.36 | step: 44.98
[default0]:[2023-08-25 18:10:16,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.11 | optimizer_step: 6.46
[default0]:[2023-08-25 18:10:16,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.07 | backward_microstep: 117.86 | backward_inner_microstep: 106.54 | backward_allreduce_microstep: 11.22 | step_microstep: 43.99
[default0]:[2023-08-25 18:10:16,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.07 (forward_moe: 21.81, 1st alltoall: 0.92, 2nd alltoall: 0.86, top-k: 8.75)
[default0]:[2023-08-25 18:10:16,781] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.85 | backward_inner: 106.55 | backward_allreduce: 11.22 | step: 44.00
[default0]:[2023-08-25 18:10:17,041] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 4.11 | optimizer_step: 6.47
[default0]:[2023-08-25 18:10:17,041] [INFO] [logging.py:96:log_dist] [Rank 0] step=800, skipped=0, lr=[8.727210666666667e-07, 8.727210666666667e-07, 8.727210666666667e-07, 8.727210666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:17,042] [INFO] [timer.py:215:stop] epoch=0/micro_step=800/global_step=800, RunningAvgSamplesPerSec=4.9101710261398805, CurrSamplesPerSec=4.760163699629792, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:17,042] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.61 | backward_microstep: 116.26 | backward_inner_microstep: 104.89 | backward_allreduce_microstep: 11.28 | step_microstep: 44.50
[default0]:[2023-08-25 18:10:17,042] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.61 (forward_moe: 21.34, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.60)
[default0]:[2023-08-25 18:10:17,042] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.26 | backward_inner: 104.90 | backward_allreduce: 11.28 | step: 44.50
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.5717], device='cuda:0'), 'moe loss': tensor([0.3009], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      800/439453125 | consumed samples:          800 | consumed tokens:      1638400 | elapsed time per iteration (ms): 318.2 | learning rate: 8.727E-07 | global batch size:     1 | lm loss: 9.914340E+00 | moe loss: 6.018645E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.143 | TFLOPs: 7.81 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 800 | lm loss value: 9.874090E+00 | lm loss PPL: 1.942061E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration     800 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:10:20,837] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step800 is about to be saved!
[default0]:[2023-08-25 18:10:20,839] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,849] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,850] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,859] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,859] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,869] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,869] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,878] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,879] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,888] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,888] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,896] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,896] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,905] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,905] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,914] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,915] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,924] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,924] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,933] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,933] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,942] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,942] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,951] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,952] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,960] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,961] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,969] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,969] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,978] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,986] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,987] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:20,997] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:20,997] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:21,006] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:21,006] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:21,014] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:21,015] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:21,024] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:21,025] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:21,033] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:21,033] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:21,043] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:21,043] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:21,052] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:21,052] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:21,061] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:21,061] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:10:21,063] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:10:21,064] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:10:21,064] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:21,344] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:21,345] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:10:25,019] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:10:25,078] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step800/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:10:25,078] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step800 is ready now!
[default0]:  successfully saved checkpoint at iteration     800 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.69, Latency(second): 4.245
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4245.39, 4245.39)
[default0]:[2023-08-25 18:10:25,336] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.18 | optimizer_step: 10.20
[default0]:[2023-08-25 18:10:25,340] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2337.18 | backward_microstep: 119.40 | backward_inner_microstep: 108.19 | backward_allreduce_microstep: 11.11 | step_microstep: 51.00
[default0]:[2023-08-25 18:10:25,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2337.08 (forward_moe: 21.75, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.74)
[default0]:[2023-08-25 18:10:25,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 119.40 | backward_inner: 108.20 | backward_allreduce: 11.11 | step: 51.01
[default0]:[2023-08-25 18:10:25,601] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:10:25,602] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.35 | backward_microstep: 112.48 | backward_inner_microstep: 101.54 | backward_allreduce_microstep: 10.85 | step_microstep: 42.14
[default0]:[2023-08-25 18:10:25,602] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.35 (forward_moe: 20.48, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.19)
[default0]:[2023-08-25 18:10:25,602] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.48 | backward_inner: 101.55 | backward_allreduce: 10.85 | step: 42.15
[default0]:[2023-08-25 18:10:25,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:10:25,849] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.25 | backward_microstep: 112.37 | backward_inner_microstep: 101.48 | backward_allreduce_microstep: 10.80 | step_microstep: 42.51
[default0]:[2023-08-25 18:10:25,849] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.25 (forward_moe: 20.55, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.30)
[default0]:[2023-08-25 18:10:25,849] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.36 | backward_inner: 101.48 | backward_allreduce: 10.80 | step: 42.51
[default0]:[2023-08-25 18:10:26,146] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:10:26,147] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.21 | backward_microstep: 113.12 | backward_inner_microstep: 101.99 | backward_allreduce_microstep: 11.04 | step_microstep: 43.09
[default0]:[2023-08-25 18:10:26,147] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.21 (forward_moe: 20.58, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:10:26,147] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.12 | backward_inner: 101.99 | backward_allreduce: 11.04 | step: 43.09
[default0]:[2023-08-25 18:10:26,392] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:10:26,393] [INFO] [logging.py:96:log_dist] [Rank 0] step=805, skipped=0, lr=[8.781824e-07, 8.781824e-07, 8.781824e-07, 8.781824e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:26,393] [INFO] [timer.py:215:stop] epoch=0/micro_step=805/global_step=805, RunningAvgSamplesPerSec=4.909729237324929, CurrSamplesPerSec=5.058247638389244, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:26,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.71 | backward_microstep: 109.41 | backward_inner_microstep: 98.50 | backward_allreduce_microstep: 10.82 | step_microstep: 42.04
[default0]:[2023-08-25 18:10:26,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.70 (forward_moe: 20.01, 1st alltoall: 0.86, 2nd alltoall: 1.01, top-k: 7.76)
[default0]:[2023-08-25 18:10:26,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.41 | backward_inner: 98.50 | backward_allreduce: 10.82 | step: 42.04
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.6789], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      805/439453125 | consumed samples:          805 | consumed tokens:      1648640 | elapsed time per iteration (ms): 1870.1 | learning rate: 8.782E-07 | global batch size:     1 | lm loss: 9.935781E+00 | moe loss: 6.019292E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.535 | TFLOPs: 1.33 |
[default0]:[2023-08-25 18:10:26,632] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:26,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.93 | backward_microstep: 109.85 | backward_inner_microstep: 98.94 | backward_allreduce_microstep: 10.81 | step_microstep: 42.13
[default0]:[2023-08-25 18:10:26,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.93 (forward_moe: 20.06, 1st alltoall: 0.86, 2nd alltoall: 0.82, top-k: 7.79)
[default0]:[2023-08-25 18:10:26,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.85 | backward_inner: 98.95 | backward_allreduce: 10.82 | step: 42.13
[default0]:[2023-08-25 18:10:26,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.33
[default0]:[2023-08-25 18:10:26,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.72 | backward_microstep: 109.35 | backward_inner_microstep: 98.44 | backward_allreduce_microstep: 10.81 | step_microstep: 41.58
[default0]:[2023-08-25 18:10:26,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.72 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.75)
[default0]:[2023-08-25 18:10:26,885] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.35 | backward_inner: 98.45 | backward_allreduce: 10.82 | step: 41.58
[default0]:[2023-08-25 18:10:27,124] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:27,124] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 109.46 | backward_inner_microstep: 98.60 | backward_allreduce_microstep: 10.77 | step_microstep: 41.73
[default0]:[2023-08-25 18:10:27,124] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.64 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:10:27,124] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.46 | backward_inner: 98.60 | backward_allreduce: 10.77 | step: 41.74
[default0]:[2023-08-25 18:10:27,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:27,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.63 | backward_microstep: 109.68 | backward_inner_microstep: 98.71 | backward_allreduce_microstep: 10.87 | step_microstep: 41.59
[default0]:[2023-08-25 18:10:27,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.63 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.78)
[default0]:[2023-08-25 18:10:27,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.68 | backward_inner: 98.71 | backward_allreduce: 10.88 | step: 41.59
[default0]:[2023-08-25 18:10:27,639] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:27,640] [INFO] [logging.py:96:log_dist] [Rank 0] step=810, skipped=0, lr=[8.836437333333333e-07, 8.836437333333333e-07, 8.836437333333333e-07, 8.836437333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:27,640] [INFO] [timer.py:215:stop] epoch=0/micro_step=810/global_step=810, RunningAvgSamplesPerSec=4.9105951798673955, CurrSamplesPerSec=5.055461406989386, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:27,640] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 109.70 | backward_inner_microstep: 98.74 | backward_allreduce_microstep: 10.86 | step_microstep: 41.99
[default0]:[2023-08-25 18:10:27,640] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:10:27,640] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.70 | backward_inner: 98.74 | backward_allreduce: 10.87 | step: 42.00
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.5308], device='cuda:0'), 'moe loss': tensor([0.3016], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      810/439453125 | consumed samples:          810 | consumed tokens:      1658880 | elapsed time per iteration (ms): 249.1 | learning rate: 8.836E-07 | global batch size:     1 | lm loss: 9.906163E+00 | moe loss: 6.031109E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.014 | TFLOPs: 9.97 |
[default0]:[2023-08-25 18:10:27,883] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:27,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.79 | backward_microstep: 109.58 | backward_inner_microstep: 98.66 | backward_allreduce_microstep: 10.83 | step_microstep: 41.62
[default0]:[2023-08-25 18:10:27,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.79 (forward_moe: 19.81, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:10:27,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.58 | backward_inner: 98.66 | backward_allreduce: 10.83 | step: 41.63
[default0]:[2023-08-25 18:10:28,130] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.33
[default0]:[2023-08-25 18:10:28,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.04 | backward_microstep: 111.81 | backward_inner_microstep: 100.79 | backward_allreduce_microstep: 10.93 | step_microstep: 42.42
[default0]:[2023-08-25 18:10:28,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.05 (forward_moe: 20.36, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.08)
[default0]:[2023-08-25 18:10:28,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.81 | backward_inner: 100.79 | backward_allreduce: 10.94 | step: 42.43
[default0]:[2023-08-25 18:10:28,405] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:10:28,405] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.41 | backward_microstep: 112.79 | backward_inner_microstep: 101.65 | backward_allreduce_microstep: 11.04 | step_microstep: 42.71
[default0]:[2023-08-25 18:10:28,405] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.41 (forward_moe: 20.42, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:10:28,405] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.78 | backward_inner: 101.65 | backward_allreduce: 11.05 | step: 42.71
[default0]:[2023-08-25 18:10:28,660] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:10:28,660] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.14 | backward_microstep: 112.83 | backward_inner_microstep: 101.74 | backward_allreduce_microstep: 10.99 | step_microstep: 42.87
[default0]:[2023-08-25 18:10:28,660] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.13 (forward_moe: 20.56, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:10:28,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.82 | backward_inner: 101.74 | backward_allreduce: 11.00 | step: 42.87
[default0]:[2023-08-25 18:10:28,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:10:28,912] [INFO] [logging.py:96:log_dist] [Rank 0] step=815, skipped=0, lr=[8.891050666666666e-07, 8.891050666666666e-07, 8.891050666666666e-07, 8.891050666666666e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:28,913] [INFO] [timer.py:215:stop] epoch=0/micro_step=815/global_step=815, RunningAvgSamplesPerSec=4.91079872778574, CurrSamplesPerSec=4.8747793200675495, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:28,913] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.58 | backward_microstep: 113.50 | backward_inner_microstep: 102.31 | backward_allreduce_microstep: 11.09 | step_microstep: 43.52
[default0]:[2023-08-25 18:10:28,913] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.57 (forward_moe: 20.68, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.28)
[default0]:[2023-08-25 18:10:28,913] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.50 | backward_inner: 102.32 | backward_allreduce: 11.09 | step: 43.52
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.0666], device='cuda:0'), 'moe loss': tensor([0.3020], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      815/439453125 | consumed samples:          815 | consumed tokens:      1669120 | elapsed time per iteration (ms): 254.9 | learning rate: 8.891E-07 | global batch size:     1 | lm loss: 9.813325E+00 | moe loss: 6.040550E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.923 | TFLOPs: 9.75 |
[default0]:[2023-08-25 18:10:29,165] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.41
[default0]:[2023-08-25 18:10:29,166] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.64 | backward_microstep: 114.51 | backward_inner_microstep: 103.19 | backward_allreduce_microstep: 11.23 | step_microstep: 43.08
[default0]:[2023-08-25 18:10:29,166] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.64 (forward_moe: 20.99, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.37)
[default0]:[2023-08-25 18:10:29,166] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.51 | backward_inner: 103.19 | backward_allreduce: 11.24 | step: 43.09
[default0]:[2023-08-25 18:10:29,416] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:10:29,417] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.65 | backward_microstep: 110.10 | backward_inner_microstep: 99.18 | backward_allreduce_microstep: 10.82 | step_microstep: 42.07
[default0]:[2023-08-25 18:10:29,417] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.65 (forward_moe: 19.88, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.82)
[default0]:[2023-08-25 18:10:29,417] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.10 | backward_inner: 99.19 | backward_allreduce: 10.83 | step: 42.07
[default0]:[2023-08-25 18:10:29,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:10:29,662] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.72 | backward_microstep: 109.73 | backward_inner_microstep: 98.83 | backward_allreduce_microstep: 10.81 | step_microstep: 42.52
[default0]:[2023-08-25 18:10:29,662] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.72 (forward_moe: 19.91, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.82)
[default0]:[2023-08-25 18:10:29,662] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.73 | backward_inner: 98.83 | backward_allreduce: 10.82 | step: 42.53
[default0]:[2023-08-25 18:10:29,917] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:29,917] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.11 | backward_microstep: 109.69 | backward_inner_microstep: 98.68 | backward_allreduce_microstep: 10.91 | step_microstep: 41.51
[default0]:[2023-08-25 18:10:29,917] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.11 (forward_moe: 19.93, 1st alltoall: 0.87, 2nd alltoall: 0.88, top-k: 7.80)
[default0]:[2023-08-25 18:10:29,917] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.68 | backward_inner: 98.68 | backward_allreduce: 10.92 | step: 41.51
[default0]:[2023-08-25 18:10:30,171] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:30,171] [INFO] [logging.py:96:log_dist] [Rank 0] step=820, skipped=0, lr=[8.945664e-07, 8.945664e-07, 8.945664e-07, 8.945664e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:30,171] [INFO] [timer.py:215:stop] epoch=0/micro_step=820/global_step=820, RunningAvgSamplesPerSec=4.911253477799458, CurrSamplesPerSec=5.046696001318736, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:30,172] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.76 | backward_microstep: 109.71 | backward_inner_microstep: 98.83 | backward_allreduce_microstep: 10.78 | step_microstep: 42.14
[default0]:[2023-08-25 18:10:30,172] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.76 (forward_moe: 20.05, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:10:30,172] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.71 | backward_inner: 98.83 | backward_allreduce: 10.78 | step: 42.14
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.3852], device='cuda:0'), 'moe loss': tensor([0.3025], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      820/439453125 | consumed samples:          820 | consumed tokens:      1679360 | elapsed time per iteration (ms): 251.7 | learning rate: 8.946E-07 | global batch size:     1 | lm loss: 9.877046E+00 | moe loss: 6.049290E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.974 | TFLOPs: 9.87 |
[default0]:[2023-08-25 18:10:30,473] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:30,473] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 109.04 | backward_inner_microstep: 98.11 | backward_allreduce_microstep: 10.84 | step_microstep: 41.60
[default0]:[2023-08-25 18:10:30,473] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.64 (forward_moe: 19.72, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.70)
[default0]:[2023-08-25 18:10:30,474] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.11 | backward_allreduce: 10.84 | step: 41.60
[default0]:[2023-08-25 18:10:30,714] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:30,715] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 109.02 | backward_inner_microstep: 98.14 | backward_allreduce_microstep: 10.79 | step_microstep: 41.38
[default0]:[2023-08-25 18:10:30,715] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.81, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:10:30,715] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.01 | backward_inner: 98.14 | backward_allreduce: 10.79 | step: 41.38
[default0]:[2023-08-25 18:10:30,977] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:30,978] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.28 | backward_microstep: 109.21 | backward_inner_microstep: 98.29 | backward_allreduce_microstep: 10.83 | step_microstep: 43.00
[default0]:[2023-08-25 18:10:30,981] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.28 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:10:30,981] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.21 | backward_inner: 98.30 | backward_allreduce: 10.83 | step: 43.00
[default0]:[2023-08-25 18:10:31,245] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:31,246] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.45 | backward_microstep: 111.90 | backward_inner_microstep: 100.99 | backward_allreduce_microstep: 10.81 | step_microstep: 41.59
[default0]:[2023-08-25 18:10:31,246] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.45 (forward_moe: 20.58, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.88)
[default0]:[2023-08-25 18:10:31,246] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.89 | backward_inner: 100.99 | backward_allreduce: 10.81 | step: 41.59
[default0]:[2023-08-25 18:10:31,493] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:31,494] [INFO] [logging.py:96:log_dist] [Rank 0] step=825, skipped=0, lr=[9.000277333333334e-07, 9.000277333333334e-07, 9.000277333333334e-07, 9.000277333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:31,494] [INFO] [timer.py:215:stop] epoch=0/micro_step=825/global_step=825, RunningAvgSamplesPerSec=4.91203904058163, CurrSamplesPerSec=5.064544719079416, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:31,494] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.05 | backward_microstep: 109.06 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.79 | step_microstep: 41.80
[default0]:[2023-08-25 18:10:31,494] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.04 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.79)
[default0]:[2023-08-25 18:10:31,494] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.06 | backward_inner: 98.18 | backward_allreduce: 10.79 | step: 41.80
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.5552], device='cuda:0'), 'moe loss': tensor([0.3018], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      825/439453125 | consumed samples:          825 | consumed tokens:      1689600 | elapsed time per iteration (ms): 264.2 | learning rate: 9.000E-07 | global batch size:     1 | lm loss: 9.911037E+00 | moe loss: 6.035988E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.785 | TFLOPs: 9.40 |
[default0]:[2023-08-25 18:10:31,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:31,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 109.12 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.85 | step_microstep: 41.37
[default0]:[2023-08-25 18:10:31,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:10:31,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.19 | backward_allreduce: 10.85 | step: 41.37
[default0]:[2023-08-25 18:10:32,013] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:10:32,014] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.66 | backward_microstep: 109.27 | backward_inner_microstep: 98.33 | backward_allreduce_microstep: 10.84 | step_microstep: 41.53
[default0]:[2023-08-25 18:10:32,014] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:10:32,014] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.27 | backward_inner: 98.34 | backward_allreduce: 10.84 | step: 41.54
[default0]:[2023-08-25 18:10:32,290] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:32,290] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.63 | backward_microstep: 108.91 | backward_inner_microstep: 98.02 | backward_allreduce_microstep: 10.80 | step_microstep: 41.42
[default0]:[2023-08-25 18:10:32,290] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.63 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:10:32,290] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.91 | backward_inner: 98.02 | backward_allreduce: 10.81 | step: 41.43
[default0]:[2023-08-25 18:10:32,543] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:32,543] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.75 | backward_microstep: 110.50 | backward_inner_microstep: 99.58 | backward_allreduce_microstep: 10.83 | step_microstep: 41.44
[default0]:[2023-08-25 18:10:32,543] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.75 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.70)
[default0]:[2023-08-25 18:10:32,544] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.50 | backward_inner: 99.59 | backward_allreduce: 10.83 | step: 41.45
[default0]:[2023-08-25 18:10:32,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:32,790] [INFO] [logging.py:96:log_dist] [Rank 0] step=830, skipped=0, lr=[9.054890666666667e-07, 9.054890666666667e-07, 9.054890666666667e-07, 9.054890666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:32,790] [INFO] [timer.py:215:stop] epoch=0/micro_step=830/global_step=830, RunningAvgSamplesPerSec=4.912950171152729, CurrSamplesPerSec=5.06865756775243, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:32,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.71 | backward_microstep: 109.11 | backward_inner_microstep: 98.24 | backward_allreduce_microstep: 10.77 | step_microstep: 41.94
[default0]:[2023-08-25 18:10:32,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.71 (forward_moe: 19.93, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:10:32,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.11 | backward_inner: 98.25 | backward_allreduce: 10.77 | step: 41.95
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.0097], device='cuda:0'), 'moe loss': tensor([0.3004], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      830/439453125 | consumed samples:          830 | consumed tokens:      1699840 | elapsed time per iteration (ms): 259.2 | learning rate: 9.055E-07 | global batch size:     1 | lm loss: 9.801931E+00 | moe loss: 6.008511E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.858 | TFLOPs: 9.59 |
[default0]:[2023-08-25 18:10:33,035] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:33,036] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.67 | backward_microstep: 109.21 | backward_inner_microstep: 98.22 | backward_allreduce_microstep: 10.89 | step_microstep: 41.56
[default0]:[2023-08-25 18:10:33,036] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.80, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:10:33,036] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.21 | backward_inner: 98.22 | backward_allreduce: 10.90 | step: 41.56
[default0]:[2023-08-25 18:10:33,281] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.29
[default0]:[2023-08-25 18:10:33,282] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 109.87 | backward_inner_microstep: 98.99 | backward_allreduce_microstep: 10.79 | step_microstep: 41.71
[default0]:[2023-08-25 18:10:33,282] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 20.24, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 8.12)
[default0]:[2023-08-25 18:10:33,282] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.87 | backward_inner: 98.99 | backward_allreduce: 10.79 | step: 41.71
[default0]:[2023-08-25 18:10:33,531] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:10:33,531] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 108.90 | backward_inner_microstep: 97.97 | backward_allreduce_microstep: 10.84 | step_microstep: 41.47
[default0]:[2023-08-25 18:10:33,532] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:10:33,532] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 97.97 | backward_allreduce: 10.84 | step: 41.48
[default0]:[2023-08-25 18:10:33,786] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:33,786] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.40 | backward_microstep: 109.17 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.81 | step_microstep: 41.52
[default0]:[2023-08-25 18:10:33,786] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.40 (forward_moe: 19.79, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:10:33,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.17 | backward_inner: 98.27 | backward_allreduce: 10.82 | step: 41.52
[default0]:[2023-08-25 18:10:34,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:34,034] [INFO] [logging.py:96:log_dist] [Rank 0] step=835, skipped=0, lr=[9.109504e-07, 9.109504e-07, 9.109504e-07, 9.109504e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:34,034] [INFO] [timer.py:215:stop] epoch=0/micro_step=835/global_step=835, RunningAvgSamplesPerSec=4.9138547525330205, CurrSamplesPerSec=5.066875737657785, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:34,035] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.56 | backward_microstep: 109.25 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.90 | step_microstep: 42.02
[default0]:[2023-08-25 18:10:34,035] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.56 (forward_moe: 19.85, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:10:34,035] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.25 | backward_inner: 98.26 | backward_allreduce: 10.90 | step: 42.02
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.2763], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      835/439453125 | consumed samples:          835 | consumed tokens:      1710080 | elapsed time per iteration (ms): 248.9 | learning rate: 9.110E-07 | global batch size:     1 | lm loss: 9.855252E+00 | moe loss: 6.015542E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.018 | TFLOPs: 9.98 |
[default0]:[2023-08-25 18:10:34,267] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.28
[default0]:[2023-08-25 18:10:34,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.01 | backward_microstep: 109.04 | backward_inner_microstep: 98.19 | backward_allreduce_microstep: 10.75 | step_microstep: 41.46
[default0]:[2023-08-25 18:10:34,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.01 (forward_moe: 19.75, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.72)
[default0]:[2023-08-25 18:10:34,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.04 | backward_inner: 98.20 | backward_allreduce: 10.75 | step: 41.46
[default0]:[2023-08-25 18:10:34,513] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:34,514] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.67 | backward_microstep: 109.00 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.78 | step_microstep: 41.52
[default0]:[2023-08-25 18:10:34,514] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.67 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:10:34,514] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.13 | backward_allreduce: 10.79 | step: 41.53
[default0]:[2023-08-25 18:10:34,759] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:34,759] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 108.77 | backward_inner_microstep: 97.92 | backward_allreduce_microstep: 10.76 | step_microstep: 41.59
[default0]:[2023-08-25 18:10:34,759] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:10:34,759] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.78 | backward_inner: 97.92 | backward_allreduce: 10.76 | step: 41.59
[default0]:[2023-08-25 18:10:34,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:34,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 108.82 | backward_inner_microstep: 97.94 | backward_allreduce_microstep: 10.78 | step_microstep: 41.36
[default0]:[2023-08-25 18:10:34,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:10:34,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.82 | backward_inner: 97.94 | backward_allreduce: 10.79 | step: 41.36
[default0]:[2023-08-25 18:10:35,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:10:35,231] [INFO] [logging.py:96:log_dist] [Rank 0] step=840, skipped=0, lr=[9.164117333333333e-07, 9.164117333333333e-07, 9.164117333333333e-07, 9.164117333333333e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:35,232] [INFO] [timer.py:215:stop] epoch=0/micro_step=840/global_step=840, RunningAvgSamplesPerSec=4.914767614173599, CurrSamplesPerSec=5.0475523431990545, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:35,232] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.57 | backward_microstep: 109.66 | backward_inner_microstep: 98.78 | backward_allreduce_microstep: 10.78 | step_microstep: 42.35
[default0]:[2023-08-25 18:10:35,232] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.57 (forward_moe: 19.97, 1st alltoall: 0.91, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:10:35,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.66 | backward_inner: 98.79 | backward_allreduce: 10.78 | step: 42.36
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.3541], device='cuda:0'), 'moe loss': tensor([0.3013], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      840/439453125 | consumed samples:          840 | consumed tokens:      1720320 | elapsed time per iteration (ms): 239.9 | learning rate: 9.164E-07 | global batch size:     1 | lm loss: 9.870823E+00 | moe loss: 6.025510E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.168 | TFLOPs: 10.36 |
[default0]:[2023-08-25 18:10:35,487] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 10.61
[default0]:[2023-08-25 18:10:35,487] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.97 | backward_microstep: 109.39 | backward_inner_microstep: 98.52 | backward_allreduce_microstep: 10.78 | step_microstep: 46.42
[default0]:[2023-08-25 18:10:35,488] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.96 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:10:35,488] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.39 | backward_inner: 98.53 | backward_allreduce: 10.78 | step: 46.43
[default0]:[2023-08-25 18:10:35,721] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:35,721] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 109.28 | backward_inner_microstep: 98.28 | backward_allreduce_microstep: 10.91 | step_microstep: 41.45
[default0]:[2023-08-25 18:10:35,721] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.41 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:10:35,722] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.28 | backward_inner: 98.29 | backward_allreduce: 10.91 | step: 41.45
[default0]:[2023-08-25 18:10:35,963] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:35,963] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.15 | backward_microstep: 109.12 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.81 | step_microstep: 41.48
[default0]:[2023-08-25 18:10:35,963] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.15 (forward_moe: 19.88, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:10:35,964] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.22 | backward_allreduce: 10.81 | step: 41.48
[default0]:[2023-08-25 18:10:36,443] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:36,443] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.63 | backward_microstep: 109.13 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.82 | step_microstep: 41.61
[default0]:[2023-08-25 18:10:36,443] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.63 (forward_moe: 19.78, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:10:36,444] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.21 | backward_allreduce: 10.82 | step: 41.61
[default0]:[2023-08-25 18:10:36,729] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:36,729] [INFO] [logging.py:96:log_dist] [Rank 0] step=845, skipped=0, lr=[9.218730666666667e-07, 9.218730666666667e-07, 9.218730666666667e-07, 9.218730666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:36,729] [INFO] [timer.py:215:stop] epoch=0/micro_step=845/global_step=845, RunningAvgSamplesPerSec=4.915400227942726, CurrSamplesPerSec=5.077013954118934, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:36,729] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 108.87 | backward_inner_microstep: 97.98 | backward_allreduce_microstep: 10.79 | step_microstep: 41.97
[default0]:[2023-08-25 18:10:36,729] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.63 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:10:36,729] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.86 | backward_inner: 97.98 | backward_allreduce: 10.80 | step: 41.98
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.7450], device='cuda:0'), 'moe loss': tensor([0.3024], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      845/439453125 | consumed samples:          845 | consumed tokens:      1730560 | elapsed time per iteration (ms): 298.9 | learning rate: 9.219E-07 | global batch size:     1 | lm loss: 9.748996E+00 | moe loss: 6.048227E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.345 | TFLOPs: 8.31 |
[default0]:[2023-08-25 18:10:36,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.44
[default0]:[2023-08-25 18:10:36,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.09 | backward_microstep: 114.66 | backward_inner_microstep: 103.44 | backward_allreduce_microstep: 11.13 | step_microstep: 43.42
[default0]:[2023-08-25 18:10:36,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.09 (forward_moe: 20.97, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.46)
[default0]:[2023-08-25 18:10:36,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.66 | backward_inner: 103.44 | backward_allreduce: 11.13 | step: 43.42
[default0]:[2023-08-25 18:10:37,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:10:37,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.75 | backward_microstep: 111.96 | backward_inner_microstep: 100.80 | backward_allreduce_microstep: 11.07 | step_microstep: 42.35
[default0]:[2023-08-25 18:10:37,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.75 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.12)
[default0]:[2023-08-25 18:10:37,251] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.96 | backward_inner: 100.81 | backward_allreduce: 11.07 | step: 42.35
[default0]:[2023-08-25 18:10:37,513] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.44
[default0]:[2023-08-25 18:10:37,514] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 112.25 | backward_inner_microstep: 101.12 | backward_allreduce_microstep: 11.03 | step_microstep: 42.56
[default0]:[2023-08-25 18:10:37,514] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.02 (forward_moe: 20.41, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.07)
[default0]:[2023-08-25 18:10:37,514] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.25 | backward_inner: 101.13 | backward_allreduce: 11.03 | step: 42.57
[default0]:[2023-08-25 18:10:37,767] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:10:37,768] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.64 | backward_microstep: 111.83 | backward_inner_microstep: 100.76 | backward_allreduce_microstep: 10.97 | step_microstep: 42.39
[default0]:[2023-08-25 18:10:37,768] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.64 (forward_moe: 20.38, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:10:37,768] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.83 | backward_inner: 100.77 | backward_allreduce: 10.98 | step: 42.39
[default0]:[2023-08-25 18:10:38,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:10:38,033] [INFO] [logging.py:96:log_dist] [Rank 0] step=850, skipped=0, lr=[9.273344000000001e-07, 9.273344000000001e-07, 9.273344000000001e-07, 9.273344000000001e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:38,034] [INFO] [timer.py:215:stop] epoch=0/micro_step=850/global_step=850, RunningAvgSamplesPerSec=4.915475379201127, CurrSamplesPerSec=4.941893949034079, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:38,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.83 | backward_microstep: 111.97 | backward_inner_microstep: 100.88 | backward_allreduce_microstep: 10.99 | step_microstep: 43.00
[default0]:[2023-08-25 18:10:38,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.83 (forward_moe: 20.50, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.11)
[default0]:[2023-08-25 18:10:38,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.97 | backward_inner: 100.89 | backward_allreduce: 11.00 | step: 43.01
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([50.0096], device='cuda:0'), 'moe loss': tensor([0.3022], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      850/439453125 | consumed samples:          850 | consumed tokens:      1740800 | elapsed time per iteration (ms): 261.1 | learning rate: 9.273E-07 | global batch size:     1 | lm loss: 1.000192E+01 | moe loss: 6.044402E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.830 | TFLOPs: 9.52 |
[default0]:[2023-08-25 18:10:38,333] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:10:38,333] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.71 | backward_microstep: 111.99 | backward_inner_microstep: 100.93 | backward_allreduce_microstep: 10.95 | step_microstep: 42.60
[default0]:[2023-08-25 18:10:38,333] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.71 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.11)
[default0]:[2023-08-25 18:10:38,334] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.98 | backward_inner: 100.94 | backward_allreduce: 10.96 | step: 42.61
[default0]:[2023-08-25 18:10:38,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:10:38,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.91 | backward_microstep: 112.06 | backward_inner_microstep: 101.01 | backward_allreduce_microstep: 10.95 | step_microstep: 42.29
[default0]:[2023-08-25 18:10:38,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.91 (forward_moe: 20.33, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.08)
[default0]:[2023-08-25 18:10:38,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.05 | backward_inner: 101.02 | backward_allreduce: 10.95 | step: 42.30
[default0]:[2023-08-25 18:10:38,820] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:10:38,820] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 112.01 | backward_inner_microstep: 100.92 | backward_allreduce_microstep: 11.00 | step_microstep: 42.50
[default0]:[2023-08-25 18:10:38,820] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.01 (forward_moe: 20.35, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.09)
[default0]:[2023-08-25 18:10:38,821] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.01 | backward_inner: 100.92 | backward_allreduce: 11.01 | step: 42.50
[default0]:[2023-08-25 18:10:39,079] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:39,080] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 109.38 | backward_inner_microstep: 98.46 | backward_allreduce_microstep: 10.83 | step_microstep: 41.65
[default0]:[2023-08-25 18:10:39,080] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.82, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:10:39,080] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.38 | backward_inner: 98.46 | backward_allreduce: 10.83 | step: 41.65
[default0]:[2023-08-25 18:10:39,325] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:39,325] [INFO] [logging.py:96:log_dist] [Rank 0] step=855, skipped=0, lr=[9.327957333333334e-07, 9.327957333333334e-07, 9.327957333333334e-07, 9.327957333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:39,325] [INFO] [timer.py:215:stop] epoch=0/micro_step=855/global_step=855, RunningAvgSamplesPerSec=4.915835906128687, CurrSamplesPerSec=4.987299597977163, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:39,325] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.78 | backward_microstep: 112.20 | backward_inner_microstep: 101.24 | backward_allreduce_microstep: 10.86 | step_microstep: 41.98
[default0]:[2023-08-25 18:10:39,325] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.78 (forward_moe: 20.04, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.86)
[default0]:[2023-08-25 18:10:39,326] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.19 | backward_inner: 101.25 | backward_allreduce: 10.86 | step: 41.99
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.5240], device='cuda:0'), 'moe loss': tensor([0.3023], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      855/439453125 | consumed samples:          855 | consumed tokens:      1751040 | elapsed time per iteration (ms): 258.3 | learning rate: 9.328E-07 | global batch size:     1 | lm loss: 9.904803E+00 | moe loss: 6.045553E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.872 | TFLOPs: 9.62 |
[default0]:[2023-08-25 18:10:39,569] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:39,569] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 109.22 | backward_inner_microstep: 98.32 | backward_allreduce_microstep: 10.81 | step_microstep: 41.70
[default0]:[2023-08-25 18:10:39,569] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.64 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.76)
[default0]:[2023-08-25 18:10:39,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.22 | backward_inner: 98.32 | backward_allreduce: 10.81 | step: 41.70
[default0]:[2023-08-25 18:10:39,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:39,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.83 | backward_microstep: 110.13 | backward_inner_microstep: 99.19 | backward_allreduce_microstep: 10.85 | step_microstep: 41.66
[default0]:[2023-08-25 18:10:39,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.83 (forward_moe: 19.95, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:10:39,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.13 | backward_inner: 99.20 | backward_allreduce: 10.85 | step: 41.66
[default0]:[2023-08-25 18:10:40,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.33
[default0]:[2023-08-25 18:10:40,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.85 | backward_microstep: 109.56 | backward_inner_microstep: 98.54 | backward_allreduce_microstep: 10.92 | step_microstep: 41.52
[default0]:[2023-08-25 18:10:40,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.84 (forward_moe: 19.86, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:10:40,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.56 | backward_inner: 98.55 | backward_allreduce: 10.93 | step: 41.52
[default0]:[2023-08-25 18:10:40,271] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:40,271] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.96 | backward_microstep: 109.35 | backward_inner_microstep: 98.44 | backward_allreduce_microstep: 10.82 | step_microstep: 41.62
[default0]:[2023-08-25 18:10:40,271] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.96 (forward_moe: 19.79, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:10:40,271] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.35 | backward_inner: 98.44 | backward_allreduce: 10.83 | step: 41.62
[default0]:[2023-08-25 18:10:40,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:10:40,512] [INFO] [logging.py:96:log_dist] [Rank 0] step=860, skipped=0, lr=[9.382570666666667e-07, 9.382570666666667e-07, 9.382570666666667e-07, 9.382570666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:40,512] [INFO] [timer.py:215:stop] epoch=0/micro_step=860/global_step=860, RunningAvgSamplesPerSec=4.916625113497338, CurrSamplesPerSec=5.055906266386205, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:40,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.81 | backward_microstep: 109.52 | backward_inner_microstep: 98.61 | backward_allreduce_microstep: 10.81 | step_microstep: 41.91
[default0]:[2023-08-25 18:10:40,513] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.81 (forward_moe: 20.05, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:10:40,513] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.52 | backward_inner: 98.62 | backward_allreduce: 10.81 | step: 41.91
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.1479], device='cuda:0'), 'moe loss': tensor([0.3015], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      860/439453125 | consumed samples:          860 | consumed tokens:      1761280 | elapsed time per iteration (ms): 237.2 | learning rate: 9.383E-07 | global batch size:     1 | lm loss: 9.829579E+00 | moe loss: 6.030762E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.216 | TFLOPs: 10.48 |
[default0]:[2023-08-25 18:10:40,749] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.34
[default0]:[2023-08-25 18:10:40,749] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.63 | backward_microstep: 110.23 | backward_inner_microstep: 99.25 | backward_allreduce_microstep: 10.89 | step_microstep: 41.91
[default0]:[2023-08-25 18:10:40,749] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.63 (forward_moe: 20.01, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:10:40,749] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.23 | backward_inner: 99.25 | backward_allreduce: 10.89 | step: 41.91
[default0]:[2023-08-25 18:10:40,998] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.58
[default0]:[2023-08-25 18:10:40,999] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.47 | backward_microstep: 111.09 | backward_inner_microstep: 100.06 | backward_allreduce_microstep: 10.94 | step_microstep: 42.61
[default0]:[2023-08-25 18:10:40,999] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.47 (forward_moe: 20.22, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.98)
[default0]:[2023-08-25 18:10:40,999] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.09 | backward_inner: 100.07 | backward_allreduce: 10.94 | step: 42.61
[default0]:[2023-08-25 18:10:41,241] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.34
[default0]:[2023-08-25 18:10:41,241] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.35 | backward_microstep: 112.07 | backward_inner_microstep: 101.04 | backward_allreduce_microstep: 10.94 | step_microstep: 42.22
[default0]:[2023-08-25 18:10:41,241] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.35 (forward_moe: 20.44, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.10)
[default0]:[2023-08-25 18:10:41,241] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.07 | backward_inner: 101.04 | backward_allreduce: 10.95 | step: 42.23
[default0]:[2023-08-25 18:10:41,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:41,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.57 | backward_microstep: 111.61 | backward_inner_microstep: 100.59 | backward_allreduce_microstep: 10.93 | step_microstep: 42.18
[default0]:[2023-08-25 18:10:41,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.57 (forward_moe: 20.37, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.99)
[default0]:[2023-08-25 18:10:41,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.61 | backward_inner: 100.60 | backward_allreduce: 10.93 | step: 42.18
[default0]:[2023-08-25 18:10:41,742] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:10:41,743] [INFO] [logging.py:96:log_dist] [Rank 0] step=865, skipped=0, lr=[9.437184e-07, 9.437184e-07, 9.437184e-07, 9.437184e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:41,743] [INFO] [timer.py:215:stop] epoch=0/micro_step=865/global_step=865, RunningAvgSamplesPerSec=4.916983655139149, CurrSamplesPerSec=4.951783232923548, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:41,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.80 | backward_microstep: 111.69 | backward_inner_microstep: 100.55 | backward_allreduce_microstep: 11.05 | step_microstep: 42.92
[default0]:[2023-08-25 18:10:41,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.80 (forward_moe: 20.28, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.05)
[default0]:[2023-08-25 18:10:41,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.69 | backward_inner: 100.56 | backward_allreduce: 11.05 | step: 42.92
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.6786], device='cuda:0'), 'moe loss': tensor([0.3004], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      865/439453125 | consumed samples:          865 | consumed tokens:      1771520 | elapsed time per iteration (ms): 246.4 | learning rate: 9.437E-07 | global batch size:     1 | lm loss: 9.735715E+00 | moe loss: 6.008812E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.059 | TFLOPs: 10.09 |
[default0]:[2023-08-25 18:10:42,060] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.43
[default0]:[2023-08-25 18:10:42,061] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.22 | backward_microstep: 113.13 | backward_inner_microstep: 101.98 | backward_allreduce_microstep: 11.06 | step_microstep: 42.92
[default0]:[2023-08-25 18:10:42,061] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.22 (forward_moe: 20.62, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:10:42,061] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.13 | backward_inner: 101.99 | backward_allreduce: 11.06 | step: 42.92
[default0]:[2023-08-25 18:10:42,372] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:10:42,373] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.39 | backward_microstep: 114.26 | backward_inner_microstep: 103.09 | backward_allreduce_microstep: 11.07 | step_microstep: 43.58
[default0]:[2023-08-25 18:10:42,373] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.39 (forward_moe: 20.86, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.40)
[default0]:[2023-08-25 18:10:42,373] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.25 | backward_inner: 103.10 | backward_allreduce: 11.07 | step: 43.59
[default0]:[2023-08-25 18:10:42,622] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.43
[default0]:[2023-08-25 18:10:42,622] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.41 | backward_microstep: 116.33 | backward_inner_microstep: 105.13 | backward_allreduce_microstep: 11.11 | step_microstep: 43.43
[default0]:[2023-08-25 18:10:42,623] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.41 (forward_moe: 21.14, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.59)
[default0]:[2023-08-25 18:10:42,623] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.33 | backward_inner: 105.13 | backward_allreduce: 11.11 | step: 43.44
[default0]:[2023-08-25 18:10:42,878] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:10:42,878] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.16 | backward_microstep: 112.55 | backward_inner_microstep: 101.47 | backward_allreduce_microstep: 10.99 | step_microstep: 42.87
[default0]:[2023-08-25 18:10:42,878] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.16 (forward_moe: 20.60, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.19)
[default0]:[2023-08-25 18:10:42,878] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.54 | backward_inner: 101.47 | backward_allreduce: 10.99 | step: 42.88
[default0]:[2023-08-25 18:10:43,119] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.39
[default0]:[2023-08-25 18:10:43,120] [INFO] [logging.py:96:log_dist] [Rank 0] step=870, skipped=0, lr=[9.491797333333334e-07, 9.491797333333334e-07, 9.491797333333334e-07, 9.491797333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:43,120] [INFO] [timer.py:215:stop] epoch=0/micro_step=870/global_step=870, RunningAvgSamplesPerSec=4.916717567021407, CurrSamplesPerSec=4.905314641314632, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:43,120] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.34 | backward_microstep: 112.77 | backward_inner_microstep: 101.69 | backward_allreduce_microstep: 10.99 | step_microstep: 43.20
[default0]:[2023-08-25 18:10:43,120] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.34 (forward_moe: 20.68, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.22)
[default0]:[2023-08-25 18:10:43,120] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.77 | backward_inner: 101.69 | backward_allreduce: 10.99 | step: 43.20
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.8973], device='cuda:0'), 'moe loss': tensor([0.3011], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      870/439453125 | consumed samples:          870 | consumed tokens:      1781760 | elapsed time per iteration (ms): 275.6 | learning rate: 9.492E-07 | global batch size:     1 | lm loss: 9.779457E+00 | moe loss: 6.021945E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.629 | TFLOPs: 9.02 |
[default0]:[2023-08-25 18:10:43,372] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.40
[default0]:[2023-08-25 18:10:43,372] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.97 | backward_microstep: 112.68 | backward_inner_microstep: 101.59 | backward_allreduce_microstep: 11.00 | step_microstep: 42.69
[default0]:[2023-08-25 18:10:43,372] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.97 (forward_moe: 20.54, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.23)
[default0]:[2023-08-25 18:10:43,372] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.68 | backward_inner: 101.60 | backward_allreduce: 11.00 | step: 42.69
[default0]:[2023-08-25 18:10:43,615] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:10:43,616] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.17 | backward_microstep: 113.01 | backward_inner_microstep: 101.80 | backward_allreduce_microstep: 11.11 | step_microstep: 42.75
[default0]:[2023-08-25 18:10:43,616] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.17 (forward_moe: 20.52, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.18)
[default0]:[2023-08-25 18:10:43,616] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.00 | backward_inner: 101.80 | backward_allreduce: 11.12 | step: 42.75
[default0]:[2023-08-25 18:10:43,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.38
[default0]:[2023-08-25 18:10:43,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.18 | backward_microstep: 112.63 | backward_inner_microstep: 101.55 | backward_allreduce_microstep: 10.98 | step_microstep: 42.60
[default0]:[2023-08-25 18:10:43,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.18 (forward_moe: 20.52, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.20)
[default0]:[2023-08-25 18:10:43,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.63 | backward_inner: 101.56 | backward_allreduce: 10.98 | step: 42.61
[default0]:[2023-08-25 18:10:44,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.08 | optimizer_step: 6.37
[default0]:[2023-08-25 18:10:44,122] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.92 | backward_microstep: 112.18 | backward_inner_microstep: 101.10 | backward_allreduce_microstep: 10.98 | step_microstep: 42.72
[default0]:[2023-08-25 18:10:44,122] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.92 (forward_moe: 20.42, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:10:44,122] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.18 | backward_inner: 101.11 | backward_allreduce: 10.98 | step: 42.72
[default0]:[2023-08-25 18:10:44,404] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:10:44,404] [INFO] [logging.py:96:log_dist] [Rank 0] step=875, skipped=0, lr=[9.546410666666666e-07, 9.546410666666666e-07, 9.546410666666666e-07, 9.546410666666666e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:44,404] [INFO] [timer.py:215:stop] epoch=0/micro_step=875/global_step=875, RunningAvgSamplesPerSec=4.916712759049296, CurrSamplesPerSec=4.918412338058294, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:44,405] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.43 | backward_microstep: 112.18 | backward_inner_microstep: 101.13 | backward_allreduce_microstep: 10.96 | step_microstep: 43.18
[default0]:[2023-08-25 18:10:44,405] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.43 (forward_moe: 20.44, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.18)
[default0]:[2023-08-25 18:10:44,405] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.18 | backward_inner: 101.14 | backward_allreduce: 10.96 | step: 43.18
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.1721], device='cuda:0'), 'moe loss': tensor([0.3023], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      875/439453125 | consumed samples:          875 | consumed tokens:      1792000 | elapsed time per iteration (ms): 256.7 | learning rate: 9.546E-07 | global batch size:     1 | lm loss: 9.834412E+00 | moe loss: 6.045008E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.896 | TFLOPs: 9.68 |
[default0]:[2023-08-25 18:10:44,655] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:10:44,655] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.05 | backward_microstep: 112.43 | backward_inner_microstep: 101.37 | backward_allreduce_microstep: 10.97 | step_microstep: 42.70
[default0]:[2023-08-25 18:10:44,655] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.05 (forward_moe: 20.42, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:10:44,656] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.43 | backward_inner: 101.38 | backward_allreduce: 10.97 | step: 42.70
[default0]:[2023-08-25 18:10:44,939] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.01 | optimizer_step: 6.34
[default0]:[2023-08-25 18:10:44,939] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.38 | backward_microstep: 111.08 | backward_inner_microstep: 100.06 | backward_allreduce_microstep: 10.92 | step_microstep: 42.67
[default0]:[2023-08-25 18:10:44,940] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.38 (forward_moe: 20.19, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.98)
[default0]:[2023-08-25 18:10:44,940] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.08 | backward_inner: 100.07 | backward_allreduce: 10.92 | step: 42.67
[default0]:[2023-08-25 18:10:45,212] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.95 | optimizer_step: 6.34
[default0]:[2023-08-25 18:10:45,212] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.66 | backward_microstep: 111.25 | backward_inner_microstep: 100.23 | backward_allreduce_microstep: 10.93 | step_microstep: 42.19
[default0]:[2023-08-25 18:10:45,212] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.66 (forward_moe: 20.21, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 8.02)
[default0]:[2023-08-25 18:10:45,212] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.25 | backward_inner: 100.23 | backward_allreduce: 10.93 | step: 42.19
[default0]:[2023-08-25 18:10:45,451] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:10:45,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.75 | backward_microstep: 115.74 | backward_inner_microstep: 104.65 | backward_allreduce_microstep: 11.00 | step_microstep: 43.80
[default0]:[2023-08-25 18:10:45,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.75 (forward_moe: 20.36, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.17)
[default0]:[2023-08-25 18:10:45,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.74 | backward_inner: 104.66 | backward_allreduce: 11.00 | step: 43.80
[default0]:[2023-08-25 18:10:45,699] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 10.01
[default0]:[2023-08-25 18:10:45,700] [INFO] [logging.py:96:log_dist] [Rank 0] step=880, skipped=0, lr=[9.601024000000002e-07, 9.601024000000002e-07, 9.601024000000002e-07, 9.601024000000002e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:45,700] [INFO] [timer.py:215:stop] epoch=0/micro_step=880/global_step=880, RunningAvgSamplesPerSec=4.916752072995864, CurrSamplesPerSec=4.913198255554475, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:45,701] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.88 | backward_microstep: 109.20 | backward_inner_microstep: 98.28 | backward_allreduce_microstep: 10.82 | step_microstep: 45.96
[default0]:[2023-08-25 18:10:45,701] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.88 (forward_moe: 19.89, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:10:45,701] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.19 | backward_inner: 98.29 | backward_allreduce: 10.82 | step: 45.97
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.7892], device='cuda:0'), 'moe loss': tensor([0.3020], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      880/439453125 | consumed samples:          880 | consumed tokens:      1802240 | elapsed time per iteration (ms): 259.6 | learning rate: 9.601E-07 | global batch size:     1 | lm loss: 9.757842E+00 | moe loss: 6.040966E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.852 | TFLOPs: 9.57 |
[default0]:[2023-08-25 18:10:45,982] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:45,982] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.72 | backward_microstep: 109.19 | backward_inner_microstep: 98.30 | backward_allreduce_microstep: 10.80 | step_microstep: 41.55
[default0]:[2023-08-25 18:10:45,982] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.72 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:10:45,982] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.19 | backward_inner: 98.30 | backward_allreduce: 10.81 | step: 41.55
[default0]:[2023-08-25 18:10:46,221] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:10:46,222] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 109.24 | backward_inner_microstep: 98.34 | backward_allreduce_microstep: 10.81 | step_microstep: 41.46
[default0]:[2023-08-25 18:10:46,222] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.81, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:10:46,222] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.24 | backward_inner: 98.34 | backward_allreduce: 10.81 | step: 41.46
[default0]:[2023-08-25 18:10:46,507] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:10:46,508] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.51 | backward_microstep: 109.18 | backward_inner_microstep: 98.29 | backward_allreduce_microstep: 10.80 | step_microstep: 41.44
[default0]:[2023-08-25 18:10:46,508] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.51 (forward_moe: 19.78, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:10:46,508] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.18 | backward_inner: 98.29 | backward_allreduce: 10.80 | step: 41.44
[default0]:[2023-08-25 18:10:46,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:46,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 112.44 | backward_inner_microstep: 101.51 | backward_allreduce_microstep: 10.83 | step_microstep: 41.56
[default0]:[2023-08-25 18:10:46,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 20.54, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 7.92)
[default0]:[2023-08-25 18:10:46,749] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.44 | backward_inner: 101.52 | backward_allreduce: 10.84 | step: 41.56
[default0]:[2023-08-25 18:10:46,992] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.33
[default0]:[2023-08-25 18:10:46,992] [INFO] [logging.py:96:log_dist] [Rank 0] step=885, skipped=0, lr=[9.655637333333335e-07, 9.655637333333335e-07, 9.655637333333335e-07, 9.655637333333335e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:46,993] [INFO] [timer.py:215:stop] epoch=0/micro_step=885/global_step=885, RunningAvgSamplesPerSec=4.917524429182004, CurrSamplesPerSec=5.0750235946083295, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:46,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.62 | backward_microstep: 109.11 | backward_inner_microstep: 98.19 | backward_allreduce_microstep: 10.82 | step_microstep: 41.79
[default0]:[2023-08-25 18:10:46,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.89, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:10:46,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.11 | backward_inner: 98.20 | backward_allreduce: 10.82 | step: 41.80
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.6652], device='cuda:0'), 'moe loss': tensor([0.3023], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      885/439453125 | consumed samples:          885 | consumed tokens:      1812480 | elapsed time per iteration (ms): 258.1 | learning rate: 9.656E-07 | global batch size:     1 | lm loss: 9.733032E+00 | moe loss: 6.046196E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.875 | TFLOPs: 9.63 |
[default0]:[2023-08-25 18:10:47,729] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.69 | optimizer_gradients: 4.26 | optimizer_step: 6.55
[default0]:[2023-08-25 18:10:47,730] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.73 | backward_microstep: 118.47 | backward_inner_microstep: 106.61 | backward_allreduce_microstep: 11.76 | step_microstep: 46.35
[default0]:[2023-08-25 18:10:47,730] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.73 (forward_moe: 21.72, 1st alltoall: 0.91, 2nd alltoall: 0.87, top-k: 8.88)
[default0]:[2023-08-25 18:10:47,730] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 118.47 | backward_inner: 106.62 | backward_allreduce: 11.77 | step: 46.36
[default0]:[2023-08-25 18:10:47,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.17 | optimizer_step: 6.49
[default0]:[2023-08-25 18:10:47,989] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 51.52 | backward_microstep: 118.91 | backward_inner_microstep: 107.48 | backward_allreduce_microstep: 11.33 | step_microstep: 44.46
[default0]:[2023-08-25 18:10:47,989] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 51.52 (forward_moe: 21.90, 1st alltoall: 0.92, 2nd alltoall: 0.85, top-k: 8.94)
[default0]:[2023-08-25 18:10:47,989] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 118.91 | backward_inner: 107.49 | backward_allreduce: 11.33 | step: 44.46
[default0]:[2023-08-25 18:10:48,272] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.17 | optimizer_step: 6.53
[default0]:[2023-08-25 18:10:48,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.45 | backward_microstep: 117.78 | backward_inner_microstep: 106.37 | backward_allreduce_microstep: 11.32 | step_microstep: 44.50
[default0]:[2023-08-25 18:10:48,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.45 (forward_moe: 21.58, 1st alltoall: 0.92, 2nd alltoall: 0.85, top-k: 8.82)
[default0]:[2023-08-25 18:10:48,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.78 | backward_inner: 106.37 | backward_allreduce: 11.32 | step: 44.51
[default0]:[2023-08-25 18:10:48,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.35
[default0]:[2023-08-25 18:10:48,523] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.21 | backward_microstep: 112.45 | backward_inner_microstep: 101.40 | backward_allreduce_microstep: 10.95 | step_microstep: 42.69
[default0]:[2023-08-25 18:10:48,523] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.21 (forward_moe: 20.44, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.16)
[default0]:[2023-08-25 18:10:48,523] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.45 | backward_inner: 101.41 | backward_allreduce: 10.95 | step: 42.69
[default0]:[2023-08-25 18:10:48,779] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:10:48,779] [INFO] [logging.py:96:log_dist] [Rank 0] step=890, skipped=0, lr=[9.710250666666668e-07, 9.710250666666668e-07, 9.710250666666668e-07, 9.710250666666668e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:48,779] [INFO] [timer.py:215:stop] epoch=0/micro_step=890/global_step=890, RunningAvgSamplesPerSec=4.916598702776017, CurrSamplesPerSec=4.929516780179936, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:48,779] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.91 | backward_microstep: 112.49 | backward_inner_microstep: 101.39 | backward_allreduce_microstep: 11.00 | step_microstep: 42.90
[default0]:[2023-08-25 18:10:48,779] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.91 (forward_moe: 20.60, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:10:48,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.49 | backward_inner: 101.40 | backward_allreduce: 11.01 | step: 42.91
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.0579], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      890/439453125 | consumed samples:          890 | consumed tokens:      1822720 | elapsed time per iteration (ms): 357.1 | learning rate: 9.710E-07 | global batch size:     1 | lm loss: 9.811580E+00 | moe loss: 6.019750E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.800 | TFLOPs: 6.96 |
[default0]:[2023-08-25 18:10:49,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:10:49,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.13 | backward_microstep: 112.34 | backward_inner_microstep: 101.29 | backward_allreduce_microstep: 10.96 | step_microstep: 42.60
[default0]:[2023-08-25 18:10:49,030] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.13 (forward_moe: 20.45, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:10:49,031] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.34 | backward_inner: 101.29 | backward_allreduce: 10.96 | step: 42.60
[default0]:[2023-08-25 18:10:49,293] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:10:49,293] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.92 | backward_microstep: 112.29 | backward_inner_microstep: 101.22 | backward_allreduce_microstep: 10.98 | step_microstep: 42.53
[default0]:[2023-08-25 18:10:49,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.92 (forward_moe: 20.57, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:10:49,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.28 | backward_inner: 101.22 | backward_allreduce: 10.98 | step: 42.53
[default0]:[2023-08-25 18:10:49,538] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:10:49,538] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.83 | backward_microstep: 114.19 | backward_inner_microstep: 102.68 | backward_allreduce_microstep: 11.41 | step_microstep: 42.66
[default0]:[2023-08-25 18:10:49,538] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.83 (forward_moe: 20.61, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:10:49,538] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.18 | backward_inner: 102.68 | backward_allreduce: 11.41 | step: 42.66
[default0]:[2023-08-25 18:10:49,793] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:10:49,793] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.99 | backward_microstep: 113.08 | backward_inner_microstep: 101.40 | backward_allreduce_microstep: 11.58 | step_microstep: 43.96
[default0]:[2023-08-25 18:10:49,793] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.99 (forward_moe: 20.53, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:10:49,793] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.08 | backward_inner: 101.40 | backward_allreduce: 11.59 | step: 43.97
[default0]:[2023-08-25 18:10:50,049] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:10:50,049] [INFO] [logging.py:96:log_dist] [Rank 0] step=895, skipped=0, lr=[9.764864e-07, 9.764864e-07, 9.764864e-07, 9.764864e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:50,049] [INFO] [timer.py:215:stop] epoch=0/micro_step=895/global_step=895, RunningAvgSamplesPerSec=4.916470996615912, CurrSamplesPerSec=4.928474152061901, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:50,049] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.03 | backward_microstep: 112.34 | backward_inner_microstep: 101.30 | backward_allreduce_microstep: 10.95 | step_microstep: 42.98
[default0]:[2023-08-25 18:10:50,050] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.03 (forward_moe: 20.43, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:10:50,050] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.34 | backward_inner: 101.30 | backward_allreduce: 10.95 | step: 42.98
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.8455], device='cuda:0'), 'moe loss': tensor([0.3009], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      895/439453125 | consumed samples:          895 | consumed tokens:      1832960 | elapsed time per iteration (ms): 254.2 | learning rate: 9.765E-07 | global batch size:     1 | lm loss: 9.769101E+00 | moe loss: 6.017252E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.934 | TFLOPs: 9.77 |
[default0]:[2023-08-25 18:10:50,324] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:10:50,325] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.06 | backward_microstep: 112.73 | backward_inner_microstep: 101.66 | backward_allreduce_microstep: 10.98 | step_microstep: 42.97
[default0]:[2023-08-25 18:10:50,325] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.06 (forward_moe: 20.69, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:10:50,325] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.73 | backward_inner: 101.67 | backward_allreduce: 10.98 | step: 42.97
[default0]:[2023-08-25 18:10:50,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.40
[default0]:[2023-08-25 18:10:50,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.40 | backward_microstep: 113.82 | backward_inner_microstep: 102.67 | backward_allreduce_microstep: 11.06 | step_microstep: 42.96
[default0]:[2023-08-25 18:10:50,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.40 (forward_moe: 21.07, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.27)
[default0]:[2023-08-25 18:10:50,570] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.82 | backward_inner: 102.68 | backward_allreduce: 11.06 | step: 42.97
[default0]:[2023-08-25 18:10:50,814] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:10:50,814] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.72 | backward_microstep: 113.67 | backward_inner_microstep: 102.55 | backward_allreduce_microstep: 11.03 | step_microstep: 43.12
[default0]:[2023-08-25 18:10:50,814] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.72 (forward_moe: 20.77, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.32)
[default0]:[2023-08-25 18:10:50,814] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.67 | backward_inner: 102.55 | backward_allreduce: 11.03 | step: 43.13
[default0]:[2023-08-25 18:10:51,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:10:51,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.97 | backward_microstep: 115.11 | backward_inner_microstep: 103.88 | backward_allreduce_microstep: 11.14 | step_microstep: 43.28
[default0]:[2023-08-25 18:10:51,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.97 (forward_moe: 21.19, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.73)
[default0]:[2023-08-25 18:10:51,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.11 | backward_inner: 103.88 | backward_allreduce: 11.14 | step: 43.28
[default0]:[2023-08-25 18:10:51,327] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:10:51,327] [INFO] [logging.py:96:log_dist] [Rank 0] step=900, skipped=0, lr=[9.819477333333334e-07, 9.819477333333334e-07, 9.819477333333334e-07, 9.819477333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:10:51,327] [INFO] [timer.py:215:stop] epoch=0/micro_step=900/global_step=900, RunningAvgSamplesPerSec=4.916382215327573, CurrSamplesPerSec=5.02266141045845, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:10:51,327] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.11 | backward_microstep: 110.26 | backward_inner_microstep: 99.29 | backward_allreduce_microstep: 10.88 | step_microstep: 42.17
[default0]:[2023-08-25 18:10:51,328] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.10 (forward_moe: 20.27, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.97)
[default0]:[2023-08-25 18:10:51,328] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.26 | backward_inner: 99.29 | backward_allreduce: 10.89 | step: 42.18
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.5931], device='cuda:0'), 'moe loss': tensor([0.3012], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      900/439453125 | consumed samples:          900 | consumed tokens:      1843200 | elapsed time per iteration (ms): 255.4 | learning rate: 9.819E-07 | global batch size:     1 | lm loss: 9.918627E+00 | moe loss: 6.023360E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.915 | TFLOPs: 9.73 |
[default0]:-----------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 900 | lm loss value: 9.811236E+00 | lm loss PPL: 1.823752E+04 | 
[default0]:-----------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration     900 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:10:55,030] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step900 is about to be saved!
[default0]:[2023-08-25 18:10:55,032] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,042] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,043] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,052] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,052] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,060] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,061] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,069] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,079] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,079] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,088] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,088] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,097] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,097] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,106] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,107] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,116] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,116] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,125] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,125] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,134] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,134] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,143] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,144] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,152] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,152] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,161] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,161] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,170] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,170] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,179] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,179] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,188] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,188] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,197] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,197] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,206] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,206] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,214] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,215] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,224] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,224] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,233] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,233] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,244] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,244] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,253] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,254] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:10:55,255] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:10:55,256] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:10:55,256] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:10:55,541] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:10:55,543] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:10:59,233] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:10:59,240] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step900/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:10:59,241] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step900 is ready now!
[default0]:  successfully saved checkpoint at iteration     900 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.7, Latency(second): 4.214
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4213.92, 4213.92)
[default0]:[2023-08-25 18:10:59,583] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.17 | optimizer_step: 10.22
[default0]:[2023-08-25 18:10:59,585] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2268.72 | backward_microstep: 117.51 | backward_inner_microstep: 106.24 | backward_allreduce_microstep: 11.18 | step_microstep: 48.45
[default0]:[2023-08-25 18:10:59,586] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2268.59 (forward_moe: 21.49, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.77)
[default0]:[2023-08-25 18:10:59,586] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.51 | backward_inner: 106.24 | backward_allreduce: 11.18 | step: 48.45
[default0]:[2023-08-25 18:10:59,849] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.14 | optimizer_step: 6.54
[default0]:[2023-08-25 18:10:59,850] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.10 | backward_microstep: 116.57 | backward_inner_microstep: 105.39 | backward_allreduce_microstep: 11.09 | step_microstep: 43.46
[default0]:[2023-08-25 18:10:59,850] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.10 (forward_moe: 21.36, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.74)
[default0]:[2023-08-25 18:10:59,851] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.56 | backward_inner: 105.40 | backward_allreduce: 11.09 | step: 43.46
[default0]:[2023-08-25 18:11:00,134] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.14 | optimizer_step: 6.50
[default0]:[2023-08-25 18:11:00,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.06 | backward_microstep: 116.43 | backward_inner_microstep: 105.29 | backward_allreduce_microstep: 11.04 | step_microstep: 43.72
[default0]:[2023-08-25 18:11:00,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.06 (forward_moe: 21.38, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.70)
[default0]:[2023-08-25 18:11:00,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.42 | backward_inner: 105.29 | backward_allreduce: 11.05 | step: 43.73
[default0]:[2023-08-25 18:11:00,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.34
[default0]:[2023-08-25 18:11:00,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.82 | backward_microstep: 111.96 | backward_inner_microstep: 100.94 | backward_allreduce_microstep: 10.93 | step_microstep: 42.54
[default0]:[2023-08-25 18:11:00,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.82 (forward_moe: 20.31, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:11:00,378] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.96 | backward_inner: 100.95 | backward_allreduce: 10.93 | step: 42.54
[default0]:[2023-08-25 18:11:00,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:00,627] [INFO] [logging.py:96:log_dist] [Rank 0] step=905, skipped=0, lr=[9.874090666666667e-07, 9.874090666666667e-07, 9.874090666666667e-07, 9.874090666666667e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:00,627] [INFO] [timer.py:215:stop] epoch=0/micro_step=905/global_step=905, RunningAvgSamplesPerSec=4.915525636987634, CurrSamplesPerSec=4.929267667805072, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:00,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.08 | backward_microstep: 112.42 | backward_inner_microstep: 101.37 | backward_allreduce_microstep: 10.96 | step_microstep: 42.82
[default0]:[2023-08-25 18:11:00,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.08 (forward_moe: 20.66, 1st alltoall: 1.02, 2nd alltoall: 0.81, top-k: 8.22)
[default0]:[2023-08-25 18:11:00,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.42 | backward_inner: 101.38 | backward_allreduce: 10.95 | step: 42.83
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.0035], device='cuda:0'), 'moe loss': tensor([0.3023], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      905/439453125 | consumed samples:          905 | consumed tokens:      1853440 | elapsed time per iteration (ms): 1859.9 | learning rate: 9.874E-07 | global batch size:     1 | lm loss: 9.800703E+00 | moe loss: 6.046993E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.538 | TFLOPs: 1.34 |
[default0]:[2023-08-25 18:11:00,928] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.37
[default0]:[2023-08-25 18:11:00,929] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.86 | backward_microstep: 112.37 | backward_inner_microstep: 101.28 | backward_allreduce_microstep: 10.99 | step_microstep: 42.76
[default0]:[2023-08-25 18:11:00,929] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.85 (forward_moe: 20.46, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:11:00,929] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.37 | backward_inner: 101.29 | backward_allreduce: 10.99 | step: 42.76
[default0]:[2023-08-25 18:11:01,196] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:01,196] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.38 | backward_microstep: 111.91 | backward_inner_microstep: 100.63 | backward_allreduce_microstep: 11.19 | step_microstep: 42.12
[default0]:[2023-08-25 18:11:01,197] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.38 (forward_moe: 20.15, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.96)
[default0]:[2023-08-25 18:11:01,197] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.90 | backward_inner: 100.63 | backward_allreduce: 11.19 | step: 42.12
[default0]:[2023-08-25 18:11:01,434] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:01,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.36 | backward_microstep: 110.78 | backward_inner_microstep: 99.86 | backward_allreduce_microstep: 10.82 | step_microstep: 42.24
[default0]:[2023-08-25 18:11:01,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.35 (forward_moe: 20.15, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.97)
[default0]:[2023-08-25 18:11:01,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.78 | backward_inner: 99.87 | backward_allreduce: 10.82 | step: 42.24
[default0]:[2023-08-25 18:11:01,688] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.33
[default0]:[2023-08-25 18:11:01,688] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.78 | backward_microstep: 111.12 | backward_inner_microstep: 100.10 | backward_allreduce_microstep: 10.93 | step_microstep: 42.11
[default0]:[2023-08-25 18:11:01,688] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.77 (forward_moe: 20.36, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 7.94)
[default0]:[2023-08-25 18:11:01,688] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.12 | backward_inner: 100.11 | backward_allreduce: 10.93 | step: 42.12
[default0]:[2023-08-25 18:11:01,946] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:01,946] [INFO] [logging.py:96:log_dist] [Rank 0] step=910, skipped=0, lr=[9.928704e-07, 9.928704e-07, 9.928704e-07, 9.928704e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:01,946] [INFO] [timer.py:215:stop] epoch=0/micro_step=910/global_step=910, RunningAvgSamplesPerSec=4.915841071795609, CurrSamplesPerSec=4.992701946346033, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:01,946] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.51 | backward_microstep: 110.87 | backward_inner_microstep: 99.90 | backward_allreduce_microstep: 10.88 | step_microstep: 42.37
[default0]:[2023-08-25 18:11:01,946] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.50 (forward_moe: 20.22, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.94)
[default0]:[2023-08-25 18:11:01,947] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.87 | backward_inner: 99.90 | backward_allreduce: 10.88 | step: 42.38
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.9067], device='cuda:0'), 'moe loss': tensor([0.3031], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      910/439453125 | consumed samples:          910 | consumed tokens:      1863680 | elapsed time per iteration (ms): 264.2 | learning rate: 9.929E-07 | global batch size:     1 | lm loss: 9.781345E+00 | moe loss: 6.061691E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.785 | TFLOPs: 9.41 |
[default0]:[2023-08-25 18:11:02,192] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:02,192] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.58 | backward_microstep: 109.07 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.79 | step_microstep: 41.46
[default0]:[2023-08-25 18:11:02,192] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.58 (forward_moe: 19.78, 1st alltoall: 0.88, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:11:02,193] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.06 | backward_inner: 98.19 | backward_allreduce: 10.79 | step: 41.46
[default0]:[2023-08-25 18:11:02,443] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:11:02,443] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.58 | backward_microstep: 108.92 | backward_inner_microstep: 98.00 | backward_allreduce_microstep: 10.82 | step_microstep: 41.43
[default0]:[2023-08-25 18:11:02,443] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.58 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:11:02,443] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.01 | backward_allreduce: 10.82 | step: 41.44
[default0]:[2023-08-25 18:11:02,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:11:02,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.53 | backward_microstep: 110.31 | backward_inner_microstep: 99.45 | backward_allreduce_microstep: 10.77 | step_microstep: 41.58
[default0]:[2023-08-25 18:11:02,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.53 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:11:02,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.31 | backward_inner: 99.45 | backward_allreduce: 10.78 | step: 41.58
[default0]:[2023-08-25 18:11:02,989] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:02,989] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.51 | backward_microstep: 108.97 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.79 | step_microstep: 41.52
[default0]:[2023-08-25 18:11:02,990] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.51 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:11:02,990] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.97 | backward_inner: 98.09 | backward_allreduce: 10.79 | step: 41.52
[default0]:[2023-08-25 18:11:03,251] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:03,251] [INFO] [logging.py:96:log_dist] [Rank 0] step=915, skipped=0, lr=[9.983317333333334e-07, 9.983317333333334e-07, 9.983317333333334e-07, 9.983317333333334e-07], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:03,251] [INFO] [timer.py:215:stop] epoch=0/micro_step=915/global_step=915, RunningAvgSamplesPerSec=4.916660599159604, CurrSamplesPerSec=5.064544719079416, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:03,252] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 109.58 | backward_inner_microstep: 98.70 | backward_allreduce_microstep: 10.79 | step_microstep: 41.78
[default0]:[2023-08-25 18:11:03,252] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:11:03,252] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.58 | backward_inner: 98.70 | backward_allreduce: 10.79 | step: 41.78
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.9148], device='cuda:0'), 'moe loss': tensor([0.3022], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      915/439453125 | consumed samples:          915 | consumed tokens:      1873920 | elapsed time per iteration (ms): 261.0 | learning rate: 9.983E-07 | global batch size:     1 | lm loss: 9.782965E+00 | moe loss: 6.043784E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.832 | TFLOPs: 9.52 |
[default0]:[2023-08-25 18:11:03,500] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:03,500] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.50 | backward_microstep: 109.17 | backward_inner_microstep: 98.27 | backward_allreduce_microstep: 10.81 | step_microstep: 41.57
[default0]:[2023-08-25 18:11:03,500] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.50 (forward_moe: 19.78, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:11:03,501] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.17 | backward_inner: 98.27 | backward_allreduce: 10.82 | step: 41.57
[default0]:[2023-08-25 18:11:03,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.45
[default0]:[2023-08-25 18:11:03,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 111.35 | backward_inner_microstep: 100.15 | backward_allreduce_microstep: 11.11 | step_microstep: 43.45
[default0]:[2023-08-25 18:11:03,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 20.18, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.97)
[default0]:[2023-08-25 18:11:03,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.34 | backward_inner: 100.15 | backward_allreduce: 11.11 | step: 43.46
[default0]:[2023-08-25 18:11:04,102] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.48
[default0]:[2023-08-25 18:11:04,102] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.20 | backward_microstep: 115.13 | backward_inner_microstep: 103.94 | backward_allreduce_microstep: 11.09 | step_microstep: 43.53
[default0]:[2023-08-25 18:11:04,103] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.19 (forward_moe: 21.09, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.50)
[default0]:[2023-08-25 18:11:04,103] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.12 | backward_inner: 103.95 | backward_allreduce: 11.09 | step: 43.54
[default0]:[2023-08-25 18:11:04,477] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.15 | optimizer_step: 6.52
[default0]:[2023-08-25 18:11:04,477] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.56 | backward_microstep: 116.56 | backward_inner_microstep: 105.21 | backward_allreduce_microstep: 11.27 | step_microstep: 44.22
[default0]:[2023-08-25 18:11:04,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.56 (forward_moe: 21.45, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.67)
[default0]:[2023-08-25 18:11:04,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.56 | backward_inner: 105.21 | backward_allreduce: 11.27 | step: 44.23
[default0]:[2023-08-25 18:11:04,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.15 | optimizer_step: 6.51
[default0]:[2023-08-25 18:11:04,732] [INFO] [logging.py:96:log_dist] [Rank 0] step=920, skipped=0, lr=[1.0037930666666667e-06, 1.0037930666666667e-06, 1.0037930666666667e-06, 1.0037930666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:04,732] [INFO] [timer.py:215:stop] epoch=0/micro_step=920/global_step=920, RunningAvgSamplesPerSec=4.916373456555147, CurrSamplesPerSec=4.719833906296595, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:04,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.23 | backward_microstep: 117.40 | backward_inner_microstep: 106.03 | backward_allreduce_microstep: 11.27 | step_microstep: 44.69
[default0]:[2023-08-25 18:11:04,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.23 (forward_moe: 21.63, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.77)
[default0]:[2023-08-25 18:11:04,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.40 | backward_inner: 106.04 | backward_allreduce: 11.27 | step: 44.69
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.7093], device='cuda:0'), 'moe loss': tensor([0.3003], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      920/439453125 | consumed samples:          920 | consumed tokens:      1884160 | elapsed time per iteration (ms): 296.5 | learning rate: 1.004E-06 | global batch size:     1 | lm loss: 9.741859E+00 | moe loss: 6.006292E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.373 | TFLOPs: 8.38 |
[default0]:[2023-08-25 18:11:05,018] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 6.52
[default0]:[2023-08-25 18:11:05,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.18 | backward_microstep: 117.11 | backward_inner_microstep: 105.73 | backward_allreduce_microstep: 11.28 | step_microstep: 44.83
[default0]:[2023-08-25 18:11:05,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.17 (forward_moe: 21.47, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.76)
[default0]:[2023-08-25 18:11:05,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.11 | backward_inner: 105.74 | backward_allreduce: 11.29 | step: 44.83
[default0]:[2023-08-25 18:11:05,271] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.69 | optimizer_gradients: 4.23 | optimizer_step: 6.55
[default0]:[2023-08-25 18:11:05,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.87 | backward_microstep: 123.56 | backward_inner_microstep: 111.65 | backward_allreduce_microstep: 11.81 | step_microstep: 47.79
[default0]:[2023-08-25 18:11:05,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.87 (forward_moe: 22.25, 1st alltoall: 0.93, 2nd alltoall: 0.87, top-k: 8.98)
[default0]:[2023-08-25 18:11:05,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 123.56 | backward_inner: 111.65 | backward_allreduce: 11.81 | step: 47.79
[default0]:[2023-08-25 18:11:05,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.73 | optimizer_gradients: 4.18 | optimizer_step: 6.52
[default0]:[2023-08-25 18:11:05,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 51.77 | backward_microstep: 119.34 | backward_inner_microstep: 107.82 | backward_allreduce_microstep: 11.42 | step_microstep: 44.75
[default0]:[2023-08-25 18:11:05,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 51.77 (forward_moe: 21.92, 1st alltoall: 0.93, 2nd alltoall: 0.86, top-k: 8.92)
[default0]:[2023-08-25 18:11:05,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 119.34 | backward_inner: 107.83 | backward_allreduce: 11.43 | step: 44.76
[default0]:[2023-08-25 18:11:05,820] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.44
[default0]:[2023-08-25 18:11:05,820] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 52.56 | backward_microstep: 115.41 | backward_inner_microstep: 104.12 | backward_allreduce_microstep: 11.19 | step_microstep: 43.58
[default0]:[2023-08-25 18:11:05,820] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 52.56 (forward_moe: 21.29, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.64)
[default0]:[2023-08-25 18:11:05,821] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.40 | backward_inner: 104.13 | backward_allreduce: 11.19 | step: 43.58
[default0]:[2023-08-25 18:11:06,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.44
[default0]:[2023-08-25 18:11:06,089] [INFO] [logging.py:96:log_dist] [Rank 0] step=925, skipped=0, lr=[1.0092544000000002e-06, 1.0092544000000002e-06, 1.0092544000000002e-06, 1.0092544000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:06,089] [INFO] [timer.py:215:stop] epoch=0/micro_step=925/global_step=925, RunningAvgSamplesPerSec=4.914954882516966, CurrSamplesPerSec=4.807914027797679, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:06,090] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.37 | backward_microstep: 115.05 | backward_inner_microstep: 103.80 | backward_allreduce_microstep: 11.15 | step_microstep: 44.03
[default0]:[2023-08-25 18:11:06,090] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.37 (forward_moe: 21.07, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.49)
[default0]:[2023-08-25 18:11:06,090] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.05 | backward_inner: 103.81 | backward_allreduce: 11.16 | step: 44.03
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.7973], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      925/439453125 | consumed samples:          925 | consumed tokens:      1894400 | elapsed time per iteration (ms): 270.9 | learning rate: 1.009E-06 | global batch size:     1 | lm loss: 9.759452E+00 | moe loss: 6.013066E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.692 | TFLOPs: 9.17 |
[default0]:[2023-08-25 18:11:06,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.42
[default0]:[2023-08-25 18:11:06,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.23 | backward_microstep: 115.07 | backward_inner_microstep: 103.85 | backward_allreduce_microstep: 11.12 | step_microstep: 43.64
[default0]:[2023-08-25 18:11:06,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.23 (forward_moe: 21.12, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.54)
[default0]:[2023-08-25 18:11:06,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.07 | backward_inner: 103.86 | backward_allreduce: 11.12 | step: 43.64
[default0]:[2023-08-25 18:11:06,695] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.41
[default0]:[2023-08-25 18:11:06,695] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.65 | backward_microstep: 114.35 | backward_inner_microstep: 103.18 | backward_allreduce_microstep: 11.07 | step_microstep: 43.18
[default0]:[2023-08-25 18:11:06,695] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.65 (forward_moe: 20.91, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.35)
[default0]:[2023-08-25 18:11:06,695] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.35 | backward_inner: 103.19 | backward_allreduce: 11.07 | step: 43.19
[default0]:[2023-08-25 18:11:06,951] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.41
[default0]:[2023-08-25 18:11:06,951] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.77 | backward_microstep: 114.17 | backward_inner_microstep: 102.95 | backward_allreduce_microstep: 11.12 | step_microstep: 43.27
[default0]:[2023-08-25 18:11:06,951] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.77 (forward_moe: 20.93, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.40)
[default0]:[2023-08-25 18:11:06,951] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.16 | backward_inner: 102.95 | backward_allreduce: 11.13 | step: 43.27
[default0]:[2023-08-25 18:11:07,224] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.44
[default0]:[2023-08-25 18:11:07,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.77 | backward_microstep: 114.11 | backward_inner_microstep: 102.92 | backward_allreduce_microstep: 11.10 | step_microstep: 43.14
[default0]:[2023-08-25 18:11:07,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.77 (forward_moe: 20.82, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.38)
[default0]:[2023-08-25 18:11:07,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.11 | backward_inner: 102.92 | backward_allreduce: 11.10 | step: 43.15
[default0]:[2023-08-25 18:11:07,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.40
[default0]:[2023-08-25 18:11:07,478] [INFO] [logging.py:96:log_dist] [Rank 0] step=930, skipped=0, lr=[1.0147157333333335e-06, 1.0147157333333335e-06, 1.0147157333333335e-06, 1.0147157333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:07,478] [INFO] [timer.py:215:stop] epoch=0/micro_step=930/global_step=930, RunningAvgSamplesPerSec=4.9145782800301525, CurrSamplesPerSec=4.851514397913329, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:07,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.71 | backward_microstep: 114.32 | backward_inner_microstep: 103.12 | backward_allreduce_microstep: 11.10 | step_microstep: 43.54
[default0]:[2023-08-25 18:11:07,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.71 (forward_moe: 20.92, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.36)
[default0]:[2023-08-25 18:11:07,479] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.32 | backward_inner: 103.13 | backward_allreduce: 11.11 | step: 43.54
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.7444], device='cuda:0'), 'moe loss': tensor([0.3014], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      930/439453125 | consumed samples:          930 | consumed tokens:      1904640 | elapsed time per iteration (ms): 278.1 | learning rate: 1.015E-06 | global batch size:     1 | lm loss: 9.748885E+00 | moe loss: 6.028555E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.595 | TFLOPs: 8.93 |
[default0]:[2023-08-25 18:11:07,766] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:11:07,766] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.79 | backward_microstep: 114.01 | backward_inner_microstep: 102.79 | backward_allreduce_microstep: 11.13 | step_microstep: 43.24
[default0]:[2023-08-25 18:11:07,766] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.78 (forward_moe: 20.83, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.34)
[default0]:[2023-08-25 18:11:07,766] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.01 | backward_inner: 102.79 | backward_allreduce: 11.13 | step: 43.25
[default0]:[2023-08-25 18:11:08,011] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:08,011] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.13 | backward_microstep: 111.86 | backward_inner_microstep: 100.85 | backward_allreduce_microstep: 10.91 | step_microstep: 42.48
[default0]:[2023-08-25 18:11:08,011] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.13 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:11:08,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.86 | backward_inner: 100.86 | backward_allreduce: 10.92 | step: 42.48
[default0]:[2023-08-25 18:11:08,241] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.47
[default0]:[2023-08-25 18:11:08,241] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.38 | backward_microstep: 111.94 | backward_inner_microstep: 100.94 | backward_allreduce_microstep: 10.90 | step_microstep: 42.46
[default0]:[2023-08-25 18:11:08,242] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.38 (forward_moe: 20.39, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.13)
[default0]:[2023-08-25 18:11:08,242] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.93 | backward_inner: 100.94 | backward_allreduce: 10.91 | step: 42.46
[default0]:[2023-08-25 18:11:08,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:11:08,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.00 | backward_microstep: 112.07 | backward_inner_microstep: 101.04 | backward_allreduce_microstep: 10.93 | step_microstep: 42.45
[default0]:[2023-08-25 18:11:08,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.00 (forward_moe: 20.40, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.12)
[default0]:[2023-08-25 18:11:08,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.06 | backward_inner: 101.05 | backward_allreduce: 10.93 | step: 42.46
[default0]:[2023-08-25 18:11:08,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:11:08,732] [INFO] [logging.py:96:log_dist] [Rank 0] step=935, skipped=0, lr=[1.0201770666666668e-06, 1.0201770666666668e-06, 1.0201770666666668e-06, 1.0201770666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:08,732] [INFO] [timer.py:215:stop] epoch=0/micro_step=935/global_step=935, RunningAvgSamplesPerSec=4.914619092714606, CurrSamplesPerSec=4.9351952520132345, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:08,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.06 | backward_microstep: 112.20 | backward_inner_microstep: 101.13 | backward_allreduce_microstep: 10.97 | step_microstep: 42.82
[default0]:[2023-08-25 18:11:08,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.06 (forward_moe: 20.40, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 8.14)
[default0]:[2023-08-25 18:11:08,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.20 | backward_inner: 101.14 | backward_allreduce: 10.97 | step: 42.83
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.2949], device='cuda:0'), 'moe loss': tensor([0.3009], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      935/439453125 | consumed samples:          935 | consumed tokens:      1914880 | elapsed time per iteration (ms): 250.7 | learning rate: 1.020E-06 | global batch size:     1 | lm loss: 9.858974E+00 | moe loss: 6.018999E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.989 | TFLOPs: 9.91 |
[default0]:[2023-08-25 18:11:08,979] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:11:08,979] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.78 | backward_microstep: 111.93 | backward_inner_microstep: 100.94 | backward_allreduce_microstep: 10.90 | step_microstep: 42.51
[default0]:[2023-08-25 18:11:08,979] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.78 (forward_moe: 20.32, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.08)
[default0]:[2023-08-25 18:11:08,980] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.93 | backward_inner: 100.94 | backward_allreduce: 10.91 | step: 42.52
[default0]:[2023-08-25 18:11:09,230] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:09,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.66 | backward_microstep: 109.45 | backward_inner_microstep: 98.49 | backward_allreduce_microstep: 10.87 | step_microstep: 41.48
[default0]:[2023-08-25 18:11:09,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:11:09,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.45 | backward_inner: 98.50 | backward_allreduce: 10.87 | step: 41.48
[default0]:[2023-08-25 18:11:09,484] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.34
[default0]:[2023-08-25 18:11:09,485] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 109.35 | backward_inner_microstep: 98.43 | backward_allreduce_microstep: 10.82 | step_microstep: 42.26
[default0]:[2023-08-25 18:11:09,485] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.64 (forward_moe: 19.93, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:11:09,485] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.34 | backward_inner: 98.44 | backward_allreduce: 10.83 | step: 42.26
[default0]:[2023-08-25 18:11:09,742] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 9.79
[default0]:[2023-08-25 18:11:09,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.56 | backward_microstep: 110.81 | backward_inner_microstep: 99.54 | backward_allreduce_microstep: 11.17 | step_microstep: 46.02
[default0]:[2023-08-25 18:11:09,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.56 (forward_moe: 19.96, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:11:09,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.81 | backward_inner: 99.55 | backward_allreduce: 11.17 | step: 46.03
[default0]:[2023-08-25 18:11:10,004] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:10,004] [INFO] [logging.py:96:log_dist] [Rank 0] step=940, skipped=0, lr=[1.0256384000000001e-06, 1.0256384000000001e-06, 1.0256384000000001e-06, 1.0256384000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:10,004] [INFO] [timer.py:215:stop] epoch=0/micro_step=940/global_step=940, RunningAvgSamplesPerSec=4.915029991722713, CurrSamplesPerSec=5.062270832377839, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:10,004] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.69 | backward_microstep: 109.43 | backward_inner_microstep: 98.55 | backward_allreduce_microstep: 10.78 | step_microstep: 41.89
[default0]:[2023-08-25 18:11:10,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.95, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.77)
[default0]:[2023-08-25 18:11:10,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.43 | backward_inner: 98.56 | backward_allreduce: 10.79 | step: 41.90
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.6826], device='cuda:0'), 'moe loss': tensor([0.3014], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      940/439453125 | consumed samples:          940 | consumed tokens:      1925120 | elapsed time per iteration (ms): 254.2 | learning rate: 1.026E-06 | global batch size:     1 | lm loss: 9.736523E+00 | moe loss: 6.027681E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.934 | TFLOPs: 9.78 |
[default0]:[2023-08-25 18:11:10,266] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:10,267] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.50 | backward_microstep: 109.46 | backward_inner_microstep: 98.56 | backward_allreduce_microstep: 10.81 | step_microstep: 41.76
[default0]:[2023-08-25 18:11:10,267] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.50 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.76)
[default0]:[2023-08-25 18:11:10,267] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.46 | backward_inner: 98.56 | backward_allreduce: 10.81 | step: 41.76
[default0]:[2023-08-25 18:11:10,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:10,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.66 | backward_microstep: 109.26 | backward_inner_microstep: 98.36 | backward_allreduce_microstep: 10.81 | step_microstep: 41.56
[default0]:[2023-08-25 18:11:10,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.86, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.86)
[default0]:[2023-08-25 18:11:10,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.26 | backward_inner: 98.36 | backward_allreduce: 10.81 | step: 41.56
[default0]:[2023-08-25 18:11:10,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:10,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.87 | backward_microstep: 109.30 | backward_inner_microstep: 98.39 | backward_allreduce_microstep: 10.81 | step_microstep: 41.63
[default0]:[2023-08-25 18:11:10,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.87 (forward_moe: 19.87, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.76)
[default0]:[2023-08-25 18:11:10,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.30 | backward_inner: 98.39 | backward_allreduce: 10.82 | step: 41.63
[default0]:[2023-08-25 18:11:11,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:11,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.20 | backward_microstep: 110.46 | backward_inner_microstep: 99.49 | backward_allreduce_microstep: 10.88 | step_microstep: 42.48
[default0]:[2023-08-25 18:11:11,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.20 (forward_moe: 20.05, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.90)
[default0]:[2023-08-25 18:11:11,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.46 | backward_inner: 99.49 | backward_allreduce: 10.88 | step: 42.48
[default0]:[2023-08-25 18:11:11,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:11:11,308] [INFO] [logging.py:96:log_dist] [Rank 0] step=945, skipped=0, lr=[1.0310997333333332e-06, 1.0310997333333332e-06, 1.0310997333333332e-06, 1.0310997333333332e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:11,308] [INFO] [timer.py:215:stop] epoch=0/micro_step=945/global_step=945, RunningAvgSamplesPerSec=4.915626468388595, CurrSamplesPerSec=4.958872949026859, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:11,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.91 | backward_microstep: 111.47 | backward_inner_microstep: 100.40 | backward_allreduce_microstep: 10.97 | step_microstep: 42.73
[default0]:[2023-08-25 18:11:11,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.91 (forward_moe: 20.16, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.95)
[default0]:[2023-08-25 18:11:11,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.47 | backward_inner: 100.41 | backward_allreduce: 10.97 | step: 42.73
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.5919], device='cuda:0'), 'moe loss': tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      945/439453125 | consumed samples:          945 | consumed tokens:      1935360 | elapsed time per iteration (ms): 260.6 | learning rate: 1.031E-06 | global batch size:     1 | lm loss: 9.718375E+00 | moe loss: 6.010649E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.837 | TFLOPs: 9.53 |
[default0]:[2023-08-25 18:11:11,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:11:11,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.58 | backward_microstep: 111.95 | backward_inner_microstep: 100.88 | backward_allreduce_microstep: 10.98 | step_microstep: 42.59
[default0]:[2023-08-25 18:11:11,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.58 (forward_moe: 20.41, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.09)
[default0]:[2023-08-25 18:11:11,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.95 | backward_inner: 100.88 | backward_allreduce: 10.98 | step: 42.60
[default0]:[2023-08-25 18:11:11,796] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:11:11,796] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.19 | backward_microstep: 112.50 | backward_inner_microstep: 101.40 | backward_allreduce_microstep: 11.01 | step_microstep: 42.75
[default0]:[2023-08-25 18:11:11,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.19 (forward_moe: 20.67, 1st alltoall: 0.87, 2nd alltoall: 0.90, top-k: 8.14)
[default0]:[2023-08-25 18:11:11,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.50 | backward_inner: 101.41 | backward_allreduce: 11.01 | step: 42.76
[default0]:[2023-08-25 18:11:12,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:12,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.17 | backward_microstep: 109.60 | backward_inner_microstep: 98.65 | backward_allreduce_microstep: 10.86 | step_microstep: 41.54
[default0]:[2023-08-25 18:11:12,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.16 (forward_moe: 19.88, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:11:12,039] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.60 | backward_inner: 98.66 | backward_allreduce: 10.86 | step: 41.55
[default0]:[2023-08-25 18:11:12,291] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 6.35
[default0]:[2023-08-25 18:11:12,291] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.79 | backward_microstep: 109.82 | backward_inner_microstep: 98.86 | backward_allreduce_microstep: 10.86 | step_microstep: 41.74
[default0]:[2023-08-25 18:11:12,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.79 (forward_moe: 19.92, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:11:12,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.82 | backward_inner: 98.87 | backward_allreduce: 10.87 | step: 41.75
[default0]:[2023-08-25 18:11:12,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:12,745] [INFO] [logging.py:96:log_dist] [Rank 0] step=950, skipped=0, lr=[1.0365610666666666e-06, 1.0365610666666666e-06, 1.0365610666666666e-06, 1.0365610666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:12,745] [INFO] [timer.py:215:stop] epoch=0/micro_step=950/global_step=950, RunningAvgSamplesPerSec=4.9160338649857245, CurrSamplesPerSec=5.0085607461904145, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:12,745] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.23 | backward_microstep: 109.84 | backward_inner_microstep: 98.90 | backward_allreduce_microstep: 10.85 | step_microstep: 42.03
[default0]:[2023-08-25 18:11:12,745] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.23 (forward_moe: 20.16, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.79)
[default0]:[2023-08-25 18:11:12,745] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.84 | backward_inner: 98.91 | backward_allreduce: 10.85 | step: 42.03
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.9662], device='cuda:0'), 'moe loss': tensor([0.3013], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      950/439453125 | consumed samples:          950 | consumed tokens:      1945600 | elapsed time per iteration (ms): 287.4 | learning rate: 1.037E-06 | global batch size:     1 | lm loss: 9.793245E+00 | moe loss: 6.025348E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.480 | TFLOPs: 8.65 |
[default0]:[2023-08-25 18:11:12,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:12,989] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.85 | backward_microstep: 109.80 | backward_inner_microstep: 98.82 | backward_allreduce_microstep: 10.89 | step_microstep: 41.68
[default0]:[2023-08-25 18:11:12,989] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.85 (forward_moe: 19.89, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:11:12,989] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.80 | backward_inner: 98.83 | backward_allreduce: 10.89 | step: 41.69
[default0]:[2023-08-25 18:11:13,242] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.33
[default0]:[2023-08-25 18:11:13,242] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 110.48 | backward_inner_microstep: 99.36 | backward_allreduce_microstep: 11.02 | step_microstep: 41.93
[default0]:[2023-08-25 18:11:13,242] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.70 (forward_moe: 19.90, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:11:13,242] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.47 | backward_inner: 99.37 | backward_allreduce: 11.02 | step: 41.93
[default0]:[2023-08-25 18:11:13,494] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:13,495] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.18 | backward_microstep: 109.60 | backward_inner_microstep: 98.68 | backward_allreduce_microstep: 10.83 | step_microstep: 42.08
[default0]:[2023-08-25 18:11:13,495] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.18 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:11:13,495] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.60 | backward_inner: 98.69 | backward_allreduce: 10.83 | step: 42.08
[default0]:[2023-08-25 18:11:13,750] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.36
[default0]:[2023-08-25 18:11:13,751] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.69 | backward_microstep: 111.32 | backward_inner_microstep: 100.29 | backward_allreduce_microstep: 10.94 | step_microstep: 42.38
[default0]:[2023-08-25 18:11:13,751] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 20.21, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.03)
[default0]:[2023-08-25 18:11:13,751] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.32 | backward_inner: 100.29 | backward_allreduce: 10.94 | step: 42.38
[default0]:[2023-08-25 18:11:13,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:11:13,993] [INFO] [logging.py:96:log_dist] [Rank 0] step=955, skipped=0, lr=[1.0420224e-06, 1.0420224e-06, 1.0420224e-06, 1.0420224e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:13,994] [INFO] [timer.py:215:stop] epoch=0/micro_step=955/global_step=955, RunningAvgSamplesPerSec=4.916519349724781, CurrSamplesPerSec=4.950777914568089, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:13,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.76 | backward_microstep: 111.96 | backward_inner_microstep: 100.93 | backward_allreduce_microstep: 10.94 | step_microstep: 42.73
[default0]:[2023-08-25 18:11:13,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.76 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.11)
[default0]:[2023-08-25 18:11:13,994] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.96 | backward_inner: 100.93 | backward_allreduce: 10.94 | step: 42.73
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.0743], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      955/439453125 | consumed samples:          955 | consumed tokens:      1955840 | elapsed time per iteration (ms): 250.3 | learning rate: 1.042E-06 | global batch size:     1 | lm loss: 9.814858E+00 | moe loss: 6.019195E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.996 | TFLOPs: 9.93 |
[default0]:[2023-08-25 18:11:14,247] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:14,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.98 | backward_microstep: 111.91 | backward_inner_microstep: 100.87 | backward_allreduce_microstep: 10.94 | step_microstep: 42.82
[default0]:[2023-08-25 18:11:14,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.98 (forward_moe: 20.37, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.10)
[default0]:[2023-08-25 18:11:14,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.91 | backward_inner: 100.88 | backward_allreduce: 10.95 | step: 42.83
[default0]:[2023-08-25 18:11:14,528] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:14,528] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.92 | backward_microstep: 112.75 | backward_inner_microstep: 101.63 | backward_allreduce_microstep: 11.02 | step_microstep: 42.87
[default0]:[2023-08-25 18:11:14,528] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.91 (forward_moe: 20.56, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.23)
[default0]:[2023-08-25 18:11:14,528] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.74 | backward_inner: 101.63 | backward_allreduce: 11.03 | step: 42.88
[default0]:[2023-08-25 18:11:14,799] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.40
[default0]:[2023-08-25 18:11:14,799] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.51 | backward_microstep: 113.56 | backward_inner_microstep: 102.37 | backward_allreduce_microstep: 11.10 | step_microstep: 43.23
[default0]:[2023-08-25 18:11:14,799] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.51 (forward_moe: 20.76, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.30)
[default0]:[2023-08-25 18:11:14,799] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.56 | backward_inner: 102.38 | backward_allreduce: 11.10 | step: 43.23
[default0]:[2023-08-25 18:11:15,056] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.40
[default0]:[2023-08-25 18:11:15,057] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.60 | backward_microstep: 113.22 | backward_inner_microstep: 102.14 | backward_allreduce_microstep: 10.98 | step_microstep: 42.73
[default0]:[2023-08-25 18:11:15,057] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.60 (forward_moe: 20.67, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.27)
[default0]:[2023-08-25 18:11:15,057] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.21 | backward_inner: 102.15 | backward_allreduce: 10.98 | step: 42.73
[default0]:[2023-08-25 18:11:15,331] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.40
[default0]:[2023-08-25 18:11:15,331] [INFO] [logging.py:96:log_dist] [Rank 0] step=960, skipped=0, lr=[1.0474837333333334e-06, 1.0474837333333334e-06, 1.0474837333333334e-06, 1.0474837333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:15,332] [INFO] [timer.py:215:stop] epoch=0/micro_step=960/global_step=960, RunningAvgSamplesPerSec=4.9163805804471625, CurrSamplesPerSec=4.828792900784363, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:15,332] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.19 | backward_microstep: 115.94 | backward_inner_microstep: 104.81 | backward_allreduce_microstep: 11.04 | step_microstep: 43.42
[default0]:[2023-08-25 18:11:15,332] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.18 (forward_moe: 20.86, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.26)
[default0]:[2023-08-25 18:11:15,332] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.94 | backward_inner: 104.82 | backward_allreduce: 11.04 | step: 43.42
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.7060], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      960/439453125 | consumed samples:          960 | consumed tokens:      1966080 | elapsed time per iteration (ms): 267.5 | learning rate: 1.047E-06 | global batch size:     1 | lm loss: 9.741202E+00 | moe loss: 6.015358E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.739 | TFLOPs: 9.29 |
[default0]:[2023-08-25 18:11:15,603] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.07 | optimizer_step: 6.37
[default0]:[2023-08-25 18:11:15,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.77 | backward_microstep: 113.20 | backward_inner_microstep: 102.04 | backward_allreduce_microstep: 11.07 | step_microstep: 42.86
[default0]:[2023-08-25 18:11:15,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.77 (forward_moe: 20.60, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:11:15,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.20 | backward_inner: 102.05 | backward_allreduce: 11.07 | step: 42.86
[default0]:[2023-08-25 18:11:15,846] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.40
[default0]:[2023-08-25 18:11:15,847] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.89 | backward_microstep: 114.23 | backward_inner_microstep: 103.15 | backward_allreduce_microstep: 10.98 | step_microstep: 43.38
[default0]:[2023-08-25 18:11:15,847] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.89 (forward_moe: 20.50, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.19)
[default0]:[2023-08-25 18:11:15,847] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.23 | backward_inner: 103.16 | backward_allreduce: 10.99 | step: 43.39
[default0]:[2023-08-25 18:11:16,329] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.37
[default0]:[2023-08-25 18:11:16,329] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.13 | backward_microstep: 112.71 | backward_inner_microstep: 101.53 | backward_allreduce_microstep: 11.08 | step_microstep: 42.73
[default0]:[2023-08-25 18:11:16,329] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.13 (forward_moe: 20.51, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.20)
[default0]:[2023-08-25 18:11:16,330] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.70 | backward_inner: 101.54 | backward_allreduce: 11.08 | step: 42.73
[default0]:[2023-08-25 18:11:16,596] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:11:16,596] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.99 | backward_microstep: 112.73 | backward_inner_microstep: 101.64 | backward_allreduce_microstep: 10.99 | step_microstep: 43.00
[default0]:[2023-08-25 18:11:16,597] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.99 (forward_moe: 20.59, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.23)
[default0]:[2023-08-25 18:11:16,597] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.73 | backward_inner: 101.65 | backward_allreduce: 10.99 | step: 43.01
[default0]:[2023-08-25 18:11:16,873] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:11:16,873] [INFO] [logging.py:96:log_dist] [Rank 0] step=965, skipped=0, lr=[1.0529450666666667e-06, 1.0529450666666667e-06, 1.0529450666666667e-06, 1.0529450666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:16,873] [INFO] [timer.py:215:stop] epoch=0/micro_step=965/global_step=965, RunningAvgSamplesPerSec=4.916287062047356, CurrSamplesPerSec=4.905555601039051, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:16,874] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.27 | backward_microstep: 112.78 | backward_inner_microstep: 101.69 | backward_allreduce_microstep: 11.00 | step_microstep: 43.24
[default0]:[2023-08-25 18:11:16,874] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.26 (forward_moe: 20.68, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.34)
[default0]:[2023-08-25 18:11:16,874] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.78 | backward_inner: 101.70 | backward_allreduce: 11.00 | step: 43.24
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.9818], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      965/439453125 | consumed samples:          965 | consumed tokens:      1976320 | elapsed time per iteration (ms): 308.0 | learning rate: 1.053E-06 | global batch size:     1 | lm loss: 9.796359E+00 | moe loss: 6.016675E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.247 | TFLOPs: 8.07 |
[default0]:[2023-08-25 18:11:17,127] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:11:17,127] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.49 | backward_microstep: 112.95 | backward_inner_microstep: 101.81 | backward_allreduce_microstep: 11.04 | step_microstep: 42.74
[default0]:[2023-08-25 18:11:17,127] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.49 (forward_moe: 20.57, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:11:17,127] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.95 | backward_inner: 101.82 | backward_allreduce: 11.05 | step: 42.75
[default0]:[2023-08-25 18:11:17,373] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.37
[default0]:[2023-08-25 18:11:17,373] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.08 | backward_microstep: 112.84 | backward_inner_microstep: 101.75 | backward_allreduce_microstep: 10.99 | step_microstep: 42.64
[default0]:[2023-08-25 18:11:17,373] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.08 (forward_moe: 20.54, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.24)
[default0]:[2023-08-25 18:11:17,374] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.84 | backward_inner: 101.76 | backward_allreduce: 11.00 | step: 42.65
[default0]:[2023-08-25 18:11:17,647] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.44
[default0]:[2023-08-25 18:11:17,648] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.41 | backward_microstep: 117.19 | backward_inner_microstep: 105.86 | backward_allreduce_microstep: 11.23 | step_microstep: 44.04
[default0]:[2023-08-25 18:11:17,648] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.41 (forward_moe: 22.54, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 9.94)
[default0]:[2023-08-25 18:11:17,648] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.18 | backward_inner: 105.87 | backward_allreduce: 11.23 | step: 44.04
[default0]:[2023-08-25 18:11:17,891] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:17,891] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.01 | backward_microstep: 112.32 | backward_inner_microstep: 101.26 | backward_allreduce_microstep: 10.96 | step_microstep: 42.87
[default0]:[2023-08-25 18:11:17,892] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.01 (forward_moe: 20.50, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.13)
[default0]:[2023-08-25 18:11:17,892] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.31 | backward_inner: 101.26 | backward_allreduce: 10.97 | step: 42.88
[default0]:[2023-08-25 18:11:18,210] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:11:18,210] [INFO] [logging.py:96:log_dist] [Rank 0] step=970, skipped=0, lr=[1.0584064e-06, 1.0584064e-06, 1.0584064e-06, 1.0584064e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:18,211] [INFO] [timer.py:215:stop] epoch=0/micro_step=970/global_step=970, RunningAvgSamplesPerSec=4.916118479037571, CurrSamplesPerSec=4.9284857343957285, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:18,211] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.97 | backward_microstep: 112.40 | backward_inner_microstep: 101.34 | backward_allreduce_microstep: 10.97 | step_microstep: 42.99
[default0]:[2023-08-25 18:11:18,211] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.97 (forward_moe: 20.58, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.16)
[default0]:[2023-08-25 18:11:18,211] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.40 | backward_inner: 101.34 | backward_allreduce: 10.97 | step: 42.99
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.7830], device='cuda:0'), 'moe loss': tensor([0.3014], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      970/439453125 | consumed samples:          970 | consumed tokens:      1986560 | elapsed time per iteration (ms): 267.7 | learning rate: 1.058E-06 | global batch size:     1 | lm loss: 9.756606E+00 | moe loss: 6.027259E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.736 | TFLOPs: 9.28 |
[default0]:[2023-08-25 18:11:18,452] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:11:18,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 112.62 | backward_inner_microstep: 101.44 | backward_allreduce_microstep: 11.08 | step_microstep: 42.51
[default0]:[2023-08-25 18:11:18,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.02 (forward_moe: 20.70, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.18)
[default0]:[2023-08-25 18:11:18,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.62 | backward_inner: 101.45 | backward_allreduce: 11.08 | step: 42.51
[default0]:[2023-08-25 18:11:18,686] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.34
[default0]:[2023-08-25 18:11:18,686] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.86 | backward_microstep: 111.72 | backward_inner_microstep: 100.70 | backward_allreduce_microstep: 10.93 | step_microstep: 42.39
[default0]:[2023-08-25 18:11:18,686] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.86 (forward_moe: 20.39, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:11:18,686] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.72 | backward_inner: 100.70 | backward_allreduce: 10.93 | step: 42.39
[default0]:[2023-08-25 18:11:18,918] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:11:18,918] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.14 | backward_microstep: 111.41 | backward_inner_microstep: 100.40 | backward_allreduce_microstep: 10.91 | step_microstep: 42.26
[default0]:[2023-08-25 18:11:18,918] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.14 (forward_moe: 20.37, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.07)
[default0]:[2023-08-25 18:11:18,919] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.41 | backward_inner: 100.41 | backward_allreduce: 10.91 | step: 42.26
[default0]:[2023-08-25 18:11:19,163] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:11:19,163] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.73 | backward_microstep: 111.33 | backward_inner_microstep: 100.32 | backward_allreduce_microstep: 10.91 | step_microstep: 42.30
[default0]:[2023-08-25 18:11:19,164] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.73 (forward_moe: 20.24, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.01)
[default0]:[2023-08-25 18:11:19,164] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.33 | backward_inner: 100.33 | backward_allreduce: 10.92 | step: 42.30
[default0]:[2023-08-25 18:11:19,400] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:11:19,401] [INFO] [logging.py:96:log_dist] [Rank 0] step=975, skipped=0, lr=[1.0638677333333333e-06, 1.0638677333333333e-06, 1.0638677333333333e-06, 1.0638677333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:19,401] [INFO] [timer.py:215:stop] epoch=0/micro_step=975/global_step=975, RunningAvgSamplesPerSec=4.916312916599367, CurrSamplesPerSec=4.959025386856343, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:19,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.84 | backward_microstep: 111.57 | backward_inner_microstep: 100.57 | backward_allreduce_microstep: 10.91 | step_microstep: 42.70
[default0]:[2023-08-25 18:11:19,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.84 (forward_moe: 20.43, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.12)
[default0]:[2023-08-25 18:11:19,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.57 | backward_inner: 100.57 | backward_allreduce: 10.91 | step: 42.70
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.5086], device='cuda:0'), 'moe loss': tensor([0.3009], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      975/439453125 | consumed samples:          975 | consumed tokens:      1996800 | elapsed time per iteration (ms): 238.1 | learning rate: 1.064E-06 | global batch size:     1 | lm loss: 9.701726E+00 | moe loss: 6.018480E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.200 | TFLOPs: 10.44 |
[default0]:[2023-08-25 18:11:19,660] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.77 | optimizer_gradients: 4.04 | optimizer_step: 6.36
[default0]:[2023-08-25 18:11:19,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.56 | backward_microstep: 114.31 | backward_inner_microstep: 103.27 | backward_allreduce_microstep: 10.95 | step_microstep: 43.38
[default0]:[2023-08-25 18:11:19,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.56 (forward_moe: 20.24, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 8.01)
[default0]:[2023-08-25 18:11:19,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.31 | backward_inner: 103.27 | backward_allreduce: 10.96 | step: 43.39
[default0]:[2023-08-25 18:11:19,926] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.03 | optimizer_step: 9.70
[default0]:[2023-08-25 18:11:19,926] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.51 | backward_microstep: 116.42 | backward_inner_microstep: 104.89 | backward_allreduce_microstep: 11.43 | step_microstep: 47.29
[default0]:[2023-08-25 18:11:19,927] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.51 (forward_moe: 21.26, 1st alltoall: 0.92, 2nd alltoall: 0.84, top-k: 8.33)
[default0]:[2023-08-25 18:11:19,927] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.42 | backward_inner: 104.90 | backward_allreduce: 11.44 | step: 47.29
[default0]:[2023-08-25 18:11:20,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.44
[default0]:[2023-08-25 18:11:20,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.52 | backward_microstep: 112.54 | backward_inner_microstep: 101.46 | backward_allreduce_microstep: 10.98 | step_microstep: 42.33
[default0]:[2023-08-25 18:11:20,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.52 (forward_moe: 20.54, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.09)
[default0]:[2023-08-25 18:11:20,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.54 | backward_inner: 101.47 | backward_allreduce: 10.98 | step: 42.33
[default0]:[2023-08-25 18:11:20,414] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:20,414] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.63 | backward_microstep: 113.48 | backward_inner_microstep: 102.34 | backward_allreduce_microstep: 11.05 | step_microstep: 42.85
[default0]:[2023-08-25 18:11:20,414] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.63 (forward_moe: 20.80, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.24)
[default0]:[2023-08-25 18:11:20,414] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.48 | backward_inner: 102.34 | backward_allreduce: 11.05 | step: 42.86
[default0]:[2023-08-25 18:11:20,656] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:20,656] [INFO] [logging.py:96:log_dist] [Rank 0] step=980, skipped=0, lr=[1.0693290666666667e-06, 1.0693290666666667e-06, 1.0693290666666667e-06, 1.0693290666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:20,657] [INFO] [timer.py:215:stop] epoch=0/micro_step=980/global_step=980, RunningAvgSamplesPerSec=4.916027423682054, CurrSamplesPerSec=4.892423475398516, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:20,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.48 | backward_microstep: 113.18 | backward_inner_microstep: 102.09 | backward_allreduce_microstep: 11.00 | step_microstep: 43.19
[default0]:[2023-08-25 18:11:20,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.48 (forward_moe: 20.84, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.23)
[default0]:[2023-08-25 18:11:20,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.18 | backward_inner: 102.09 | backward_allreduce: 11.01 | step: 43.19
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.8479], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      980/439453125 | consumed samples:          980 | consumed tokens:      2007040 | elapsed time per iteration (ms): 251.2 | learning rate: 1.069E-06 | global batch size:     1 | lm loss: 9.769570E+00 | moe loss: 6.016777E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.981 | TFLOPs: 9.89 |
[default0]:[2023-08-25 18:11:20,911] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:20,911] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 109.41 | backward_inner_microstep: 98.48 | backward_allreduce_microstep: 10.84 | step_microstep: 41.52
[default0]:[2023-08-25 18:11:20,911] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.79, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:11:20,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.41 | backward_inner: 98.48 | backward_allreduce: 10.84 | step: 41.52
[default0]:[2023-08-25 18:11:21,152] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.33
[default0]:[2023-08-25 18:11:21,153] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.88 | backward_microstep: 109.83 | backward_inner_microstep: 98.92 | backward_allreduce_microstep: 10.81 | step_microstep: 42.16
[default0]:[2023-08-25 18:11:21,153] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.87 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:11:21,153] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.82 | backward_inner: 98.92 | backward_allreduce: 10.82 | step: 42.17
[default0]:[2023-08-25 18:11:21,396] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.37
[default0]:[2023-08-25 18:11:21,396] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.62 | backward_microstep: 109.44 | backward_inner_microstep: 98.57 | backward_allreduce_microstep: 10.78 | step_microstep: 41.61
[default0]:[2023-08-25 18:11:21,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.86, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.76)
[default0]:[2023-08-25 18:11:21,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.44 | backward_inner: 98.58 | backward_allreduce: 10.78 | step: 41.62
[default0]:[2023-08-25 18:11:21,631] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:21,632] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.93 | backward_microstep: 109.71 | backward_inner_microstep: 98.77 | backward_allreduce_microstep: 10.84 | step_microstep: 42.02
[default0]:[2023-08-25 18:11:21,632] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.93 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.76)
[default0]:[2023-08-25 18:11:21,632] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.71 | backward_inner: 98.78 | backward_allreduce: 10.84 | step: 42.02
[default0]:[2023-08-25 18:11:21,898] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:21,898] [INFO] [logging.py:96:log_dist] [Rank 0] step=985, skipped=0, lr=[1.0747904e-06, 1.0747904e-06, 1.0747904e-06, 1.0747904e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:21,899] [INFO] [timer.py:215:stop] epoch=0/micro_step=985/global_step=985, RunningAvgSamplesPerSec=4.916706210189594, CurrSamplesPerSec=5.063609244219948, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:21,899] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.65 | backward_microstep: 109.33 | backward_inner_microstep: 98.45 | backward_allreduce_microstep: 10.79 | step_microstep: 41.94
[default0]:[2023-08-25 18:11:21,899] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.65 (forward_moe: 19.86, 1st alltoall: 0.90, 2nd alltoall: 0.79, top-k: 7.77)
[default0]:[2023-08-25 18:11:21,899] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.33 | backward_inner: 98.45 | backward_allreduce: 10.79 | step: 41.95
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.4548], device='cuda:0'), 'moe loss': tensor([0.3016], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      985/439453125 | consumed samples:          985 | consumed tokens:      2017280 | elapsed time per iteration (ms): 248.2 | learning rate: 1.075E-06 | global batch size:     1 | lm loss: 9.690951E+00 | moe loss: 6.031542E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.028 | TFLOPs: 10.01 |
[default0]:[2023-08-25 18:11:22,156] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:22,157] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 109.59 | backward_inner_microstep: 98.65 | backward_allreduce_microstep: 10.84 | step_microstep: 42.35
[default0]:[2023-08-25 18:11:22,157] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.90, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:11:22,157] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.58 | backward_inner: 98.66 | backward_allreduce: 10.85 | step: 42.36
[default0]:[2023-08-25 18:11:22,396] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:22,396] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.95 | backward_microstep: 109.59 | backward_inner_microstep: 98.67 | backward_allreduce_microstep: 10.82 | step_microstep: 41.66
[default0]:[2023-08-25 18:11:22,396] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.95 (forward_moe: 19.86, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:11:22,396] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.59 | backward_inner: 98.68 | backward_allreduce: 10.82 | step: 41.66
[default0]:[2023-08-25 18:11:22,683] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:22,683] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.08 | backward_microstep: 114.24 | backward_inner_microstep: 103.18 | backward_allreduce_microstep: 10.96 | step_microstep: 42.92
[default0]:[2023-08-25 18:11:22,683] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.08 (forward_moe: 20.56, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.23)
[default0]:[2023-08-25 18:11:22,684] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.24 | backward_inner: 103.19 | backward_allreduce: 10.96 | step: 42.92
[default0]:[2023-08-25 18:11:22,932] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.37
[default0]:[2023-08-25 18:11:22,932] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.19 | backward_microstep: 112.79 | backward_inner_microstep: 101.58 | backward_allreduce_microstep: 11.12 | step_microstep: 42.70
[default0]:[2023-08-25 18:11:22,932] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.19 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:11:22,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.79 | backward_inner: 101.59 | backward_allreduce: 11.12 | step: 42.71
[default0]:[2023-08-25 18:11:23,222] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:11:23,222] [INFO] [logging.py:96:log_dist] [Rank 0] step=990, skipped=0, lr=[1.0802517333333333e-06, 1.0802517333333333e-06, 1.0802517333333333e-06, 1.0802517333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:23,223] [INFO] [timer.py:215:stop] epoch=0/micro_step=990/global_step=990, RunningAvgSamplesPerSec=4.9168418003652254, CurrSamplesPerSec=4.8444427504368806, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:23,223] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.20 | backward_microstep: 114.26 | backward_inner_microstep: 103.03 | backward_allreduce_microstep: 11.14 | step_microstep: 44.40
[default0]:[2023-08-25 18:11:23,223] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.21 (forward_moe: 21.00, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.35)
[default0]:[2023-08-25 18:11:23,223] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.26 | backward_inner: 103.03 | backward_allreduce: 11.14 | step: 44.41
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.9837], device='cuda:0'), 'moe loss': tensor([0.3006], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      990/439453125 | consumed samples:          990 | consumed tokens:      2027520 | elapsed time per iteration (ms): 267.2 | learning rate: 1.080E-06 | global batch size:     1 | lm loss: 9.596741E+00 | moe loss: 6.012803E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.742 | TFLOPs: 9.30 |
[default0]:[2023-08-25 18:11:23,491] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.44
[default0]:[2023-08-25 18:11:23,492] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.78 | backward_microstep: 114.82 | backward_inner_microstep: 103.63 | backward_allreduce_microstep: 11.09 | step_microstep: 43.51
[default0]:[2023-08-25 18:11:23,492] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.78 (forward_moe: 20.90, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.43)
[default0]:[2023-08-25 18:11:23,492] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.82 | backward_inner: 103.64 | backward_allreduce: 11.10 | step: 43.51
[default0]:[2023-08-25 18:11:23,770] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:11:23,770] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.85 | backward_microstep: 114.64 | backward_inner_microstep: 103.43 | backward_allreduce_microstep: 11.11 | step_microstep: 43.35
[default0]:[2023-08-25 18:11:23,770] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.85 (forward_moe: 21.16, 1st alltoall: 0.89, 2nd alltoall: 0.95, top-k: 8.54)
[default0]:[2023-08-25 18:11:23,771] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.63 | backward_inner: 103.44 | backward_allreduce: 11.11 | step: 43.35
[default0]:[2023-08-25 18:11:24,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.43
[default0]:[2023-08-25 18:11:24,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.19 | backward_microstep: 114.61 | backward_inner_microstep: 103.40 | backward_allreduce_microstep: 11.11 | step_microstep: 43.40
[default0]:[2023-08-25 18:11:24,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.19 (forward_moe: 20.95, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.43)
[default0]:[2023-08-25 18:11:24,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.61 | backward_inner: 103.41 | backward_allreduce: 11.12 | step: 43.40
[default0]:[2023-08-25 18:11:24,337] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.41
[default0]:[2023-08-25 18:11:24,338] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.94 | backward_microstep: 114.55 | backward_inner_microstep: 103.35 | backward_allreduce_microstep: 11.11 | step_microstep: 43.27
[default0]:[2023-08-25 18:11:24,338] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.94 (forward_moe: 20.93, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.43)
[default0]:[2023-08-25 18:11:24,338] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.55 | backward_inner: 103.36 | backward_allreduce: 11.11 | step: 43.28
[default0]:[2023-08-25 18:11:24,593] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.44
[default0]:[2023-08-25 18:11:24,593] [INFO] [logging.py:96:log_dist] [Rank 0] step=995, skipped=0, lr=[1.0857130666666666e-06, 1.0857130666666666e-06, 1.0857130666666666e-06, 1.0857130666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:24,593] [INFO] [timer.py:215:stop] epoch=0/micro_step=995/global_step=995, RunningAvgSamplesPerSec=4.916413060636155, CurrSamplesPerSec=4.823578389543001, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:24,594] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.21 | backward_microstep: 114.47 | backward_inner_microstep: 103.20 | backward_allreduce_microstep: 11.18 | step_microstep: 44.09
[default0]:[2023-08-25 18:11:24,594] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.21 (forward_moe: 20.92, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.43)
[default0]:[2023-08-25 18:11:24,594] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.48 | backward_inner: 103.20 | backward_allreduce: 11.18 | step: 44.09
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.0655], device='cuda:0'), 'moe loss': tensor([0.3009], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration      995/439453125 | consumed samples:          995 | consumed tokens:      2037760 | elapsed time per iteration (ms): 271.5 | learning rate: 1.086E-06 | global batch size:     1 | lm loss: 9.813103E+00 | moe loss: 6.018862E-02 | loss scale: 4096.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.683 | TFLOPs: 9.15 |
[default0]:[2023-08-25 18:11:24,861] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.43
[default0]:[2023-08-25 18:11:24,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.37 | backward_microstep: 114.29 | backward_inner_microstep: 103.10 | backward_allreduce_microstep: 11.10 | step_microstep: 43.27
[default0]:[2023-08-25 18:11:24,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.37 (forward_moe: 20.91, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.41)
[default0]:[2023-08-25 18:11:24,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.29 | backward_inner: 103.10 | backward_allreduce: 11.10 | step: 43.28
[default0]:[2023-08-25 18:11:25,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:11:25,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.91 | backward_microstep: 112.40 | backward_inner_microstep: 101.38 | backward_allreduce_microstep: 10.93 | step_microstep: 42.48
[default0]:[2023-08-25 18:11:25,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.91 (forward_moe: 20.47, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.17)
[default0]:[2023-08-25 18:11:25,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.40 | backward_inner: 101.38 | backward_allreduce: 10.93 | step: 42.48
[default0]:[2023-08-25 18:11:25,370] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.40
[default0]:[2023-08-25 18:11:25,370] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.17 | backward_microstep: 114.52 | backward_inner_microstep: 103.46 | backward_allreduce_microstep: 10.96 | step_microstep: 42.73
[default0]:[2023-08-25 18:11:25,370] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.17 (forward_moe: 20.63, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.20)
[default0]:[2023-08-25 18:11:25,371] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.52 | backward_inner: 103.47 | backward_allreduce: 10.96 | step: 42.73
[default0]:[2023-08-25 18:11:25,616] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:25,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.00 | backward_microstep: 112.33 | backward_inner_microstep: 101.25 | backward_allreduce_microstep: 10.99 | step_microstep: 42.56
[default0]:[2023-08-25 18:11:25,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.00 (forward_moe: 20.55, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.22)
[default0]:[2023-08-25 18:11:25,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.33 | backward_inner: 101.26 | backward_allreduce: 10.99 | step: 42.56
[default0]:[2023-08-25 18:11:25,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:11:25,885] [INFO] [logging.py:96:log_dist] [Rank 0] step=1000, skipped=0, lr=[1.0911744000000001e-06, 1.0911744000000001e-06, 1.0911744000000001e-06, 1.0911744000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:25,885] [INFO] [timer.py:215:stop] epoch=0/micro_step=1000/global_step=1000, RunningAvgSamplesPerSec=4.916267642195401, CurrSamplesPerSec=4.86332203201165, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:25,885] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.24 | backward_microstep: 114.35 | backward_inner_microstep: 103.32 | backward_allreduce_microstep: 10.94 | step_microstep: 43.47
[default0]:[2023-08-25 18:11:25,885] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.24 (forward_moe: 20.63, 1st alltoall: 0.88, 2nd alltoall: 0.84, top-k: 8.16)
[default0]:[2023-08-25 18:11:25,885] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.35 | backward_inner: 103.32 | backward_allreduce: 10.95 | step: 43.47
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.9861], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1000/439453125 | consumed samples:         1000 | consumed tokens:      2048000 | elapsed time per iteration (ms): 258.2 | learning rate: 1.091E-06 | global batch size:     1 | lm loss: 9.797222E+00 | moe loss: 6.014773E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.872 | TFLOPs: 9.62 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1000 | lm loss value: 9.768670E+00 | lm loss PPL: 1.747751E+04 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration    1000 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:11:29,486] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1000 is about to be saved!
[default0]:[2023-08-25 18:11:29,488] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,498] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,498] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,508] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,508] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,518] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,518] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,527] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,528] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,537] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,537] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,546] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,546] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,555] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,555] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,565] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,566] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,575] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,575] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,585] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,585] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,594] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,594] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,603] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,603] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,612] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,612] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,622] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,622] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,631] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,631] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,642] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,652] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,652] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,663] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,663] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,673] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,682] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,683] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,691] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,692] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,702] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,702] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,711] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,711] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:29,721] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:29,721] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:11:29,724] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:11:29,725] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:11:29,725] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:11:30,008] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:11:30,009] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:11:33,695] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:11:33,707] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1000/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:11:33,707] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
[default0]:  successfully saved checkpoint at iteration    1000 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.7, Latency(second): 4.224
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4224.21, 4224.21)
[default0]:[2023-08-25 18:11:34,010] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.19 | optimizer_step: 10.27
[default0]:[2023-08-25 18:11:34,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2242.22 | backward_microstep: 166.79 | backward_inner_microstep: 155.55 | backward_allreduce_microstep: 11.14 | step_microstep: 47.59
[default0]:[2023-08-25 18:11:34,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2242.10 (forward_moe: 21.80, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.94)
[default0]:[2023-08-25 18:11:34,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 166.78 | backward_inner: 155.56 | backward_allreduce: 11.14 | step: 47.59
[default0]:[2023-08-25 18:11:34,296] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.15 | optimizer_step: 6.51
[default0]:[2023-08-25 18:11:34,297] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.07 | backward_microstep: 116.68 | backward_inner_microstep: 105.54 | backward_allreduce_microstep: 11.04 | step_microstep: 44.15
[default0]:[2023-08-25 18:11:34,297] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.08 (forward_moe: 21.43, 1st alltoall: 0.94, 2nd alltoall: 0.83, top-k: 8.73)
[default0]:[2023-08-25 18:11:34,297] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.67 | backward_inner: 105.54 | backward_allreduce: 11.05 | step: 44.16
[default0]:[2023-08-25 18:11:34,562] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.13 | optimizer_step: 6.49
[default0]:[2023-08-25 18:11:34,562] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.10 | backward_microstep: 116.60 | backward_inner_microstep: 105.45 | backward_allreduce_microstep: 11.06 | step_microstep: 43.72
[default0]:[2023-08-25 18:11:34,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.10 (forward_moe: 21.33, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.71)
[default0]:[2023-08-25 18:11:34,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.60 | backward_inner: 105.46 | backward_allreduce: 11.06 | step: 43.73
[default0]:[2023-08-25 18:11:34,829] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.16 | optimizer_step: 6.51
[default0]:[2023-08-25 18:11:34,830] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.01 | backward_microstep: 116.97 | backward_inner_microstep: 105.61 | backward_allreduce_microstep: 11.26 | step_microstep: 44.62
[default0]:[2023-08-25 18:11:34,830] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.00 (forward_moe: 21.43, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.78)
[default0]:[2023-08-25 18:11:34,830] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.96 | backward_inner: 105.61 | backward_allreduce: 11.27 | step: 44.62
[default0]:[2023-08-25 18:11:35,093] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.15 | optimizer_step: 6.49
[default0]:[2023-08-25 18:11:35,093] [INFO] [logging.py:96:log_dist] [Rank 0] step=1005, skipped=0, lr=[1.0966357333333334e-06, 1.0966357333333334e-06, 1.0966357333333334e-06, 1.0966357333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:35,094] [INFO] [timer.py:215:stop] epoch=0/micro_step=1005/global_step=1005, RunningAvgSamplesPerSec=4.913975190229363, CurrSamplesPerSec=4.71819331266508, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:35,094] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.17 | backward_microstep: 117.44 | backward_inner_microstep: 106.07 | backward_allreduce_microstep: 11.28 | step_microstep: 44.85
[default0]:[2023-08-25 18:11:35,094] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.17 (forward_moe: 21.49, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.77)
[default0]:[2023-08-25 18:11:35,094] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.44 | backward_inner: 106.07 | backward_allreduce: 11.28 | step: 44.85
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.0289], device='cuda:0'), 'moe loss': tensor([0.3021], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1005/439453125 | consumed samples:         1005 | consumed tokens:      2058240 | elapsed time per iteration (ms): 1841.8 | learning rate: 1.097E-06 | global batch size:     1 | lm loss: 9.605781E+00 | moe loss: 6.042803E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.543 | TFLOPs: 1.35 |
[default0]:[2023-08-25 18:11:35,353] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.44
[default0]:[2023-08-25 18:11:35,354] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.65 | backward_microstep: 117.44 | backward_inner_microstep: 106.08 | backward_allreduce_microstep: 11.26 | step_microstep: 44.58
[default0]:[2023-08-25 18:11:35,354] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.65 (forward_moe: 21.49, 1st alltoall: 0.92, 2nd alltoall: 0.85, top-k: 8.75)
[default0]:[2023-08-25 18:11:35,354] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.43 | backward_inner: 106.09 | backward_allreduce: 11.26 | step: 44.59
[default0]:[2023-08-25 18:11:35,805] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.43
[default0]:[2023-08-25 18:11:35,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.00 | backward_microstep: 119.06 | backward_inner_microstep: 106.09 | backward_allreduce_microstep: 12.87 | step_microstep: 45.49
[default0]:[2023-08-25 18:11:35,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.00 (forward_moe: 21.48, 1st alltoall: 1.01, 2nd alltoall: 0.83, top-k: 8.52)
[default0]:[2023-08-25 18:11:35,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 119.06 | backward_inner: 106.10 | backward_allreduce: 12.87 | step: 45.50
[default0]:[2023-08-25 18:11:36,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.42
[default0]:[2023-08-25 18:11:36,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.05 | backward_microstep: 116.98 | backward_inner_microstep: 105.72 | backward_allreduce_microstep: 11.16 | step_microstep: 43.50
[default0]:[2023-08-25 18:11:36,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.05 (forward_moe: 21.01, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.48)
[default0]:[2023-08-25 18:11:36,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.98 | backward_inner: 105.73 | backward_allreduce: 11.16 | step: 43.50
[default0]:[2023-08-25 18:11:36,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.07 | optimizer_step: 6.44
[default0]:[2023-08-25 18:11:36,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.48 | backward_microstep: 114.93 | backward_inner_microstep: 103.71 | backward_allreduce_microstep: 11.12 | step_microstep: 43.55
[default0]:[2023-08-25 18:11:36,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.48 (forward_moe: 21.02, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.48)
[default0]:[2023-08-25 18:11:36,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.92 | backward_inner: 103.72 | backward_allreduce: 11.13 | step: 43.55
[default0]:[2023-08-25 18:11:36,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.40
[default0]:[2023-08-25 18:11:36,564] [INFO] [logging.py:96:log_dist] [Rank 0] step=1010, skipped=0, lr=[1.1020970666666668e-06, 1.1020970666666668e-06, 1.1020970666666668e-06, 1.1020970666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:36,565] [INFO] [timer.py:215:stop] epoch=0/micro_step=1010/global_step=1010, RunningAvgSamplesPerSec=4.913148462355752, CurrSamplesPerSec=4.877954152415134, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:36,565] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.64 | backward_microstep: 113.50 | backward_inner_microstep: 102.37 | backward_allreduce_microstep: 11.03 | step_microstep: 43.30
[default0]:[2023-08-25 18:11:36,565] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.64 (forward_moe: 20.79, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:11:36,565] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.50 | backward_inner: 102.38 | backward_allreduce: 11.03 | step: 43.30
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.4083], device='cuda:0'), 'moe loss': tensor([0.3013], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1010/439453125 | consumed samples:         1010 | consumed tokens:      2068480 | elapsed time per iteration (ms): 294.3 | learning rate: 1.102E-06 | global batch size:     1 | lm loss: 9.681665E+00 | moe loss: 6.025568E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.398 | TFLOPs: 8.44 |
[default0]:[2023-08-25 18:11:36,830] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.40
[default0]:[2023-08-25 18:11:36,831] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.43 | backward_microstep: 113.31 | backward_inner_microstep: 102.15 | backward_allreduce_microstep: 11.07 | step_microstep: 42.94
[default0]:[2023-08-25 18:11:36,831] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.43 (forward_moe: 20.67, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.27)
[default0]:[2023-08-25 18:11:36,831] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.31 | backward_inner: 102.15 | backward_allreduce: 11.08 | step: 42.94
[default0]:[2023-08-25 18:11:37,116] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.40
[default0]:[2023-08-25 18:11:37,117] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.35 | backward_microstep: 113.20 | backward_inner_microstep: 102.11 | backward_allreduce_microstep: 11.00 | step_microstep: 42.89
[default0]:[2023-08-25 18:11:37,117] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.35 (forward_moe: 20.65, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:11:37,117] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.20 | backward_inner: 102.11 | backward_allreduce: 11.00 | step: 42.89
[default0]:[2023-08-25 18:11:37,402] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.71 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:11:37,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.57 | backward_microstep: 113.22 | backward_inner_microstep: 102.09 | backward_allreduce_microstep: 11.04 | step_microstep: 42.91
[default0]:[2023-08-25 18:11:37,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.57 (forward_moe: 20.73, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.26)
[default0]:[2023-08-25 18:11:37,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.22 | backward_inner: 102.10 | backward_allreduce: 11.04 | step: 42.91
[default0]:[2023-08-25 18:11:37,671] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:11:37,672] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.38 | backward_microstep: 113.53 | backward_inner_microstep: 102.40 | backward_allreduce_microstep: 11.03 | step_microstep: 43.09
[default0]:[2023-08-25 18:11:37,672] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.38 (forward_moe: 20.67, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.26)
[default0]:[2023-08-25 18:11:37,672] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.53 | backward_inner: 102.41 | backward_allreduce: 11.04 | step: 43.10
[default0]:[2023-08-25 18:11:37,911] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:37,911] [INFO] [logging.py:96:log_dist] [Rank 0] step=1015, skipped=0, lr=[1.1075584e-06, 1.1075584e-06, 1.1075584e-06, 1.1075584e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:37,911] [INFO] [timer.py:215:stop] epoch=0/micro_step=1015/global_step=1015, RunningAvgSamplesPerSec=4.913027749779137, CurrSamplesPerSec=4.887537682235193, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:37,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.44 | backward_microstep: 113.32 | backward_inner_microstep: 102.15 | backward_allreduce_microstep: 11.07 | step_microstep: 43.31
[default0]:[2023-08-25 18:11:37,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.44 (forward_moe: 20.76, 1st alltoall: 0.88, 2nd alltoall: 0.87, top-k: 8.23)
[default0]:[2023-08-25 18:11:37,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.32 | backward_inner: 102.16 | backward_allreduce: 11.08 | step: 43.31
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.9994], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1015/439453125 | consumed samples:         1015 | consumed tokens:      2078720 | elapsed time per iteration (ms): 269.4 | learning rate: 1.108E-06 | global batch size:     1 | lm loss: 9.799880E+00 | moe loss: 6.019734E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.712 | TFLOPs: 9.22 |
[default0]:[2023-08-25 18:11:38,167] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:11:38,168] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.34 | backward_microstep: 113.36 | backward_inner_microstep: 102.25 | backward_allreduce_microstep: 11.02 | step_microstep: 43.09
[default0]:[2023-08-25 18:11:38,168] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.34 (forward_moe: 20.66, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.25)
[default0]:[2023-08-25 18:11:38,168] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.36 | backward_inner: 102.25 | backward_allreduce: 11.02 | step: 43.09
[default0]:[2023-08-25 18:11:38,420] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:11:38,420] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.89 | backward_microstep: 113.72 | backward_inner_microstep: 102.55 | backward_allreduce_microstep: 11.07 | step_microstep: 43.10
[default0]:[2023-08-25 18:11:38,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.89 (forward_moe: 20.84, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.42)
[default0]:[2023-08-25 18:11:38,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.72 | backward_inner: 102.56 | backward_allreduce: 11.07 | step: 43.10
[default0]:[2023-08-25 18:11:38,679] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:11:38,679] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.75 | backward_microstep: 114.35 | backward_inner_microstep: 103.17 | backward_allreduce_microstep: 11.08 | step_microstep: 43.47
[default0]:[2023-08-25 18:11:38,679] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.75 (forward_moe: 20.87, 1st alltoall: 0.88, 2nd alltoall: 0.84, top-k: 8.40)
[default0]:[2023-08-25 18:11:38,680] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.35 | backward_inner: 103.18 | backward_allreduce: 11.09 | step: 43.47
[default0]:[2023-08-25 18:11:38,947] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:11:38,947] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.07 | backward_microstep: 115.09 | backward_inner_microstep: 103.76 | backward_allreduce_microstep: 11.23 | step_microstep: 43.54
[default0]:[2023-08-25 18:11:38,947] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.07 (forward_moe: 21.00, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.48)
[default0]:[2023-08-25 18:11:38,948] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.09 | backward_inner: 103.77 | backward_allreduce: 11.23 | step: 43.54
[default0]:[2023-08-25 18:11:39,190] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.33
[default0]:[2023-08-25 18:11:39,190] [INFO] [logging.py:96:log_dist] [Rank 0] step=1020, skipped=0, lr=[1.1130197333333334e-06, 1.1130197333333334e-06, 1.1130197333333334e-06, 1.1130197333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:39,190] [INFO] [timer.py:215:stop] epoch=0/micro_step=1020/global_step=1020, RunningAvgSamplesPerSec=4.912865504747413, CurrSamplesPerSec=4.988438460760818, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:39,190] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.36 | backward_microstep: 111.06 | backward_inner_microstep: 100.05 | backward_allreduce_microstep: 10.92 | step_microstep: 42.49
[default0]:[2023-08-25 18:11:39,190] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.36 (forward_moe: 20.24, 1st alltoall: 0.86, 2nd alltoall: 0.82, top-k: 7.93)
[default0]:[2023-08-25 18:11:39,191] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.06 | backward_inner: 100.05 | backward_allreduce: 10.93 | step: 42.50
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.1495], device='cuda:0'), 'moe loss': tensor([0.3039], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1020/439453125 | consumed samples:         1020 | consumed tokens:      2088960 | elapsed time per iteration (ms): 255.5 | learning rate: 1.113E-06 | global batch size:     1 | lm loss: 9.829900E+00 | moe loss: 6.077566E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.914 | TFLOPs: 9.72 |
[default0]:[2023-08-25 18:11:39,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.33
[default0]:[2023-08-25 18:11:39,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.53 | backward_microstep: 111.18 | backward_inner_microstep: 100.22 | backward_allreduce_microstep: 10.87 | step_microstep: 42.24
[default0]:[2023-08-25 18:11:39,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.53 (forward_moe: 20.46, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.98)
[default0]:[2023-08-25 18:11:39,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.18 | backward_inner: 100.23 | backward_allreduce: 10.87 | step: 42.24
[default0]:[2023-08-25 18:11:39,685] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:11:39,843] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.23 | backward_microstep: 110.92 | backward_inner_microstep: 99.95 | backward_allreduce_microstep: 10.87 | step_microstep: 199.90
[default0]:[2023-08-25 18:11:39,843] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.22 (forward_moe: 20.13, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.95)
[default0]:[2023-08-25 18:11:39,844] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.91 | backward_inner: 99.95 | backward_allreduce: 10.87 | step: 199.90
[default0]:[2023-08-25 18:11:40,104] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:40,105] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.37 | backward_microstep: 114.10 | backward_inner_microstep: 103.13 | backward_allreduce_microstep: 10.87 | step_microstep: 42.54
[default0]:[2023-08-25 18:11:40,105] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.37 (forward_moe: 20.37, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.00)
[default0]:[2023-08-25 18:11:40,105] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.09 | backward_inner: 103.13 | backward_allreduce: 10.87 | step: 42.55
[default0]:[2023-08-25 18:11:40,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.95 | optimizer_step: 6.34
[default0]:[2023-08-25 18:11:40,345] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.63 | backward_microstep: 111.93 | backward_inner_microstep: 100.71 | backward_allreduce_microstep: 11.13 | step_microstep: 42.11
[default0]:[2023-08-25 18:11:40,345] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.63 (forward_moe: 20.35, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 8.08)
[default0]:[2023-08-25 18:11:40,345] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.93 | backward_inner: 100.72 | backward_allreduce: 11.13 | step: 42.11
[default0]:[2023-08-25 18:11:40,588] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:40,588] [INFO] [logging.py:96:log_dist] [Rank 0] step=1025, skipped=0, lr=[1.1184810666666667e-06, 1.1184810666666667e-06, 1.1184810666666667e-06, 1.1184810666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:40,588] [INFO] [timer.py:215:stop] epoch=0/micro_step=1025/global_step=1025, RunningAvgSamplesPerSec=4.909359618931158, CurrSamplesPerSec=5.037858068576686, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:40,589] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 109.94 | backward_inner_microstep: 99.09 | backward_allreduce_microstep: 10.76 | step_microstep: 42.01
[default0]:[2023-08-25 18:11:40,589] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.00 (forward_moe: 20.00, 1st alltoall: 0.91, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:11:40,589] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.94 | backward_inner: 99.10 | backward_allreduce: 10.76 | step: 42.02
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.3418], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1025/439453125 | consumed samples:         1025 | consumed tokens:      2099200 | elapsed time per iteration (ms): 279.9 | learning rate: 1.118E-06 | global batch size:     1 | lm loss: 9.668369E+00 | moe loss: 6.019348E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.573 | TFLOPs: 8.88 |
[default0]:[2023-08-25 18:11:40,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.33
[default0]:[2023-08-25 18:11:40,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.09 | backward_microstep: 109.94 | backward_inner_microstep: 99.11 | backward_allreduce_microstep: 10.75 | step_microstep: 41.79
[default0]:[2023-08-25 18:11:40,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.09 (forward_moe: 20.04, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.93)
[default0]:[2023-08-25 18:11:40,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.94 | backward_inner: 99.11 | backward_allreduce: 10.75 | step: 41.80
[default0]:[2023-08-25 18:11:41,111] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:41,111] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.78 | backward_microstep: 110.60 | backward_inner_microstep: 99.75 | backward_allreduce_microstep: 10.76 | step_microstep: 41.80
[default0]:[2023-08-25 18:11:41,111] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.78 (forward_moe: 20.36, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.84)
[default0]:[2023-08-25 18:11:41,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.60 | backward_inner: 99.76 | backward_allreduce: 10.76 | step: 41.81
[default0]:[2023-08-25 18:11:41,353] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:41,354] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.19 | backward_microstep: 109.91 | backward_inner_microstep: 99.04 | backward_allreduce_microstep: 10.77 | step_microstep: 41.76
[default0]:[2023-08-25 18:11:41,354] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.19 (forward_moe: 20.08, 1st alltoall: 0.96, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:11:41,354] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.91 | backward_inner: 99.05 | backward_allreduce: 10.78 | step: 41.76
[default0]:[2023-08-25 18:11:41,608] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:41,609] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.38 | backward_microstep: 108.84 | backward_inner_microstep: 98.02 | backward_allreduce_microstep: 10.73 | step_microstep: 41.46
[default0]:[2023-08-25 18:11:41,609] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.38 (forward_moe: 19.73, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:11:41,609] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.83 | backward_inner: 98.02 | backward_allreduce: 10.73 | step: 41.46
[default0]:[2023-08-25 18:11:41,868] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:41,868] [INFO] [logging.py:96:log_dist] [Rank 0] step=1030, skipped=0, lr=[1.1239424e-06, 1.1239424e-06, 1.1239424e-06, 1.1239424e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:41,868] [INFO] [timer.py:215:stop] epoch=0/micro_step=1030/global_step=1030, RunningAvgSamplesPerSec=4.910024976813846, CurrSamplesPerSec=5.069129258261514, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:41,869] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.73 | backward_microstep: 109.10 | backward_inner_microstep: 98.27 | backward_allreduce_microstep: 10.74 | step_microstep: 41.91
[default0]:[2023-08-25 18:11:41,869] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.72 (forward_moe: 19.86, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:11:41,869] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.10 | backward_inner: 98.28 | backward_allreduce: 10.74 | step: 41.91
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.0900], device='cuda:0'), 'moe loss': tensor([0.3004], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1030/439453125 | consumed samples:         1030 | consumed tokens:      2109440 | elapsed time per iteration (ms): 256.0 | learning rate: 1.124E-06 | global batch size:     1 | lm loss: 9.618003E+00 | moe loss: 6.007898E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.906 | TFLOPs: 9.70 |
[default0]:[2023-08-25 18:11:42,130] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:42,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 108.98 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.70 | step_microstep: 41.54
[default0]:[2023-08-25 18:11:42,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.43 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:11:42,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.97 | backward_inner: 98.18 | backward_allreduce: 10.71 | step: 41.55
[default0]:[2023-08-25 18:11:42,439] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:42,440] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.38 | backward_microstep: 108.96 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.74 | step_microstep: 41.48
[default0]:[2023-08-25 18:11:42,440] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.38 (forward_moe: 19.70, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:11:42,440] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.14 | backward_allreduce: 10.74 | step: 41.49
[default0]:[2023-08-25 18:11:42,673] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:42,673] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 109.18 | backward_inner_microstep: 98.39 | backward_allreduce_microstep: 10.69 | step_microstep: 41.57
[default0]:[2023-08-25 18:11:42,673] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.89, 1st alltoall: 0.90, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:11:42,673] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.18 | backward_inner: 98.40 | backward_allreduce: 10.70 | step: 41.57
[default0]:[2023-08-25 18:11:42,949] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:42,949] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.51 | backward_microstep: 109.08 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.71 | step_microstep: 41.60
[default0]:[2023-08-25 18:11:42,950] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.50 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.77)
[default0]:[2023-08-25 18:11:42,950] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.07 | backward_inner: 98.27 | backward_allreduce: 10.72 | step: 41.60
[default0]:[2023-08-25 18:11:43,213] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.28 | optimizer_step: 6.36
[default0]:[2023-08-25 18:11:43,213] [INFO] [logging.py:96:log_dist] [Rank 0] step=1035, skipped=0, lr=[1.1294037333333333e-06, 1.1294037333333333e-06, 1.1294037333333333e-06, 1.1294037333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:43,214] [INFO] [timer.py:215:stop] epoch=0/micro_step=1035/global_step=1035, RunningAvgSamplesPerSec=4.910789260813819, CurrSamplesPerSec=5.052173096056603, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:43,214] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 108.94 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.76 | step_microstep: 43.05
[default0]:[2023-08-25 18:11:43,214] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.73, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:11:43,214] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.94 | backward_inner: 98.09 | backward_allreduce: 10.76 | step: 43.06
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.1272], device='cuda:0'), 'moe loss': tensor([0.3016], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1035/439453125 | consumed samples:         1035 | consumed tokens:      2119680 | elapsed time per iteration (ms): 268.7 | learning rate: 1.129E-06 | global batch size:     1 | lm loss: 9.625443E+00 | moe loss: 6.031629E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.721 | TFLOPs: 9.25 |
[default0]:[2023-08-25 18:11:43,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:43,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.19 | backward_microstep: 110.63 | backward_inner_microstep: 99.71 | backward_allreduce_microstep: 10.83 | step_microstep: 42.04
[default0]:[2023-08-25 18:11:43,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.18 (forward_moe: 20.06, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:11:43,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.63 | backward_inner: 99.71 | backward_allreduce: 10.84 | step: 42.04
[default0]:[2023-08-25 18:11:43,707] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:43,707] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.39 | backward_microstep: 110.96 | backward_inner_microstep: 100.02 | backward_allreduce_microstep: 10.84 | step_microstep: 42.22
[default0]:[2023-08-25 18:11:43,707] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.39 (forward_moe: 20.30, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.00)
[default0]:[2023-08-25 18:11:43,708] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.96 | backward_inner: 100.03 | backward_allreduce: 10.85 | step: 42.22
[default0]:[2023-08-25 18:11:43,944] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.39
[default0]:[2023-08-25 18:11:43,945] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.80 | backward_microstep: 111.33 | backward_inner_microstep: 100.40 | backward_allreduce_microstep: 10.84 | step_microstep: 42.80
[default0]:[2023-08-25 18:11:43,945] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.80 (forward_moe: 20.25, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.04)
[default0]:[2023-08-25 18:11:43,945] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.33 | backward_inner: 100.41 | backward_allreduce: 10.84 | step: 42.80
[default0]:[2023-08-25 18:11:44,205] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 10.03
[default0]:[2023-08-25 18:11:44,206] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.80 | backward_microstep: 111.89 | backward_inner_microstep: 100.90 | backward_allreduce_microstep: 10.90 | step_microstep: 46.60
[default0]:[2023-08-25 18:11:44,206] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.80 (forward_moe: 20.35, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:11:44,207] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.89 | backward_inner: 100.90 | backward_allreduce: 10.90 | step: 46.60
[default0]:[2023-08-25 18:11:44,451] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:11:44,452] [INFO] [logging.py:96:log_dist] [Rank 0] step=1040, skipped=0, lr=[1.1348650666666666e-06, 1.1348650666666666e-06, 1.1348650666666666e-06, 1.1348650666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:44,452] [INFO] [timer.py:215:stop] epoch=0/micro_step=1040/global_step=1040, RunningAvgSamplesPerSec=4.910966104738091, CurrSamplesPerSec=4.934173438801391, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:44,452] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.01 | backward_microstep: 112.28 | backward_inner_microstep: 101.26 | backward_allreduce_microstep: 10.92 | step_microstep: 42.87
[default0]:[2023-08-25 18:11:44,452] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.01 (forward_moe: 20.52, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.09)
[default0]:[2023-08-25 18:11:44,452] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.27 | backward_inner: 101.27 | backward_allreduce: 10.92 | step: 42.88
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.4102], device='cuda:0'), 'moe loss': tensor([0.3029], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1040/439453125 | consumed samples:         1040 | consumed tokens:      2129920 | elapsed time per iteration (ms): 247.7 | learning rate: 1.135E-06 | global batch size:     1 | lm loss: 9.682040E+00 | moe loss: 6.058446E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.038 | TFLOPs: 10.03 |
[default0]:[2023-08-25 18:11:44,721] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:44,722] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.75 | backward_microstep: 112.62 | backward_inner_microstep: 101.59 | backward_allreduce_microstep: 10.94 | step_microstep: 42.85
[default0]:[2023-08-25 18:11:44,722] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.75 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:11:44,722] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.62 | backward_inner: 101.59 | backward_allreduce: 10.95 | step: 42.86
[default0]:[2023-08-25 18:11:44,977] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:44,977] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.52 | backward_microstep: 113.60 | backward_inner_microstep: 102.49 | backward_allreduce_microstep: 11.01 | step_microstep: 43.11
[default0]:[2023-08-25 18:11:44,978] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.51 (forward_moe: 20.78, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:11:44,978] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.60 | backward_inner: 102.50 | backward_allreduce: 11.01 | step: 43.11
[default0]:[2023-08-25 18:11:45,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.34
[default0]:[2023-08-25 18:11:45,219] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.12 | backward_microstep: 110.31 | backward_inner_microstep: 99.45 | backward_allreduce_microstep: 10.77 | step_microstep: 41.93
[default0]:[2023-08-25 18:11:45,219] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.12 (forward_moe: 20.11, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.89)
[default0]:[2023-08-25 18:11:45,219] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.31 | backward_inner: 99.46 | backward_allreduce: 10.77 | step: 41.94
[default0]:[2023-08-25 18:11:45,468] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:45,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.46 | backward_microstep: 110.22 | backward_inner_microstep: 99.31 | backward_allreduce_microstep: 10.82 | step_microstep: 41.90
[default0]:[2023-08-25 18:11:45,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.46 (forward_moe: 20.07, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.92)
[default0]:[2023-08-25 18:11:45,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.22 | backward_inner: 99.31 | backward_allreduce: 10.82 | step: 41.90
[default0]:[2023-08-25 18:11:45,714] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:11:45,714] [INFO] [logging.py:96:log_dist] [Rank 0] step=1045, skipped=0, lr=[1.1403264000000002e-06, 1.1403264000000002e-06, 1.1403264000000002e-06, 1.1403264000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:45,714] [INFO] [timer.py:215:stop] epoch=0/micro_step=1045/global_step=1045, RunningAvgSamplesPerSec=4.911248922976005, CurrSamplesPerSec=5.019211392329325, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:45,715] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.24 | backward_microstep: 110.28 | backward_inner_microstep: 99.39 | backward_allreduce_microstep: 10.80 | step_microstep: 42.18
[default0]:[2023-08-25 18:11:45,715] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.23 (forward_moe: 20.04, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:11:45,715] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.28 | backward_inner: 99.39 | backward_allreduce: 10.81 | step: 42.18
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.5182], device='cuda:0'), 'moe loss': tensor([0.3031], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1045/439453125 | consumed samples:         1045 | consumed tokens:      2140160 | elapsed time per iteration (ms): 252.6 | learning rate: 1.140E-06 | global batch size:     1 | lm loss: 9.703639E+00 | moe loss: 6.061656E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.959 | TFLOPs: 9.84 |
[default0]:[2023-08-25 18:11:45,963] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:45,963] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.33 | backward_microstep: 110.49 | backward_inner_microstep: 99.57 | backward_allreduce_microstep: 10.82 | step_microstep: 42.12
[default0]:[2023-08-25 18:11:45,963] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.33 (forward_moe: 20.03, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:11:45,964] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.49 | backward_inner: 99.58 | backward_allreduce: 10.83 | step: 42.12
[default0]:[2023-08-25 18:11:46,210] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:11:46,210] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.69 | backward_microstep: 110.25 | backward_inner_microstep: 99.36 | backward_allreduce_microstep: 10.80 | step_microstep: 41.88
[default0]:[2023-08-25 18:11:46,210] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.69 (forward_moe: 20.03, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.92)
[default0]:[2023-08-25 18:11:46,210] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.25 | backward_inner: 99.36 | backward_allreduce: 10.81 | step: 41.88
[default0]:[2023-08-25 18:11:46,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:46,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.20 | backward_microstep: 110.21 | backward_inner_microstep: 99.33 | backward_allreduce_microstep: 10.78 | step_microstep: 41.94
[default0]:[2023-08-25 18:11:46,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.19 (forward_moe: 20.03, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.90)
[default0]:[2023-08-25 18:11:46,454] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.21 | backward_inner: 99.34 | backward_allreduce: 10.78 | step: 41.94
[default0]:[2023-08-25 18:11:46,698] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:46,698] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.38 | backward_microstep: 113.70 | backward_inner_microstep: 102.20 | backward_allreduce_microstep: 11.40 | step_microstep: 42.87
[default0]:[2023-08-25 18:11:46,698] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.37 (forward_moe: 20.70, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.08)
[default0]:[2023-08-25 18:11:46,698] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.70 | backward_inner: 102.21 | backward_allreduce: 11.41 | step: 42.88
[default0]:[2023-08-25 18:11:46,979] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:46,979] [INFO] [logging.py:96:log_dist] [Rank 0] step=1050, skipped=0, lr=[1.1457877333333335e-06, 1.1457877333333335e-06, 1.1457877333333335e-06, 1.1457877333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:46,979] [INFO] [timer.py:215:stop] epoch=0/micro_step=1050/global_step=1050, RunningAvgSamplesPerSec=4.911490884145963, CurrSamplesPerSec=4.896312855683642, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:46,980] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.03 | backward_microstep: 113.44 | backward_inner_microstep: 102.41 | backward_allreduce_microstep: 10.93 | step_microstep: 43.22
[default0]:[2023-08-25 18:11:46,980] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.03 (forward_moe: 20.89, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.28)
[default0]:[2023-08-25 18:11:46,980] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.44 | backward_inner: 102.42 | backward_allreduce: 10.93 | step: 43.23
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.2695], device='cuda:0'), 'moe loss': tensor([0.3016], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1050/439453125 | consumed samples:         1050 | consumed tokens:      2150400 | elapsed time per iteration (ms): 253.1 | learning rate: 1.146E-06 | global batch size:     1 | lm loss: 9.653897E+00 | moe loss: 6.032786E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.950 | TFLOPs: 9.82 |
[default0]:[2023-08-25 18:11:47,239] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:11:47,239] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.94 | backward_microstep: 111.83 | backward_inner_microstep: 100.84 | backward_allreduce_microstep: 10.89 | step_microstep: 42.44
[default0]:[2023-08-25 18:11:47,239] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.94 (forward_moe: 20.39, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.09)
[default0]:[2023-08-25 18:11:47,240] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.83 | backward_inner: 100.85 | backward_allreduce: 10.90 | step: 42.45
[default0]:[2023-08-25 18:11:47,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:11:47,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.87 | backward_microstep: 111.83 | backward_inner_microstep: 100.86 | backward_allreduce_microstep: 10.87 | step_microstep: 42.39
[default0]:[2023-08-25 18:11:47,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.86 (forward_moe: 20.40, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.11)
[default0]:[2023-08-25 18:11:47,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.82 | backward_inner: 100.87 | backward_allreduce: 10.88 | step: 42.39
[default0]:[2023-08-25 18:11:47,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.03 | optimizer_step: 6.40
[default0]:[2023-08-25 18:11:47,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.10 | backward_microstep: 112.84 | backward_inner_microstep: 101.29 | backward_allreduce_microstep: 11.46 | step_microstep: 45.49
[default0]:[2023-08-25 18:11:47,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.10 (forward_moe: 20.51, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.18)
[default0]:[2023-08-25 18:11:47,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.84 | backward_inner: 101.29 | backward_allreduce: 11.46 | step: 45.49
[default0]:[2023-08-25 18:11:48,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:11:48,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.77 | backward_microstep: 112.26 | backward_inner_microstep: 101.25 | backward_allreduce_microstep: 10.90 | step_microstep: 42.46
[default0]:[2023-08-25 18:11:48,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.77 (forward_moe: 20.48, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.11)
[default0]:[2023-08-25 18:11:48,000] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.25 | backward_inner: 101.25 | backward_allreduce: 10.91 | step: 42.46
[default0]:[2023-08-25 18:11:48,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:48,248] [INFO] [logging.py:96:log_dist] [Rank 0] step=1055, skipped=0, lr=[1.1512490666666668e-06, 1.1512490666666668e-06, 1.1512490666666668e-06, 1.1512490666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:48,248] [INFO] [timer.py:215:stop] epoch=0/micro_step=1055/global_step=1055, RunningAvgSamplesPerSec=4.911641929317249, CurrSamplesPerSec=5.078335579310854, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:48,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 108.78 | backward_inner_microstep: 97.99 | backward_allreduce_microstep: 10.70 | step_microstep: 41.91
[default0]:[2023-08-25 18:11:48,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:11:48,249] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.78 | backward_inner: 98.00 | backward_allreduce: 10.70 | step: 41.91
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.2868], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1055/439453125 | consumed samples:         1055 | consumed tokens:      2160640 | elapsed time per iteration (ms): 253.5 | learning rate: 1.151E-06 | global batch size:     1 | lm loss: 9.657361E+00 | moe loss: 6.015414E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.945 | TFLOPs: 9.80 |
[default0]:[2023-08-25 18:11:48,494] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:48,494] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.51 | backward_microstep: 109.32 | backward_inner_microstep: 98.51 | backward_allreduce_microstep: 10.71 | step_microstep: 41.58
[default0]:[2023-08-25 18:11:48,494] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.51 (forward_moe: 19.86, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:11:48,495] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.31 | backward_inner: 98.52 | backward_allreduce: 10.71 | step: 41.58
[default0]:[2023-08-25 18:11:48,730] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.28
[default0]:[2023-08-25 18:11:48,730] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 108.94 | backward_inner_microstep: 98.19 | backward_allreduce_microstep: 10.66 | step_microstep: 41.51
[default0]:[2023-08-25 18:11:48,731] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.80, 1st alltoall: 0.91, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:11:48,731] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.94 | backward_inner: 98.19 | backward_allreduce: 10.66 | step: 41.52
[default0]:[2023-08-25 18:11:48,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:48,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.80 | backward_microstep: 109.13 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.77 | step_microstep: 41.52
[default0]:[2023-08-25 18:11:48,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.80 (forward_moe: 19.75, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:11:48,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.13 | backward_inner: 98.26 | backward_allreduce: 10.78 | step: 41.52
[default0]:[2023-08-25 18:11:49,223] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:11:49,223] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 108.96 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.69 | step_microstep: 41.55
[default0]:[2023-08-25 18:11:49,223] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:11:49,223] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.18 | backward_allreduce: 10.70 | step: 41.56
[default0]:[2023-08-25 18:11:49,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.88 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:49,469] [INFO] [logging.py:96:log_dist] [Rank 0] step=1060, skipped=0, lr=[1.1567104000000001e-06, 1.1567104000000001e-06, 1.1567104000000001e-06, 1.1567104000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:49,469] [INFO] [timer.py:215:stop] epoch=0/micro_step=1060/global_step=1060, RunningAvgSamplesPerSec=4.912386352582105, CurrSamplesPerSec=5.071114996185454, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:49,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.75 | backward_microstep: 109.16 | backward_inner_microstep: 98.38 | backward_allreduce_microstep: 10.69 | step_microstep: 41.74
[default0]:[2023-08-25 18:11:49,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.75 (forward_moe: 19.91, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:11:49,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.15 | backward_inner: 98.38 | backward_allreduce: 10.69 | step: 41.75
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.3727], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1060/439453125 | consumed samples:         1060 | consumed tokens:      2170880 | elapsed time per iteration (ms): 244.4 | learning rate: 1.157E-06 | global batch size:     1 | lm loss: 9.674550E+00 | moe loss: 6.015120E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.091 | TFLOPs: 10.17 |
[default0]:[2023-08-25 18:11:49,711] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:49,711] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.04 | backward_microstep: 108.80 | backward_inner_microstep: 98.03 | backward_allreduce_microstep: 10.68 | step_microstep: 41.34
[default0]:[2023-08-25 18:11:49,712] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.04 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:11:49,712] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.80 | backward_inner: 98.03 | backward_allreduce: 10.69 | step: 41.35
[default0]:[2023-08-25 18:11:49,965] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:11:49,965] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.05 | backward_microstep: 111.80 | backward_inner_microstep: 100.83 | backward_allreduce_microstep: 10.88 | step_microstep: 42.68
[default0]:[2023-08-25 18:11:49,966] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.05 (forward_moe: 20.37, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 8.10)
[default0]:[2023-08-25 18:11:49,966] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.80 | backward_inner: 100.84 | backward_allreduce: 10.88 | step: 42.68
[default0]:[2023-08-25 18:11:50,219] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:11:50,219] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 52.42 | backward_microstep: 113.26 | backward_inner_microstep: 102.27 | backward_allreduce_microstep: 10.89 | step_microstep: 42.66
[default0]:[2023-08-25 18:11:50,219] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 52.42 (forward_moe: 20.87, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:11:50,220] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.26 | backward_inner: 102.28 | backward_allreduce: 10.89 | step: 42.67
[default0]:[2023-08-25 18:11:50,637] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:11:50,638] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.29 | backward_microstep: 110.73 | backward_inner_microstep: 99.81 | backward_allreduce_microstep: 10.82 | step_microstep: 42.02
[default0]:[2023-08-25 18:11:50,638] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.29 (forward_moe: 20.13, 1st alltoall: 0.87, 2nd alltoall: 0.83, top-k: 7.95)
[default0]:[2023-08-25 18:11:50,638] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.72 | backward_inner: 99.81 | backward_allreduce: 10.82 | step: 42.02
[default0]:[2023-08-25 18:11:50,898] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:50,898] [INFO] [logging.py:96:log_dist] [Rank 0] step=1065, skipped=0, lr=[1.1621717333333334e-06, 1.1621717333333334e-06, 1.1621717333333334e-06, 1.1621717333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:50,898] [INFO] [timer.py:215:stop] epoch=0/micro_step=1065/global_step=1065, RunningAvgSamplesPerSec=4.912597205166525, CurrSamplesPerSec=4.994949440818188, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:50,899] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.35 | backward_microstep: 111.00 | backward_inner_microstep: 100.09 | backward_allreduce_microstep: 10.81 | step_microstep: 42.33
[default0]:[2023-08-25 18:11:50,899] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.34 (forward_moe: 20.35, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.17)
[default0]:[2023-08-25 18:11:50,899] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.00 | backward_inner: 100.10 | backward_allreduce: 10.81 | step: 42.33
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.4283], device='cuda:0'), 'moe loss': tensor([0.3004], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1065/439453125 | consumed samples:         1065 | consumed tokens:      2181120 | elapsed time per iteration (ms): 285.7 | learning rate: 1.162E-06 | global batch size:     1 | lm loss: 9.685667E+00 | moe loss: 6.007241E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.500 | TFLOPs: 8.70 |
[default0]:[2023-08-25 18:11:51,157] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.17 | optimizer_step: 6.35
[default0]:[2023-08-25 18:11:51,157] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.61 | backward_microstep: 111.06 | backward_inner_microstep: 100.15 | backward_allreduce_microstep: 10.82 | step_microstep: 42.87
[default0]:[2023-08-25 18:11:51,157] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.61 (forward_moe: 20.13, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.98)
[default0]:[2023-08-25 18:11:51,157] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.06 | backward_inner: 100.16 | backward_allreduce: 10.82 | step: 42.87
[default0]:[2023-08-25 18:11:51,417] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:51,417] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.17 | backward_microstep: 110.73 | backward_inner_microstep: 99.79 | backward_allreduce_microstep: 10.83 | step_microstep: 41.96
[default0]:[2023-08-25 18:11:51,417] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.17 (forward_moe: 20.19, 1st alltoall: 0.89, 2nd alltoall: 0.80, top-k: 7.97)
[default0]:[2023-08-25 18:11:51,417] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.72 | backward_inner: 99.80 | backward_allreduce: 10.84 | step: 41.97
[default0]:[2023-08-25 18:11:51,688] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:51,689] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 108.94 | backward_inner_microstep: 98.12 | backward_allreduce_microstep: 10.72 | step_microstep: 41.61
[default0]:[2023-08-25 18:11:51,689] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.89, top-k: 7.71)
[default0]:[2023-08-25 18:11:51,689] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.94 | backward_inner: 98.13 | backward_allreduce: 10.73 | step: 41.61
[default0]:[2023-08-25 18:11:51,936] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.88 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:51,937] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.02 | backward_microstep: 108.96 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.77 | step_microstep: 41.30
[default0]:[2023-08-25 18:11:51,937] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.02 (forward_moe: 19.78, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:11:51,937] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.10 | backward_allreduce: 10.78 | step: 41.30
[default0]:[2023-08-25 18:11:52,196] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:52,197] [INFO] [logging.py:96:log_dist] [Rank 0] step=1070, skipped=0, lr=[1.1676330666666667e-06, 1.1676330666666667e-06, 1.1676330666666667e-06, 1.1676330666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:52,197] [INFO] [timer.py:215:stop] epoch=0/micro_step=1070/global_step=1070, RunningAvgSamplesPerSec=4.913179157486018, CurrSamplesPerSec=5.07375893045075, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:52,197] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.34 | backward_microstep: 109.16 | backward_inner_microstep: 98.36 | backward_allreduce_microstep: 10.71 | step_microstep: 42.03
[default0]:[2023-08-25 18:11:52,197] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.34 (forward_moe: 20.02, 1st alltoall: 0.85, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:11:52,197] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.16 | backward_inner: 98.36 | backward_allreduce: 10.71 | step: 42.03
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.6626], device='cuda:0'), 'moe loss': tensor([0.3021], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1070/439453125 | consumed samples:         1070 | consumed tokens:      2191360 | elapsed time per iteration (ms): 259.7 | learning rate: 1.168E-06 | global batch size:     1 | lm loss: 9.732510E+00 | moe loss: 6.041129E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.851 | TFLOPs: 9.57 |
[default0]:[2023-08-25 18:11:52,468] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.88 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:52,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.79 | backward_microstep: 108.90 | backward_inner_microstep: 98.06 | backward_allreduce_microstep: 10.74 | step_microstep: 41.32
[default0]:[2023-08-25 18:11:52,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.78 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:11:52,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 98.06 | backward_allreduce: 10.75 | step: 41.32
[default0]:[2023-08-25 18:11:52,699] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:52,699] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.56 | backward_microstep: 109.02 | backward_inner_microstep: 98.20 | backward_allreduce_microstep: 10.73 | step_microstep: 41.38
[default0]:[2023-08-25 18:11:52,699] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.56 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:11:52,699] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.02 | backward_inner: 98.21 | backward_allreduce: 10.73 | step: 41.39
[default0]:[2023-08-25 18:11:52,931] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:52,932] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 108.99 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.75 | step_microstep: 41.60
[default0]:[2023-08-25 18:11:52,932] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.76, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:11:52,932] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.99 | backward_inner: 98.16 | backward_allreduce: 10.75 | step: 41.61
[default0]:[2023-08-25 18:11:53,185] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.70 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:53,185] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.85 | backward_microstep: 109.02 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.72 | step_microstep: 41.48
[default0]:[2023-08-25 18:11:53,185] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.85 (forward_moe: 19.74, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:11:53,185] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.02 | backward_inner: 98.22 | backward_allreduce: 10.72 | step: 41.49
[default0]:[2023-08-25 18:11:53,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.39
[default0]:[2023-08-25 18:11:53,426] [INFO] [logging.py:96:log_dist] [Rank 0] step=1075, skipped=0, lr=[1.1730944e-06, 1.1730944e-06, 1.1730944e-06, 1.1730944e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:53,427] [INFO] [timer.py:215:stop] epoch=0/micro_step=1075/global_step=1075, RunningAvgSamplesPerSec=4.913823271539814, CurrSamplesPerSec=4.969030516924163, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:53,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.57 | backward_microstep: 111.42 | backward_inner_microstep: 100.40 | backward_allreduce_microstep: 10.92 | step_microstep: 42.70
[default0]:[2023-08-25 18:11:53,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.57 (forward_moe: 20.26, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.03)
[default0]:[2023-08-25 18:11:53,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.42 | backward_inner: 100.41 | backward_allreduce: 10.92 | step: 42.70
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.5728], device='cuda:0'), 'moe loss': tensor([0.3014], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1075/439453125 | consumed samples:         1075 | consumed tokens:      2201600 | elapsed time per iteration (ms): 246.0 | learning rate: 1.173E-06 | global batch size:     1 | lm loss: 9.714555E+00 | moe loss: 6.028959E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.064 | TFLOPs: 10.10 |
[default0]:[2023-08-25 18:11:53,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:53,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.72 | backward_microstep: 109.17 | backward_inner_microstep: 98.30 | backward_allreduce_microstep: 10.78 | step_microstep: 41.42
[default0]:[2023-08-25 18:11:53,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.72 (forward_moe: 19.78, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:11:53,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.17 | backward_inner: 98.30 | backward_allreduce: 10.78 | step: 41.42
[default0]:[2023-08-25 18:11:53,938] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.94 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:53,939] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.74 | backward_microstep: 109.12 | backward_inner_microstep: 98.27 | backward_allreduce_microstep: 10.76 | step_microstep: 42.01
[default0]:[2023-08-25 18:11:53,939] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.74 (forward_moe: 19.85, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:11:53,939] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.28 | backward_allreduce: 10.76 | step: 42.01
[default0]:[2023-08-25 18:11:54,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:54,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.58 | backward_microstep: 109.01 | backward_inner_microstep: 98.19 | backward_allreduce_microstep: 10.74 | step_microstep: 41.54
[default0]:[2023-08-25 18:11:54,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.58 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:11:54,184] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.01 | backward_inner: 98.19 | backward_allreduce: 10.74 | step: 41.55
[default0]:[2023-08-25 18:11:54,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 10.03
[default0]:[2023-08-25 18:11:54,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 109.24 | backward_inner_microstep: 98.41 | backward_allreduce_microstep: 10.74 | step_microstep: 45.60
[default0]:[2023-08-25 18:11:54,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:11:54,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.24 | backward_inner: 98.42 | backward_allreduce: 10.74 | step: 45.61
[default0]:[2023-08-25 18:11:54,677] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:11:54,677] [INFO] [logging.py:96:log_dist] [Rank 0] step=1080, skipped=0, lr=[1.1785557333333334e-06, 1.1785557333333334e-06, 1.1785557333333334e-06, 1.1785557333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:54,678] [INFO] [timer.py:215:stop] epoch=0/micro_step=1080/global_step=1080, RunningAvgSamplesPerSec=4.914440210675685, CurrSamplesPerSec=5.078335579310854, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:54,678] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 109.14 | backward_inner_microstep: 98.34 | backward_allreduce_microstep: 10.70 | step_microstep: 41.75
[default0]:[2023-08-25 18:11:54,678] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.90, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.73)
[default0]:[2023-08-25 18:11:54,678] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.14 | backward_inner: 98.35 | backward_allreduce: 10.70 | step: 41.76
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.5728], device='cuda:0'), 'moe loss': tensor([0.3014], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1080/439453125 | consumed samples:         1080 | consumed tokens:      2211840 | elapsed time per iteration (ms): 250.7 | learning rate: 1.179E-06 | global batch size:     1 | lm loss: 9.714569E+00 | moe loss: 6.028792E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.989 | TFLOPs: 9.91 |
[default0]:[2023-08-25 18:11:54,952] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:54,953] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 109.00 | backward_inner_microstep: 98.19 | backward_allreduce_microstep: 10.71 | step_microstep: 41.48
[default0]:[2023-08-25 18:11:54,953] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:11:54,953] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.20 | backward_allreduce: 10.72 | step: 41.48
[default0]:[2023-08-25 18:11:55,236] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:55,236] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.54 | backward_microstep: 109.10 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.74 | step_microstep: 41.64
[default0]:[2023-08-25 18:11:55,236] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.53 (forward_moe: 19.76, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:11:55,236] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.10 | backward_inner: 98.27 | backward_allreduce: 10.75 | step: 41.65
[default0]:[2023-08-25 18:11:55,567] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:55,567] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.58 | backward_microstep: 109.02 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.80 | step_microstep: 41.44
[default0]:[2023-08-25 18:11:55,567] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.58 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:11:55,568] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.02 | backward_inner: 98.13 | backward_allreduce: 10.81 | step: 41.44
[default0]:[2023-08-25 18:11:55,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:55,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.22 | backward_microstep: 109.12 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.77 | step_microstep: 41.46
[default0]:[2023-08-25 18:11:55,797] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.22 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:11:55,798] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.27 | backward_allreduce: 10.77 | step: 41.47
[default0]:[2023-08-25 18:11:56,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:56,024] [INFO] [logging.py:96:log_dist] [Rank 0] step=1085, skipped=0, lr=[1.1840170666666667e-06, 1.1840170666666667e-06, 1.1840170666666667e-06, 1.1840170666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:56,024] [INFO] [timer.py:215:stop] epoch=0/micro_step=1085/global_step=1085, RunningAvgSamplesPerSec=4.91514110829565, CurrSamplesPerSec=5.064361265394832, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:56,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.75 | backward_microstep: 109.09 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.82 | step_microstep: 42.08
[default0]:[2023-08-25 18:11:56,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.75 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:11:56,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.09 | backward_inner: 98.17 | backward_allreduce: 10.83 | step: 42.09
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.6029], device='cuda:0'), 'moe loss': tensor([0.3031], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1085/439453125 | consumed samples:         1085 | consumed tokens:      2222080 | elapsed time per iteration (ms): 268.7 | learning rate: 1.184E-06 | global batch size:     1 | lm loss: 9.720587E+00 | moe loss: 6.061280E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.722 | TFLOPs: 9.25 |
[default0]:[2023-08-25 18:11:56,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:56,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.41 | backward_microstep: 109.05 | backward_inner_microstep: 98.23 | backward_allreduce_microstep: 10.72 | step_microstep: 41.46
[default0]:[2023-08-25 18:11:56,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.41 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.76)
[default0]:[2023-08-25 18:11:56,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.24 | backward_allreduce: 10.73 | step: 41.46
[default0]:[2023-08-25 18:11:56,553] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:11:56,553] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.59 | backward_microstep: 108.87 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.68 | step_microstep: 41.49
[default0]:[2023-08-25 18:11:56,553] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.59 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:11:56,554] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.87 | backward_inner: 98.10 | backward_allreduce: 10.69 | step: 41.49
[default0]:[2023-08-25 18:11:56,793] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:11:56,794] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.57 | backward_microstep: 109.47 | backward_inner_microstep: 98.64 | backward_allreduce_microstep: 10.73 | step_microstep: 41.45
[default0]:[2023-08-25 18:11:56,794] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.57 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:11:56,794] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.47 | backward_inner: 98.65 | backward_allreduce: 10.73 | step: 41.46
[default0]:[2023-08-25 18:11:57,074] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.28
[default0]:[2023-08-25 18:11:57,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 109.03 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.72 | step_microstep: 41.76
[default0]:[2023-08-25 18:11:57,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.73, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:11:57,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.21 | backward_allreduce: 10.72 | step: 41.76
[default0]:[2023-08-25 18:11:57,316] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.27
[default0]:[2023-08-25 18:11:57,316] [INFO] [logging.py:96:log_dist] [Rank 0] step=1090, skipped=0, lr=[1.1894784000000002e-06, 1.1894784000000002e-06, 1.1894784000000002e-06, 1.1894784000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:57,316] [INFO] [timer.py:215:stop] epoch=0/micro_step=1090/global_step=1090, RunningAvgSamplesPerSec=4.91581261987551, CurrSamplesPerSec=5.072678939870012, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:57,316] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 109.20 | backward_inner_microstep: 98.36 | backward_allreduce_microstep: 10.74 | step_microstep: 41.87
[default0]:[2023-08-25 18:11:57,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.85, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.70)
[default0]:[2023-08-25 18:11:57,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.20 | backward_inner: 98.37 | backward_allreduce: 10.75 | step: 41.88
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.7913], device='cuda:0'), 'moe loss': tensor([0.3018], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1090/439453125 | consumed samples:         1090 | consumed tokens:      2232320 | elapsed time per iteration (ms): 258.9 | learning rate: 1.189E-06 | global batch size:     1 | lm loss: 9.758254E+00 | moe loss: 6.035845E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.863 | TFLOPs: 9.60 |
[default0]:[2023-08-25 18:11:57,589] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:57,589] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 108.94 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.71 | step_microstep: 41.65
[default0]:[2023-08-25 18:11:57,589] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.71, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:11:57,589] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.93 | backward_inner: 98.14 | backward_allreduce: 10.71 | step: 41.65
[default0]:[2023-08-25 18:11:57,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:57,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.84 | backward_microstep: 110.52 | backward_inner_microstep: 99.71 | backward_allreduce_microstep: 10.72 | step_microstep: 41.55
[default0]:[2023-08-25 18:11:57,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.84 (forward_moe: 19.85, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:11:57,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.52 | backward_inner: 99.71 | backward_allreduce: 10.73 | step: 41.56
[default0]:[2023-08-25 18:11:58,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:58,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.89 | backward_microstep: 109.52 | backward_inner_microstep: 98.66 | backward_allreduce_microstep: 10.77 | step_microstep: 42.00
[default0]:[2023-08-25 18:11:58,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.89 (forward_moe: 19.85, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:11:58,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.52 | backward_inner: 98.67 | backward_allreduce: 10.77 | step: 42.01
[default0]:[2023-08-25 18:11:58,318] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:58,318] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.90 | backward_microstep: 109.81 | backward_inner_microstep: 98.90 | backward_allreduce_microstep: 10.82 | step_microstep: 41.82
[default0]:[2023-08-25 18:11:58,318] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.90 (forward_moe: 19.91, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.83)
[default0]:[2023-08-25 18:11:58,318] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.80 | backward_inner: 98.90 | backward_allreduce: 10.82 | step: 41.82
[default0]:[2023-08-25 18:11:58,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:11:58,559] [INFO] [logging.py:96:log_dist] [Rank 0] step=1095, skipped=0, lr=[1.1949397333333335e-06, 1.1949397333333335e-06, 1.1949397333333335e-06, 1.1949397333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:58,559] [INFO] [timer.py:215:stop] epoch=0/micro_step=1095/global_step=1095, RunningAvgSamplesPerSec=4.916380684789568, CurrSamplesPerSec=5.018388656439978, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:58,560] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.24 | backward_microstep: 110.21 | backward_inner_microstep: 99.28 | backward_allreduce_microstep: 10.84 | step_microstep: 42.26
[default0]:[2023-08-25 18:11:58,560] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.24 (forward_moe: 20.00, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.87)
[default0]:[2023-08-25 18:11:58,560] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.21 | backward_inner: 99.28 | backward_allreduce: 10.84 | step: 42.27
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.1678], device='cuda:0'), 'moe loss': tensor([0.3015], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1095/439453125 | consumed samples:         1095 | consumed tokens:      2242560 | elapsed time per iteration (ms): 248.2 | learning rate: 1.195E-06 | global batch size:     1 | lm loss: 9.633561E+00 | moe loss: 6.029946E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.030 | TFLOPs: 10.01 |
[default0]:[2023-08-25 18:11:58,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.32
[default0]:[2023-08-25 18:11:58,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.12 | backward_microstep: 110.93 | backward_inner_microstep: 100.01 | backward_allreduce_microstep: 10.83 | step_microstep: 42.41
[default0]:[2023-08-25 18:11:58,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.12 (forward_moe: 20.18, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.98)
[default0]:[2023-08-25 18:11:58,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.93 | backward_inner: 100.02 | backward_allreduce: 10.83 | step: 42.41
[default0]:[2023-08-25 18:11:59,074] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:11:59,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.55 | backward_microstep: 111.13 | backward_inner_microstep: 100.16 | backward_allreduce_microstep: 10.88 | step_microstep: 42.27
[default0]:[2023-08-25 18:11:59,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.55 (forward_moe: 20.18, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.99)
[default0]:[2023-08-25 18:11:59,075] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.13 | backward_inner: 100.17 | backward_allreduce: 10.88 | step: 42.27
[default0]:[2023-08-25 18:11:59,364] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:11:59,364] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.52 | backward_microstep: 111.89 | backward_inner_microstep: 100.89 | backward_allreduce_microstep: 10.90 | step_microstep: 42.66
[default0]:[2023-08-25 18:11:59,365] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.52 (forward_moe: 20.38, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.08)
[default0]:[2023-08-25 18:11:59,365] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.88 | backward_inner: 100.90 | backward_allreduce: 10.90 | step: 42.67
[default0]:[2023-08-25 18:11:59,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.10 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:59,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.93 | backward_microstep: 112.51 | backward_inner_microstep: 101.46 | backward_allreduce_microstep: 10.96 | step_microstep: 42.78
[default0]:[2023-08-25 18:11:59,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.93 (forward_moe: 20.50, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.18)
[default0]:[2023-08-25 18:11:59,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.51 | backward_inner: 101.47 | backward_allreduce: 10.96 | step: 42.78
[default0]:[2023-08-25 18:11:59,882] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:11:59,883] [INFO] [logging.py:96:log_dist] [Rank 0] step=1100, skipped=0, lr=[1.2004010666666668e-06, 1.2004010666666668e-06, 1.2004010666666668e-06, 1.2004010666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:11:59,883] [INFO] [timer.py:215:stop] epoch=0/micro_step=1100/global_step=1100, RunningAvgSamplesPerSec=4.916519625015386, CurrSamplesPerSec=4.8842878004131665, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:11:59,883] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.55 | backward_microstep: 113.44 | backward_inner_microstep: 102.38 | backward_allreduce_microstep: 10.96 | step_microstep: 43.20
[default0]:[2023-08-25 18:11:59,883] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.55 (forward_moe: 20.88, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:11:59,883] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.44 | backward_inner: 102.39 | backward_allreduce: 10.97 | step: 43.20
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.4575], device='cuda:0'), 'moe loss': tensor([0.3006], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1100/439453125 | consumed samples:         1100 | consumed tokens:      2252800 | elapsed time per iteration (ms): 264.7 | learning rate: 1.200E-06 | global batch size:     1 | lm loss: 9.691492E+00 | moe loss: 6.011524E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.778 | TFLOPs: 9.39 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1100 | lm loss value: 9.678628E+00 | lm loss PPL: 1.597257E+04 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration    1100 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:12:03,504] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1100 is about to be saved!
[default0]:[2023-08-25 18:12:03,506] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,516] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,517] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,526] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,526] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,535] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,535] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,544] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,545] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,554] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,554] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,563] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,563] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,572] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,572] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,581] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,582] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,590] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,590] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,601] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,601] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,610] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,610] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,619] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,620] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,629] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,629] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,638] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,638] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,647] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,647] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,656] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,657] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,666] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,666] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,674] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,675] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,683] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,684] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,692] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,693] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,702] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,702] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,712] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,713] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,721] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,721] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:03,730] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:03,730] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:12:03,732] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:12:03,733] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:12:03,733] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:04,012] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:04,013] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:12:07,699] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:12:07,716] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1100/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:12:07,716] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1100 is ready now!
[default0]:  successfully saved checkpoint at iteration    1100 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.7, Latency(second): 4.217
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4217.50, 4217.50)
[default0]:[2023-08-25 18:12:07,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.16 | optimizer_step: 10.49
[default0]:[2023-08-25 18:12:07,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2293.76 | backward_microstep: 117.38 | backward_inner_microstep: 106.21 | backward_allreduce_microstep: 11.08 | step_microstep: 48.05
[default0]:[2023-08-25 18:12:07,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2293.67 (forward_moe: 21.62, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.88)
[default0]:[2023-08-25 18:12:07,971] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.38 | backward_inner: 106.22 | backward_allreduce: 11.08 | step: 48.05
[default0]:[2023-08-25 18:12:08,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.13 | optimizer_step: 6.51
[default0]:[2023-08-25 18:12:08,251] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.22 | backward_microstep: 116.78 | backward_inner_microstep: 105.69 | backward_allreduce_microstep: 10.99 | step_microstep: 43.88
[default0]:[2023-08-25 18:12:08,251] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.22 (forward_moe: 21.53, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.76)
[default0]:[2023-08-25 18:12:08,251] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.78 | backward_inner: 105.70 | backward_allreduce: 11.00 | step: 43.88
[default0]:[2023-08-25 18:12:08,509] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.14 | optimizer_step: 6.51
[default0]:[2023-08-25 18:12:08,510] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.04 | backward_microstep: 116.69 | backward_inner_microstep: 105.56 | backward_allreduce_microstep: 11.03 | step_microstep: 44.36
[default0]:[2023-08-25 18:12:08,510] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.04 (forward_moe: 21.48, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.81)
[default0]:[2023-08-25 18:12:08,510] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.69 | backward_inner: 105.57 | backward_allreduce: 11.03 | step: 44.36
[default0]:[2023-08-25 18:12:08,789] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:12:08,789] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.71 | backward_microstep: 112.65 | backward_inner_microstep: 101.53 | backward_allreduce_microstep: 11.02 | step_microstep: 43.13
[default0]:[2023-08-25 18:12:08,789] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.71 (forward_moe: 20.51, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.19)
[default0]:[2023-08-25 18:12:08,789] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.65 | backward_inner: 101.54 | backward_allreduce: 11.03 | step: 43.13
[default0]:[2023-08-25 18:12:09,036] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.40
[default0]:[2023-08-25 18:12:09,037] [INFO] [logging.py:96:log_dist] [Rank 0] step=1105, skipped=0, lr=[1.2058624000000002e-06, 1.2058624000000002e-06, 1.2058624000000002e-06, 1.2058624000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:09,037] [INFO] [timer.py:215:stop] epoch=0/micro_step=1105/global_step=1105, RunningAvgSamplesPerSec=4.915813877856682, CurrSamplesPerSec=4.863485570038277, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:09,037] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.47 | backward_microstep: 113.49 | backward_inner_microstep: 102.37 | backward_allreduce_microstep: 11.03 | step_microstep: 44.12
[default0]:[2023-08-25 18:12:09,037] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.47 (forward_moe: 20.72, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.32)
[default0]:[2023-08-25 18:12:09,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.49 | backward_inner: 102.37 | backward_allreduce: 11.03 | step: 44.12
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.0567], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1105/439453125 | consumed samples:         1105 | consumed tokens:      2263040 | elapsed time per iteration (ms): 1830.9 | learning rate: 1.206E-06 | global batch size:     1 | lm loss: 9.611338E+00 | moe loss: 6.014174E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.546 | TFLOPs: 1.36 |
[default0]:[2023-08-25 18:12:09,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:12:09,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.59 | backward_microstep: 113.89 | backward_inner_microstep: 102.76 | backward_allreduce_microstep: 11.04 | step_microstep: 43.14
[default0]:[2023-08-25 18:12:09,310] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.59 (forward_moe: 20.86, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.31)
[default0]:[2023-08-25 18:12:09,310] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.89 | backward_inner: 102.77 | backward_allreduce: 11.04 | step: 43.14
[default0]:[2023-08-25 18:12:09,568] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.39
[default0]:[2023-08-25 18:12:09,569] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.60 | backward_microstep: 111.78 | backward_inner_microstep: 100.82 | backward_allreduce_microstep: 10.86 | step_microstep: 43.01
[default0]:[2023-08-25 18:12:09,569] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.60 (forward_moe: 20.46, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.10)
[default0]:[2023-08-25 18:12:09,569] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.77 | backward_inner: 100.83 | backward_allreduce: 10.86 | step: 43.02
[default0]:[2023-08-25 18:12:09,830] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:09,831] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.91 | backward_microstep: 111.92 | backward_inner_microstep: 100.92 | backward_allreduce_microstep: 10.90 | step_microstep: 42.78
[default0]:[2023-08-25 18:12:09,831] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.90 (forward_moe: 20.45, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.09)
[default0]:[2023-08-25 18:12:09,831] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.92 | backward_inner: 100.93 | backward_allreduce: 10.90 | step: 42.78
[default0]:[2023-08-25 18:12:10,060] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:12:10,061] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.94 | backward_microstep: 111.80 | backward_inner_microstep: 100.80 | backward_allreduce_microstep: 10.90 | step_microstep: 42.27
[default0]:[2023-08-25 18:12:10,061] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.94 (forward_moe: 20.37, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.08)
[default0]:[2023-08-25 18:12:10,062] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.80 | backward_inner: 100.80 | backward_allreduce: 10.91 | step: 42.27
[default0]:[2023-08-25 18:12:10,337] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:12:10,337] [INFO] [logging.py:96:log_dist] [Rank 0] step=1110, skipped=0, lr=[1.2113237333333333e-06, 1.2113237333333333e-06, 1.2113237333333333e-06, 1.2113237333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:10,337] [INFO] [timer.py:215:stop] epoch=0/micro_step=1110/global_step=1110, RunningAvgSamplesPerSec=4.915167620141108, CurrSamplesPerSec=4.257511008431169, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:10,337] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 78.79 | backward_microstep: 112.61 | backward_inner_microstep: 101.28 | backward_allreduce_microstep: 11.24 | step_microstep: 42.91
[default0]:[2023-08-25 18:12:10,337] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 78.79 (forward_moe: 20.52, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.11)
[default0]:[2023-08-25 18:12:10,338] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.61 | backward_inner: 101.28 | backward_allreduce: 11.24 | step: 42.92
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.3486], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1110/439453125 | consumed samples:         1110 | consumed tokens:      2273280 | elapsed time per iteration (ms): 260.2 | learning rate: 1.211E-06 | global batch size:     1 | lm loss: 9.669728E+00 | moe loss: 6.015375E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.844 | TFLOPs: 9.55 |
[default0]:[2023-08-25 18:12:10,590] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:10,590] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.72 | backward_microstep: 110.29 | backward_inner_microstep: 99.44 | backward_allreduce_microstep: 10.76 | step_microstep: 41.95
[default0]:[2023-08-25 18:12:10,590] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.72 (forward_moe: 20.02, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.91)
[default0]:[2023-08-25 18:12:10,590] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.29 | backward_inner: 99.45 | backward_allreduce: 10.76 | step: 41.95
[default0]:[2023-08-25 18:12:10,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.34
[default0]:[2023-08-25 18:12:10,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.15 | backward_microstep: 110.49 | backward_inner_microstep: 99.60 | backward_allreduce_microstep: 10.79 | step_microstep: 41.98
[default0]:[2023-08-25 18:12:10,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.14 (forward_moe: 20.08, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.91)
[default0]:[2023-08-25 18:12:10,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.49 | backward_inner: 99.61 | backward_allreduce: 10.80 | step: 41.98
[default0]:[2023-08-25 18:12:11,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:11,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.47 | backward_microstep: 111.05 | backward_inner_microstep: 100.11 | backward_allreduce_microstep: 10.85 | step_microstep: 41.84
[default0]:[2023-08-25 18:12:11,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.47 (forward_moe: 20.04, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.89)
[default0]:[2023-08-25 18:12:11,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.05 | backward_inner: 100.12 | backward_allreduce: 10.85 | step: 41.84
[default0]:[2023-08-25 18:12:11,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:11,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.41 | backward_microstep: 110.53 | backward_inner_microstep: 99.60 | backward_allreduce_microstep: 10.85 | step_microstep: 42.00
[default0]:[2023-08-25 18:12:11,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.41 (forward_moe: 20.06, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.93)
[default0]:[2023-08-25 18:12:11,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.53 | backward_inner: 99.60 | backward_allreduce: 10.85 | step: 42.00
[default0]:[2023-08-25 18:12:11,581] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:11,581] [INFO] [logging.py:96:log_dist] [Rank 0] step=1115, skipped=0, lr=[1.2167850666666666e-06, 1.2167850666666666e-06, 1.2167850666666666e-06, 1.2167850666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:11,582] [INFO] [timer.py:215:stop] epoch=0/micro_step=1115/global_step=1115, RunningAvgSamplesPerSec=4.915482815193771, CurrSamplesPerSec=5.0103616420945, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:11,582] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.35 | backward_microstep: 110.34 | backward_inner_microstep: 99.44 | backward_allreduce_microstep: 10.80 | step_microstep: 42.35
[default0]:[2023-08-25 18:12:11,582] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.35 (forward_moe: 20.13, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.98)
[default0]:[2023-08-25 18:12:11,582] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.34 | backward_inner: 99.45 | backward_allreduce: 10.81 | step: 42.35
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.5497], device='cuda:0'), 'moe loss': tensor([0.3012], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1115/439453125 | consumed samples:         1115 | consumed tokens:      2283520 | elapsed time per iteration (ms): 248.9 | learning rate: 1.217E-06 | global batch size:     1 | lm loss: 9.509949E+00 | moe loss: 6.023399E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.018 | TFLOPs: 9.98 |
[default0]:[2023-08-25 18:12:11,835] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:11,835] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.03 | backward_microstep: 110.37 | backward_inner_microstep: 99.47 | backward_allreduce_microstep: 10.80 | step_microstep: 42.02
[default0]:[2023-08-25 18:12:11,835] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.03 (forward_moe: 20.07, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.94)
[default0]:[2023-08-25 18:12:11,835] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.37 | backward_inner: 99.48 | backward_allreduce: 10.81 | step: 42.02
[default0]:[2023-08-25 18:12:12,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:12,077] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.12 | backward_microstep: 110.38 | backward_inner_microstep: 99.47 | backward_allreduce_microstep: 10.81 | step_microstep: 41.81
[default0]:[2023-08-25 18:12:12,077] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.12 (forward_moe: 20.02, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.88)
[default0]:[2023-08-25 18:12:12,077] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.38 | backward_inner: 99.48 | backward_allreduce: 10.81 | step: 41.82
[default0]:[2023-08-25 18:12:12,340] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:12,340] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 110.50 | backward_inner_microstep: 99.57 | backward_allreduce_microstep: 10.83 | step_microstep: 42.03
[default0]:[2023-08-25 18:12:12,340] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.00 (forward_moe: 20.03, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.91)
[default0]:[2023-08-25 18:12:12,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.49 | backward_inner: 99.57 | backward_allreduce: 10.84 | step: 42.04
[default0]:[2023-08-25 18:12:12,575] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:12:12,576] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.73 | backward_microstep: 109.00 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.74 | step_microstep: 41.49
[default0]:[2023-08-25 18:12:12,576] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.72 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.75)
[default0]:[2023-08-25 18:12:12,576] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.99 | backward_inner: 98.17 | backward_allreduce: 10.74 | step: 41.49
[default0]:[2023-08-25 18:12:12,815] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:12:12,816] [INFO] [logging.py:96:log_dist] [Rank 0] step=1120, skipped=0, lr=[1.2222464e-06, 1.2222464e-06, 1.2222464e-06, 1.2222464e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:12,816] [INFO] [timer.py:215:stop] epoch=0/micro_step=1120/global_step=1120, RunningAvgSamplesPerSec=4.91599333704387, CurrSamplesPerSec=5.032158368326335, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:12,816] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.80 | backward_microstep: 110.68 | backward_inner_microstep: 99.87 | backward_allreduce_microstep: 10.71 | step_microstep: 41.70
[default0]:[2023-08-25 18:12:12,816] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.80 (forward_moe: 19.95, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.79)
[default0]:[2023-08-25 18:12:12,816] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.68 | backward_inner: 99.88 | backward_allreduce: 10.71 | step: 41.70
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.5430], device='cuda:0'), 'moe loss': tensor([0.2999], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1120/439453125 | consumed samples:         1120 | consumed tokens:      2293760 | elapsed time per iteration (ms): 246.7 | learning rate: 1.222E-06 | global batch size:     1 | lm loss: 9.508595E+00 | moe loss: 5.998111E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.054 | TFLOPs: 10.07 |
[default0]:[2023-08-25 18:12:13,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.88 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:13,067] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.38 | backward_microstep: 108.94 | backward_inner_microstep: 98.12 | backward_allreduce_microstep: 10.73 | step_microstep: 41.58
[default0]:[2023-08-25 18:12:13,067] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.37 (forward_moe: 19.85, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:12:13,067] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.94 | backward_inner: 98.12 | backward_allreduce: 10.73 | step: 41.58
[default0]:[2023-08-25 18:12:13,307] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.88 | optimizer_step: 6.29
[default0]:[2023-08-25 18:12:13,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 109.97 | backward_inner_microstep: 99.13 | backward_allreduce_microstep: 10.75 | step_microstep: 41.42
[default0]:[2023-08-25 18:12:13,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.70 (forward_moe: 19.87, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.84)
[default0]:[2023-08-25 18:12:13,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.97 | backward_inner: 99.14 | backward_allreduce: 10.75 | step: 41.42
[default0]:[2023-08-25 18:12:13,542] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:13,542] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.58 | backward_microstep: 108.98 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.73 | step_microstep: 41.44
[default0]:[2023-08-25 18:12:13,544] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.58 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:12:13,544] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.98 | backward_inner: 98.16 | backward_allreduce: 10.74 | step: 41.44
[default0]:[2023-08-25 18:12:14,230] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.72 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:14,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 68.89 | backward_microstep: 109.25 | backward_inner_microstep: 98.36 | backward_allreduce_microstep: 10.80 | step_microstep: 44.33
[default0]:[2023-08-25 18:12:14,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 68.89 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:12:14,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.25 | backward_inner: 98.36 | backward_allreduce: 10.80 | step: 44.33
[default0]:[2023-08-25 18:12:14,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:12:14,470] [INFO] [logging.py:96:log_dist] [Rank 0] step=1125, skipped=0, lr=[1.2277077333333334e-06, 1.2277077333333334e-06, 1.2277077333333334e-06, 1.2277077333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:14,471] [INFO] [timer.py:215:stop] epoch=0/micro_step=1125/global_step=1125, RunningAvgSamplesPerSec=4.916108536489017, CurrSamplesPerSec=5.075613168047011, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:14,471] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.74 | backward_microstep: 109.02 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.75 | step_microstep: 41.73
[default0]:[2023-08-25 18:12:14,471] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.74 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:12:14,471] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.02 | backward_inner: 98.18 | backward_allreduce: 10.76 | step: 41.74
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.1257], device='cuda:0'), 'moe loss': tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1125/439453125 | consumed samples:         1125 | consumed tokens:      2304000 | elapsed time per iteration (ms): 331.0 | learning rate: 1.228E-06 | global batch size:     1 | lm loss: 9.625140E+00 | moe loss: 6.009895E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.021 | TFLOPs: 7.51 |
[default0]:[2023-08-25 18:12:14,722] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.34
[default0]:[2023-08-25 18:12:14,723] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.48 | backward_microstep: 109.36 | backward_inner_microstep: 98.47 | backward_allreduce_microstep: 10.80 | step_microstep: 41.37
[default0]:[2023-08-25 18:12:14,723] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.82, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:12:14,723] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.36 | backward_inner: 98.47 | backward_allreduce: 10.80 | step: 41.37
[default0]:[2023-08-25 18:12:14,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:14,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.48 | backward_microstep: 109.09 | backward_inner_microstep: 98.28 | backward_allreduce_microstep: 10.71 | step_microstep: 41.55
[default0]:[2023-08-25 18:12:14,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:12:14,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.28 | backward_allreduce: 10.71 | step: 41.55
[default0]:[2023-08-25 18:12:15,222] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:15,222] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.81 | backward_microstep: 108.91 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.73 | step_microstep: 41.43
[default0]:[2023-08-25 18:12:15,222] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.80 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:12:15,222] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.91 | backward_inner: 98.09 | backward_allreduce: 10.73 | step: 41.43
[default0]:[2023-08-25 18:12:15,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.36
[default0]:[2023-08-25 18:12:15,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.56 | backward_microstep: 110.33 | backward_inner_microstep: 99.31 | backward_allreduce_microstep: 10.92 | step_microstep: 42.42
[default0]:[2023-08-25 18:12:15,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.56 (forward_moe: 20.05, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.92)
[default0]:[2023-08-25 18:12:15,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.32 | backward_inner: 99.32 | backward_allreduce: 10.92 | step: 42.43
[default0]:[2023-08-25 18:12:15,706] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:12:15,706] [INFO] [logging.py:96:log_dist] [Rank 0] step=1130, skipped=0, lr=[1.2331690666666667e-06, 1.2331690666666667e-06, 1.2331690666666667e-06, 1.2331690666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:15,706] [INFO] [timer.py:215:stop] epoch=0/micro_step=1130/global_step=1130, RunningAvgSamplesPerSec=4.916641433655351, CurrSamplesPerSec=4.945302597805313, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:15,707] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.64 | backward_microstep: 112.29 | backward_inner_microstep: 101.29 | backward_allreduce_microstep: 10.90 | step_microstep: 42.71
[default0]:[2023-08-25 18:12:15,707] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.64 (forward_moe: 20.60, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.08)
[default0]:[2023-08-25 18:12:15,707] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.29 | backward_inner: 101.30 | backward_allreduce: 10.91 | step: 42.71
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.9202], device='cuda:0'), 'moe loss': tensor([0.3024], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1130/439453125 | consumed samples:         1130 | consumed tokens:      2314240 | elapsed time per iteration (ms): 246.9 | learning rate: 1.233E-06 | global batch size:     1 | lm loss: 9.584035E+00 | moe loss: 6.047233E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.050 | TFLOPs: 10.06 |
[default0]:[2023-08-25 18:12:15,966] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:12:15,966] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.79 | backward_microstep: 112.40 | backward_inner_microstep: 101.41 | backward_allreduce_microstep: 10.89 | step_microstep: 42.53
[default0]:[2023-08-25 18:12:15,966] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.50, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.18)
[default0]:[2023-08-25 18:12:15,966] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.40 | backward_inner: 101.42 | backward_allreduce: 10.90 | step: 42.54
[default0]:[2023-08-25 18:12:16,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.84 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:16,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 109.36 | backward_inner_microstep: 98.49 | backward_allreduce_microstep: 10.77 | step_microstep: 41.80
[default0]:[2023-08-25 18:12:16,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.00 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.77)
[default0]:[2023-08-25 18:12:16,232] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.36 | backward_inner: 98.49 | backward_allreduce: 10.77 | step: 41.80
[default0]:[2023-08-25 18:12:16,467] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:16,468] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 109.31 | backward_inner_microstep: 98.46 | backward_allreduce_microstep: 10.75 | step_microstep: 41.68
[default0]:[2023-08-25 18:12:16,468] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:12:16,468] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.30 | backward_inner: 98.47 | backward_allreduce: 10.75 | step: 41.68
[default0]:[2023-08-25 18:12:16,719] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:16,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.92 | backward_microstep: 113.17 | backward_inner_microstep: 102.14 | backward_allreduce_microstep: 10.93 | step_microstep: 41.78
[default0]:[2023-08-25 18:12:16,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.92 (forward_moe: 20.56, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.00)
[default0]:[2023-08-25 18:12:16,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.17 | backward_inner: 102.15 | backward_allreduce: 10.93 | step: 41.79
[default0]:[2023-08-25 18:12:17,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:17,007] [INFO] [logging.py:96:log_dist] [Rank 0] step=1135, skipped=0, lr=[1.2386304e-06, 1.2386304e-06, 1.2386304e-06, 1.2386304e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:17,007] [INFO] [timer.py:215:stop] epoch=0/micro_step=1135/global_step=1135, RunningAvgSamplesPerSec=4.917066392600811, CurrSamplesPerSec=5.065015644378107, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:17,007] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.63 | backward_microstep: 109.23 | backward_inner_microstep: 98.40 | backward_allreduce_microstep: 10.73 | step_microstep: 42.04
[default0]:[2023-08-25 18:12:17,007] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.63 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.80)
[default0]:[2023-08-25 18:12:17,007] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.23 | backward_inner: 98.41 | backward_allreduce: 10.73 | step: 42.04
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.9739], device='cuda:0'), 'moe loss': tensor([0.3022], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1135/439453125 | consumed samples:         1135 | consumed tokens:      2324480 | elapsed time per iteration (ms): 260.1 | learning rate: 1.239E-06 | global batch size:     1 | lm loss: 9.594778E+00 | moe loss: 6.043147E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.844 | TFLOPs: 9.55 |
[default0]:[2023-08-25 18:12:17,282] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:12:17,283] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 109.37 | backward_inner_microstep: 98.54 | backward_allreduce_microstep: 10.74 | step_microstep: 41.82
[default0]:[2023-08-25 18:12:17,283] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.92, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:12:17,283] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.37 | backward_inner: 98.55 | backward_allreduce: 10.74 | step: 41.82
[default0]:[2023-08-25 18:12:17,534] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:12:17,534] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.78 | backward_microstep: 109.18 | backward_inner_microstep: 98.32 | backward_allreduce_microstep: 10.77 | step_microstep: 41.61
[default0]:[2023-08-25 18:12:17,535] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.78 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.77)
[default0]:[2023-08-25 18:12:17,535] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.18 | backward_inner: 98.33 | backward_allreduce: 10.77 | step: 41.62
[default0]:[2023-08-25 18:12:17,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:12:17,781] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 112.35 | backward_inner_microstep: 100.87 | backward_allreduce_microstep: 11.38 | step_microstep: 45.17
[default0]:[2023-08-25 18:12:17,781] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 20.44, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.01)
[default0]:[2023-08-25 18:12:17,781] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.35 | backward_inner: 100.88 | backward_allreduce: 11.38 | step: 45.18
[default0]:[2023-08-25 18:12:18,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 9.75
[default0]:[2023-08-25 18:12:18,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.34 | backward_microstep: 111.72 | backward_inner_microstep: 100.70 | backward_allreduce_microstep: 10.92 | step_microstep: 45.32
[default0]:[2023-08-25 18:12:18,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.34 (forward_moe: 21.42, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 9.35)
[default0]:[2023-08-25 18:12:18,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.72 | backward_inner: 100.71 | backward_allreduce: 10.92 | step: 45.33
[default0]:[2023-08-25 18:12:18,284] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.94 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:18,284] [INFO] [logging.py:96:log_dist] [Rank 0] step=1140, skipped=0, lr=[1.2440917333333334e-06, 1.2440917333333334e-06, 1.2440917333333334e-06, 1.2440917333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:18,285] [INFO] [timer.py:215:stop] epoch=0/micro_step=1140/global_step=1140, RunningAvgSamplesPerSec=4.917291259860069, CurrSamplesPerSec=4.994087067514116, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:18,285] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.31 | backward_microstep: 110.84 | backward_inner_microstep: 99.89 | backward_allreduce_microstep: 10.85 | step_microstep: 42.53
[default0]:[2023-08-25 18:12:18,285] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.31 (forward_moe: 20.22, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.91)
[default0]:[2023-08-25 18:12:18,285] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.84 | backward_inner: 99.90 | backward_allreduce: 10.85 | step: 42.53
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.9156], device='cuda:0'), 'moe loss': tensor([0.3026], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1140/439453125 | consumed samples:         1140 | consumed tokens:      2334720 | elapsed time per iteration (ms): 255.9 | learning rate: 1.244E-06 | global batch size:     1 | lm loss: 9.583120E+00 | moe loss: 6.052369E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.908 | TFLOPs: 9.71 |
[default0]:[2023-08-25 18:12:18,565] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:18,565] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.66 | backward_microstep: 111.42 | backward_inner_microstep: 100.50 | backward_allreduce_microstep: 10.82 | step_microstep: 42.17
[default0]:[2023-08-25 18:12:18,566] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.66 (forward_moe: 20.26, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.03)
[default0]:[2023-08-25 18:12:18,566] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.42 | backward_inner: 100.51 | backward_allreduce: 10.83 | step: 42.17
[default0]:[2023-08-25 18:12:18,792] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:18,792] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.72 | backward_microstep: 109.90 | backward_inner_microstep: 99.05 | backward_allreduce_microstep: 10.75 | step_microstep: 41.67
[default0]:[2023-08-25 18:12:18,792] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.72 (forward_moe: 19.97, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:12:18,792] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.90 | backward_inner: 99.06 | backward_allreduce: 10.76 | step: 41.67
[default0]:[2023-08-25 18:12:19,036] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.36
[default0]:[2023-08-25 18:12:19,037] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.80 | backward_microstep: 109.66 | backward_inner_microstep: 98.76 | backward_allreduce_microstep: 10.80 | step_microstep: 42.43
[default0]:[2023-08-25 18:12:19,037] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.80 (forward_moe: 19.89, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:12:19,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.66 | backward_inner: 98.77 | backward_allreduce: 10.81 | step: 42.43
[default0]:[2023-08-25 18:12:19,291] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:19,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.03 | backward_microstep: 109.94 | backward_inner_microstep: 99.11 | backward_allreduce_microstep: 10.75 | step_microstep: 41.67
[default0]:[2023-08-25 18:12:19,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.03 (forward_moe: 19.95, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.84)
[default0]:[2023-08-25 18:12:19,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.94 | backward_inner: 99.11 | backward_allreduce: 10.75 | step: 41.67
[default0]:[2023-08-25 18:12:19,534] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:19,534] [INFO] [logging.py:96:log_dist] [Rank 0] step=1145, skipped=0, lr=[1.2495530666666667e-06, 1.2495530666666667e-06, 1.2495530666666667e-06, 1.2495530666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:19,534] [INFO] [timer.py:215:stop] epoch=0/micro_step=1145/global_step=1145, RunningAvgSamplesPerSec=4.917742951488723, CurrSamplesPerSec=5.04630133162649, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:19,534] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.71 | backward_microstep: 109.76 | backward_inner_microstep: 98.90 | backward_allreduce_microstep: 10.76 | step_microstep: 42.16
[default0]:[2023-08-25 18:12:19,535] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.71 (forward_moe: 19.92, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:12:19,535] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.75 | backward_inner: 98.90 | backward_allreduce: 10.77 | step: 42.17
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.0718], device='cuda:0'), 'moe loss': tensor([0.3023], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1145/439453125 | consumed samples:         1145 | consumed tokens:      2344960 | elapsed time per iteration (ms): 250.0 | learning rate: 1.250E-06 | global batch size:     1 | lm loss: 9.614355E+00 | moe loss: 6.046733E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.000 | TFLOPs: 9.94 |
[default0]:[2023-08-25 18:12:19,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:19,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.08 | backward_microstep: 111.63 | backward_inner_microstep: 100.14 | backward_allreduce_microstep: 11.39 | step_microstep: 42.53
[default0]:[2023-08-25 18:12:19,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.08 (forward_moe: 20.18, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.88)
[default0]:[2023-08-25 18:12:19,809] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.63 | backward_inner: 100.15 | backward_allreduce: 11.40 | step: 42.53
[default0]:[2023-08-25 18:12:20,045] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:20,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.07 | backward_microstep: 109.73 | backward_inner_microstep: 98.84 | backward_allreduce_microstep: 10.79 | step_microstep: 41.77
[default0]:[2023-08-25 18:12:20,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.07 (forward_moe: 19.90, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:12:20,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.73 | backward_inner: 98.85 | backward_allreduce: 10.79 | step: 41.78
[default0]:[2023-08-25 18:12:20,297] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.29
[default0]:[2023-08-25 18:12:20,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 114.24 | backward_inner_microstep: 103.40 | backward_allreduce_microstep: 10.74 | step_microstep: 43.62
[default0]:[2023-08-25 18:12:20,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.00 (forward_moe: 19.93, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:12:20,300] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.23 | backward_inner: 103.40 | backward_allreduce: 10.75 | step: 43.63
[default0]:[2023-08-25 18:12:20,576] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:12:20,577] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.79 | backward_microstep: 113.05 | backward_inner_microstep: 101.99 | backward_allreduce_microstep: 10.96 | step_microstep: 43.00
[default0]:[2023-08-25 18:12:20,577] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.73, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.36)
[default0]:[2023-08-25 18:12:20,577] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.04 | backward_inner: 101.99 | backward_allreduce: 10.97 | step: 43.00
[default0]:[2023-08-25 18:12:20,819] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:20,819] [INFO] [logging.py:96:log_dist] [Rank 0] step=1150, skipped=0, lr=[1.2550144e-06, 1.2550144e-06, 1.2550144e-06, 1.2550144e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:20,819] [INFO] [timer.py:215:stop] epoch=0/micro_step=1150/global_step=1150, RunningAvgSamplesPerSec=4.917891767951382, CurrSamplesPerSec=4.953245179674981, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:20,820] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.53 | backward_microstep: 112.31 | backward_inner_microstep: 101.33 | backward_allreduce_microstep: 10.89 | step_microstep: 42.50
[default0]:[2023-08-25 18:12:20,820] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.53 (forward_moe: 20.56, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.06)
[default0]:[2023-08-25 18:12:20,820] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.31 | backward_inner: 101.33 | backward_allreduce: 10.89 | step: 42.51
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.9840], device='cuda:0'), 'moe loss': tensor([0.3014], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1150/439453125 | consumed samples:         1150 | consumed tokens:      2355200 | elapsed time per iteration (ms): 257.1 | learning rate: 1.255E-06 | global batch size:     1 | lm loss: 9.596791E+00 | moe loss: 6.028008E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.890 | TFLOPs: 9.67 |
[default0]:[2023-08-25 18:12:21,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:21,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.12 | backward_microstep: 111.42 | backward_inner_microstep: 100.47 | backward_allreduce_microstep: 10.86 | step_microstep: 42.14
[default0]:[2023-08-25 18:12:21,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.12 (forward_moe: 20.10, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.93)
[default0]:[2023-08-25 18:12:21,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.42 | backward_inner: 100.48 | backward_allreduce: 10.86 | step: 42.14
[default0]:[2023-08-25 18:12:21,347] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:21,348] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.58 | backward_microstep: 111.08 | backward_inner_microstep: 100.13 | backward_allreduce_microstep: 10.86 | step_microstep: 42.46
[default0]:[2023-08-25 18:12:21,348] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.58 (forward_moe: 20.38, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.22)
[default0]:[2023-08-25 18:12:21,349] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.08 | backward_inner: 100.14 | backward_allreduce: 10.86 | step: 42.46
[default0]:[2023-08-25 18:12:21,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:21,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.27 | backward_microstep: 110.69 | backward_inner_microstep: 99.76 | backward_allreduce_microstep: 10.83 | step_microstep: 42.03
[default0]:[2023-08-25 18:12:21,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.27 (forward_moe: 20.14, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.98)
[default0]:[2023-08-25 18:12:21,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.69 | backward_inner: 99.68 | backward_allreduce: 10.84 | step: 42.03
[default0]:[2023-08-25 18:12:21,924] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:21,924] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.36 | backward_microstep: 110.80 | backward_inner_microstep: 99.88 | backward_allreduce_microstep: 10.83 | step_microstep: 42.06
[default0]:[2023-08-25 18:12:21,924] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.36 (forward_moe: 20.16, 1st alltoall: 0.91, 2nd alltoall: 0.80, top-k: 7.95)
[default0]:[2023-08-25 18:12:21,924] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.79 | backward_inner: 99.88 | backward_allreduce: 10.83 | step: 42.06
[default0]:[2023-08-25 18:12:22,162] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:22,162] [INFO] [logging.py:96:log_dist] [Rank 0] step=1155, skipped=0, lr=[1.2604757333333333e-06, 1.2604757333333333e-06, 1.2604757333333333e-06, 1.2604757333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:22,163] [INFO] [timer.py:215:stop] epoch=0/micro_step=1155/global_step=1155, RunningAvgSamplesPerSec=4.918210202644773, CurrSamplesPerSec=4.993581676764622, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:22,163] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.87 | backward_microstep: 110.48 | backward_inner_microstep: 99.55 | backward_allreduce_microstep: 10.83 | step_microstep: 42.38
[default0]:[2023-08-25 18:12:22,163] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.87 (forward_moe: 20.11, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.93)
[default0]:[2023-08-25 18:12:22,163] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.48 | backward_inner: 99.56 | backward_allreduce: 10.84 | step: 42.38
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([49.1918], device='cuda:0'), 'moe loss': tensor([0.3021], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1155/439453125 | consumed samples:         1155 | consumed tokens:      2365440 | elapsed time per iteration (ms): 268.6 | learning rate: 1.260E-06 | global batch size:     1 | lm loss: 9.838367E+00 | moe loss: 6.041114E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.723 | TFLOPs: 9.25 |
[default0]:[2023-08-25 18:12:22,487] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:12:22,487] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.49 | backward_microstep: 111.86 | backward_inner_microstep: 100.75 | backward_allreduce_microstep: 11.01 | step_microstep: 42.94
[default0]:[2023-08-25 18:12:22,487] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.49 (forward_moe: 20.37, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:12:22,488] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.86 | backward_inner: 100.76 | backward_allreduce: 11.02 | step: 42.94
[default0]:[2023-08-25 18:12:22,737] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.06 | optimizer_step: 6.41
[default0]:[2023-08-25 18:12:22,738] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.39 | backward_microstep: 113.94 | backward_inner_microstep: 102.77 | backward_allreduce_microstep: 11.07 | step_microstep: 43.02
[default0]:[2023-08-25 18:12:22,738] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.39 (forward_moe: 20.79, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.35)
[default0]:[2023-08-25 18:12:22,738] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.93 | backward_inner: 102.77 | backward_allreduce: 11.08 | step: 43.02
[default0]:[2023-08-25 18:12:22,995] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.07 | optimizer_step: 6.42
[default0]:[2023-08-25 18:12:22,995] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.12 | backward_microstep: 114.42 | backward_inner_microstep: 103.27 | backward_allreduce_microstep: 11.06 | step_microstep: 43.17
[default0]:[2023-08-25 18:12:22,995] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.12 (forward_moe: 20.93, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.42)
[default0]:[2023-08-25 18:12:22,995] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.42 | backward_inner: 103.27 | backward_allreduce: 11.06 | step: 43.17
[default0]:[2023-08-25 18:12:23,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.69 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:23,249] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.09 | backward_microstep: 111.27 | backward_inner_microstep: 99.98 | backward_allreduce_microstep: 11.19 | step_microstep: 42.01
[default0]:[2023-08-25 18:12:23,249] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.09 (forward_moe: 20.41, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.93)
[default0]:[2023-08-25 18:12:23,249] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.27 | backward_inner: 99.99 | backward_allreduce: 11.20 | step: 42.01
[default0]:[2023-08-25 18:12:23,505] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:23,505] [INFO] [logging.py:96:log_dist] [Rank 0] step=1160, skipped=0, lr=[1.2659370666666666e-06, 1.2659370666666666e-06, 1.2659370666666666e-06, 1.2659370666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:23,505] [INFO] [timer.py:215:stop] epoch=0/micro_step=1160/global_step=1160, RunningAvgSamplesPerSec=4.918267292408137, CurrSamplesPerSec=5.0027063228241175, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:23,505] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.50 | backward_microstep: 110.60 | backward_inner_microstep: 99.70 | backward_allreduce_microstep: 10.80 | step_microstep: 42.29
[default0]:[2023-08-25 18:12:23,505] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.50 (forward_moe: 20.24, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.95)
[default0]:[2023-08-25 18:12:23,506] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.59 | backward_inner: 99.71 | backward_allreduce: 10.80 | step: 42.29
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.5735], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1160/439453125 | consumed samples:         1160 | consumed tokens:      2375680 | elapsed time per iteration (ms): 268.3 | learning rate: 1.266E-06 | global batch size:     1 | lm loss: 9.514700E+00 | moe loss: 6.019503E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.727 | TFLOPs: 9.26 |
[default0]:[2023-08-25 18:12:23,762] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:23,762] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.14 | backward_microstep: 110.29 | backward_inner_microstep: 99.43 | backward_allreduce_microstep: 10.77 | step_microstep: 42.01
[default0]:[2023-08-25 18:12:23,763] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.14 (forward_moe: 20.02, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.89)
[default0]:[2023-08-25 18:12:23,763] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.29 | backward_inner: 99.43 | backward_allreduce: 10.78 | step: 42.01
[default0]:[2023-08-25 18:12:24,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:24,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.24 | backward_microstep: 110.32 | backward_inner_microstep: 99.45 | backward_allreduce_microstep: 10.77 | step_microstep: 41.83
[default0]:[2023-08-25 18:12:24,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.23 (forward_moe: 20.17, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 8.01)
[default0]:[2023-08-25 18:12:24,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.31 | backward_inner: 99.46 | backward_allreduce: 10.77 | step: 41.83
[default0]:[2023-08-25 18:12:24,275] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:12:24,276] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.95 | backward_microstep: 109.05 | backward_inner_microstep: 98.22 | backward_allreduce_microstep: 10.74 | step_microstep: 41.74
[default0]:[2023-08-25 18:12:24,276] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.95 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.76)
[default0]:[2023-08-25 18:12:24,276] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.23 | backward_allreduce: 10.74 | step: 41.74
[default0]:[2023-08-25 18:12:24,515] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:24,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.69 | backward_microstep: 109.13 | backward_inner_microstep: 98.31 | backward_allreduce_microstep: 10.73 | step_microstep: 41.45
[default0]:[2023-08-25 18:12:24,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.95, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.73)
[default0]:[2023-08-25 18:12:24,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.13 | backward_inner: 98.32 | backward_allreduce: 10.74 | step: 41.45
[default0]:[2023-08-25 18:12:24,822] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:12:24,822] [INFO] [logging.py:96:log_dist] [Rank 0] step=1165, skipped=0, lr=[1.2713984000000001e-06, 1.2713984000000001e-06, 1.2713984000000001e-06, 1.2713984000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:24,822] [INFO] [timer.py:215:stop] epoch=0/micro_step=1165/global_step=1165, RunningAvgSamplesPerSec=4.918772262320557, CurrSamplesPerSec=5.070060645328183, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:24,823] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.73 | backward_microstep: 109.08 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.81 | step_microstep: 41.89
[default0]:[2023-08-25 18:12:24,823] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.73 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:12:24,823] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.18 | backward_allreduce: 10.82 | step: 41.89
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.8300], device='cuda:0'), 'moe loss': tensor([0.3012], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1165/439453125 | consumed samples:         1165 | consumed tokens:      2385920 | elapsed time per iteration (ms): 263.7 | learning rate: 1.271E-06 | global batch size:     1 | lm loss: 9.566005E+00 | moe loss: 6.024377E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.793 | TFLOPs: 9.42 |
[default0]:[2023-08-25 18:12:25,087] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:25,088] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.50 | backward_microstep: 109.32 | backward_inner_microstep: 98.49 | backward_allreduce_microstep: 10.73 | step_microstep: 41.49
[default0]:[2023-08-25 18:12:25,088] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.50 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:12:25,088] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.32 | backward_inner: 98.49 | backward_allreduce: 10.74 | step: 41.50
[default0]:[2023-08-25 18:12:25,352] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:25,352] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.89 | backward_microstep: 109.36 | backward_inner_microstep: 98.28 | backward_allreduce_microstep: 10.99 | step_microstep: 41.48
[default0]:[2023-08-25 18:12:25,352] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.89 (forward_moe: 19.86, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:12:25,352] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.36 | backward_inner: 98.28 | backward_allreduce: 10.99 | step: 41.48
[default0]:[2023-08-25 18:12:25,609] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:12:25,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 109.09 | backward_inner_microstep: 98.27 | backward_allreduce_microstep: 10.72 | step_microstep: 41.48
[default0]:[2023-08-25 18:12:25,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.81, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:12:25,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.09 | backward_inner: 98.28 | backward_allreduce: 10.73 | step: 41.49
[default0]:[2023-08-25 18:12:25,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.88 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:25,866] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.01 | backward_microstep: 109.04 | backward_inner_microstep: 98.25 | backward_allreduce_microstep: 10.69 | step_microstep: 41.51
[default0]:[2023-08-25 18:12:25,866] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.01 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:12:25,866] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.04 | backward_inner: 98.26 | backward_allreduce: 10.69 | step: 41.52
[default0]:[2023-08-25 18:12:26,111] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.27
[default0]:[2023-08-25 18:12:26,111] [INFO] [logging.py:96:log_dist] [Rank 0] step=1170, skipped=0, lr=[1.2768597333333335e-06, 1.2768597333333335e-06, 1.2768597333333335e-06, 1.2768597333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:26,112] [INFO] [timer.py:215:stop] epoch=0/micro_step=1170/global_step=1170, RunningAvgSamplesPerSec=4.919398032857379, CurrSamplesPerSec=5.068277828797912, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:26,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.67 | backward_microstep: 109.15 | backward_inner_microstep: 98.34 | backward_allreduce_microstep: 10.72 | step_microstep: 41.94
[default0]:[2023-08-25 18:12:26,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.90, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:12:26,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.14 | backward_inner: 98.34 | backward_allreduce: 10.72 | step: 41.95
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.9881], device='cuda:0'), 'moe loss': tensor([0.3019], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1170/439453125 | consumed samples:         1170 | consumed tokens:      2396160 | elapsed time per iteration (ms): 257.5 | learning rate: 1.277E-06 | global batch size:     1 | lm loss: 9.597614E+00 | moe loss: 6.038667E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.883 | TFLOPs: 9.65 |
[default0]:[2023-08-25 18:12:26,361] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:12:26,362] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 109.34 | backward_inner_microstep: 98.38 | backward_allreduce_microstep: 10.86 | step_microstep: 41.55
[default0]:[2023-08-25 18:12:26,362] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.90, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.88)
[default0]:[2023-08-25 18:12:26,362] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.34 | backward_inner: 98.38 | backward_allreduce: 10.87 | step: 41.55
[default0]:[2023-08-25 18:12:26,598] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:26,598] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.57 | backward_microstep: 108.86 | backward_inner_microstep: 98.05 | backward_allreduce_microstep: 10.71 | step_microstep: 41.57
[default0]:[2023-08-25 18:12:26,598] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.56 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:12:26,598] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.86 | backward_inner: 98.06 | backward_allreduce: 10.72 | step: 41.58
[default0]:[2023-08-25 18:12:26,879] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:26,879] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.26 | backward_microstep: 109.04 | backward_inner_microstep: 98.20 | backward_allreduce_microstep: 10.75 | step_microstep: 41.55
[default0]:[2023-08-25 18:12:26,879] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.26 (forward_moe: 19.88, 1st alltoall: 0.95, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:12:26,879] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.04 | backward_inner: 98.20 | backward_allreduce: 10.75 | step: 41.55
[default0]:[2023-08-25 18:12:27,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:12:27,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 109.11 | backward_inner_microstep: 98.24 | backward_allreduce_microstep: 10.77 | step_microstep: 41.32
[default0]:[2023-08-25 18:12:27,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.79, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:12:27,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.11 | backward_inner: 98.25 | backward_allreduce: 10.78 | step: 41.33
[default0]:[2023-08-25 18:12:27,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:27,387] [INFO] [logging.py:96:log_dist] [Rank 0] step=1175, skipped=0, lr=[1.2823210666666668e-06, 1.2823210666666668e-06, 1.2823210666666668e-06, 1.2823210666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:27,388] [INFO] [timer.py:215:stop] epoch=0/micro_step=1175/global_step=1175, RunningAvgSamplesPerSec=4.920019880449279, CurrSamplesPerSec=5.0604629613989704, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:27,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.90 | backward_microstep: 109.08 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.73 | step_microstep: 42.09
[default0]:[2023-08-25 18:12:27,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.90 (forward_moe: 19.83, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:12:27,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.26 | backward_allreduce: 10.73 | step: 42.10
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.5495], device='cuda:0'), 'moe loss': tensor([0.3011], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1175/439453125 | consumed samples:         1175 | consumed tokens:      2406400 | elapsed time per iteration (ms): 255.1 | learning rate: 1.282E-06 | global batch size:     1 | lm loss: 9.509892E+00 | moe loss: 6.022960E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.920 | TFLOPs: 9.74 |
[default0]:[2023-08-25 18:12:27,682] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:12:27,682] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.57 | backward_microstep: 111.37 | backward_inner_microstep: 100.38 | backward_allreduce_microstep: 10.89 | step_microstep: 42.56
[default0]:[2023-08-25 18:12:27,682] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.57 (forward_moe: 20.35, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 8.12)
[default0]:[2023-08-25 18:12:27,682] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.36 | backward_inner: 100.38 | backward_allreduce: 10.90 | step: 42.56
[default0]:[2023-08-25 18:12:27,923] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:12:27,923] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.53 | backward_microstep: 112.38 | backward_inner_microstep: 101.29 | backward_allreduce_microstep: 10.99 | step_microstep: 42.95
[default0]:[2023-08-25 18:12:27,923] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.53 (forward_moe: 20.46, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:12:27,923] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.38 | backward_inner: 101.30 | backward_allreduce: 11.00 | step: 42.96
[default0]:[2023-08-25 18:12:28,197] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 40.74
[default0]:[2023-08-25 18:12:28,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.85 | backward_microstep: 112.77 | backward_inner_microstep: 101.74 | backward_allreduce_microstep: 10.94 | step_microstep: 78.68
[default0]:[2023-08-25 18:12:28,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.85 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:12:28,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.77 | backward_inner: 101.75 | backward_allreduce: 10.94 | step: 78.68
[default0]:[2023-08-25 18:12:28,437] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.38
[default0]:[2023-08-25 18:12:28,437] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.74 | backward_microstep: 113.59 | backward_inner_microstep: 102.51 | backward_allreduce_microstep: 10.98 | step_microstep: 42.96
[default0]:[2023-08-25 18:12:28,437] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.74 (forward_moe: 20.81, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.30)
[default0]:[2023-08-25 18:12:28,437] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.59 | backward_inner: 102.52 | backward_allreduce: 10.98 | step: 42.96
[default0]:[2023-08-25 18:12:28,719] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.37
[default0]:[2023-08-25 18:12:28,719] [INFO] [logging.py:96:log_dist] [Rank 0] step=1180, skipped=0, lr=[1.2877824e-06, 1.2877824e-06, 1.2877824e-06, 1.2877824e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:28,720] [INFO] [timer.py:215:stop] epoch=0/micro_step=1180/global_step=1180, RunningAvgSamplesPerSec=4.9192685640237235, CurrSamplesPerSec=4.984377710965074, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:28,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.39 | backward_microstep: 111.23 | backward_inner_microstep: 100.33 | backward_allreduce_microstep: 10.80 | step_microstep: 42.46
[default0]:[2023-08-25 18:12:28,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.39 (forward_moe: 20.31, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.99)
[default0]:[2023-08-25 18:12:28,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.23 | backward_inner: 100.34 | backward_allreduce: 10.80 | step: 42.46
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.9268], device='cuda:0'), 'moe loss': tensor([0.2998], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1180/439453125 | consumed samples:         1180 | consumed tokens:      2416640 | elapsed time per iteration (ms): 266.6 | learning rate: 1.288E-06 | global batch size:     1 | lm loss: 9.585365E+00 | moe loss: 5.996637E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.751 | TFLOPs: 9.32 |
[default0]:[2023-08-25 18:12:28,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:28,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.36 | backward_microstep: 111.15 | backward_inner_microstep: 100.14 | backward_allreduce_microstep: 10.92 | step_microstep: 42.16
[default0]:[2023-08-25 18:12:28,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.36 (forward_moe: 20.19, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.98)
[default0]:[2023-08-25 18:12:28,975] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.14 | backward_inner: 100.14 | backward_allreduce: 10.92 | step: 42.17
[default0]:[2023-08-25 18:12:29,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:12:29,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.67 | backward_microstep: 111.07 | backward_inner_microstep: 100.09 | backward_allreduce_microstep: 10.87 | step_microstep: 41.99
[default0]:[2023-08-25 18:12:29,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.67 (forward_moe: 20.18, 1st alltoall: 0.89, 2nd alltoall: 0.80, top-k: 7.99)
[default0]:[2023-08-25 18:12:29,232] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.06 | backward_inner: 100.10 | backward_allreduce: 10.88 | step: 41.99
[default0]:[2023-08-25 18:12:29,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.74 | optimizer_gradients: 3.90 | optimizer_step: 6.27
[default0]:[2023-08-25 18:12:29,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.66 | backward_microstep: 108.88 | backward_inner_microstep: 98.03 | backward_allreduce_microstep: 10.76 | step_microstep: 41.73
[default0]:[2023-08-25 18:12:29,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:12:29,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.88 | backward_inner: 98.03 | backward_allreduce: 10.77 | step: 41.73
[default0]:[2023-08-25 18:12:29,712] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:29,712] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 109.27 | backward_inner_microstep: 98.44 | backward_allreduce_microstep: 10.74 | step_microstep: 41.39
[default0]:[2023-08-25 18:12:29,713] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.79, 1st alltoall: 0.85, 2nd alltoall: 0.79, top-k: 7.78)
[default0]:[2023-08-25 18:12:29,713] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.27 | backward_inner: 98.45 | backward_allreduce: 10.74 | step: 41.40
[default0]:[2023-08-25 18:12:29,955] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:29,956] [INFO] [logging.py:96:log_dist] [Rank 0] step=1185, skipped=0, lr=[1.2932437333333334e-06, 1.2932437333333334e-06, 1.2932437333333334e-06, 1.2932437333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:29,956] [INFO] [timer.py:215:stop] epoch=0/micro_step=1185/global_step=1185, RunningAvgSamplesPerSec=4.919757003550199, CurrSamplesPerSec=5.065254198397689, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:29,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.74 | backward_microstep: 109.17 | backward_inner_microstep: 98.33 | backward_allreduce_microstep: 10.76 | step_microstep: 41.97
[default0]:[2023-08-25 18:12:29,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.74 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:12:29,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.17 | backward_inner: 98.33 | backward_allreduce: 10.76 | step: 41.97
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.9561], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1185/439453125 | consumed samples:         1185 | consumed tokens:      2426880 | elapsed time per iteration (ms): 247.2 | learning rate: 1.293E-06 | global batch size:     1 | lm loss: 9.591214E+00 | moe loss: 6.019981E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.045 | TFLOPs: 10.05 |
[default0]:[2023-08-25 18:12:30,234] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:30,234] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 108.95 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.76 | step_microstep: 41.66
[default0]:[2023-08-25 18:12:30,234] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.73, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:12:30,235] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.95 | backward_inner: 98.10 | backward_allreduce: 10.76 | step: 41.67
[default0]:[2023-08-25 18:12:30,482] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.96 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:30,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.22 | backward_microstep: 109.27 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.91 | step_microstep: 41.78
[default0]:[2023-08-25 18:12:30,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.22 (forward_moe: 19.75, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:12:30,483] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.27 | backward_inner: 98.27 | backward_allreduce: 10.92 | step: 41.78
[default0]:[2023-08-25 18:12:30,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:30,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.12 | backward_microstep: 109.04 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.73 | step_microstep: 41.65
[default0]:[2023-08-25 18:12:30,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.12 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:12:30,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.04 | backward_inner: 98.22 | backward_allreduce: 10.74 | step: 41.65
[default0]:[2023-08-25 18:12:30,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.40
[default0]:[2023-08-25 18:12:30,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.58 | backward_microstep: 109.09 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.73 | step_microstep: 41.59
[default0]:[2023-08-25 18:12:30,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.58 (forward_moe: 19.86, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:12:30,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.09 | backward_inner: 98.27 | backward_allreduce: 10.74 | step: 41.60
[default0]:[2023-08-25 18:12:31,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:31,250] [INFO] [logging.py:96:log_dist] [Rank 0] step=1190, skipped=0, lr=[1.2987050666666667e-06, 1.2987050666666667e-06, 1.2987050666666667e-06, 1.2987050666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:31,250] [INFO] [timer.py:215:stop] epoch=0/micro_step=1190/global_step=1190, RunningAvgSamplesPerSec=4.920305734515082, CurrSamplesPerSec=5.057491333313236, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:31,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.58 | backward_microstep: 109.86 | backward_inner_microstep: 99.09 | backward_allreduce_microstep: 10.68 | step_microstep: 41.73
[default0]:[2023-08-25 18:12:31,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.58 (forward_moe: 20.13, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:12:31,251] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.86 | backward_inner: 99.09 | backward_allreduce: 10.68 | step: 41.74
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.8523], device='cuda:0'), 'moe loss': tensor([0.3003], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1190/439453125 | consumed samples:         1190 | consumed tokens:      2437120 | elapsed time per iteration (ms): 258.8 | learning rate: 1.299E-06 | global batch size:     1 | lm loss: 9.570454E+00 | moe loss: 6.005872E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.864 | TFLOPs: 9.60 |
[default0]:[2023-08-25 18:12:31,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:31,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.42 | backward_microstep: 109.24 | backward_inner_microstep: 98.39 | backward_allreduce_microstep: 10.76 | step_microstep: 41.55
[default0]:[2023-08-25 18:12:31,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.42 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:12:31,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.24 | backward_inner: 98.40 | backward_allreduce: 10.76 | step: 41.55
[default0]:[2023-08-25 18:12:31,751] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:31,752] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.58 | backward_microstep: 109.13 | backward_inner_microstep: 98.08 | backward_allreduce_microstep: 10.95 | step_microstep: 41.41
[default0]:[2023-08-25 18:12:31,752] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.58 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:12:31,752] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.13 | backward_inner: 98.09 | backward_allreduce: 10.96 | step: 41.41
[default0]:[2023-08-25 18:12:31,997] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:31,997] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.43 | backward_microstep: 108.97 | backward_inner_microstep: 98.14 | backward_allreduce_microstep: 10.74 | step_microstep: 41.56
[default0]:[2023-08-25 18:12:31,998] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.42 (forward_moe: 19.74, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:12:31,998] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.97 | backward_inner: 98.14 | backward_allreduce: 10.75 | step: 41.57
[default0]:[2023-08-25 18:12:32,243] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:32,243] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.37 | backward_microstep: 111.07 | backward_inner_microstep: 100.00 | backward_allreduce_microstep: 10.98 | step_microstep: 42.12
[default0]:[2023-08-25 18:12:32,243] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.37 (forward_moe: 20.14, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.96)
[default0]:[2023-08-25 18:12:32,243] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.07 | backward_inner: 100.00 | backward_allreduce: 10.98 | step: 42.13
[default0]:[2023-08-25 18:12:32,479] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:12:32,479] [INFO] [logging.py:96:log_dist] [Rank 0] step=1195, skipped=0, lr=[1.3041664e-06, 1.3041664e-06, 1.3041664e-06, 1.3041664e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:32,479] [INFO] [timer.py:215:stop] epoch=0/micro_step=1195/global_step=1195, RunningAvgSamplesPerSec=4.920859278193324, CurrSamplesPerSec=5.058442850613083, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:32,479] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 108.83 | backward_inner_microstep: 98.04 | backward_allreduce_microstep: 10.70 | step_microstep: 42.32
[default0]:[2023-08-25 18:12:32,479] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.00 (forward_moe: 19.81, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:12:32,480] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.83 | backward_inner: 98.05 | backward_allreduce: 10.70 | step: 42.32
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.7330], device='cuda:0'), 'moe loss': tensor([0.3003], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1195/439453125 | consumed samples:         1195 | consumed tokens:      2447360 | elapsed time per iteration (ms): 245.7 | learning rate: 1.304E-06 | global batch size:     1 | lm loss: 9.546606E+00 | moe loss: 6.006119E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.070 | TFLOPs: 10.11 |
[default0]:[2023-08-25 18:12:32,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:32,742] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.33 | backward_microstep: 108.92 | backward_inner_microstep: 98.05 | backward_allreduce_microstep: 10.77 | step_microstep: 41.63
[default0]:[2023-08-25 18:12:32,742] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.33 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:12:32,742] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.06 | backward_allreduce: 10.77 | step: 41.63
[default0]:[2023-08-25 18:12:32,983] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.88 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:32,983] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.43 | backward_microstep: 108.96 | backward_inner_microstep: 98.08 | backward_allreduce_microstep: 10.79 | step_microstep: 41.36
[default0]:[2023-08-25 18:12:32,983] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.43 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:12:32,983] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.09 | backward_allreduce: 10.79 | step: 41.37
[default0]:[2023-08-25 18:12:33,228] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:12:33,228] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.58 | backward_microstep: 109.39 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 11.08 | step_microstep: 41.89
[default0]:[2023-08-25 18:12:33,228] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.58 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:12:33,228] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.39 | backward_inner: 98.22 | backward_allreduce: 11.09 | step: 41.89
[default0]:[2023-08-25 18:12:33,467] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:33,468] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.48 | backward_microstep: 108.93 | backward_inner_microstep: 98.12 | backward_allreduce_microstep: 10.72 | step_microstep: 41.67
[default0]:[2023-08-25 18:12:33,468] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:12:33,468] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.12 | backward_allreduce: 10.72 | step: 41.68
[default0]:[2023-08-25 18:12:33,751] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:33,751] [INFO] [logging.py:96:log_dist] [Rank 0] step=1200, skipped=0, lr=[1.3096277333333333e-06, 1.3096277333333333e-06, 1.3096277333333333e-06, 1.3096277333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:33,752] [INFO] [timer.py:215:stop] epoch=0/micro_step=1200/global_step=1200, RunningAvgSamplesPerSec=4.92149011426592, CurrSamplesPerSec=5.075416628347669, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:33,752] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.62 | backward_microstep: 109.01 | backward_inner_microstep: 98.14 | backward_allreduce_microstep: 10.78 | step_microstep: 41.86
[default0]:[2023-08-25 18:12:33,752] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.89, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:12:33,752] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.01 | backward_inner: 98.15 | backward_allreduce: 10.78 | step: 41.87
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.8626], device='cuda:0'), 'moe loss': tensor([0.3000], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1200/439453125 | consumed samples:         1200 | consumed tokens:      2457600 | elapsed time per iteration (ms): 254.7 | learning rate: 1.310E-06 | global batch size:     1 | lm loss: 9.572520E+00 | moe loss: 6.000330E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.926 | TFLOPs: 9.76 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1200 | lm loss value: 9.600830E+00 | lm loss PPL: 1.477704E+04 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration    1200 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:12:37,527] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1200 is about to be saved!
[default0]:[2023-08-25 18:12:37,529] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,539] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,548] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,549] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,558] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,558] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,568] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,568] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,577] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,577] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,586] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,586] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,594] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,594] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,603] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,604] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,612] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,613] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,621] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,621] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,630] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,630] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,639] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,640] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,649] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,649] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,658] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,658] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,666] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,666] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,675] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,676] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,684] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,685] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,694] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,694] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,703] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,703] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,712] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,713] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,722] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,722] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,730] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,730] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,739] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,739] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:37,748] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:37,749] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:12:37,750] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:12:37,752] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:12:37,752] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:12:38,033] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:12:38,034] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:12:41,705] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:12:41,714] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1200/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:12:41,714] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1200 is ready now!
[default0]:  successfully saved checkpoint at iteration    1200 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.69, Latency(second): 4.24
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4239.61, 4239.61)
[default0]:[2023-08-25 18:12:42,004] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.18 | optimizer_step: 10.14
[default0]:[2023-08-25 18:12:42,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2313.24 | backward_microstep: 117.17 | backward_inner_microstep: 106.05 | backward_allreduce_microstep: 11.03 | step_microstep: 47.41
[default0]:[2023-08-25 18:12:42,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2313.17 (forward_moe: 21.46, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.75)
[default0]:[2023-08-25 18:12:42,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.16 | backward_inner: 106.05 | backward_allreduce: 11.03 | step: 47.41
[default0]:[2023-08-25 18:12:42,258] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.15 | optimizer_step: 6.51
[default0]:[2023-08-25 18:12:42,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.27 | backward_microstep: 116.81 | backward_inner_microstep: 105.69 | backward_allreduce_microstep: 11.03 | step_microstep: 44.29
[default0]:[2023-08-25 18:12:42,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.27 (forward_moe: 21.38, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.74)
[default0]:[2023-08-25 18:12:42,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.80 | backward_inner: 105.69 | backward_allreduce: 11.03 | step: 44.29
[default0]:[2023-08-25 18:12:42,526] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.46
[default0]:[2023-08-25 18:12:42,527] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.28 | backward_microstep: 116.64 | backward_inner_microstep: 105.46 | backward_allreduce_microstep: 11.09 | step_microstep: 43.57
[default0]:[2023-08-25 18:12:42,527] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.28 (forward_moe: 21.37, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.73)
[default0]:[2023-08-25 18:12:42,527] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.64 | backward_inner: 105.46 | backward_allreduce: 11.10 | step: 43.57
[default0]:[2023-08-25 18:12:42,789] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.10 | optimizer_step: 6.44
[default0]:[2023-08-25 18:12:42,789] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.21 | backward_microstep: 114.70 | backward_inner_microstep: 103.49 | backward_allreduce_microstep: 11.12 | step_microstep: 43.85
[default0]:[2023-08-25 18:12:42,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.20 (forward_moe: 20.92, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.46)
[default0]:[2023-08-25 18:12:42,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.70 | backward_inner: 103.49 | backward_allreduce: 11.12 | step: 43.86
[default0]:[2023-08-25 18:12:43,045] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.70 | optimizer_gradients: 4.20 | optimizer_step: 6.48
[default0]:[2023-08-25 18:12:43,045] [INFO] [logging.py:96:log_dist] [Rank 0] step=1205, skipped=0, lr=[1.3150890666666667e-06, 1.3150890666666667e-06, 1.3150890666666667e-06, 1.3150890666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:43,045] [INFO] [timer.py:215:stop] epoch=0/micro_step=1205/global_step=1205, RunningAvgSamplesPerSec=4.920604881058138, CurrSamplesPerSec=4.743104959317875, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:43,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.23 | backward_microstep: 115.76 | backward_inner_microstep: 104.47 | backward_allreduce_microstep: 11.18 | step_microstep: 44.28
[default0]:[2023-08-25 18:12:43,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.23 (forward_moe: 21.19, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.61)
[default0]:[2023-08-25 18:12:43,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.76 | backward_inner: 104.48 | backward_allreduce: 11.19 | step: 44.29
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.1092], device='cuda:0'), 'moe loss': tensor([0.3021], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1205/439453125 | consumed samples:         1205 | consumed tokens:      2467840 | elapsed time per iteration (ms): 1858.5 | learning rate: 1.315E-06 | global batch size:     1 | lm loss: 9.421834E+00 | moe loss: 6.042204E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.538 | TFLOPs: 1.34 |
[default0]:[2023-08-25 18:12:43,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.47
[default0]:[2023-08-25 18:12:43,310] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.73 | backward_microstep: 116.68 | backward_inner_microstep: 105.41 | backward_allreduce_microstep: 11.18 | step_microstep: 43.74
[default0]:[2023-08-25 18:12:43,310] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.73 (forward_moe: 21.23, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.61)
[default0]:[2023-08-25 18:12:43,310] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.68 | backward_inner: 105.41 | backward_allreduce: 11.18 | step: 43.74
[default0]:[2023-08-25 18:12:43,562] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:43,562] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.50 | backward_microstep: 111.35 | backward_inner_microstep: 100.36 | backward_allreduce_microstep: 10.90 | step_microstep: 42.33
[default0]:[2023-08-25 18:12:43,562] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.50 (forward_moe: 20.21, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.02)
[default0]:[2023-08-25 18:12:43,562] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.35 | backward_inner: 100.36 | backward_allreduce: 10.91 | step: 42.34
[default0]:[2023-08-25 18:12:43,804] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:43,804] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.68 | backward_microstep: 111.20 | backward_inner_microstep: 100.28 | backward_allreduce_microstep: 10.83 | step_microstep: 42.08
[default0]:[2023-08-25 18:12:43,804] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.68 (forward_moe: 20.19, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.99)
[default0]:[2023-08-25 18:12:43,805] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.20 | backward_inner: 100.28 | backward_allreduce: 10.83 | step: 42.09
[default0]:[2023-08-25 18:12:44,083] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:44,084] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.50 | backward_microstep: 110.84 | backward_inner_microstep: 99.95 | backward_allreduce_microstep: 10.80 | step_microstep: 42.22
[default0]:[2023-08-25 18:12:44,084] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.50 (forward_moe: 20.15, 1st alltoall: 0.87, 2nd alltoall: 0.83, top-k: 7.97)
[default0]:[2023-08-25 18:12:44,084] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.84 | backward_inner: 99.96 | backward_allreduce: 10.80 | step: 42.22
[default0]:[2023-08-25 18:12:44,370] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:44,370] [INFO] [logging.py:96:log_dist] [Rank 0] step=1210, skipped=0, lr=[1.3205504000000002e-06, 1.3205504000000002e-06, 1.3205504000000002e-06, 1.3205504000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:44,370] [INFO] [timer.py:215:stop] epoch=0/micro_step=1210/global_step=1210, RunningAvgSamplesPerSec=4.920670823678118, CurrSamplesPerSec=4.982844054462791, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:44,371] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.46 | backward_microstep: 111.11 | backward_inner_microstep: 100.15 | backward_allreduce_microstep: 10.87 | step_microstep: 42.57
[default0]:[2023-08-25 18:12:44,371] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.46 (forward_moe: 20.30, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.98)
[default0]:[2023-08-25 18:12:44,371] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.11 | backward_inner: 100.15 | backward_allreduce: 10.88 | step: 42.57
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.5642], device='cuda:0'), 'moe loss': tensor([0.3018], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1210/439453125 | consumed samples:         1210 | consumed tokens:      2478080 | elapsed time per iteration (ms): 265.6 | learning rate: 1.321E-06 | global batch size:     1 | lm loss: 9.512834E+00 | moe loss: 6.036422E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.765 | TFLOPs: 9.36 |
[default0]:[2023-08-25 18:12:44,621] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:12:44,621] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.49 | backward_microstep: 114.49 | backward_inner_microstep: 103.53 | backward_allreduce_microstep: 10.86 | step_microstep: 42.21
[default0]:[2023-08-25 18:12:44,622] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.49 (forward_moe: 20.79, 1st alltoall: 0.99, 2nd alltoall: 0.84, top-k: 8.04)
[default0]:[2023-08-25 18:12:44,622] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.48 | backward_inner: 103.53 | backward_allreduce: 10.87 | step: 42.22
[default0]:[2023-08-25 18:12:44,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:44,859] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.58 | backward_microstep: 111.10 | backward_inner_microstep: 100.12 | backward_allreduce_microstep: 10.88 | step_microstep: 42.18
[default0]:[2023-08-25 18:12:44,859] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.58 (forward_moe: 20.24, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 8.02)
[default0]:[2023-08-25 18:12:44,859] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.10 | backward_inner: 100.12 | backward_allreduce: 10.89 | step: 42.18
[default0]:[2023-08-25 18:12:45,097] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:45,097] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.46 | backward_microstep: 111.12 | backward_inner_microstep: 100.22 | backward_allreduce_microstep: 10.80 | step_microstep: 42.16
[default0]:[2023-08-25 18:12:45,097] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.46 (forward_moe: 20.18, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 7.99)
[default0]:[2023-08-25 18:12:45,097] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.11 | backward_inner: 100.22 | backward_allreduce: 10.81 | step: 42.17
[default0]:[2023-08-25 18:12:45,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.34
[default0]:[2023-08-25 18:12:45,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.51 | backward_microstep: 110.84 | backward_inner_microstep: 99.92 | backward_allreduce_microstep: 10.82 | step_microstep: 41.92
[default0]:[2023-08-25 18:12:45,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.51 (forward_moe: 20.11, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.93)
[default0]:[2023-08-25 18:12:45,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.83 | backward_inner: 99.93 | backward_allreduce: 10.82 | step: 41.92
[default0]:[2023-08-25 18:12:45,587] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:45,588] [INFO] [logging.py:96:log_dist] [Rank 0] step=1215, skipped=0, lr=[1.3260117333333335e-06, 1.3260117333333335e-06, 1.3260117333333335e-06, 1.3260117333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:45,588] [INFO] [timer.py:215:stop] epoch=0/micro_step=1215/global_step=1215, RunningAvgSamplesPerSec=4.920841415832711, CurrSamplesPerSec=4.994437928303931, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:45,588] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.15 | backward_microstep: 111.00 | backward_inner_microstep: 100.06 | backward_allreduce_microstep: 10.84 | step_microstep: 42.53
[default0]:[2023-08-25 18:12:45,588] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.15 (forward_moe: 20.35, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 8.08)
[default0]:[2023-08-25 18:12:45,588] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.00 | backward_inner: 100.07 | backward_allreduce: 10.84 | step: 42.54
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.0588], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1215/439453125 | consumed samples:         1215 | consumed tokens:      2488320 | elapsed time per iteration (ms): 243.0 | learning rate: 1.326E-06 | global batch size:     1 | lm loss: 9.611755E+00 | moe loss: 6.013956E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.116 | TFLOPs: 10.23 |
[default0]:[2023-08-25 18:12:45,832] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.94 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:45,832] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.39 | backward_microstep: 111.11 | backward_inner_microstep: 100.16 | backward_allreduce_microstep: 10.84 | step_microstep: 41.95
[default0]:[2023-08-25 18:12:45,832] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.39 (forward_moe: 20.12, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.94)
[default0]:[2023-08-25 18:12:45,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.10 | backward_inner: 100.17 | backward_allreduce: 10.85 | step: 41.95
[default0]:[2023-08-25 18:12:46,082] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:46,082] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.18 | backward_microstep: 110.79 | backward_inner_microstep: 99.85 | backward_allreduce_microstep: 10.85 | step_microstep: 42.04
[default0]:[2023-08-25 18:12:46,082] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.18 (forward_moe: 20.10, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.93)
[default0]:[2023-08-25 18:12:46,082] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.79 | backward_inner: 99.85 | backward_allreduce: 10.85 | step: 42.04
[default0]:[2023-08-25 18:12:46,357] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:46,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.30 | backward_microstep: 110.72 | backward_inner_microstep: 99.80 | backward_allreduce_microstep: 10.82 | step_microstep: 41.94
[default0]:[2023-08-25 18:12:46,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.30 (forward_moe: 20.15, 1st alltoall: 0.87, 2nd alltoall: 0.83, top-k: 7.97)
[default0]:[2023-08-25 18:12:46,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.72 | backward_inner: 99.81 | backward_allreduce: 10.83 | step: 41.95
[default0]:[2023-08-25 18:12:46,600] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.80 | optimizer_gradients: 4.00 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:46,601] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.33 | backward_microstep: 110.96 | backward_inner_microstep: 100.05 | backward_allreduce_microstep: 10.82 | step_microstep: 42.56
[default0]:[2023-08-25 18:12:46,601] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.33 (forward_moe: 20.13, 1st alltoall: 0.90, 2nd alltoall: 0.81, top-k: 7.94)
[default0]:[2023-08-25 18:12:46,601] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.96 | backward_inner: 100.06 | backward_allreduce: 10.83 | step: 42.56
[default0]:[2023-08-25 18:12:46,835] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:46,835] [INFO] [logging.py:96:log_dist] [Rank 0] step=1220, skipped=0, lr=[1.3314730666666668e-06, 1.3314730666666668e-06, 1.3314730666666668e-06, 1.3314730666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:46,835] [INFO] [timer.py:215:stop] epoch=0/micro_step=1220/global_step=1220, RunningAvgSamplesPerSec=4.921105587115568, CurrSamplesPerSec=4.944299908877758, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:46,836] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.81 | backward_microstep: 111.35 | backward_inner_microstep: 100.41 | backward_allreduce_microstep: 10.84 | step_microstep: 42.55
[default0]:[2023-08-25 18:12:46,836] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.81 (forward_moe: 20.28, 1st alltoall: 0.86, 2nd alltoall: 0.82, top-k: 7.97)
[default0]:[2023-08-25 18:12:46,836] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.35 | backward_inner: 100.42 | backward_allreduce: 10.85 | step: 42.56
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.5976], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1220/439453125 | consumed samples:         1220 | consumed tokens:      2498560 | elapsed time per iteration (ms): 249.6 | learning rate: 1.331E-06 | global batch size:     1 | lm loss: 9.519514E+00 | moe loss: 6.013669E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.007 | TFLOPs: 9.96 |
[default0]:[2023-08-25 18:12:47,105] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:12:47,105] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.85 | backward_microstep: 113.56 | backward_inner_microstep: 102.50 | backward_allreduce_microstep: 10.96 | step_microstep: 43.04
[default0]:[2023-08-25 18:12:47,105] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.85 (forward_moe: 20.74, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.32)
[default0]:[2023-08-25 18:12:47,105] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.56 | backward_inner: 102.50 | backward_allreduce: 10.97 | step: 43.05
[default0]:[2023-08-25 18:12:47,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:12:47,368] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.16 | backward_microstep: 112.86 | backward_inner_microstep: 101.83 | backward_allreduce_microstep: 10.93 | step_microstep: 42.58
[default0]:[2023-08-25 18:12:47,368] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.16 (forward_moe: 20.55, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:12:47,368] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.86 | backward_inner: 101.84 | backward_allreduce: 10.94 | step: 42.58
[default0]:[2023-08-25 18:12:47,651] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.06 | optimizer_step: 6.40
[default0]:[2023-08-25 18:12:47,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.09 | backward_microstep: 112.85 | backward_inner_microstep: 101.78 | backward_allreduce_microstep: 10.98 | step_microstep: 48.63
[default0]:[2023-08-25 18:12:47,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.09 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:12:47,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.85 | backward_inner: 101.79 | backward_allreduce: 10.98 | step: 48.64
[default0]:[2023-08-25 18:12:47,925] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.36
[default0]:[2023-08-25 18:12:47,925] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.24 | backward_microstep: 118.69 | backward_inner_microstep: 107.05 | backward_allreduce_microstep: 11.54 | step_microstep: 44.57
[default0]:[2023-08-25 18:12:47,925] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.24 (forward_moe: 21.71, 1st alltoall: 0.92, 2nd alltoall: 0.86, top-k: 8.57)
[default0]:[2023-08-25 18:12:47,925] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 118.69 | backward_inner: 107.06 | backward_allreduce: 11.55 | step: 44.57
[default0]:[2023-08-25 18:12:48,173] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:48,174] [INFO] [logging.py:96:log_dist] [Rank 0] step=1225, skipped=0, lr=[1.3369344000000001e-06, 1.3369344000000001e-06, 1.3369344000000001e-06, 1.3369344000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:48,174] [INFO] [timer.py:215:stop] epoch=0/micro_step=1225/global_step=1225, RunningAvgSamplesPerSec=4.920822776523594, CurrSamplesPerSec=5.003768659876955, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:48,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.30 | backward_microstep: 110.63 | backward_inner_microstep: 99.69 | backward_allreduce_microstep: 10.85 | step_microstep: 42.38
[default0]:[2023-08-25 18:12:48,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.30 (forward_moe: 20.10, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.96)
[default0]:[2023-08-25 18:12:48,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.63 | backward_inner: 99.69 | backward_allreduce: 10.86 | step: 42.38
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.3803], device='cuda:0'), 'moe loss': tensor([0.3001], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1225/439453125 | consumed samples:         1225 | consumed tokens:      2508800 | elapsed time per iteration (ms): 267.6 | learning rate: 1.337E-06 | global batch size:     1 | lm loss: 9.476060E+00 | moe loss: 6.002246E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.738 | TFLOPs: 9.29 |
[default0]:[2023-08-25 18:12:48,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:48,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.46 | backward_microstep: 110.90 | backward_inner_microstep: 99.92 | backward_allreduce_microstep: 10.89 | step_microstep: 42.01
[default0]:[2023-08-25 18:12:48,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.47 (forward_moe: 20.15, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.97)
[default0]:[2023-08-25 18:12:48,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.90 | backward_inner: 99.92 | backward_allreduce: 10.89 | step: 42.01
[default0]:[2023-08-25 18:12:48,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:12:48,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.31 | backward_microstep: 111.23 | backward_inner_microstep: 100.26 | backward_allreduce_microstep: 10.88 | step_microstep: 42.14
[default0]:[2023-08-25 18:12:48,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.31 (forward_moe: 20.15, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.98)
[default0]:[2023-08-25 18:12:48,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.23 | backward_inner: 100.27 | backward_allreduce: 10.88 | step: 42.14
[default0]:[2023-08-25 18:12:48,921] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.34
[default0]:[2023-08-25 18:12:48,921] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.51 | backward_microstep: 110.97 | backward_inner_microstep: 100.04 | backward_allreduce_microstep: 10.84 | step_microstep: 42.07
[default0]:[2023-08-25 18:12:48,921] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.51 (forward_moe: 20.11, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.96)
[default0]:[2023-08-25 18:12:48,922] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.97 | backward_inner: 100.04 | backward_allreduce: 10.84 | step: 42.07
[default0]:[2023-08-25 18:12:49,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:49,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.06 | backward_microstep: 109.30 | backward_inner_microstep: 98.45 | backward_allreduce_microstep: 10.75 | step_microstep: 41.66
[default0]:[2023-08-25 18:12:49,156] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.06 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:12:49,156] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.30 | backward_inner: 98.46 | backward_allreduce: 10.76 | step: 41.66
[default0]:[2023-08-25 18:12:49,402] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:49,403] [INFO] [logging.py:96:log_dist] [Rank 0] step=1230, skipped=0, lr=[1.3423957333333334e-06, 1.3423957333333334e-06, 1.3423957333333334e-06, 1.3423957333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:49,403] [INFO] [timer.py:215:stop] epoch=0/micro_step=1230/global_step=1230, RunningAvgSamplesPerSec=4.921205323838624, CurrSamplesPerSec=5.054297830087161, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:49,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.80 | backward_microstep: 109.54 | backward_inner_microstep: 98.73 | backward_allreduce_microstep: 10.71 | step_microstep: 41.96
[default0]:[2023-08-25 18:12:49,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.80 (forward_moe: 19.98, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:12:49,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.53 | backward_inner: 98.74 | backward_allreduce: 10.71 | step: 41.96
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.0930], device='cuda:0'), 'moe loss': tensor([0.3011], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1230/439453125 | consumed samples:         1230 | consumed tokens:      2519040 | elapsed time per iteration (ms): 246.0 | learning rate: 1.342E-06 | global batch size:     1 | lm loss: 9.618597E+00 | moe loss: 6.021433E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.065 | TFLOPs: 10.10 |
[default0]:[2023-08-25 18:12:49,656] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:49,656] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.86 | backward_microstep: 109.69 | backward_inner_microstep: 98.83 | backward_allreduce_microstep: 10.76 | step_microstep: 41.58
[default0]:[2023-08-25 18:12:49,656] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.85 (forward_moe: 19.92, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.86)
[default0]:[2023-08-25 18:12:49,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.69 | backward_inner: 98.84 | backward_allreduce: 10.77 | step: 41.58
[default0]:[2023-08-25 18:12:49,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:12:49,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.83 | backward_microstep: 112.01 | backward_inner_microstep: 101.14 | backward_allreduce_microstep: 10.77 | step_microstep: 41.57
[default0]:[2023-08-25 18:12:49,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.83 (forward_moe: 20.50, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 7.93)
[default0]:[2023-08-25 18:12:49,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.00 | backward_inner: 101.14 | backward_allreduce: 10.77 | step: 41.57
[default0]:[2023-08-25 18:12:50,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:50,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.85 | backward_microstep: 109.35 | backward_inner_microstep: 98.53 | backward_allreduce_microstep: 10.72 | step_microstep: 41.56
[default0]:[2023-08-25 18:12:50,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.85 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:12:50,155] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.35 | backward_inner: 98.54 | backward_allreduce: 10.72 | step: 41.57
[default0]:[2023-08-25 18:12:50,395] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:50,395] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 109.35 | backward_inner_microstep: 98.51 | backward_allreduce_microstep: 10.75 | step_microstep: 41.51
[default0]:[2023-08-25 18:12:50,395] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 19.83, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:12:50,396] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.35 | backward_inner: 98.51 | backward_allreduce: 10.75 | step: 41.52
[default0]:[2023-08-25 18:12:50,638] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:50,638] [INFO] [logging.py:96:log_dist] [Rank 0] step=1235, skipped=0, lr=[1.3478570666666668e-06, 1.3478570666666668e-06, 1.3478570666666668e-06, 1.3478570666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:50,638] [INFO] [timer.py:215:stop] epoch=0/micro_step=1235/global_step=1235, RunningAvgSamplesPerSec=4.921682783719374, CurrSamplesPerSec=5.057314488143784, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:50,639] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 109.58 | backward_inner_microstep: 98.51 | backward_allreduce_microstep: 10.77 | step_microstep: 41.93
[default0]:[2023-08-25 18:12:50,639] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.70 (forward_moe: 19.81, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:12:50,639] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.57 | backward_inner: 98.52 | backward_allreduce: 10.97 | step: 41.93
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.3468], device='cuda:0'), 'moe loss': tensor([0.3017], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1235/439453125 | consumed samples:         1235 | consumed tokens:      2529280 | elapsed time per iteration (ms): 247.0 | learning rate: 1.348E-06 | global batch size:     1 | lm loss: 9.469362E+00 | moe loss: 6.034359E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.048 | TFLOPs: 10.06 |
[default0]:[2023-08-25 18:12:50,889] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:12:50,889] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.89 | backward_microstep: 111.18 | backward_inner_microstep: 100.21 | backward_allreduce_microstep: 10.88 | step_microstep: 42.36
[default0]:[2023-08-25 18:12:50,889] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.89 (forward_moe: 20.24, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.02)
[default0]:[2023-08-25 18:12:50,889] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.18 | backward_inner: 100.22 | backward_allreduce: 10.88 | step: 42.36
[default0]:[2023-08-25 18:12:51,158] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:12:51,158] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.96 | backward_microstep: 112.41 | backward_inner_microstep: 101.40 | backward_allreduce_microstep: 10.92 | step_microstep: 43.64
[default0]:[2023-08-25 18:12:51,158] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.95 (forward_moe: 20.48, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:12:51,159] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.41 | backward_inner: 101.40 | backward_allreduce: 10.92 | step: 43.64
[default0]:[2023-08-25 18:12:51,420] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.39
[default0]:[2023-08-25 18:12:51,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.14 | backward_microstep: 112.19 | backward_inner_microstep: 101.19 | backward_allreduce_microstep: 10.91 | step_microstep: 42.37
[default0]:[2023-08-25 18:12:51,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.14 (forward_moe: 20.51, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.18)
[default0]:[2023-08-25 18:12:51,421] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.19 | backward_inner: 101.20 | backward_allreduce: 10.91 | step: 42.37
[default0]:[2023-08-25 18:12:51,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:51,695] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.83 | backward_microstep: 112.15 | backward_inner_microstep: 101.19 | backward_allreduce_microstep: 10.85 | step_microstep: 42.95
[default0]:[2023-08-25 18:12:51,695] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.83 (forward_moe: 20.38, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.10)
[default0]:[2023-08-25 18:12:51,695] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.14 | backward_inner: 101.20 | backward_allreduce: 10.85 | step: 42.95
[default0]:[2023-08-25 18:12:51,966] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.05 | optimizer_step: 6.36
[default0]:[2023-08-25 18:12:51,967] [INFO] [logging.py:96:log_dist] [Rank 0] step=1240, skipped=0, lr=[1.3533184e-06, 1.3533184e-06, 1.3533184e-06, 1.3533184e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:51,967] [INFO] [timer.py:215:stop] epoch=0/micro_step=1240/global_step=1240, RunningAvgSamplesPerSec=4.921622703030052, CurrSamplesPerSec=4.839333987915234, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:51,968] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.91 | backward_microstep: 112.13 | backward_inner_microstep: 101.13 | backward_allreduce_microstep: 10.91 | step_microstep: 44.07
[default0]:[2023-08-25 18:12:51,968] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.91 (forward_moe: 20.53, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.11)
[default0]:[2023-08-25 18:12:51,968] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.13 | backward_inner: 101.13 | backward_allreduce: 10.91 | step: 44.08
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.0380], device='cuda:0'), 'moe loss': tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1240/439453125 | consumed samples:         1240 | consumed tokens:      2539520 | elapsed time per iteration (ms): 266.2 | learning rate: 1.353E-06 | global batch size:     1 | lm loss: 9.607595E+00 | moe loss: 6.010193E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.756 | TFLOPs: 9.33 |
[default0]:[2023-08-25 18:12:52,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 9.88
[default0]:[2023-08-25 18:12:52,226] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.78 | backward_microstep: 111.99 | backward_inner_microstep: 100.93 | backward_allreduce_microstep: 10.97 | step_microstep: 47.02
[default0]:[2023-08-25 18:12:52,227] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.78 (forward_moe: 20.34, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.08)
[default0]:[2023-08-25 18:12:52,227] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.99 | backward_inner: 100.93 | backward_allreduce: 10.97 | step: 47.03
[default0]:[2023-08-25 18:12:52,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:52,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.70 | backward_microstep: 111.71 | backward_inner_microstep: 100.72 | backward_allreduce_microstep: 10.89 | step_microstep: 42.53
[default0]:[2023-08-25 18:12:52,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.70 (forward_moe: 20.37, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.11)
[default0]:[2023-08-25 18:12:52,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.71 | backward_inner: 100.73 | backward_allreduce: 10.89 | step: 42.53
[default0]:[2023-08-25 18:12:52,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:52,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.28 | backward_microstep: 111.72 | backward_inner_microstep: 100.74 | backward_allreduce_microstep: 10.88 | step_microstep: 42.36
[default0]:[2023-08-25 18:12:52,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.28 (forward_moe: 20.34, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.09)
[default0]:[2023-08-25 18:12:52,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.71 | backward_inner: 100.75 | backward_allreduce: 10.88 | step: 42.36
[default0]:[2023-08-25 18:12:53,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.38
[default0]:[2023-08-25 18:12:53,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.85 | backward_microstep: 113.70 | backward_inner_microstep: 102.60 | backward_allreduce_microstep: 11.00 | step_microstep: 43.11
[default0]:[2023-08-25 18:12:53,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.85 (forward_moe: 20.44, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:12:53,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.69 | backward_inner: 102.60 | backward_allreduce: 11.00 | step: 43.11
[default0]:[2023-08-25 18:12:53,286] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:12:53,286] [INFO] [logging.py:96:log_dist] [Rank 0] step=1245, skipped=0, lr=[1.3587797333333334e-06, 1.3587797333333334e-06, 1.3587797333333334e-06, 1.3587797333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:53,286] [INFO] [timer.py:215:stop] epoch=0/micro_step=1245/global_step=1245, RunningAvgSamplesPerSec=4.921513507416865, CurrSamplesPerSec=4.843816151581748, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:53,287] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.67 | backward_microstep: 114.72 | backward_inner_microstep: 103.57 | backward_allreduce_microstep: 11.05 | step_microstep: 43.50
[default0]:[2023-08-25 18:12:53,287] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.67 (forward_moe: 21.16, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.71)
[default0]:[2023-08-25 18:12:53,287] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.72 | backward_inner: 103.58 | backward_allreduce: 11.06 | step: 43.50
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([48.0798], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1245/439453125 | consumed samples:         1245 | consumed tokens:      2549760 | elapsed time per iteration (ms): 263.6 | learning rate: 1.359E-06 | global batch size:     1 | lm loss: 9.615965E+00 | moe loss: 6.016062E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.793 | TFLOPs: 9.43 |
[default0]:[2023-08-25 18:12:53,540] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.05 | optimizer_step: 6.44
[default0]:[2023-08-25 18:12:53,540] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.70 | backward_microstep: 114.35 | backward_inner_microstep: 103.22 | backward_allreduce_microstep: 11.03 | step_microstep: 43.23
[default0]:[2023-08-25 18:12:53,540] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.70 (forward_moe: 20.88, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.42)
[default0]:[2023-08-25 18:12:53,540] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.34 | backward_inner: 103.23 | backward_allreduce: 11.03 | step: 43.23
[default0]:[2023-08-25 18:12:53,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:12:53,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.76 | backward_microstep: 112.67 | backward_inner_microstep: 101.64 | backward_allreduce_microstep: 10.94 | step_microstep: 42.57
[default0]:[2023-08-25 18:12:53,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.76 (forward_moe: 20.50, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.19)
[default0]:[2023-08-25 18:12:53,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.67 | backward_inner: 101.64 | backward_allreduce: 10.95 | step: 42.57
[default0]:[2023-08-25 18:12:54,050] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:12:54,051] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 112.58 | backward_inner_microstep: 101.54 | backward_allreduce_microstep: 10.95 | step_microstep: 42.71
[default0]:[2023-08-25 18:12:54,051] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.03 (forward_moe: 20.52, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:12:54,051] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.58 | backward_inner: 101.54 | backward_allreduce: 10.96 | step: 42.72
[default0]:[2023-08-25 18:12:54,308] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.36
[default0]:[2023-08-25 18:12:54,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.16 | backward_microstep: 112.71 | backward_inner_microstep: 101.58 | backward_allreduce_microstep: 11.03 | step_microstep: 42.66
[default0]:[2023-08-25 18:12:54,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.16 (forward_moe: 20.52, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:12:54,309] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.70 | backward_inner: 101.58 | backward_allreduce: 11.04 | step: 42.66
[default0]:[2023-08-25 18:12:54,555] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.41
[default0]:[2023-08-25 18:12:54,555] [INFO] [logging.py:96:log_dist] [Rank 0] step=1250, skipped=0, lr=[1.3642410666666667e-06, 1.3642410666666667e-06, 1.3642410666666667e-06, 1.3642410666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:54,555] [INFO] [timer.py:215:stop] epoch=0/micro_step=1250/global_step=1250, RunningAvgSamplesPerSec=4.921440209284144, CurrSamplesPerSec=4.918193181631634, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:54,555] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 112.79 | backward_inner_microstep: 101.79 | backward_allreduce_microstep: 10.91 | step_microstep: 42.96
[default0]:[2023-08-25 18:12:54,555] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.01 (forward_moe: 20.68, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:12:54,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.79 | backward_inner: 101.79 | backward_allreduce: 10.91 | step: 42.97
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.7777], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1250/439453125 | consumed samples:         1250 | consumed tokens:      2560000 | elapsed time per iteration (ms): 253.7 | learning rate: 1.364E-06 | global batch size:     1 | lm loss: 9.355543E+00 | moe loss: 6.015387E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.942 | TFLOPs: 9.80 |
[default0]:[2023-08-25 18:12:54,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:54,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.21 | backward_microstep: 110.18 | backward_inner_microstep: 99.28 | backward_allreduce_microstep: 10.81 | step_microstep: 41.81
[default0]:[2023-08-25 18:12:54,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.20 (forward_moe: 19.93, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.86)
[default0]:[2023-08-25 18:12:54,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.18 | backward_inner: 99.28 | backward_allreduce: 10.81 | step: 41.81
[default0]:[2023-08-25 18:12:55,045] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:55,045] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.15 | backward_microstep: 109.94 | backward_inner_microstep: 99.04 | backward_allreduce_microstep: 10.80 | step_microstep: 41.69
[default0]:[2023-08-25 18:12:55,045] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.14 (forward_moe: 20.00, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:12:55,045] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.94 | backward_inner: 99.05 | backward_allreduce: 10.81 | step: 41.70
[default0]:[2023-08-25 18:12:55,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:55,273] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.58 | backward_microstep: 110.03 | backward_inner_microstep: 99.19 | backward_allreduce_microstep: 10.74 | step_microstep: 41.92
[default0]:[2023-08-25 18:12:55,274] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.58 (forward_moe: 20.07, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.95)
[default0]:[2023-08-25 18:12:55,274] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.03 | backward_inner: 99.20 | backward_allreduce: 10.75 | step: 41.92
[default0]:[2023-08-25 18:12:55,513] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:55,514] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.93 | backward_microstep: 109.94 | backward_inner_microstep: 99.09 | backward_allreduce_microstep: 10.75 | step_microstep: 41.81
[default0]:[2023-08-25 18:12:55,514] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.93 (forward_moe: 19.98, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:12:55,514] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.93 | backward_inner: 99.10 | backward_allreduce: 10.75 | step: 41.81
[default0]:[2023-08-25 18:12:55,751] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:55,752] [INFO] [logging.py:96:log_dist] [Rank 0] step=1255, skipped=0, lr=[1.3697024000000002e-06, 1.3697024000000002e-06, 1.3697024000000002e-06, 1.3697024000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:55,752] [INFO] [timer.py:215:stop] epoch=0/micro_step=1255/global_step=1255, RunningAvgSamplesPerSec=4.921808535434468, CurrSamplesPerSec=5.015190357757796, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:55,752] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.48 | backward_microstep: 110.24 | backward_inner_microstep: 99.39 | backward_allreduce_microstep: 10.76 | step_microstep: 42.11
[default0]:[2023-08-25 18:12:55,752] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.48 (forward_moe: 19.96, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:12:55,752] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.24 | backward_inner: 99.40 | backward_allreduce: 10.76 | step: 42.12
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.9551], device='cuda:0'), 'moe loss': tensor([0.3014], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1255/439453125 | consumed samples:         1255 | consumed tokens:      2570240 | elapsed time per iteration (ms): 239.2 | learning rate: 1.370E-06 | global batch size:     1 | lm loss: 9.591025E+00 | moe loss: 6.028171E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.180 | TFLOPs: 10.39 |
[default0]:[2023-08-25 18:12:56,001] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:56,002] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.75 | backward_microstep: 109.70 | backward_inner_microstep: 98.83 | backward_allreduce_microstep: 10.78 | step_microstep: 42.35
[default0]:[2023-08-25 18:12:56,002] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.75 (forward_moe: 19.90, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:12:56,003] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.70 | backward_inner: 98.83 | backward_allreduce: 10.78 | step: 42.36
[default0]:[2023-08-25 18:12:56,257] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:56,257] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.99 | backward_microstep: 109.67 | backward_inner_microstep: 98.82 | backward_allreduce_microstep: 10.76 | step_microstep: 41.69
[default0]:[2023-08-25 18:12:56,258] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.98 (forward_moe: 19.89, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.81)
[default0]:[2023-08-25 18:12:56,258] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.67 | backward_inner: 98.82 | backward_allreduce: 10.76 | step: 41.70
[default0]:[2023-08-25 18:12:56,521] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.28
[default0]:[2023-08-25 18:12:56,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.75 | backward_microstep: 109.51 | backward_inner_microstep: 98.63 | backward_allreduce_microstep: 10.79 | step_microstep: 41.52
[default0]:[2023-08-25 18:12:56,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.75 (forward_moe: 19.85, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.78)
[default0]:[2023-08-25 18:12:56,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.51 | backward_inner: 98.63 | backward_allreduce: 10.79 | step: 41.53
[default0]:[2023-08-25 18:12:56,755] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:56,755] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 109.94 | backward_inner_microstep: 99.08 | backward_allreduce_microstep: 10.77 | step_microstep: 41.61
[default0]:[2023-08-25 18:12:56,755] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.99 (forward_moe: 19.90, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:12:56,755] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.93 | backward_inner: 99.08 | backward_allreduce: 10.77 | step: 41.62
[default0]:[2023-08-25 18:12:57,006] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.74 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:57,006] [INFO] [logging.py:96:log_dist] [Rank 0] step=1260, skipped=0, lr=[1.3751637333333335e-06, 1.3751637333333335e-06, 1.3751637333333335e-06, 1.3751637333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:57,006] [INFO] [timer.py:215:stop] epoch=0/micro_step=1260/global_step=1260, RunningAvgSamplesPerSec=4.922288879767462, CurrSamplesPerSec=5.044923507711775, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:57,007] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.89 | backward_microstep: 109.65 | backward_inner_microstep: 98.78 | backward_allreduce_microstep: 10.78 | step_microstep: 42.13
[default0]:[2023-08-25 18:12:57,007] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.89 (forward_moe: 20.01, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.80)
[default0]:[2023-08-25 18:12:57,007] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.65 | backward_inner: 98.78 | backward_allreduce: 10.78 | step: 42.13
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.1292], device='cuda:0'), 'moe loss': tensor([0.3015], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1260/439453125 | consumed samples:         1260 | consumed tokens:      2580480 | elapsed time per iteration (ms): 250.7 | learning rate: 1.375E-06 | global batch size:     1 | lm loss: 9.425833E+00 | moe loss: 6.030387E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.989 | TFLOPs: 9.91 |
[default0]:[2023-08-25 18:12:57,258] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:12:57,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 109.74 | backward_inner_microstep: 98.87 | backward_allreduce_microstep: 10.78 | step_microstep: 42.08
[default0]:[2023-08-25 18:12:57,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.67 (forward_moe: 20.04, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.95)
[default0]:[2023-08-25 18:12:57,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.74 | backward_inner: 98.87 | backward_allreduce: 10.79 | step: 42.09
[default0]:[2023-08-25 18:12:57,498] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:57,498] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.96 | backward_microstep: 109.50 | backward_inner_microstep: 98.67 | backward_allreduce_microstep: 10.74 | step_microstep: 41.57
[default0]:[2023-08-25 18:12:57,498] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.96 (forward_moe: 20.01, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:12:57,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.50 | backward_inner: 98.67 | backward_allreduce: 10.75 | step: 41.57
[default0]:[2023-08-25 18:12:57,789] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:57,789] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.79 | backward_microstep: 112.21 | backward_inner_microstep: 101.15 | backward_allreduce_microstep: 10.96 | step_microstep: 42.49
[default0]:[2023-08-25 18:12:57,789] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.39, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.10)
[default0]:[2023-08-25 18:12:57,789] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.20 | backward_inner: 101.16 | backward_allreduce: 10.96 | step: 42.49
[default0]:[2023-08-25 18:12:58,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:12:58,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.52 | backward_microstep: 112.71 | backward_inner_microstep: 101.78 | backward_allreduce_microstep: 10.84 | step_microstep: 42.23
[default0]:[2023-08-25 18:12:58,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.52 (forward_moe: 21.70, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 9.46)
[default0]:[2023-08-25 18:12:58,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.71 | backward_inner: 101.79 | backward_allreduce: 10.84 | step: 42.23
[default0]:[2023-08-25 18:12:58,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.33
[default0]:[2023-08-25 18:12:58,292] [INFO] [logging.py:96:log_dist] [Rank 0] step=1265, skipped=0, lr=[1.3806250666666669e-06, 1.3806250666666669e-06, 1.3806250666666669e-06, 1.3806250666666669e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:58,292] [INFO] [timer.py:215:stop] epoch=0/micro_step=1265/global_step=1265, RunningAvgSamplesPerSec=4.922552308891742, CurrSamplesPerSec=4.967294501080078, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:58,293] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.65 | backward_microstep: 111.49 | backward_inner_microstep: 100.54 | backward_allreduce_microstep: 10.85 | step_microstep: 42.65
[default0]:[2023-08-25 18:12:58,293] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.65 (forward_moe: 20.38, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:12:58,293] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.49 | backward_inner: 100.55 | backward_allreduce: 10.86 | step: 42.65
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.1754], device='cuda:0'), 'moe loss': tensor([0.3014], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1265/439453125 | consumed samples:         1265 | consumed tokens:      2590720 | elapsed time per iteration (ms): 257.5 | learning rate: 1.381E-06 | global batch size:     1 | lm loss: 9.435073E+00 | moe loss: 6.027377E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.884 | TFLOPs: 9.65 |
[default0]:[2023-08-25 18:12:58,571] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.37
[default0]:[2023-08-25 18:12:58,571] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.55 | backward_microstep: 111.48 | backward_inner_microstep: 100.47 | backward_allreduce_microstep: 10.91 | step_microstep: 42.51
[default0]:[2023-08-25 18:12:58,571] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.55 (forward_moe: 20.38, 1st alltoall: 0.97, 2nd alltoall: 0.81, top-k: 8.06)
[default0]:[2023-08-25 18:12:58,571] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.48 | backward_inner: 100.48 | backward_allreduce: 10.91 | step: 42.51
[default0]:[2023-08-25 18:12:58,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:58,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.02 | backward_microstep: 110.05 | backward_inner_microstep: 99.17 | backward_allreduce_microstep: 10.78 | step_microstep: 41.61
[default0]:[2023-08-25 18:12:58,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.02 (forward_moe: 20.00, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:12:58,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.10 | backward_inner: 99.18 | backward_allreduce: 10.78 | step: 41.61
[default0]:[2023-08-25 18:12:59,050] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:59,050] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.79 | backward_microstep: 109.61 | backward_inner_microstep: 98.77 | backward_allreduce_microstep: 10.75 | step_microstep: 41.67
[default0]:[2023-08-25 18:12:59,050] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.79 (forward_moe: 19.95, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:12:59,050] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.61 | backward_inner: 98.77 | backward_allreduce: 10.76 | step: 41.67
[default0]:[2023-08-25 18:12:59,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:12:59,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.88 | backward_microstep: 109.60 | backward_inner_microstep: 98.77 | backward_allreduce_microstep: 10.74 | step_microstep: 41.76
[default0]:[2023-08-25 18:12:59,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.88 (forward_moe: 19.98, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:12:59,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.60 | backward_inner: 98.78 | backward_allreduce: 10.74 | step: 41.77
[default0]:[2023-08-25 18:12:59,562] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.92 | optimizer_step: 6.42
[default0]:[2023-08-25 18:12:59,563] [INFO] [logging.py:96:log_dist] [Rank 0] step=1270, skipped=0, lr=[1.3860864000000002e-06, 1.3860864000000002e-06, 1.3860864000000002e-06, 1.3860864000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:12:59,563] [INFO] [timer.py:215:stop] epoch=0/micro_step=1270/global_step=1270, RunningAvgSamplesPerSec=4.9229664144763134, CurrSamplesPerSec=5.045032735005828, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:12:59,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.85 | backward_microstep: 109.75 | backward_inner_microstep: 98.90 | backward_allreduce_microstep: 10.74 | step_microstep: 42.08
[default0]:[2023-08-25 18:12:59,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.85 (forward_moe: 20.05, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.82)
[default0]:[2023-08-25 18:12:59,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.74 | backward_inner: 98.91 | backward_allreduce: 10.75 | step: 42.09
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.4438], device='cuda:0'), 'moe loss': tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1270/439453125 | consumed samples:         1270 | consumed tokens:      2600960 | elapsed time per iteration (ms): 253.9 | learning rate: 1.386E-06 | global batch size:     1 | lm loss: 9.488760E+00 | moe loss: 6.009037E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.939 | TFLOPs: 9.79 |
[default0]:[2023-08-25 18:12:59,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:12:59,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.83 | backward_microstep: 110.13 | backward_inner_microstep: 99.29 | backward_allreduce_microstep: 10.75 | step_microstep: 41.92
[default0]:[2023-08-25 18:12:59,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.83 (forward_moe: 19.88, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.80)
[default0]:[2023-08-25 18:12:59,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.13 | backward_inner: 99.29 | backward_allreduce: 10.75 | step: 41.93
[default0]:[2023-08-25 18:13:00,039] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:00,039] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.88 | backward_microstep: 109.52 | backward_inner_microstep: 98.71 | backward_allreduce_microstep: 10.73 | step_microstep: 41.74
[default0]:[2023-08-25 18:13:00,039] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.88 (forward_moe: 20.00, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.81)
[default0]:[2023-08-25 18:13:00,040] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.52 | backward_inner: 98.71 | backward_allreduce: 10.73 | step: 41.74
[default0]:[2023-08-25 18:13:00,296] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:00,296] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 109.53 | backward_inner_microstep: 98.67 | backward_allreduce_microstep: 10.76 | step_microstep: 41.73
[default0]:[2023-08-25 18:13:00,296] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:13:00,296] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.53 | backward_inner: 98.67 | backward_allreduce: 10.77 | step: 41.73
[default0]:[2023-08-25 18:13:00,540] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:00,541] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.91 | backward_microstep: 111.21 | backward_inner_microstep: 100.29 | backward_allreduce_microstep: 10.82 | step_microstep: 42.18
[default0]:[2023-08-25 18:13:00,541] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.91 (forward_moe: 20.28, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.01)
[default0]:[2023-08-25 18:13:00,541] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.21 | backward_inner: 100.30 | backward_allreduce: 10.83 | step: 42.18
[default0]:[2023-08-25 18:13:00,786] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:13:00,787] [INFO] [logging.py:96:log_dist] [Rank 0] step=1275, skipped=0, lr=[1.3915477333333335e-06, 1.3915477333333335e-06, 1.3915477333333335e-06, 1.3915477333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:00,787] [INFO] [timer.py:215:stop] epoch=0/micro_step=1275/global_step=1275, RunningAvgSamplesPerSec=4.92331044269939, CurrSamplesPerSec=4.9268242259080015, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:00,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.38 | backward_microstep: 112.18 | backward_inner_microstep: 101.14 | backward_allreduce_microstep: 10.94 | step_microstep: 42.86
[default0]:[2023-08-25 18:13:00,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.38 (forward_moe: 20.45, 1st alltoall: 0.88, 2nd alltoall: 0.91, top-k: 8.08)
[default0]:[2023-08-25 18:13:00,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.17 | backward_inner: 101.14 | backward_allreduce: 10.94 | step: 42.87
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.7966], device='cuda:0'), 'moe loss': tensor([0.3024], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1275/439453125 | consumed samples:         1275 | consumed tokens:      2611200 | elapsed time per iteration (ms): 245.4 | learning rate: 1.392E-06 | global batch size:     1 | lm loss: 9.559315E+00 | moe loss: 6.048124E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.076 | TFLOPs: 10.13 |
[default0]:[2023-08-25 18:13:01,041] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:01,042] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 109.92 | backward_inner_microstep: 98.80 | backward_allreduce_microstep: 11.03 | step_microstep: 41.96
[default0]:[2023-08-25 18:13:01,042] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.76)
[default0]:[2023-08-25 18:13:01,042] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.92 | backward_inner: 98.81 | backward_allreduce: 11.03 | step: 41.96
[default0]:[2023-08-25 18:13:01,285] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:01,286] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.33 | backward_microstep: 110.33 | backward_inner_microstep: 99.34 | backward_allreduce_microstep: 10.90 | step_microstep: 41.82
[default0]:[2023-08-25 18:13:01,286] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.33 (forward_moe: 20.16, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 8.07)
[default0]:[2023-08-25 18:13:01,286] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.33 | backward_inner: 99.34 | backward_allreduce: 10.91 | step: 41.82
[default0]:[2023-08-25 18:13:01,523] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:01,523] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.96 | backward_microstep: 109.40 | backward_inner_microstep: 98.54 | backward_allreduce_microstep: 10.77 | step_microstep: 41.53
[default0]:[2023-08-25 18:13:01,523] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.96 (forward_moe: 19.82, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:13:01,523] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.40 | backward_inner: 98.54 | backward_allreduce: 10.77 | step: 41.54
[default0]:[2023-08-25 18:13:01,769] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:01,769] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.62 | backward_microstep: 109.50 | backward_inner_microstep: 98.69 | backward_allreduce_microstep: 10.71 | step_microstep: 41.87
[default0]:[2023-08-25 18:13:01,770] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.78)
[default0]:[2023-08-25 18:13:01,770] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.50 | backward_inner: 98.70 | backward_allreduce: 10.72 | step: 41.87
[default0]:[2023-08-25 18:13:02,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:02,028] [INFO] [logging.py:96:log_dist] [Rank 0] step=1280, skipped=0, lr=[1.3970090666666668e-06, 1.3970090666666668e-06, 1.3970090666666668e-06, 1.3970090666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:02,029] [INFO] [timer.py:215:stop] epoch=0/micro_step=1280/global_step=1280, RunningAvgSamplesPerSec=4.9236692158067425, CurrSamplesPerSec=4.98626795265172, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:02,029] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.02 | backward_microstep: 109.68 | backward_inner_microstep: 98.87 | backward_allreduce_microstep: 10.72 | step_microstep: 42.34
[default0]:[2023-08-25 18:13:02,029] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.02 (forward_moe: 19.99, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.79)
[default0]:[2023-08-25 18:13:02,029] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.68 | backward_inner: 98.88 | backward_allreduce: 10.72 | step: 42.34
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.8943], device='cuda:0'), 'moe loss': tensor([0.3021], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1280/439453125 | consumed samples:         1280 | consumed tokens:      2621440 | elapsed time per iteration (ms): 254.9 | learning rate: 1.397E-06 | global batch size:     1 | lm loss: 9.578869E+00 | moe loss: 6.041080E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.924 | TFLOPs: 9.75 |
[default0]:[2023-08-25 18:13:02,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 10.04
[default0]:[2023-08-25 18:13:02,318] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.75 | backward_microstep: 109.58 | backward_inner_microstep: 98.57 | backward_allreduce_microstep: 10.91 | step_microstep: 45.32
[default0]:[2023-08-25 18:13:02,318] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.75 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.78)
[default0]:[2023-08-25 18:13:02,318] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.57 | backward_inner: 98.58 | backward_allreduce: 10.91 | step: 45.32
[default0]:[2023-08-25 18:13:02,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:02,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.82 | backward_microstep: 109.34 | backward_inner_microstep: 98.44 | backward_allreduce_microstep: 10.80 | step_microstep: 41.58
[default0]:[2023-08-25 18:13:02,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.82 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.76)
[default0]:[2023-08-25 18:13:02,563] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.34 | backward_inner: 98.45 | backward_allreduce: 10.81 | step: 41.58
[default0]:[2023-08-25 18:13:02,805] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.40
[default0]:[2023-08-25 18:13:02,805] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.10 | backward_microstep: 112.77 | backward_inner_microstep: 101.73 | backward_allreduce_microstep: 10.95 | step_microstep: 42.71
[default0]:[2023-08-25 18:13:02,805] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.10 (forward_moe: 20.72, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:13:02,805] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.77 | backward_inner: 101.73 | backward_allreduce: 10.95 | step: 42.72
[default0]:[2023-08-25 18:13:03,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:03,097] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.04 | backward_microstep: 108.98 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.72 | step_microstep: 42.32
[default0]:[2023-08-25 18:13:03,097] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.04 (forward_moe: 19.75, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:13:03,097] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.98 | backward_inner: 98.17 | backward_allreduce: 10.72 | step: 42.32
[default0]:[2023-08-25 18:13:03,362] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:03,363] [INFO] [logging.py:96:log_dist] [Rank 0] step=1285, skipped=0, lr=[1.4024704000000001e-06, 1.4024704000000001e-06, 1.4024704000000001e-06, 1.4024704000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:03,363] [INFO] [timer.py:215:stop] epoch=0/micro_step=1285/global_step=1285, RunningAvgSamplesPerSec=4.923976147050443, CurrSamplesPerSec=5.056631616003549, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:03,363] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.43 | backward_microstep: 109.08 | backward_inner_microstep: 98.28 | backward_allreduce_microstep: 10.70 | step_microstep: 41.72
[default0]:[2023-08-25 18:13:03,363] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.43 (forward_moe: 19.85, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:13:03,363] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.28 | backward_allreduce: 10.71 | step: 41.72
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.7840], device='cuda:0'), 'moe loss': tensor([0.3019], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1285/439453125 | consumed samples:         1285 | consumed tokens:      2631680 | elapsed time per iteration (ms): 259.8 | learning rate: 1.402E-06 | global batch size:     1 | lm loss: 9.356801E+00 | moe loss: 6.037771E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.850 | TFLOPs: 9.57 |
[default0]:[2023-08-25 18:13:03,611] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.41
[default0]:[2023-08-25 18:13:03,611] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.42 | backward_microstep: 109.03 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.73 | step_microstep: 41.64
[default0]:[2023-08-25 18:13:03,611] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.42 (forward_moe: 19.86, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.72)
[default0]:[2023-08-25 18:13:03,611] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.21 | backward_allreduce: 10.73 | step: 41.64
[default0]:[2023-08-25 18:13:03,861] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:03,861] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.67 | backward_microstep: 109.17 | backward_inner_microstep: 98.34 | backward_allreduce_microstep: 10.74 | step_microstep: 41.40
[default0]:[2023-08-25 18:13:03,861] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.67 (forward_moe: 19.87, 1st alltoall: 0.85, 2nd alltoall: 0.88, top-k: 7.73)
[default0]:[2023-08-25 18:13:03,861] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.17 | backward_inner: 98.34 | backward_allreduce: 10.75 | step: 41.40
[default0]:[2023-08-25 18:13:04,129] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:04,130] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 108.88 | backward_inner_microstep: 98.07 | backward_allreduce_microstep: 10.72 | step_microstep: 41.58
[default0]:[2023-08-25 18:13:04,130] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.41 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:13:04,130] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.88 | backward_inner: 98.07 | backward_allreduce: 10.73 | step: 41.59
[default0]:[2023-08-25 18:13:04,391] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:13:04,391] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.72 | backward_microstep: 109.01 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.74 | step_microstep: 41.44
[default0]:[2023-08-25 18:13:04,391] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.71 (forward_moe: 19.77, 1st alltoall: 0.89, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:13:04,391] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.01 | backward_inner: 98.18 | backward_allreduce: 10.74 | step: 41.44
[default0]:[2023-08-25 18:13:04,620] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:04,621] [INFO] [logging.py:96:log_dist] [Rank 0] step=1290, skipped=0, lr=[1.4079317333333334e-06, 1.4079317333333334e-06, 1.4079317333333334e-06, 1.4079317333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:04,621] [INFO] [timer.py:215:stop] epoch=0/micro_step=1290/global_step=1290, RunningAvgSamplesPerSec=4.924559436399071, CurrSamplesPerSec=5.079467191127441, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:04,621] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.48 | backward_microstep: 108.99 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.72 | step_microstep: 41.85
[default0]:[2023-08-25 18:13:04,621] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.86, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:13:04,621] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.99 | backward_inner: 98.18 | backward_allreduce: 10.73 | step: 41.85
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.4023], device='cuda:0'), 'moe loss': tensor([0.3001], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1290/439453125 | consumed samples:         1290 | consumed tokens:      2641920 | elapsed time per iteration (ms): 251.8 | learning rate: 1.408E-06 | global batch size:     1 | lm loss: 9.480452E+00 | moe loss: 6.001033E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.971 | TFLOPs: 9.87 |
[default0]:[2023-08-25 18:13:04,870] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:04,871] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.24 | backward_microstep: 109.52 | backward_inner_microstep: 98.52 | backward_allreduce_microstep: 10.91 | step_microstep: 41.37
[default0]:[2023-08-25 18:13:04,871] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.24 (forward_moe: 19.78, 1st alltoall: 0.85, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:13:04,871] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.52 | backward_inner: 98.53 | backward_allreduce: 10.91 | step: 41.37
[default0]:[2023-08-25 18:13:05,109] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:05,110] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 108.94 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.75 | step_microstep: 41.52
[default0]:[2023-08-25 18:13:05,110] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:13:05,110] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.93 | backward_inner: 98.09 | backward_allreduce: 10.76 | step: 41.53
[default0]:[2023-08-25 18:13:05,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:05,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.65 | backward_microstep: 108.99 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.71 | step_microstep: 41.67
[default0]:[2023-08-25 18:13:05,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.65 (forward_moe: 19.81, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:13:05,350] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.98 | backward_inner: 98.18 | backward_allreduce: 10.72 | step: 41.67
[default0]:[2023-08-25 18:13:05,591] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:13:05,592] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.74 | backward_microstep: 109.03 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.76 | step_microstep: 41.40
[default0]:[2023-08-25 18:13:05,592] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.73 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:13:05,592] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.18 | backward_allreduce: 10.76 | step: 41.40
[default0]:[2023-08-25 18:13:05,885] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:13:05,885] [INFO] [logging.py:96:log_dist] [Rank 0] step=1295, skipped=0, lr=[1.4133930666666667e-06, 1.4133930666666667e-06, 1.4133930666666667e-06, 1.4133930666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:05,885] [INFO] [timer.py:215:stop] epoch=0/micro_step=1295/global_step=1295, RunningAvgSamplesPerSec=4.925082124432315, CurrSamplesPerSec=5.0659761140957755, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:05,885] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.57 | backward_microstep: 109.15 | backward_inner_microstep: 98.33 | backward_allreduce_microstep: 10.72 | step_microstep: 42.15
[default0]:[2023-08-25 18:13:05,886] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.57 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.81)
[default0]:[2023-08-25 18:13:05,886] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.15 | backward_inner: 98.34 | backward_allreduce: 10.72 | step: 42.16
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.0756], device='cuda:0'), 'moe loss': tensor([0.3004], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1295/439453125 | consumed samples:         1295 | consumed tokens:      2652160 | elapsed time per iteration (ms): 252.5 | learning rate: 1.413E-06 | global batch size:     1 | lm loss: 9.415123E+00 | moe loss: 6.008441E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.960 | TFLOPs: 9.84 |
[default0]:[2023-08-25 18:13:06,173] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:13:06,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.35 | backward_microstep: 108.97 | backward_inner_microstep: 98.12 | backward_allreduce_microstep: 10.76 | step_microstep: 41.64
[default0]:[2023-08-25 18:13:06,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.35 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:13:06,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.97 | backward_inner: 98.13 | backward_allreduce: 10.77 | step: 41.64
[default0]:[2023-08-25 18:13:06,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.88 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:06,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.89 | backward_microstep: 109.06 | backward_inner_microstep: 98.20 | backward_allreduce_microstep: 10.77 | step_microstep: 41.54
[default0]:[2023-08-25 18:13:06,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.89 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:13:06,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.06 | backward_inner: 98.20 | backward_allreduce: 10.77 | step: 41.55
[default0]:[2023-08-25 18:13:06,749] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:06,749] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.69 | backward_microstep: 108.98 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.76 | step_microstep: 41.44
[default0]:[2023-08-25 18:13:06,749] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:13:06,749] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.98 | backward_inner: 98.13 | backward_allreduce: 10.77 | step: 41.45
[default0]:[2023-08-25 18:13:06,992] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:06,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.66 | backward_microstep: 108.89 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.70 | step_microstep: 41.68
[default0]:[2023-08-25 18:13:06,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:13:06,993] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.88 | backward_inner: 98.10 | backward_allreduce: 10.71 | step: 41.68
[default0]:[2023-08-25 18:13:07,246] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:07,246] [INFO] [logging.py:96:log_dist] [Rank 0] step=1300, skipped=0, lr=[1.4188544000000003e-06, 1.4188544000000003e-06, 1.4188544000000003e-06, 1.4188544000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:07,246] [INFO] [timer.py:215:stop] epoch=0/micro_step=1300/global_step=1300, RunningAvgSamplesPerSec=4.925642117295295, CurrSamplesPerSec=5.071918313449404, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:07,247] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 109.08 | backward_inner_microstep: 98.29 | backward_allreduce_microstep: 10.70 | step_microstep: 41.84
[default0]:[2023-08-25 18:13:07,247] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.70 (forward_moe: 19.86, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:13:07,247] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.29 | backward_allreduce: 10.70 | step: 41.84
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.5171], device='cuda:0'), 'moe loss': tensor([0.3009], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1300/439453125 | consumed samples:         1300 | consumed tokens:      2662400 | elapsed time per iteration (ms): 272.4 | learning rate: 1.419E-06 | global batch size:     1 | lm loss: 9.503412E+00 | moe loss: 6.018739E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.671 | TFLOPs: 9.12 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1300 | lm loss value: 9.422374E+00 | lm loss PPL: 1.236189E+04 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration    1300 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:13:10,968] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1300 is about to be saved!
[default0]:[2023-08-25 18:13:10,970] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:10,980] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:10,980] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:10,990] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:10,990] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:10,999] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:10,999] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,008] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,008] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,017] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,017] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,027] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,027] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,036] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,036] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,044] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,045] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,054] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,054] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,063] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,064] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,072] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,073] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,082] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,083] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,092] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,092] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,101] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,101] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,109] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,110] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,118] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,119] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,129] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,129] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,138] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,138] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,147] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,147] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,156] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,157] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,165] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,166] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,174] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,174] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,183] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,183] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,192] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,192] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:13:11,194] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:13:11,195] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:13:11,195] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:11,470] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:11,471] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:13:15,276] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:13:15,290] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1300/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:13:15,291] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1300 is ready now!
[default0]:  successfully saved checkpoint at iteration    1300 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.68, Latency(second): 4.327
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4327.27, 4327.27)
[default0]:[2023-08-25 18:13:15,554] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.17 | optimizer_step: 10.02
[default0]:[2023-08-25 18:13:15,555] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2291.60 | backward_microstep: 117.58 | backward_inner_microstep: 106.43 | backward_allreduce_microstep: 11.05 | step_microstep: 47.73
[default0]:[2023-08-25 18:13:15,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2291.54 (forward_moe: 21.48, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.75)
[default0]:[2023-08-25 18:13:15,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.57 | backward_inner: 106.44 | backward_allreduce: 11.05 | step: 47.73
[default0]:[2023-08-25 18:13:15,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.15 | optimizer_step: 6.51
[default0]:[2023-08-25 18:13:15,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.20 | backward_microstep: 116.63 | backward_inner_microstep: 105.53 | backward_allreduce_microstep: 11.00 | step_microstep: 43.80
[default0]:[2023-08-25 18:13:15,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.20 (forward_moe: 21.46, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.72)
[default0]:[2023-08-25 18:13:15,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.63 | backward_inner: 105.54 | backward_allreduce: 11.00 | step: 43.80
[default0]:[2023-08-25 18:13:16,109] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.44
[default0]:[2023-08-25 18:13:16,109] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.06 | backward_microstep: 116.78 | backward_inner_microstep: 105.70 | backward_allreduce_microstep: 10.99 | step_microstep: 43.65
[default0]:[2023-08-25 18:13:16,109] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.06 (forward_moe: 21.42, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.72)
[default0]:[2023-08-25 18:13:16,110] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.78 | backward_inner: 105.71 | backward_allreduce: 10.99 | step: 43.65
[default0]:[2023-08-25 18:13:16,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.43
[default0]:[2023-08-25 18:13:16,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.82 | backward_microstep: 115.14 | backward_inner_microstep: 103.86 | backward_allreduce_microstep: 11.19 | step_microstep: 43.56
[default0]:[2023-08-25 18:13:16,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.82 (forward_moe: 21.08, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.55)
[default0]:[2023-08-25 18:13:16,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.14 | backward_inner: 103.87 | backward_allreduce: 11.19 | step: 43.57
[default0]:[2023-08-25 18:13:16,698] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.08 | optimizer_step: 6.40
[default0]:[2023-08-25 18:13:16,698] [INFO] [logging.py:96:log_dist] [Rank 0] step=1305, skipped=0, lr=[1.4243157333333336e-06, 1.4243157333333336e-06, 1.4243157333333336e-06, 1.4243157333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:16,699] [INFO] [timer.py:215:stop] epoch=0/micro_step=1305/global_step=1305, RunningAvgSamplesPerSec=4.924765961617256, CurrSamplesPerSec=4.7234216986869075, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:16,699] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.38 | backward_microstep: 118.27 | backward_inner_microstep: 106.54 | backward_allreduce_microstep: 11.63 | step_microstep: 44.52
[default0]:[2023-08-25 18:13:16,699] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.38 (forward_moe: 21.62, 1st alltoall: 0.93, 2nd alltoall: 0.86, top-k: 8.70)
[default0]:[2023-08-25 18:13:16,699] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 118.27 | backward_inner: 106.55 | backward_allreduce: 11.64 | step: 44.52
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.3812], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1305/439453125 | consumed samples:         1305 | consumed tokens:      2672640 | elapsed time per iteration (ms): 1890.5 | learning rate: 1.424E-06 | global batch size:     1 | lm loss: 9.476231E+00 | moe loss: 6.020179E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.529 | TFLOPs: 1.31 |
[default0]:[2023-08-25 18:13:16,966] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:13:16,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.89 | backward_microstep: 112.11 | backward_inner_microstep: 101.11 | backward_allreduce_microstep: 10.91 | step_microstep: 42.41
[default0]:[2023-08-25 18:13:16,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.89 (forward_moe: 20.49, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.11)
[default0]:[2023-08-25 18:13:16,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.11 | backward_inner: 101.11 | backward_allreduce: 10.91 | step: 42.42
[default0]:[2023-08-25 18:13:17,216] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:13:17,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.99 | backward_microstep: 111.95 | backward_inner_microstep: 100.98 | backward_allreduce_microstep: 10.88 | step_microstep: 42.98
[default0]:[2023-08-25 18:13:17,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.98 (forward_moe: 20.39, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:13:17,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.95 | backward_inner: 100.98 | backward_allreduce: 10.88 | step: 42.98
[default0]:[2023-08-25 18:13:17,486] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:13:17,486] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.79 | backward_microstep: 111.91 | backward_inner_microstep: 100.96 | backward_allreduce_microstep: 10.85 | step_microstep: 42.46
[default0]:[2023-08-25 18:13:17,486] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.39, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:13:17,486] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.90 | backward_inner: 100.97 | backward_allreduce: 10.85 | step: 42.46
[default0]:[2023-08-25 18:13:17,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:13:17,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.79 | backward_microstep: 110.32 | backward_inner_microstep: 98.93 | backward_allreduce_microstep: 11.29 | step_microstep: 43.05
[default0]:[2023-08-25 18:13:17,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.79 (forward_moe: 20.02, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:13:17,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.32 | backward_inner: 98.94 | backward_allreduce: 11.29 | step: 43.06
[default0]:[2023-08-25 18:13:18,004] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:18,005] [INFO] [logging.py:96:log_dist] [Rank 0] step=1310, skipped=0, lr=[1.429777066666667e-06, 1.429777066666667e-06, 1.429777066666667e-06, 1.429777066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:18,005] [INFO] [timer.py:215:stop] epoch=0/micro_step=1310/global_step=1310, RunningAvgSamplesPerSec=4.92489885531443, CurrSamplesPerSec=4.97044376422796, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:18,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.05 | backward_microstep: 111.53 | backward_inner_microstep: 100.65 | backward_allreduce_microstep: 10.77 | step_microstep: 42.06
[default0]:[2023-08-25 18:13:18,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.05 (forward_moe: 20.02, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:13:18,005] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.53 | backward_inner: 100.66 | backward_allreduce: 10.78 | step: 42.06
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.1550], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1310/439453125 | consumed samples:         1310 | consumed tokens:      2682880 | elapsed time per iteration (ms): 261.1 | learning rate: 1.430E-06 | global batch size:     1 | lm loss: 9.431003E+00 | moe loss: 6.015097E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.829 | TFLOPs: 9.52 |
[default0]:[2023-08-25 18:13:18,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:18,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.79 | backward_microstep: 109.63 | backward_inner_microstep: 98.76 | backward_allreduce_microstep: 10.77 | step_microstep: 41.61
[default0]:[2023-08-25 18:13:18,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.79 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.82, top-k: 7.80)
[default0]:[2023-08-25 18:13:18,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.63 | backward_inner: 98.76 | backward_allreduce: 10.78 | step: 41.61
[default0]:[2023-08-25 18:13:18,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:18,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.80 | backward_microstep: 109.72 | backward_inner_microstep: 98.82 | backward_allreduce_microstep: 10.80 | step_microstep: 41.77
[default0]:[2023-08-25 18:13:18,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.80 (forward_moe: 19.90, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:13:18,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.72 | backward_inner: 98.83 | backward_allreduce: 10.80 | step: 41.77
[default0]:[2023-08-25 18:13:18,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:18,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 109.27 | backward_inner_microstep: 98.40 | backward_allreduce_microstep: 10.78 | step_microstep: 41.35
[default0]:[2023-08-25 18:13:18,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.87, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:13:18,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.27 | backward_inner: 98.40 | backward_allreduce: 10.78 | step: 41.35
[default0]:[2023-08-25 18:13:18,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:18,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 109.03 | backward_inner_microstep: 98.24 | backward_allreduce_microstep: 10.69 | step_microstep: 41.43
[default0]:[2023-08-25 18:13:18,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:13:18,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.25 | backward_allreduce: 10.70 | step: 41.43
[default0]:[2023-08-25 18:13:19,234] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:19,234] [INFO] [logging.py:96:log_dist] [Rank 0] step=1315, skipped=0, lr=[1.4352384000000002e-06, 1.4352384000000002e-06, 1.4352384000000002e-06, 1.4352384000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:19,235] [INFO] [timer.py:215:stop] epoch=0/micro_step=1315/global_step=1315, RunningAvgSamplesPerSec=4.925432226147418, CurrSamplesPerSec=5.084393111231524, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:19,235] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 108.91 | backward_inner_microstep: 98.11 | backward_allreduce_microstep: 10.71 | step_microstep: 41.82
[default0]:[2023-08-25 18:13:19,235] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.41 (forward_moe: 19.81, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:13:19,235] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.91 | backward_inner: 98.11 | backward_allreduce: 10.71 | step: 41.82
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.1686], device='cuda:0'), 'moe loss': tensor([0.3000], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1315/439453125 | consumed samples:         1315 | consumed tokens:      2693120 | elapsed time per iteration (ms): 246.3 | learning rate: 1.435E-06 | global batch size:     1 | lm loss: 9.433712E+00 | moe loss: 6.000878E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.060 | TFLOPs: 10.09 |
[default0]:[2023-08-25 18:13:19,481] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:13:19,481] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.72 | backward_microstep: 108.90 | backward_inner_microstep: 98.12 | backward_allreduce_microstep: 10.69 | step_microstep: 41.58
[default0]:[2023-08-25 18:13:19,481] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.72 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:13:19,481] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 98.12 | backward_allreduce: 10.69 | step: 41.59
[default0]:[2023-08-25 18:13:19,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:19,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 108.91 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.73 | step_microstep: 41.80
[default0]:[2023-08-25 18:13:19,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:13:19,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.91 | backward_inner: 98.10 | backward_allreduce: 10.73 | step: 41.81
[default0]:[2023-08-25 18:13:20,002] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:13:20,002] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.25 | backward_microstep: 109.22 | backward_inner_microstep: 98.42 | backward_allreduce_microstep: 10.70 | step_microstep: 41.35
[default0]:[2023-08-25 18:13:20,002] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.25 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:13:20,002] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.22 | backward_inner: 98.43 | backward_allreduce: 10.71 | step: 41.35
[default0]:[2023-08-25 18:13:20,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:20,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 108.86 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.66 | step_microstep: 41.49
[default0]:[2023-08-25 18:13:20,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:13:20,238] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.86 | backward_inner: 98.11 | backward_allreduce: 10.67 | step: 41.49
[default0]:[2023-08-25 18:13:20,489] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:20,490] [INFO] [logging.py:96:log_dist] [Rank 0] step=1320, skipped=0, lr=[1.4406997333333335e-06, 1.4406997333333335e-06, 1.4406997333333335e-06, 1.4406997333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:20,490] [INFO] [timer.py:215:stop] epoch=0/micro_step=1320/global_step=1320, RunningAvgSamplesPerSec=4.925896719447968, CurrSamplesPerSec=4.9646486765447415, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:20,490] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.37 | backward_microstep: 111.72 | backward_inner_microstep: 100.73 | backward_allreduce_microstep: 10.89 | step_microstep: 42.78
[default0]:[2023-08-25 18:13:20,490] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.37 (forward_moe: 20.46, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.08)
[default0]:[2023-08-25 18:13:20,490] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.72 | backward_inner: 100.74 | backward_allreduce: 10.90 | step: 42.78
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.7023], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1320/439453125 | consumed samples:         1320 | consumed tokens:      2703360 | elapsed time per iteration (ms): 251.0 | learning rate: 1.441E-06 | global batch size:     1 | lm loss: 9.540456E+00 | moe loss: 6.016784E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.985 | TFLOPs: 9.90 |
[default0]:[2023-08-25 18:13:20,788] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:13:20,788] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.70 | backward_microstep: 112.06 | backward_inner_microstep: 101.04 | backward_allreduce_microstep: 10.93 | step_microstep: 42.66
[default0]:[2023-08-25 18:13:20,788] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.70 (forward_moe: 20.45, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.16)
[default0]:[2023-08-25 18:13:20,788] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.06 | backward_inner: 101.04 | backward_allreduce: 10.93 | step: 42.66
[default0]:[2023-08-25 18:13:21,074] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.40
[default0]:[2023-08-25 18:13:21,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.20 | backward_microstep: 113.99 | backward_inner_microstep: 102.90 | backward_allreduce_microstep: 11.00 | step_microstep: 289.46
[default0]:[2023-08-25 18:13:21,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.20 (forward_moe: 20.83, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.29)
[default0]:[2023-08-25 18:13:21,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.99 | backward_inner: 102.90 | backward_allreduce: 11.01 | step: 289.47
[default0]:[2023-08-25 18:13:21,572] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 6.52
[default0]:[2023-08-25 18:13:21,573] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.40 | backward_microstep: 117.42 | backward_inner_microstep: 106.10 | backward_allreduce_microstep: 11.23 | step_microstep: 44.62
[default0]:[2023-08-25 18:13:21,573] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.40 (forward_moe: 21.52, 1st alltoall: 0.92, 2nd alltoall: 0.84, top-k: 8.76)
[default0]:[2023-08-25 18:13:21,573] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.42 | backward_inner: 106.10 | backward_allreduce: 11.23 | step: 44.62
[default0]:[2023-08-25 18:13:21,844] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 4.16 | optimizer_step: 6.51
[default0]:[2023-08-25 18:13:21,844] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 52.26 | backward_microstep: 117.70 | backward_inner_microstep: 106.36 | backward_allreduce_microstep: 11.25 | step_microstep: 44.34
[default0]:[2023-08-25 18:13:21,844] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 52.26 (forward_moe: 21.70, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.84)
[default0]:[2023-08-25 18:13:21,845] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.70 | backward_inner: 106.36 | backward_allreduce: 11.25 | step: 44.34
[default0]:[2023-08-25 18:13:22,346] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.45
[default0]:[2023-08-25 18:13:22,346] [INFO] [logging.py:96:log_dist] [Rank 0] step=1325, skipped=0, lr=[1.4461610666666668e-06, 1.4461610666666668e-06, 1.4461610666666668e-06, 1.4461610666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:22,347] [INFO] [timer.py:215:stop] epoch=0/micro_step=1325/global_step=1325, RunningAvgSamplesPerSec=4.920798083418407, CurrSamplesPerSec=4.712452263756858, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:22,347] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.27 | backward_microstep: 117.76 | backward_inner_microstep: 106.44 | backward_allreduce_microstep: 11.23 | step_microstep: 44.62
[default0]:[2023-08-25 18:13:22,347] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.27 (forward_moe: 21.60, 1st alltoall: 0.92, 2nd alltoall: 0.85, top-k: 8.85)
[default0]:[2023-08-25 18:13:22,347] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.76 | backward_inner: 106.44 | backward_allreduce: 11.23 | step: 44.63
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.4958], device='cuda:0'), 'moe loss': tensor([0.3012], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1325/439453125 | consumed samples:         1325 | consumed tokens:      2713600 | elapsed time per iteration (ms): 371.0 | learning rate: 1.446E-06 | global batch size:     1 | lm loss: 9.299159E+00 | moe loss: 6.023569E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.695 | TFLOPs: 6.70 |
[default0]:[2023-08-25 18:13:22,602] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.44
[default0]:[2023-08-25 18:13:22,603] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.21 | backward_microstep: 115.42 | backward_inner_microstep: 104.24 | backward_allreduce_microstep: 11.09 | step_microstep: 43.73
[default0]:[2023-08-25 18:13:22,603] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.21 (forward_moe: 21.16, 1st alltoall: 0.89, 2nd alltoall: 0.89, top-k: 8.55)
[default0]:[2023-08-25 18:13:22,603] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.42 | backward_inner: 104.24 | backward_allreduce: 11.09 | step: 43.73
[default0]:[2023-08-25 18:13:22,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.43
[default0]:[2023-08-25 18:13:22,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.77 | backward_microstep: 115.41 | backward_inner_microstep: 104.23 | backward_allreduce_microstep: 11.09 | step_microstep: 43.55
[default0]:[2023-08-25 18:13:22,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.77 (forward_moe: 21.15, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.55)
[default0]:[2023-08-25 18:13:22,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.41 | backward_inner: 104.23 | backward_allreduce: 11.09 | step: 43.55
[default0]:[2023-08-25 18:13:23,114] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.44
[default0]:[2023-08-25 18:13:23,114] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.51 | backward_microstep: 116.75 | backward_inner_microstep: 105.55 | backward_allreduce_microstep: 11.10 | step_microstep: 43.73
[default0]:[2023-08-25 18:13:23,114] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.51 (forward_moe: 21.19, 1st alltoall: 0.99, 2nd alltoall: 0.83, top-k: 8.53)
[default0]:[2023-08-25 18:13:23,115] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.75 | backward_inner: 105.56 | backward_allreduce: 11.10 | step: 43.73
[default0]:[2023-08-25 18:13:23,368] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:13:23,368] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.07 | backward_microstep: 114.88 | backward_inner_microstep: 103.88 | backward_allreduce_microstep: 10.91 | step_microstep: 42.70
[default0]:[2023-08-25 18:13:23,368] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.07 (forward_moe: 20.67, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.32)
[default0]:[2023-08-25 18:13:23,368] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.88 | backward_inner: 103.88 | backward_allreduce: 10.91 | step: 42.70
[default0]:[2023-08-25 18:13:23,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:13:23,627] [INFO] [logging.py:96:log_dist] [Rank 0] step=1330, skipped=0, lr=[1.4516224000000002e-06, 1.4516224000000002e-06, 1.4516224000000002e-06, 1.4516224000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:23,627] [INFO] [timer.py:215:stop] epoch=0/micro_step=1330/global_step=1330, RunningAvgSamplesPerSec=4.920427564958474, CurrSamplesPerSec=4.917305221297868, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:23,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.09 | backward_microstep: 112.73 | backward_inner_microstep: 101.70 | backward_allreduce_microstep: 10.94 | step_microstep: 42.99
[default0]:[2023-08-25 18:13:23,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.08 (forward_moe: 20.69, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.22)
[default0]:[2023-08-25 18:13:23,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.73 | backward_inner: 101.70 | backward_allreduce: 10.95 | step: 43.00
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.4974], device='cuda:0'), 'moe loss': tensor([0.3011], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1330/439453125 | consumed samples:         1330 | consumed tokens:      2723840 | elapsed time per iteration (ms): 256.0 | learning rate: 1.452E-06 | global batch size:     1 | lm loss: 9.499484E+00 | moe loss: 6.021769E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.906 | TFLOPs: 9.71 |
[default0]:[2023-08-25 18:13:23,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.09 | optimizer_step: 6.38
[default0]:[2023-08-25 18:13:23,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.97 | backward_microstep: 112.59 | backward_inner_microstep: 101.54 | backward_allreduce_microstep: 10.96 | step_microstep: 42.75
[default0]:[2023-08-25 18:13:23,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.97 (forward_moe: 20.51, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.19)
[default0]:[2023-08-25 18:13:23,907] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.58 | backward_inner: 101.54 | backward_allreduce: 10.96 | step: 42.75
[default0]:[2023-08-25 18:13:24,164] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:13:24,164] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.20 | backward_microstep: 112.59 | backward_inner_microstep: 101.54 | backward_allreduce_microstep: 10.96 | step_microstep: 42.67
[default0]:[2023-08-25 18:13:24,164] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.20 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:13:24,164] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.59 | backward_inner: 101.55 | backward_allreduce: 10.96 | step: 42.67
[default0]:[2023-08-25 18:13:24,419] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:13:24,420] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.10 | backward_microstep: 112.55 | backward_inner_microstep: 101.54 | backward_allreduce_microstep: 10.91 | step_microstep: 42.61
[default0]:[2023-08-25 18:13:24,420] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.10 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:13:24,420] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.54 | backward_inner: 101.55 | backward_allreduce: 10.91 | step: 42.61
[default0]:[2023-08-25 18:13:24,702] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:13:24,702] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.22 | backward_microstep: 112.46 | backward_inner_microstep: 101.45 | backward_allreduce_microstep: 10.90 | step_microstep: 42.64
[default0]:[2023-08-25 18:13:24,703] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.22 (forward_moe: 20.54, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.22)
[default0]:[2023-08-25 18:13:24,703] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.46 | backward_inner: 101.46 | backward_allreduce: 10.91 | step: 42.64
[default0]:[2023-08-25 18:13:24,952] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.40
[default0]:[2023-08-25 18:13:24,953] [INFO] [logging.py:96:log_dist] [Rank 0] step=1335, skipped=0, lr=[1.4570837333333335e-06, 1.4570837333333335e-06, 1.4570837333333335e-06, 1.4570837333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:24,953] [INFO] [timer.py:215:stop] epoch=0/micro_step=1335/global_step=1335, RunningAvgSamplesPerSec=4.9204274682674445, CurrSamplesPerSec=4.913094662170156, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:24,953] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.09 | backward_microstep: 112.53 | backward_inner_microstep: 101.53 | backward_allreduce_microstep: 10.91 | step_microstep: 43.37
[default0]:[2023-08-25 18:13:24,953] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.09 (forward_moe: 20.50, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.19)
[default0]:[2023-08-25 18:13:24,953] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.53 | backward_inner: 101.54 | backward_allreduce: 10.91 | step: 43.37
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.8416], device='cuda:0'), 'moe loss': tensor([0.3003], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1335/439453125 | consumed samples:         1335 | consumed tokens:      2734080 | elapsed time per iteration (ms): 266.7 | learning rate: 1.457E-06 | global batch size:     1 | lm loss: 9.368324E+00 | moe loss: 6.006051E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.749 | TFLOPs: 9.32 |
[default0]:[2023-08-25 18:13:25,207] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:13:25,207] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.25 | backward_microstep: 112.65 | backward_inner_microstep: 101.57 | backward_allreduce_microstep: 10.99 | step_microstep: 42.74
[default0]:[2023-08-25 18:13:25,207] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.25 (forward_moe: 20.62, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.29)
[default0]:[2023-08-25 18:13:25,207] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.65 | backward_inner: 101.57 | backward_allreduce: 10.99 | step: 42.74
[default0]:[2023-08-25 18:13:25,445] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:13:25,445] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.79 | backward_microstep: 112.67 | backward_inner_microstep: 101.64 | backward_allreduce_microstep: 10.94 | step_microstep: 43.04
[default0]:[2023-08-25 18:13:25,446] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.79 (forward_moe: 20.54, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:13:25,446] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.67 | backward_inner: 101.65 | backward_allreduce: 10.94 | step: 43.04
[default0]:[2023-08-25 18:13:25,785] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 10.10
[default0]:[2023-08-25 18:13:25,785] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.33 | backward_microstep: 112.83 | backward_inner_microstep: 101.78 | backward_allreduce_microstep: 10.96 | step_microstep: 47.57
[default0]:[2023-08-25 18:13:25,785] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.33 (forward_moe: 20.70, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.22)
[default0]:[2023-08-25 18:13:25,786] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.83 | backward_inner: 101.78 | backward_allreduce: 10.96 | step: 47.57
[default0]:[2023-08-25 18:13:26,053] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.47
[default0]:[2023-08-25 18:13:26,054] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.55 | backward_microstep: 115.73 | backward_inner_microstep: 104.50 | backward_allreduce_microstep: 11.13 | step_microstep: 44.01
[default0]:[2023-08-25 18:13:26,054] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.54 (forward_moe: 21.13, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.53)
[default0]:[2023-08-25 18:13:26,054] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.73 | backward_inner: 104.51 | backward_allreduce: 11.14 | step: 44.01
[default0]:[2023-08-25 18:13:26,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.12 | optimizer_step: 6.47
[default0]:[2023-08-25 18:13:26,317] [INFO] [logging.py:96:log_dist] [Rank 0] step=1340, skipped=0, lr=[1.4625450666666668e-06, 1.4625450666666668e-06, 1.4625450666666668e-06, 1.4625450666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:26,318] [INFO] [timer.py:215:stop] epoch=0/micro_step=1340/global_step=1340, RunningAvgSamplesPerSec=4.920060783565815, CurrSamplesPerSec=4.761411973050136, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:26,318] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.58 | backward_microstep: 116.50 | backward_inner_microstep: 105.21 | backward_allreduce_microstep: 11.19 | step_microstep: 44.38
[default0]:[2023-08-25 18:13:26,318] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.58 (forward_moe: 21.48, 1st alltoall: 0.90, 2nd alltoall: 0.85, top-k: 8.67)
[default0]:[2023-08-25 18:13:26,318] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.50 | backward_inner: 105.22 | backward_allreduce: 11.19 | step: 44.38
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.7982], device='cuda:0'), 'moe loss': tensor([0.2999], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1340/439453125 | consumed samples:         1340 | consumed tokens:      2744320 | elapsed time per iteration (ms): 271.4 | learning rate: 1.463E-06 | global batch size:     1 | lm loss: 9.359637E+00 | moe loss: 5.998122E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.684 | TFLOPs: 9.15 |
[default0]:[2023-08-25 18:13:26,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.45
[default0]:[2023-08-25 18:13:26,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.10 | backward_microstep: 115.21 | backward_inner_microstep: 104.01 | backward_allreduce_microstep: 11.10 | step_microstep: 43.81
[default0]:[2023-08-25 18:13:26,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.10 (forward_moe: 21.13, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.54)
[default0]:[2023-08-25 18:13:26,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.20 | backward_inner: 104.02 | backward_allreduce: 11.11 | step: 43.81
[default0]:[2023-08-25 18:13:26,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:13:26,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.43 | backward_microstep: 115.50 | backward_inner_microstep: 104.30 | backward_allreduce_microstep: 11.10 | step_microstep: 43.90
[default0]:[2023-08-25 18:13:26,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.43 (forward_moe: 21.24, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.53)
[default0]:[2023-08-25 18:13:26,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.49 | backward_inner: 104.31 | backward_allreduce: 11.10 | step: 43.90
[default0]:[2023-08-25 18:13:27,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.08 | optimizer_step: 6.43
[default0]:[2023-08-25 18:13:27,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.53 | backward_microstep: 115.27 | backward_inner_microstep: 104.05 | backward_allreduce_microstep: 11.12 | step_microstep: 43.76
[default0]:[2023-08-25 18:13:27,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.53 (forward_moe: 21.10, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.54)
[default0]:[2023-08-25 18:13:27,132] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.27 | backward_inner: 104.06 | backward_allreduce: 11.12 | step: 43.76
[default0]:[2023-08-25 18:13:27,391] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:13:27,392] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.26 | backward_microstep: 112.68 | backward_inner_microstep: 101.64 | backward_allreduce_microstep: 10.94 | step_microstep: 42.78
[default0]:[2023-08-25 18:13:27,392] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.26 (forward_moe: 20.52, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.20)
[default0]:[2023-08-25 18:13:27,392] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.68 | backward_inner: 101.65 | backward_allreduce: 10.95 | step: 42.79
[default0]:[2023-08-25 18:13:27,649] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:13:27,650] [INFO] [logging.py:96:log_dist] [Rank 0] step=1345, skipped=0, lr=[1.4680064000000003e-06, 1.4680064000000003e-06, 1.4680064000000003e-06, 1.4680064000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:27,650] [INFO] [timer.py:215:stop] epoch=0/micro_step=1345/global_step=1345, RunningAvgSamplesPerSec=4.919777826880888, CurrSamplesPerSec=4.916504025872487, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:27,650] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.07 | backward_microstep: 112.60 | backward_inner_microstep: 101.59 | backward_allreduce_microstep: 10.92 | step_microstep: 43.18
[default0]:[2023-08-25 18:13:27,650] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.07 (forward_moe: 20.61, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.21)
[default0]:[2023-08-25 18:13:27,650] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.60 | backward_inner: 101.59 | backward_allreduce: 10.92 | step: 43.19
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.7458], device='cuda:0'), 'moe loss': tensor([0.3003], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1345/439453125 | consumed samples:         1345 | consumed tokens:      2754560 | elapsed time per iteration (ms): 266.6 | learning rate: 1.468E-06 | global batch size:     1 | lm loss: 9.349168E+00 | moe loss: 6.006736E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.752 | TFLOPs: 9.32 |
[default0]:[2023-08-25 18:13:27,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.38
[default0]:[2023-08-25 18:13:27,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.55 | backward_microstep: 112.56 | backward_inner_microstep: 101.57 | backward_allreduce_microstep: 10.90 | step_microstep: 42.76
[default0]:[2023-08-25 18:13:27,912] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.55 (forward_moe: 20.58, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.22)
[default0]:[2023-08-25 18:13:27,913] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.56 | backward_inner: 101.57 | backward_allreduce: 10.91 | step: 42.76
[default0]:[2023-08-25 18:13:28,153] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.37
[default0]:[2023-08-25 18:13:28,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.82 | backward_microstep: 112.62 | backward_inner_microstep: 101.56 | backward_allreduce_microstep: 10.96 | step_microstep: 42.86
[default0]:[2023-08-25 18:13:28,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.82 (forward_moe: 20.67, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.30)
[default0]:[2023-08-25 18:13:28,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.62 | backward_inner: 101.57 | backward_allreduce: 10.97 | step: 42.86
[default0]:[2023-08-25 18:13:28,390] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:28,391] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.73 | backward_microstep: 108.96 | backward_inner_microstep: 98.14 | backward_allreduce_microstep: 10.73 | step_microstep: 41.50
[default0]:[2023-08-25 18:13:28,391] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.73 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:13:28,391] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.14 | backward_allreduce: 10.73 | step: 41.50
[default0]:[2023-08-25 18:13:28,641] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:28,642] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 108.77 | backward_inner_microstep: 97.99 | backward_allreduce_microstep: 10.69 | step_microstep: 41.51
[default0]:[2023-08-25 18:13:28,642] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:13:28,642] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.77 | backward_inner: 97.99 | backward_allreduce: 10.69 | step: 41.51
[default0]:[2023-08-25 18:13:28,895] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.88 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:28,895] [INFO] [logging.py:96:log_dist] [Rank 0] step=1350, skipped=0, lr=[1.4734677333333336e-06, 1.4734677333333336e-06, 1.4734677333333336e-06, 1.4734677333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:28,895] [INFO] [timer.py:215:stop] epoch=0/micro_step=1350/global_step=1350, RunningAvgSamplesPerSec=4.920077844400784, CurrSamplesPerSec=5.070501948145363, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:28,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 109.25 | backward_inner_microstep: 98.44 | backward_allreduce_microstep: 10.72 | step_microstep: 41.79
[default0]:[2023-08-25 18:13:28,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.64 (forward_moe: 19.84, 1st alltoall: 0.85, 2nd alltoall: 0.79, top-k: 7.70)
[default0]:[2023-08-25 18:13:28,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.25 | backward_inner: 98.45 | backward_allreduce: 10.72 | step: 41.79
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.6652], device='cuda:0'), 'moe loss': tensor([0.3051], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1350/439453125 | consumed samples:         1350 | consumed tokens:      2764800 | elapsed time per iteration (ms): 249.2 | learning rate: 1.473E-06 | global batch size:     1 | lm loss: 9.533034E+00 | moe loss: 6.102698E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.013 | TFLOPs: 9.97 |
[default0]:[2023-08-25 18:13:29,139] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:29,139] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.79 | backward_microstep: 108.78 | backward_inner_microstep: 97.99 | backward_allreduce_microstep: 10.70 | step_microstep: 41.48
[default0]:[2023-08-25 18:13:29,139] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.79 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:13:29,140] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.78 | backward_inner: 98.00 | backward_allreduce: 10.70 | step: 41.48
[default0]:[2023-08-25 18:13:29,384] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:29,384] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.40 | backward_microstep: 108.99 | backward_inner_microstep: 98.15 | backward_allreduce_microstep: 10.74 | step_microstep: 41.50
[default0]:[2023-08-25 18:13:29,384] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.39 (forward_moe: 19.79, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.76)
[default0]:[2023-08-25 18:13:29,384] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.99 | backward_inner: 98.16 | backward_allreduce: 10.75 | step: 41.51
[default0]:[2023-08-25 18:13:29,700] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:29,700] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 108.81 | backward_inner_microstep: 98.03 | backward_allreduce_microstep: 10.69 | step_microstep: 41.39
[default0]:[2023-08-25 18:13:29,700] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:13:29,700] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.81 | backward_inner: 98.03 | backward_allreduce: 10.70 | step: 41.40
[default0]:[2023-08-25 18:13:29,953] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:29,954] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.32 | backward_microstep: 108.86 | backward_inner_microstep: 98.05 | backward_allreduce_microstep: 10.71 | step_microstep: 41.38
[default0]:[2023-08-25 18:13:29,954] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.32 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:13:29,954] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.86 | backward_inner: 98.06 | backward_allreduce: 10.72 | step: 41.38
[default0]:[2023-08-25 18:13:30,201] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:30,201] [INFO] [logging.py:96:log_dist] [Rank 0] step=1355, skipped=0, lr=[1.478929066666667e-06, 1.478929066666667e-06, 1.478929066666667e-06, 1.478929066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:30,201] [INFO] [timer.py:215:stop] epoch=0/micro_step=1355/global_step=1355, RunningAvgSamplesPerSec=4.920669612210883, CurrSamplesPerSec=5.082643316154097, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:30,201] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.40 | backward_microstep: 108.72 | backward_inner_microstep: 97.93 | backward_allreduce_microstep: 10.70 | step_microstep: 41.81
[default0]:[2023-08-25 18:13:30,202] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.40 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:13:30,202] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.84 | backward_inner: 97.94 | backward_allreduce: 10.70 | step: 41.81
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.1352], device='cuda:0'), 'moe loss': tensor([0.3038], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1355/439453125 | consumed samples:         1355 | consumed tokens:      2775040 | elapsed time per iteration (ms): 261.0 | learning rate: 1.479E-06 | global batch size:     1 | lm loss: 9.427045E+00 | moe loss: 6.076071E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.832 | TFLOPs: 9.52 |
[default0]:[2023-08-25 18:13:30,441] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:30,442] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.63 | backward_microstep: 108.87 | backward_inner_microstep: 98.04 | backward_allreduce_microstep: 10.73 | step_microstep: 41.45
[default0]:[2023-08-25 18:13:30,442] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.63 (forward_moe: 19.85, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:13:30,442] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.87 | backward_inner: 98.05 | backward_allreduce: 10.74 | step: 41.45
[default0]:[2023-08-25 18:13:30,686] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:30,687] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.42 | backward_microstep: 108.90 | backward_inner_microstep: 98.12 | backward_allreduce_microstep: 10.68 | step_microstep: 42.01
[default0]:[2023-08-25 18:13:30,687] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.42 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:13:30,687] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 98.12 | backward_allreduce: 10.69 | step: 42.02
[default0]:[2023-08-25 18:13:30,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:30,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 109.17 | backward_inner_microstep: 98.34 | backward_allreduce_microstep: 10.73 | step_microstep: 41.48
[default0]:[2023-08-25 18:13:30,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:13:30,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.17 | backward_inner: 98.35 | backward_allreduce: 10.74 | step: 41.48
[default0]:[2023-08-25 18:13:31,191] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:31,191] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.72 | backward_microstep: 109.40 | backward_inner_microstep: 98.59 | backward_allreduce_microstep: 10.72 | step_microstep: 41.47
[default0]:[2023-08-25 18:13:31,191] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.71 (forward_moe: 19.93, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:13:31,191] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.40 | backward_inner: 98.60 | backward_allreduce: 10.72 | step: 41.46
[default0]:[2023-08-25 18:13:31,437] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:31,437] [INFO] [logging.py:96:log_dist] [Rank 0] step=1360, skipped=0, lr=[1.4843903999999998e-06, 1.4843903999999998e-06, 1.4843903999999998e-06, 1.4843903999999998e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:31,438] [INFO] [timer.py:215:stop] epoch=0/micro_step=1360/global_step=1360, RunningAvgSamplesPerSec=4.921215285664668, CurrSamplesPerSec=5.076172161017, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:31,438] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 109.08 | backward_inner_microstep: 98.27 | backward_allreduce_microstep: 10.71 | step_microstep: 41.89
[default0]:[2023-08-25 18:13:31,438] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.95, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:13:31,438] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.28 | backward_allreduce: 10.71 | step: 41.90
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.8412], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1360/439453125 | consumed samples:         1360 | consumed tokens:      2785280 | elapsed time per iteration (ms): 247.5 | learning rate: 1.484E-06 | global batch size:     1 | lm loss: 9.368231E+00 | moe loss: 6.013489E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.041 | TFLOPs: 10.04 |
[default0]:[2023-08-25 18:13:31,685] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:31,685] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.72 | backward_microstep: 108.95 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.73 | step_microstep: 41.58
[default0]:[2023-08-25 18:13:31,686] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.72 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.70)
[default0]:[2023-08-25 18:13:31,686] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.95 | backward_inner: 98.13 | backward_allreduce: 10.73 | step: 41.59
[default0]:[2023-08-25 18:13:31,945] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:13:31,945] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.43 | backward_microstep: 112.41 | backward_inner_microstep: 101.40 | backward_allreduce_microstep: 10.91 | step_microstep: 42.44
[default0]:[2023-08-25 18:13:31,945] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.42 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:13:31,945] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.41 | backward_inner: 101.41 | backward_allreduce: 10.92 | step: 42.45
[default0]:[2023-08-25 18:13:32,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.38
[default0]:[2023-08-25 18:13:32,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.33 | backward_microstep: 112.20 | backward_inner_microstep: 101.17 | backward_allreduce_microstep: 10.92 | step_microstep: 42.59
[default0]:[2023-08-25 18:13:32,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.33 (forward_moe: 20.47, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.16)
[default0]:[2023-08-25 18:13:32,184] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.19 | backward_inner: 101.18 | backward_allreduce: 10.93 | step: 42.59
[default0]:[2023-08-25 18:13:32,437] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:13:32,437] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.46 | backward_microstep: 111.24 | backward_inner_microstep: 100.31 | backward_allreduce_microstep: 10.84 | step_microstep: 42.29
[default0]:[2023-08-25 18:13:32,437] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.46 (forward_moe: 20.25, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.04)
[default0]:[2023-08-25 18:13:32,438] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.24 | backward_inner: 100.31 | backward_allreduce: 10.84 | step: 42.29
[default0]:[2023-08-25 18:13:32,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:13:32,692] [INFO] [logging.py:96:log_dist] [Rank 0] step=1365, skipped=0, lr=[1.4898517333333334e-06, 1.4898517333333334e-06, 1.4898517333333334e-06, 1.4898517333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:32,692] [INFO] [timer.py:215:stop] epoch=0/micro_step=1365/global_step=1365, RunningAvgSamplesPerSec=4.921393376272762, CurrSamplesPerSec=4.972759693451703, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:32,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.69 | backward_microstep: 111.22 | backward_inner_microstep: 100.25 | backward_allreduce_microstep: 10.89 | step_microstep: 42.61
[default0]:[2023-08-25 18:13:32,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.69 (forward_moe: 20.27, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.05)
[default0]:[2023-08-25 18:13:32,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.22 | backward_inner: 100.25 | backward_allreduce: 10.89 | step: 42.62
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.4340], device='cuda:0'), 'moe loss': tensor([0.3006], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1365/439453125 | consumed samples:         1365 | consumed tokens:      2795520 | elapsed time per iteration (ms): 250.9 | learning rate: 1.490E-06 | global batch size:     1 | lm loss: 9.286807E+00 | moe loss: 6.012864E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.985 | TFLOPs: 9.90 |
[default0]:[2023-08-25 18:13:33,130] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:13:33,130] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.63 | backward_microstep: 112.83 | backward_inner_microstep: 101.89 | backward_allreduce_microstep: 10.85 | step_microstep: 42.30
[default0]:[2023-08-25 18:13:33,130] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.63 (forward_moe: 20.25, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.04)
[default0]:[2023-08-25 18:13:33,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.82 | backward_inner: 101.89 | backward_allreduce: 10.85 | step: 42.31
[default0]:[2023-08-25 18:13:33,379] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:13:33,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.01 | backward_microstep: 113.37 | backward_inner_microstep: 102.43 | backward_allreduce_microstep: 10.85 | step_microstep: 42.84
[default0]:[2023-08-25 18:13:33,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.02 (forward_moe: 20.27, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.04)
[default0]:[2023-08-25 18:13:33,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.37 | backward_inner: 102.43 | backward_allreduce: 10.86 | step: 42.84
[default0]:[2023-08-25 18:13:33,642] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:13:33,642] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.76 | backward_microstep: 108.99 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.72 | step_microstep: 41.44
[default0]:[2023-08-25 18:13:33,642] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.76 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:13:33,642] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.99 | backward_inner: 98.18 | backward_allreduce: 10.72 | step: 41.44
[default0]:[2023-08-25 18:13:33,886] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:33,887] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 108.87 | backward_inner_microstep: 98.05 | backward_allreduce_microstep: 10.73 | step_microstep: 41.55
[default0]:[2023-08-25 18:13:33,887] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 19.78, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:13:33,887] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.87 | backward_inner: 98.06 | backward_allreduce: 10.74 | step: 41.55
[default0]:[2023-08-25 18:13:34,120] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:34,121] [INFO] [logging.py:96:log_dist] [Rank 0] step=1370, skipped=0, lr=[1.4953130666666667e-06, 1.4953130666666667e-06, 1.4953130666666667e-06, 1.4953130666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:34,121] [INFO] [timer.py:215:stop] epoch=0/micro_step=1370/global_step=1370, RunningAvgSamplesPerSec=4.921706855168347, CurrSamplesPerSec=5.0578755568204015, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:34,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.59 | backward_microstep: 109.18 | backward_inner_microstep: 98.35 | backward_allreduce_microstep: 10.73 | step_microstep: 42.40
[default0]:[2023-08-25 18:13:34,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.59 (forward_moe: 19.92, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.79)
[default0]:[2023-08-25 18:13:34,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.17 | backward_inner: 98.36 | backward_allreduce: 10.73 | step: 42.40
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.3595], device='cuda:0'), 'moe loss': tensor([0.2999], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1370/439453125 | consumed samples:         1370 | consumed tokens:      2805760 | elapsed time per iteration (ms): 285.8 | learning rate: 1.495E-06 | global batch size:     1 | lm loss: 9.271907E+00 | moe loss: 5.998188E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.499 | TFLOPs: 8.69 |
[default0]:[2023-08-25 18:13:34,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:34,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 108.95 | backward_inner_microstep: 98.14 | backward_allreduce_microstep: 10.71 | step_microstep: 41.44
[default0]:[2023-08-25 18:13:34,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:13:34,359] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.95 | backward_inner: 98.15 | backward_allreduce: 10.72 | step: 41.45
[default0]:[2023-08-25 18:13:34,603] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:34,603] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.37 | backward_microstep: 108.98 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.72 | step_microstep: 41.45
[default0]:[2023-08-25 18:13:34,603] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.37 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.75)
[default0]:[2023-08-25 18:13:34,603] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.97 | backward_inner: 98.17 | backward_allreduce: 10.72 | step: 41.46
[default0]:[2023-08-25 18:13:34,874] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:34,874] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.75 | backward_microstep: 108.93 | backward_inner_microstep: 98.06 | backward_allreduce_microstep: 10.77 | step_microstep: 41.45
[default0]:[2023-08-25 18:13:34,874] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.74 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:13:34,874] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.93 | backward_inner: 98.07 | backward_allreduce: 10.78 | step: 41.45
[default0]:[2023-08-25 18:13:35,111] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:35,111] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 109.17 | backward_inner_microstep: 98.38 | backward_allreduce_microstep: 10.70 | step_microstep: 41.59
[default0]:[2023-08-25 18:13:35,111] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 19.99, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:13:35,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.16 | backward_inner: 98.38 | backward_allreduce: 10.70 | step: 41.59
[default0]:[2023-08-25 18:13:35,527] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.40
[default0]:[2023-08-25 18:13:35,528] [INFO] [logging.py:96:log_dist] [Rank 0] step=1375, skipped=0, lr=[1.5007744e-06, 1.5007744e-06, 1.5007744e-06, 1.5007744e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:35,528] [INFO] [timer.py:215:stop] epoch=0/micro_step=1375/global_step=1375, RunningAvgSamplesPerSec=4.922079834960777, CurrSamplesPerSec=4.824649249035772, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:35,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.62 | backward_microstep: 113.66 | backward_inner_microstep: 102.51 | backward_allreduce_microstep: 11.05 | step_microstep: 44.46
[default0]:[2023-08-25 18:13:35,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.62 (forward_moe: 20.75, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.33)
[default0]:[2023-08-25 18:13:35,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.66 | backward_inner: 102.52 | backward_allreduce: 11.06 | step: 44.46
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.0245], device='cuda:0'), 'moe loss': tensor([0.3001], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1375/439453125 | consumed samples:         1375 | consumed tokens:      2816000 | elapsed time per iteration (ms): 282.5 | learning rate: 1.501E-06 | global batch size:     1 | lm loss: 9.404900E+00 | moe loss: 6.002798E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.540 | TFLOPs: 8.80 |
[default0]:[2023-08-25 18:13:35,812] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.44
[default0]:[2023-08-25 18:13:35,812] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.29 | backward_microstep: 120.06 | backward_inner_microstep: 107.33 | backward_allreduce_microstep: 12.62 | step_microstep: 44.16
[default0]:[2023-08-25 18:13:35,813] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.29 (forward_moe: 21.51, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.64)
[default0]:[2023-08-25 18:13:35,813] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 120.06 | backward_inner: 107.34 | backward_allreduce: 12.62 | step: 44.16
[default0]:[2023-08-25 18:13:36,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 9.93
[default0]:[2023-08-25 18:13:36,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.09 | backward_microstep: 114.07 | backward_inner_microstep: 102.95 | backward_allreduce_microstep: 11.03 | step_microstep: 46.86
[default0]:[2023-08-25 18:13:36,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.09 (forward_moe: 20.90, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.35)
[default0]:[2023-08-25 18:13:36,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.07 | backward_inner: 102.96 | backward_allreduce: 11.03 | step: 46.86
[default0]:[2023-08-25 18:13:36,375] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.40
[default0]:[2023-08-25 18:13:36,375] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.66 | backward_microstep: 113.94 | backward_inner_microstep: 102.84 | backward_allreduce_microstep: 11.01 | step_microstep: 43.14
[default0]:[2023-08-25 18:13:36,375] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.66 (forward_moe: 20.80, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.36)
[default0]:[2023-08-25 18:13:36,375] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.94 | backward_inner: 102.85 | backward_allreduce: 11.01 | step: 43.15
[default0]:[2023-08-25 18:13:36,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.40
[default0]:[2023-08-25 18:13:36,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.25 | backward_microstep: 112.99 | backward_inner_microstep: 101.95 | backward_allreduce_microstep: 10.95 | step_microstep: 42.95
[default0]:[2023-08-25 18:13:36,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.25 (forward_moe: 20.63, 1st alltoall: 0.91, 2nd alltoall: 0.83, top-k: 8.26)
[default0]:[2023-08-25 18:13:36,661] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.99 | backward_inner: 101.95 | backward_allreduce: 10.95 | step: 42.95
[default0]:[2023-08-25 18:13:36,939] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:13:36,939] [INFO] [logging.py:96:log_dist] [Rank 0] step=1380, skipped=0, lr=[1.5062357333333333e-06, 1.5062357333333333e-06, 1.5062357333333333e-06, 1.5062357333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:36,939] [INFO] [timer.py:215:stop] epoch=0/micro_step=1380/global_step=1380, RunningAvgSamplesPerSec=4.921696091098424, CurrSamplesPerSec=4.88101383668292, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:36,940] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.59 | backward_microstep: 113.59 | backward_inner_microstep: 102.51 | backward_allreduce_microstep: 10.98 | step_microstep: 43.14
[default0]:[2023-08-25 18:13:36,940] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.59 (forward_moe: 20.82, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.27)
[default0]:[2023-08-25 18:13:36,940] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.59 | backward_inner: 102.52 | backward_allreduce: 10.98 | step: 43.15
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.1871], device='cuda:0'), 'moe loss': tensor([0.3011], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1380/439453125 | consumed samples:         1380 | consumed tokens:      2826240 | elapsed time per iteration (ms): 283.4 | learning rate: 1.506E-06 | global batch size:     1 | lm loss: 9.437424E+00 | moe loss: 6.022422E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.529 | TFLOPs: 8.77 |
[default0]:[2023-08-25 18:13:37,209] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:13:37,209] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.35 | backward_microstep: 113.17 | backward_inner_microstep: 102.12 | backward_allreduce_microstep: 10.96 | step_microstep: 42.98
[default0]:[2023-08-25 18:13:37,210] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.35 (forward_moe: 20.69, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:13:37,210] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.17 | backward_inner: 102.12 | backward_allreduce: 10.97 | step: 42.99
[default0]:[2023-08-25 18:13:37,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:13:37,457] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.79 | backward_microstep: 111.39 | backward_inner_microstep: 100.42 | backward_allreduce_microstep: 10.87 | step_microstep: 42.27
[default0]:[2023-08-25 18:13:37,457] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.28, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.07)
[default0]:[2023-08-25 18:13:37,457] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.39 | backward_inner: 100.43 | backward_allreduce: 10.88 | step: 42.27
[default0]:[2023-08-25 18:13:37,715] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:13:37,715] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.56 | backward_microstep: 111.32 | backward_inner_microstep: 100.40 | backward_allreduce_microstep: 10.82 | step_microstep: 42.27
[default0]:[2023-08-25 18:13:37,715] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.56 (forward_moe: 20.23, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.03)
[default0]:[2023-08-25 18:13:37,715] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.31 | backward_inner: 100.41 | backward_allreduce: 10.82 | step: 42.28
[default0]:[2023-08-25 18:13:37,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:37,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.92 | backward_microstep: 111.38 | backward_inner_microstep: 100.40 | backward_allreduce_microstep: 10.88 | step_microstep: 42.26
[default0]:[2023-08-25 18:13:37,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.92 (forward_moe: 20.28, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.07)
[default0]:[2023-08-25 18:13:37,968] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.38 | backward_inner: 100.41 | backward_allreduce: 10.88 | step: 42.26
[default0]:[2023-08-25 18:13:38,211] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:38,211] [INFO] [logging.py:96:log_dist] [Rank 0] step=1385, skipped=0, lr=[1.5116970666666666e-06, 1.5116970666666666e-06, 1.5116970666666666e-06, 1.5116970666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:38,211] [INFO] [timer.py:215:stop] epoch=0/micro_step=1385/global_step=1385, RunningAvgSamplesPerSec=4.9218085798080855, CurrSamplesPerSec=4.960479880408353, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:38,212] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.00 | backward_microstep: 111.39 | backward_inner_microstep: 100.43 | backward_allreduce_microstep: 10.87 | step_microstep: 42.65
[default0]:[2023-08-25 18:13:38,212] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.01 (forward_moe: 20.26, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.04)
[default0]:[2023-08-25 18:13:38,212] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.38 | backward_inner: 100.43 | backward_allreduce: 10.87 | step: 42.66
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.7663], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1385/439453125 | consumed samples:         1385 | consumed tokens:      2836480 | elapsed time per iteration (ms): 252.5 | learning rate: 1.512E-06 | global batch size:     1 | lm loss: 9.353263E+00 | moe loss: 6.016247E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.960 | TFLOPs: 9.84 |
[default0]:[2023-08-25 18:13:38,469] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:38,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.06 | backward_microstep: 109.78 | backward_inner_microstep: 98.89 | backward_allreduce_microstep: 10.80 | step_microstep: 41.98
[default0]:[2023-08-25 18:13:38,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.06 (forward_moe: 19.96, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:13:38,470] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.78 | backward_inner: 98.89 | backward_allreduce: 10.81 | step: 41.98
[default0]:[2023-08-25 18:13:38,709] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 6.36
[default0]:[2023-08-25 18:13:38,710] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.12 | backward_microstep: 109.87 | backward_inner_microstep: 99.03 | backward_allreduce_microstep: 10.74 | step_microstep: 42.05
[default0]:[2023-08-25 18:13:38,710] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.12 (forward_moe: 19.99, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.86)
[default0]:[2023-08-25 18:13:38,710] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.86 | backward_inner: 99.04 | backward_allreduce: 10.74 | step: 42.05
[default0]:[2023-08-25 18:13:38,950] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.92 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:38,950] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.92 | backward_microstep: 110.24 | backward_inner_microstep: 99.36 | backward_allreduce_microstep: 10.78 | step_microstep: 41.84
[default0]:[2023-08-25 18:13:38,950] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.92 (forward_moe: 19.96, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.85)
[default0]:[2023-08-25 18:13:38,951] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.23 | backward_inner: 99.37 | backward_allreduce: 10.79 | step: 41.85
[default0]:[2023-08-25 18:13:39,193] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:39,193] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.08 | backward_microstep: 110.04 | backward_inner_microstep: 99.18 | backward_allreduce_microstep: 10.76 | step_microstep: 41.80
[default0]:[2023-08-25 18:13:39,193] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.08 (forward_moe: 20.09, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:13:39,193] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.03 | backward_inner: 99.19 | backward_allreduce: 10.77 | step: 41.80
[default0]:[2023-08-25 18:13:39,428] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:39,428] [INFO] [logging.py:96:log_dist] [Rank 0] step=1390, skipped=0, lr=[1.5171584e-06, 1.5171584e-06, 1.5171584e-06, 1.5171584e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:39,429] [INFO] [timer.py:215:stop] epoch=0/micro_step=1390/global_step=1390, RunningAvgSamplesPerSec=4.922203811960428, CurrSamplesPerSec=5.044237911062364, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:39,429] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.83 | backward_microstep: 109.74 | backward_inner_microstep: 98.86 | backward_allreduce_microstep: 10.78 | step_microstep: 42.12
[default0]:[2023-08-25 18:13:39,429] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.83 (forward_moe: 20.05, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.80)
[default0]:[2023-08-25 18:13:39,429] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.74 | backward_inner: 98.87 | backward_allreduce: 10.79 | step: 42.13
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.7723], device='cuda:0'), 'moe loss': tensor([0.3019], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1390/439453125 | consumed samples:         1390 | consumed tokens:      2846720 | elapsed time per iteration (ms): 243.0 | learning rate: 1.517E-06 | global batch size:     1 | lm loss: 9.554459E+00 | moe loss: 6.038852E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.116 | TFLOPs: 10.23 |
[default0]:[2023-08-25 18:13:39,675] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:39,675] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.66 | backward_microstep: 109.57 | backward_inner_microstep: 98.74 | backward_allreduce_microstep: 10.73 | step_microstep: 41.78
[default0]:[2023-08-25 18:13:39,675] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:13:39,675] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.57 | backward_inner: 98.75 | backward_allreduce: 10.74 | step: 41.79
[default0]:[2023-08-25 18:13:39,939] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:39,939] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.71 | backward_microstep: 109.48 | backward_inner_microstep: 98.64 | backward_allreduce_microstep: 10.75 | step_microstep: 41.73
[default0]:[2023-08-25 18:13:39,939] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.70 (forward_moe: 19.88, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.80)
[default0]:[2023-08-25 18:13:39,939] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.47 | backward_inner: 98.64 | backward_allreduce: 10.75 | step: 41.73
[default0]:[2023-08-25 18:13:40,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:40,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.76 | backward_microstep: 109.91 | backward_inner_microstep: 99.07 | backward_allreduce_microstep: 10.74 | step_microstep: 41.77
[default0]:[2023-08-25 18:13:40,187] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.76 (forward_moe: 20.00, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.82)
[default0]:[2023-08-25 18:13:40,187] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.91 | backward_inner: 99.08 | backward_allreduce: 10.75 | step: 41.78
[default0]:[2023-08-25 18:13:40,618] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.29
[default0]:[2023-08-25 18:13:40,618] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.90 | backward_microstep: 109.62 | backward_inner_microstep: 98.74 | backward_allreduce_microstep: 10.79 | step_microstep: 41.88
[default0]:[2023-08-25 18:13:40,618] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.90 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.79)
[default0]:[2023-08-25 18:13:40,618] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.62 | backward_inner: 98.74 | backward_allreduce: 10.79 | step: 41.89
[default0]:[2023-08-25 18:13:40,864] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.39
[default0]:[2023-08-25 18:13:40,864] [INFO] [logging.py:96:log_dist] [Rank 0] step=1395, skipped=0, lr=[1.5226197333333332e-06, 1.5226197333333332e-06, 1.5226197333333332e-06, 1.5226197333333332e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:40,865] [INFO] [timer.py:215:stop] epoch=0/micro_step=1395/global_step=1395, RunningAvgSamplesPerSec=4.922675515558543, CurrSamplesPerSec=5.084541036448692, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:40,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.57 | backward_microstep: 108.83 | backward_inner_microstep: 97.99 | backward_allreduce_microstep: 10.74 | step_microstep: 41.73
[default0]:[2023-08-25 18:13:40,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.57 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:13:40,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.83 | backward_inner: 98.00 | backward_allreduce: 10.75 | step: 41.73
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.5019], device='cuda:0'), 'moe loss': tensor([0.3025], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1395/439453125 | consumed samples:         1395 | consumed tokens:      2856960 | elapsed time per iteration (ms): 287.3 | learning rate: 1.523E-06 | global batch size:     1 | lm loss: 9.300385E+00 | moe loss: 6.049963E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.481 | TFLOPs: 8.65 |
[default0]:[2023-08-25 18:13:41,116] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:41,117] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 110.05 | backward_inner_microstep: 99.23 | backward_allreduce_microstep: 10.72 | step_microstep: 41.77
[default0]:[2023-08-25 18:13:41,117] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.41 (forward_moe: 20.08, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:13:41,117] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.05 | backward_inner: 99.24 | backward_allreduce: 10.72 | step: 41.77
[default0]:[2023-08-25 18:13:41,361] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:41,362] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 108.97 | backward_inner_microstep: 98.14 | backward_allreduce_microstep: 10.73 | step_microstep: 41.48
[default0]:[2023-08-25 18:13:41,362] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.70 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:13:41,362] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.15 | backward_allreduce: 10.73 | step: 41.48
[default0]:[2023-08-25 18:13:41,603] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:41,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.51 | backward_microstep: 108.91 | backward_inner_microstep: 98.08 | backward_allreduce_microstep: 10.74 | step_microstep: 41.43
[default0]:[2023-08-25 18:13:41,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.51 (forward_moe: 19.81, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:13:41,604] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.91 | backward_inner: 98.08 | backward_allreduce: 10.74 | step: 41.43
[default0]:[2023-08-25 18:13:41,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:13:41,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 111.94 | backward_inner_microstep: 101.13 | backward_allreduce_microstep: 10.71 | step_microstep: 41.68
[default0]:[2023-08-25 18:13:41,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.96, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.73)
[default0]:[2023-08-25 18:13:41,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.94 | backward_inner: 101.14 | backward_allreduce: 10.71 | step: 41.69
[default0]:[2023-08-25 18:13:42,106] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:42,106] [INFO] [logging.py:96:log_dist] [Rank 0] step=1400, skipped=0, lr=[1.5280810666666666e-06, 1.5280810666666666e-06, 1.5280810666666666e-06, 1.5280810666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:42,106] [INFO] [timer.py:215:stop] epoch=0/micro_step=1400/global_step=1400, RunningAvgSamplesPerSec=4.92314214880268, CurrSamplesPerSec=5.070207737731869, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:42,106] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.50 | backward_microstep: 109.05 | backward_inner_microstep: 98.24 | backward_allreduce_microstep: 10.72 | step_microstep: 42.16
[default0]:[2023-08-25 18:13:42,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.50 (forward_moe: 19.86, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:13:42,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.24 | backward_allreduce: 10.73 | step: 42.17
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.5928], device='cuda:0'), 'moe loss': tensor([0.3013], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1400/439453125 | consumed samples:         1400 | consumed tokens:      2867200 | elapsed time per iteration (ms): 248.2 | learning rate: 1.528E-06 | global batch size:     1 | lm loss: 9.318552E+00 | moe loss: 6.025888E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.029 | TFLOPs: 10.01 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1400 | lm loss value: 9.303277E+00 | lm loss PPL: 1.097392E+04 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration    1400 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:13:45,836] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1400 is about to be saved!
[default0]:[2023-08-25 18:13:45,838] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,848] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,848] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,857] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,857] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,866] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,867] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,876] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,877] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,886] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,886] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,896] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,896] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,905] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,905] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,914] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,915] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,924] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,924] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,933] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,933] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,942] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,942] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,951] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,952] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,961] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,961] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,970] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,970] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,979] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,979] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:45,992] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:45,993] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:46,003] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:46,003] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:46,017] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:46,017] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:46,027] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:46,027] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:46,036] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:46,037] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:46,046] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:46,047] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:46,056] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:46,056] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:46,068] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:46,068] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:46,078] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:46,078] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:13:46,080] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:13:46,082] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:13:46,082] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:13:46,360] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:13:46,361] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:13:50,050] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:13:50,078] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1400/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:13:50,078] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1400 is ready now!
[default0]:  successfully saved checkpoint at iteration    1400 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.69, Latency(second): 4.249
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4249.40, 4249.40)
[default0]:[2023-08-25 18:13:50,329] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.18 | optimizer_step: 10.61
[default0]:[2023-08-25 18:13:50,330] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2304.40 | backward_microstep: 117.25 | backward_inner_microstep: 106.10 | backward_allreduce_microstep: 11.06 | step_microstep: 48.04
[default0]:[2023-08-25 18:13:50,330] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2304.29 (forward_moe: 21.46, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.76)
[default0]:[2023-08-25 18:13:50,330] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.25 | backward_inner: 106.11 | backward_allreduce: 11.06 | step: 48.04
[default0]:[2023-08-25 18:13:50,620] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.14 | optimizer_step: 6.50
[default0]:[2023-08-25 18:13:50,620] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.05 | backward_microstep: 116.43 | backward_inner_microstep: 105.36 | backward_allreduce_microstep: 10.97 | step_microstep: 43.55
[default0]:[2023-08-25 18:13:50,620] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.05 (forward_moe: 21.39, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.76)
[default0]:[2023-08-25 18:13:50,621] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.42 | backward_inner: 105.37 | backward_allreduce: 10.97 | step: 43.56
[default0]:[2023-08-25 18:13:50,895] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.47
[default0]:[2023-08-25 18:13:50,895] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.95 | backward_microstep: 116.54 | backward_inner_microstep: 105.49 | backward_allreduce_microstep: 10.96 | step_microstep: 43.34
[default0]:[2023-08-25 18:13:50,895] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.95 (forward_moe: 21.37, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.73)
[default0]:[2023-08-25 18:13:50,895] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.54 | backward_inner: 105.49 | backward_allreduce: 10.96 | step: 43.34
[default0]:[2023-08-25 18:13:51,208] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.11 | optimizer_step: 6.47
[default0]:[2023-08-25 18:13:51,208] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.09 | backward_microstep: 116.60 | backward_inner_microstep: 105.19 | backward_allreduce_microstep: 11.31 | step_microstep: 43.97
[default0]:[2023-08-25 18:13:51,208] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.09 (forward_moe: 21.26, 1st alltoall: 0.91, 2nd alltoall: 0.83, top-k: 8.58)
[default0]:[2023-08-25 18:13:51,209] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.60 | backward_inner: 105.20 | backward_allreduce: 11.32 | step: 43.98
[default0]:[2023-08-25 18:13:51,462] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.47
[default0]:[2023-08-25 18:13:51,462] [INFO] [logging.py:96:log_dist] [Rank 0] step=1405, skipped=0, lr=[1.5335423999999999e-06, 1.5335423999999999e-06, 1.5335423999999999e-06, 1.5335423999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:51,463] [INFO] [timer.py:215:stop] epoch=0/micro_step=1405/global_step=1405, RunningAvgSamplesPerSec=4.922462030794283, CurrSamplesPerSec=4.766893742570026, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:51,463] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.90 | backward_microstep: 115.74 | backward_inner_microstep: 104.51 | backward_allreduce_microstep: 11.13 | step_microstep: 44.63
[default0]:[2023-08-25 18:13:51,463] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.90 (forward_moe: 21.17, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.59)
[default0]:[2023-08-25 18:13:51,463] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.73 | backward_inner: 104.52 | backward_allreduce: 11.13 | step: 44.63
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.9903], device='cuda:0'), 'moe loss': tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1405/439453125 | consumed samples:         1405 | consumed tokens:      2877440 | elapsed time per iteration (ms): 1872.1 | learning rate: 1.534E-06 | global batch size:     1 | lm loss: 9.398059E+00 | moe loss: 6.010039E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.534 | TFLOPs: 1.33 |
[default0]:[2023-08-25 18:13:51,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:13:51,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.10 | backward_microstep: 112.11 | backward_inner_microstep: 101.10 | backward_allreduce_microstep: 10.91 | step_microstep: 42.54
[default0]:[2023-08-25 18:13:51,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.10 (forward_moe: 20.43, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:13:51,742] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.11 | backward_inner: 101.11 | backward_allreduce: 10.91 | step: 42.54
[default0]:[2023-08-25 18:13:51,989] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:13:51,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.98 | backward_microstep: 115.69 | backward_inner_microstep: 104.70 | backward_allreduce_microstep: 10.91 | step_microstep: 43.78
[default0]:[2023-08-25 18:13:51,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.98 (forward_moe: 20.56, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.20)
[default0]:[2023-08-25 18:13:51,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.69 | backward_inner: 104.70 | backward_allreduce: 10.91 | step: 43.79
[default0]:[2023-08-25 18:13:52,244] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:13:52,245] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.93 | backward_microstep: 112.87 | backward_inner_microstep: 101.75 | backward_allreduce_microstep: 11.02 | step_microstep: 42.63
[default0]:[2023-08-25 18:13:52,245] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.92 (forward_moe: 20.72, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.39)
[default0]:[2023-08-25 18:13:52,245] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.86 | backward_inner: 101.75 | backward_allreduce: 11.03 | step: 42.63
[default0]:[2023-08-25 18:13:52,490] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:13:52,491] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.25 | backward_microstep: 112.16 | backward_inner_microstep: 101.14 | backward_allreduce_microstep: 10.92 | step_microstep: 42.53
[default0]:[2023-08-25 18:13:52,491] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.25 (forward_moe: 20.43, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:13:52,491] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.15 | backward_inner: 101.14 | backward_allreduce: 10.93 | step: 42.53
[default0]:[2023-08-25 18:13:52,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:13:52,726] [INFO] [logging.py:96:log_dist] [Rank 0] step=1410, skipped=0, lr=[1.5390037333333334e-06, 1.5390037333333334e-06, 1.5390037333333334e-06, 1.5390037333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:52,726] [INFO] [timer.py:215:stop] epoch=0/micro_step=1410/global_step=1410, RunningAvgSamplesPerSec=4.922410292922086, CurrSamplesPerSec=4.928207773408172, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:52,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.18 | backward_microstep: 112.30 | backward_inner_microstep: 101.29 | backward_allreduce_microstep: 10.92 | step_microstep: 42.89
[default0]:[2023-08-25 18:13:52,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.17 (forward_moe: 20.56, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.16)
[default0]:[2023-08-25 18:13:52,727] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.30 | backward_inner: 101.29 | backward_allreduce: 10.92 | step: 42.90
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.0411], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1410/439453125 | consumed samples:         1410 | consumed tokens:      2887680 | elapsed time per iteration (ms): 251.9 | learning rate: 1.539E-06 | global batch size:     1 | lm loss: 9.408214E+00 | moe loss: 6.015423E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.970 | TFLOPs: 9.86 |
[default0]:[2023-08-25 18:13:52,987] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:13:52,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.99 | backward_microstep: 112.41 | backward_inner_microstep: 101.41 | backward_allreduce_microstep: 10.91 | step_microstep: 42.69
[default0]:[2023-08-25 18:13:52,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.99 (forward_moe: 20.40, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:13:52,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.41 | backward_inner: 101.41 | backward_allreduce: 10.91 | step: 42.69
[default0]:[2023-08-25 18:13:53,230] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:13:53,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.52 | backward_microstep: 112.60 | backward_inner_microstep: 101.26 | backward_allreduce_microstep: 11.24 | step_microstep: 43.11
[default0]:[2023-08-25 18:13:53,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.52 (forward_moe: 20.44, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.12)
[default0]:[2023-08-25 18:13:53,231] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.59 | backward_inner: 101.26 | backward_allreduce: 11.25 | step: 43.11
[default0]:[2023-08-25 18:13:53,477] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.39
[default0]:[2023-08-25 18:13:53,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.44 | backward_microstep: 113.45 | backward_inner_microstep: 102.34 | backward_allreduce_microstep: 11.01 | step_microstep: 43.79
[default0]:[2023-08-25 18:13:53,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.43 (forward_moe: 20.84, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.30)
[default0]:[2023-08-25 18:13:53,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.45 | backward_inner: 102.35 | backward_allreduce: 11.02 | step: 43.80
[default0]:[2023-08-25 18:13:53,711] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:53,711] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.93 | backward_microstep: 109.86 | backward_inner_microstep: 99.02 | backward_allreduce_microstep: 10.74 | step_microstep: 41.77
[default0]:[2023-08-25 18:13:53,711] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.93 (forward_moe: 19.90, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.81)
[default0]:[2023-08-25 18:13:53,711] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.85 | backward_inner: 99.03 | backward_allreduce: 10.74 | step: 41.78
[default0]:[2023-08-25 18:13:53,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:53,969] [INFO] [logging.py:96:log_dist] [Rank 0] step=1415, skipped=0, lr=[1.5444650666666667e-06, 1.5444650666666667e-06, 1.5444650666666667e-06, 1.5444650666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:53,969] [INFO] [timer.py:215:stop] epoch=0/micro_step=1415/global_step=1415, RunningAvgSamplesPerSec=4.922466120270233, CurrSamplesPerSec=5.032756140201416, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:53,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.36 | backward_microstep: 109.67 | backward_inner_microstep: 98.82 | backward_allreduce_microstep: 10.75 | step_microstep: 42.12
[default0]:[2023-08-25 18:13:53,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.36 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:13:53,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.67 | backward_inner: 98.82 | backward_allreduce: 10.76 | step: 42.12
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.8243], device='cuda:0'), 'moe loss': tensor([0.3017], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1415/439453125 | consumed samples:         1415 | consumed tokens:      2897920 | elapsed time per iteration (ms): 248.4 | learning rate: 1.544E-06 | global batch size:     1 | lm loss: 9.364868E+00 | moe loss: 6.033167E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.026 | TFLOPs: 10.00 |
[default0]:[2023-08-25 18:13:54,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:54,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.66 | backward_microstep: 109.77 | backward_inner_microstep: 98.91 | backward_allreduce_microstep: 10.76 | step_microstep: 41.78
[default0]:[2023-08-25 18:13:54,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:13:54,234] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.77 | backward_inner: 98.92 | backward_allreduce: 10.77 | step: 41.79
[default0]:[2023-08-25 18:13:54,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:54,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.69 | backward_microstep: 109.62 | backward_inner_microstep: 98.73 | backward_allreduce_microstep: 10.79 | step_microstep: 41.83
[default0]:[2023-08-25 18:13:54,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.88, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.80)
[default0]:[2023-08-25 18:13:54,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.61 | backward_inner: 98.74 | backward_allreduce: 10.80 | step: 41.83
[default0]:[2023-08-25 18:13:54,742] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.93 | optimizer_step: 6.29
[default0]:[2023-08-25 18:13:54,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.82 | backward_microstep: 109.79 | backward_inner_microstep: 98.92 | backward_allreduce_microstep: 10.77 | step_microstep: 41.63
[default0]:[2023-08-25 18:13:54,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.82 (forward_moe: 19.88, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:13:54,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.78 | backward_inner: 98.93 | backward_allreduce: 10.77 | step: 41.63
[default0]:[2023-08-25 18:13:54,987] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:54,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.94 | backward_microstep: 109.57 | backward_inner_microstep: 98.74 | backward_allreduce_microstep: 10.74 | step_microstep: 41.65
[default0]:[2023-08-25 18:13:54,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.94 (forward_moe: 19.90, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.84)
[default0]:[2023-08-25 18:13:54,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.57 | backward_inner: 98.74 | backward_allreduce: 10.74 | step: 41.66
[default0]:[2023-08-25 18:13:55,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:55,225] [INFO] [logging.py:96:log_dist] [Rank 0] step=1420, skipped=0, lr=[1.5499264e-06, 1.5499264e-06, 1.5499264e-06, 1.5499264e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:55,225] [INFO] [timer.py:215:stop] epoch=0/micro_step=1420/global_step=1420, RunningAvgSamplesPerSec=4.922902637686712, CurrSamplesPerSec=5.044583719707931, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:55,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.89 | backward_microstep: 109.69 | backward_inner_microstep: 98.85 | backward_allreduce_microstep: 10.75 | step_microstep: 42.10
[default0]:[2023-08-25 18:13:55,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.89 (forward_moe: 20.13, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.80)
[default0]:[2023-08-25 18:13:55,226] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.69 | backward_inner: 98.85 | backward_allreduce: 10.76 | step: 42.11
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.3096], device='cuda:0'), 'moe loss': tensor([0.3017], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1420/439453125 | consumed samples:         1420 | consumed tokens:      2908160 | elapsed time per iteration (ms): 251.4 | learning rate: 1.550E-06 | global batch size:     1 | lm loss: 9.261923E+00 | moe loss: 6.033269E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.978 | TFLOPs: 9.88 |
[default0]:[2023-08-25 18:13:55,498] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:13:55,498] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.03 | backward_microstep: 112.07 | backward_inner_microstep: 101.06 | backward_allreduce_microstep: 10.92 | step_microstep: 42.78
[default0]:[2023-08-25 18:13:55,498] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.03 (forward_moe: 20.45, 1st alltoall: 0.87, 2nd alltoall: 0.83, top-k: 8.14)
[default0]:[2023-08-25 18:13:55,498] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.07 | backward_inner: 101.06 | backward_allreduce: 10.92 | step: 42.79
[default0]:[2023-08-25 18:13:55,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:55,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.92 | backward_microstep: 109.75 | backward_inner_microstep: 98.91 | backward_allreduce_microstep: 10.74 | step_microstep: 42.14
[default0]:[2023-08-25 18:13:55,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.92 (forward_moe: 19.99, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.83)
[default0]:[2023-08-25 18:13:55,748] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.75 | backward_inner: 98.92 | backward_allreduce: 10.75 | step: 42.15
[default0]:[2023-08-25 18:13:56,037] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:56,202] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.44 | backward_microstep: 110.03 | backward_inner_microstep: 99.13 | backward_allreduce_microstep: 10.81 | step_microstep: 206.22
[default0]:[2023-08-25 18:13:56,202] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.44 (forward_moe: 19.95, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.86)
[default0]:[2023-08-25 18:13:56,202] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.03 | backward_inner: 99.14 | backward_allreduce: 10.81 | step: 206.22
[default0]:[2023-08-25 18:13:56,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:56,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.52 | backward_microstep: 112.58 | backward_inner_microstep: 101.74 | backward_allreduce_microstep: 10.74 | step_microstep: 41.80
[default0]:[2023-08-25 18:13:56,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.52 (forward_moe: 20.56, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.01)
[default0]:[2023-08-25 18:13:56,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.58 | backward_inner: 101.75 | backward_allreduce: 10.74 | step: 41.80
[default0]:[2023-08-25 18:13:56,690] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:56,690] [INFO] [logging.py:96:log_dist] [Rank 0] step=1425, skipped=0, lr=[1.5553877333333333e-06, 1.5553877333333333e-06, 1.5553877333333333e-06, 1.5553877333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:56,690] [INFO] [timer.py:215:stop] epoch=0/micro_step=1425/global_step=1425, RunningAvgSamplesPerSec=4.920269839894852, CurrSamplesPerSec=5.032333458512654, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:56,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.32 | backward_microstep: 109.90 | backward_inner_microstep: 99.01 | backward_allreduce_microstep: 10.79 | step_microstep: 41.97
[default0]:[2023-08-25 18:13:56,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.32 (forward_moe: 19.96, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:13:56,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.90 | backward_inner: 99.02 | backward_allreduce: 10.80 | step: 41.97
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.1267], device='cuda:0'), 'moe loss': tensor([0.3002], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1425/439453125 | consumed samples:         1425 | consumed tokens:      2918400 | elapsed time per iteration (ms): 293.2 | learning rate: 1.555E-06 | global batch size:     1 | lm loss: 9.425330E+00 | moe loss: 6.003693E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.410 | TFLOPs: 8.47 |
[default0]:[2023-08-25 18:13:56,932] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:56,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 109.10 | backward_inner_microstep: 98.30 | backward_allreduce_microstep: 10.71 | step_microstep: 41.55
[default0]:[2023-08-25 18:13:56,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:13:56,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.10 | backward_inner: 98.31 | backward_allreduce: 10.71 | step: 41.56
[default0]:[2023-08-25 18:13:57,173] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:13:57,173] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 111.52 | backward_inner_microstep: 100.74 | backward_allreduce_microstep: 10.69 | step_microstep: 41.39
[default0]:[2023-08-25 18:13:57,173] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:13:57,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.52 | backward_inner: 100.75 | backward_allreduce: 10.69 | step: 41.39
[default0]:[2023-08-25 18:13:57,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:13:57,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.94 | backward_microstep: 108.91 | backward_inner_microstep: 98.08 | backward_allreduce_microstep: 10.74 | step_microstep: 41.58
[default0]:[2023-08-25 18:13:57,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.94 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:13:57,401] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 98.08 | backward_allreduce: 10.74 | step: 41.58
[default0]:[2023-08-25 18:13:57,659] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:13:57,659] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 108.96 | backward_inner_microstep: 98.12 | backward_allreduce_microstep: 10.75 | step_microstep: 41.44
[default0]:[2023-08-25 18:13:57,659] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.43 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:13:57,659] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.12 | backward_allreduce: 10.75 | step: 41.45
[default0]:[2023-08-25 18:13:57,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.27
[default0]:[2023-08-25 18:13:57,896] [INFO] [logging.py:96:log_dist] [Rank 0] step=1430, skipped=0, lr=[1.5608490666666667e-06, 1.5608490666666667e-06, 1.5608490666666667e-06, 1.5608490666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:57,896] [INFO] [timer.py:215:stop] epoch=0/micro_step=1430/global_step=1430, RunningAvgSamplesPerSec=4.92075530159051, CurrSamplesPerSec=5.070103546397634, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:57,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.69 | backward_microstep: 109.08 | backward_inner_microstep: 98.24 | backward_allreduce_microstep: 10.75 | step_microstep: 41.92
[default0]:[2023-08-25 18:13:57,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.96, 1st alltoall: 0.91, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:13:57,897] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.25 | backward_allreduce: 10.75 | step: 41.92
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.8727], device='cuda:0'), 'moe loss': tensor([0.2996], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1430/439453125 | consumed samples:         1430 | consumed tokens:      2928640 | elapsed time per iteration (ms): 240.8 | learning rate: 1.561E-06 | global batch size:     1 | lm loss: 9.374545E+00 | moe loss: 5.991969E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.152 | TFLOPs: 10.32 |
[default0]:[2023-08-25 18:13:58,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:13:58,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 109.05 | backward_inner_microstep: 98.23 | backward_allreduce_microstep: 10.73 | step_microstep: 41.47
[default0]:[2023-08-25 18:13:58,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 19.81, 1st alltoall: 0.96, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:13:58,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.23 | backward_allreduce: 10.73 | step: 41.47
[default0]:[2023-08-25 18:13:58,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:58,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.42 | backward_microstep: 108.92 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.72 | step_microstep: 41.51
[default0]:[2023-08-25 18:13:58,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.42 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:13:58,580] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.11 | backward_allreduce: 10.73 | step: 41.51
[default0]:[2023-08-25 18:13:58,837] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.27
[default0]:[2023-08-25 18:13:58,838] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.59 | backward_microstep: 109.08 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.73 | step_microstep: 41.43
[default0]:[2023-08-25 18:13:58,838] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.59 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.87, top-k: 7.73)
[default0]:[2023-08-25 18:13:58,838] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.08 | backward_inner: 98.26 | backward_allreduce: 10.73 | step: 41.44
[default0]:[2023-08-25 18:13:59,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:13:59,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.75 | backward_microstep: 108.95 | backward_inner_microstep: 98.15 | backward_allreduce_microstep: 10.71 | step_microstep: 41.37
[default0]:[2023-08-25 18:13:59,076] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.75 (forward_moe: 19.81, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:13:59,077] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.95 | backward_inner: 98.15 | backward_allreduce: 10.71 | step: 41.37
[default0]:[2023-08-25 18:13:59,334] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:13:59,334] [INFO] [logging.py:96:log_dist] [Rank 0] step=1435, skipped=0, lr=[1.5663104e-06, 1.5663104e-06, 1.5663104e-06, 1.5663104e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:13:59,334] [INFO] [timer.py:215:stop] epoch=0/micro_step=1435/global_step=1435, RunningAvgSamplesPerSec=4.921283680185603, CurrSamplesPerSec=5.062881891550646, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:13:59,335] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 109.39 | backward_inner_microstep: 98.49 | backward_allreduce_microstep: 10.80 | step_microstep: 42.05
[default0]:[2023-08-25 18:13:59,335] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 20.03, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.71)
[default0]:[2023-08-25 18:13:59,335] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.39 | backward_inner: 98.50 | backward_allreduce: 10.81 | step: 42.05
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.6772], device='cuda:0'), 'moe loss': tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1435/439453125 | consumed samples:         1435 | consumed tokens:      2938880 | elapsed time per iteration (ms): 287.7 | learning rate: 1.566E-06 | global batch size:     1 | lm loss: 9.335432E+00 | moe loss: 6.010311E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.476 | TFLOPs: 8.64 |
[default0]:[2023-08-25 18:13:59,582] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:13:59,583] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.81 | backward_microstep: 108.89 | backward_inner_microstep: 98.07 | backward_allreduce_microstep: 10.72 | step_microstep: 41.32
[default0]:[2023-08-25 18:13:59,583] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.81 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:13:59,583] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.89 | backward_inner: 98.08 | backward_allreduce: 10.72 | step: 41.32
[default0]:[2023-08-25 18:13:59,817] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:13:59,818] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.73 | backward_microstep: 110.24 | backward_inner_microstep: 99.26 | backward_allreduce_microstep: 10.89 | step_microstep: 42.35
[default0]:[2023-08-25 18:13:59,818] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.72 (forward_moe: 20.01, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.89)
[default0]:[2023-08-25 18:13:59,818] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.24 | backward_inner: 99.27 | backward_allreduce: 10.89 | step: 42.35
[default0]:[2023-08-25 18:14:00,062] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:14:00,062] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 111.99 | backward_inner_microstep: 101.03 | backward_allreduce_microstep: 10.87 | step_microstep: 42.40
[default0]:[2023-08-25 18:14:00,062] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.01 (forward_moe: 20.41, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:14:00,063] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.99 | backward_inner: 101.04 | backward_allreduce: 10.87 | step: 42.40
[default0]:[2023-08-25 18:14:00,337] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:14:00,338] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.84 | backward_microstep: 112.30 | backward_inner_microstep: 101.29 | backward_allreduce_microstep: 10.91 | step_microstep: 43.93
[default0]:[2023-08-25 18:14:00,339] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.84 (forward_moe: 20.43, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:14:00,339] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.30 | backward_inner: 101.29 | backward_allreduce: 10.91 | step: 43.94
[default0]:[2023-08-25 18:14:00,586] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 9.88
[default0]:[2023-08-25 18:14:00,586] [INFO] [logging.py:96:log_dist] [Rank 0] step=1440, skipped=0, lr=[1.5717717333333333e-06, 1.5717717333333333e-06, 1.5717717333333333e-06, 1.5717717333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:00,587] [INFO] [timer.py:215:stop] epoch=0/micro_step=1440/global_step=1440, RunningAvgSamplesPerSec=4.921393796173374, CurrSamplesPerSec=4.822119900437454, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:00,587] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.40 | backward_microstep: 112.85 | backward_inner_microstep: 101.78 | backward_allreduce_microstep: 10.97 | step_microstep: 46.59
[default0]:[2023-08-25 18:14:00,587] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.40 (forward_moe: 20.67, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.19)
[default0]:[2023-08-25 18:14:00,587] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.85 | backward_inner: 101.79 | backward_allreduce: 10.97 | step: 46.59
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.4050], device='cuda:0'), 'moe loss': tensor([0.3028], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1440/439453125 | consumed samples:         1440 | consumed tokens:      2949120 | elapsed time per iteration (ms): 250.3 | learning rate: 1.572E-06 | global batch size:     1 | lm loss: 9.280997E+00 | moe loss: 6.055652E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.995 | TFLOPs: 9.93 |
[default0]:[2023-08-25 18:14:00,842] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.38
[default0]:[2023-08-25 18:14:00,842] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.94 | backward_microstep: 113.05 | backward_inner_microstep: 101.93 | backward_allreduce_microstep: 11.03 | step_microstep: 42.96
[default0]:[2023-08-25 18:14:00,842] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.94 (forward_moe: 20.58, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.24)
[default0]:[2023-08-25 18:14:00,842] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.05 | backward_inner: 101.94 | backward_allreduce: 11.03 | step: 42.96
[default0]:[2023-08-25 18:14:01,084] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.38
[default0]:[2023-08-25 18:14:01,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.22 | backward_microstep: 114.42 | backward_inner_microstep: 103.38 | backward_allreduce_microstep: 10.94 | step_microstep: 43.10
[default0]:[2023-08-25 18:14:01,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.22 (forward_moe: 21.08, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.66)
[default0]:[2023-08-25 18:14:01,085] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.42 | backward_inner: 103.39 | backward_allreduce: 10.95 | step: 43.10
[default0]:[2023-08-25 18:14:01,326] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.24 | optimizer_step: 6.38
[default0]:[2023-08-25 18:14:01,326] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.69 | backward_microstep: 113.51 | backward_inner_microstep: 102.42 | backward_allreduce_microstep: 11.00 | step_microstep: 43.00
[default0]:[2023-08-25 18:14:01,326] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.69 (forward_moe: 20.70, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.29)
[default0]:[2023-08-25 18:14:01,326] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.51 | backward_inner: 102.42 | backward_allreduce: 11.01 | step: 43.00
[default0]:[2023-08-25 18:14:01,577] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.70 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:14:01,577] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.73 | backward_microstep: 109.84 | backward_inner_microstep: 98.95 | backward_allreduce_microstep: 10.79 | step_microstep: 41.95
[default0]:[2023-08-25 18:14:01,577] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.73 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.84)
[default0]:[2023-08-25 18:14:01,577] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.84 | backward_inner: 98.96 | backward_allreduce: 10.79 | step: 41.95
[default0]:[2023-08-25 18:14:01,838] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:01,838] [INFO] [logging.py:96:log_dist] [Rank 0] step=1445, skipped=0, lr=[1.5772330666666666e-06, 1.5772330666666666e-06, 1.5772330666666666e-06, 1.5772330666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:01,839] [INFO] [timer.py:215:stop] epoch=0/micro_step=1445/global_step=1445, RunningAvgSamplesPerSec=4.921473699917612, CurrSamplesPerSec=5.035928517570443, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:01,839] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.16 | backward_microstep: 109.77 | backward_inner_microstep: 98.93 | backward_allreduce_microstep: 10.74 | step_microstep: 42.11
[default0]:[2023-08-25 18:14:01,839] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.16 (forward_moe: 19.92, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.83)
[default0]:[2023-08-25 18:14:01,839] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.77 | backward_inner: 98.94 | backward_allreduce: 10.75 | step: 42.11
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.7813], device='cuda:0'), 'moe loss': tensor([0.3041], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1445/439453125 | consumed samples:         1445 | consumed tokens:      2959360 | elapsed time per iteration (ms): 250.4 | learning rate: 1.577E-06 | global batch size:     1 | lm loss: 9.156264E+00 | moe loss: 6.082577E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.993 | TFLOPs: 9.92 |
[default0]:[2023-08-25 18:14:02,090] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.36
[default0]:[2023-08-25 18:14:02,091] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.64 | backward_microstep: 110.30 | backward_inner_microstep: 99.37 | backward_allreduce_microstep: 10.84 | step_microstep: 42.63
[default0]:[2023-08-25 18:14:02,092] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.64 (forward_moe: 19.98, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:14:02,092] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.30 | backward_inner: 99.38 | backward_allreduce: 10.84 | step: 42.63
[default0]:[2023-08-25 18:14:02,331] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:02,331] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.07 | backward_microstep: 109.99 | backward_inner_microstep: 99.11 | backward_allreduce_microstep: 10.78 | step_microstep: 41.85
[default0]:[2023-08-25 18:14:02,332] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.07 (forward_moe: 19.98, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.86)
[default0]:[2023-08-25 18:14:02,332] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.99 | backward_inner: 99.12 | backward_allreduce: 10.79 | step: 41.85
[default0]:[2023-08-25 18:14:02,590] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:02,590] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 109.07 | backward_inner_microstep: 98.24 | backward_allreduce_microstep: 10.73 | step_microstep: 41.43
[default0]:[2023-08-25 18:14:02,590] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 19.81, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.75)
[default0]:[2023-08-25 18:14:02,590] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.07 | backward_inner: 98.25 | backward_allreduce: 10.74 | step: 41.43
[default0]:[2023-08-25 18:14:02,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:14:02,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.58 | backward_microstep: 108.88 | backward_inner_microstep: 98.08 | backward_allreduce_microstep: 10.70 | step_microstep: 41.49
[default0]:[2023-08-25 18:14:02,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.58 (forward_moe: 19.73, 1st alltoall: 0.85, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:14:02,833] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.87 | backward_inner: 98.09 | backward_allreduce: 10.70 | step: 41.49
[default0]:[2023-08-25 18:14:03,134] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:03,134] [INFO] [logging.py:96:log_dist] [Rank 0] step=1450, skipped=0, lr=[1.5826944e-06, 1.5826944e-06, 1.5826944e-06, 1.5826944e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:03,134] [INFO] [timer.py:215:stop] epoch=0/micro_step=1450/global_step=1450, RunningAvgSamplesPerSec=4.921854205133475, CurrSamplesPerSec=5.039740653604824, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:03,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.39 | backward_microstep: 110.56 | backward_inner_microstep: 99.75 | backward_allreduce_microstep: 10.72 | step_microstep: 41.92
[default0]:[2023-08-25 18:14:03,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.39 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:14:03,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.56 | backward_inner: 99.76 | backward_allreduce: 10.72 | step: 41.93
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.5919], device='cuda:0'), 'moe loss': tensor([0.3000], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1450/439453125 | consumed samples:         1450 | consumed tokens:      2969600 | elapsed time per iteration (ms): 260.4 | learning rate: 1.583E-06 | global batch size:     1 | lm loss: 9.318378E+00 | moe loss: 6.000625E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.840 | TFLOPs: 9.54 |
[default0]:[2023-08-25 18:14:03,395] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:03,396] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 109.24 | backward_inner_microstep: 98.42 | backward_allreduce_microstep: 10.73 | step_microstep: 41.47
[default0]:[2023-08-25 18:14:03,396] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.74, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:03,396] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.24 | backward_inner: 98.42 | backward_allreduce: 10.73 | step: 41.47
[default0]:[2023-08-25 18:14:03,662] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:03,662] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 111.62 | backward_inner_microstep: 100.74 | backward_allreduce_microstep: 10.78 | step_microstep: 42.07
[default0]:[2023-08-25 18:14:03,663] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:03,663] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.61 | backward_inner: 100.75 | backward_allreduce: 10.78 | step: 42.08
[default0]:[2023-08-25 18:14:03,903] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:03,904] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.71 | backward_microstep: 108.98 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.71 | step_microstep: 41.43
[default0]:[2023-08-25 18:14:03,904] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.70 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:03,904] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.98 | backward_inner: 98.18 | backward_allreduce: 10.71 | step: 41.43
[default0]:[2023-08-25 18:14:04,158] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:14:04,158] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 109.02 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.75 | step_microstep: 41.36
[default0]:[2023-08-25 18:14:04,159] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.40 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:14:04,159] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.02 | backward_inner: 98.18 | backward_allreduce: 10.76 | step: 41.37
[default0]:[2023-08-25 18:14:04,398] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:04,399] [INFO] [logging.py:96:log_dist] [Rank 0] step=1455, skipped=0, lr=[1.5881557333333334e-06, 1.5881557333333334e-06, 1.5881557333333334e-06, 1.5881557333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:04,399] [INFO] [timer.py:215:stop] epoch=0/micro_step=1455/global_step=1455, RunningAvgSamplesPerSec=4.922325239403561, CurrSamplesPerSec=5.0761291571864255, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:04,399] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.43 | backward_microstep: 109.27 | backward_inner_microstep: 98.41 | backward_allreduce_microstep: 10.76 | step_microstep: 41.76
[default0]:[2023-08-25 18:14:04,399] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.43 (forward_moe: 19.73, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:04,399] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.27 | backward_inner: 98.42 | backward_allreduce: 10.77 | step: 41.76
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.8301], device='cuda:0'), 'moe loss': tensor([0.3016], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1455/439453125 | consumed samples:         1455 | consumed tokens:      2979840 | elapsed time per iteration (ms): 252.9 | learning rate: 1.588E-06 | global batch size:     1 | lm loss: 9.366027E+00 | moe loss: 6.032627E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.954 | TFLOPs: 9.82 |
[default0]:[2023-08-25 18:14:04,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:14:04,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.63 | backward_microstep: 108.79 | backward_inner_microstep: 98.01 | backward_allreduce_microstep: 10.69 | step_microstep: 41.55
[default0]:[2023-08-25 18:14:04,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.63 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.74)
[default0]:[2023-08-25 18:14:04,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.79 | backward_inner: 98.01 | backward_allreduce: 10.69 | step: 41.55
[default0]:[2023-08-25 18:14:04,916] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.27
[default0]:[2023-08-25 18:14:04,917] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 109.01 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.78 | step_microstep: 41.45
[default0]:[2023-08-25 18:14:04,917] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:04,917] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.13 | backward_allreduce: 10.79 | step: 41.46
[default0]:[2023-08-25 18:14:05,182] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:05,182] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 109.98 | backward_inner_microstep: 99.13 | backward_allreduce_microstep: 10.76 | step_microstep: 41.74
[default0]:[2023-08-25 18:14:05,182] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.00 (forward_moe: 19.93, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.84)
[default0]:[2023-08-25 18:14:05,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.98 | backward_inner: 99.13 | backward_allreduce: 10.76 | step: 41.75
[default0]:[2023-08-25 18:14:05,406] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.38
[default0]:[2023-08-25 18:14:05,407] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.27 | backward_microstep: 110.71 | backward_inner_microstep: 99.73 | backward_allreduce_microstep: 10.88 | step_microstep: 41.88
[default0]:[2023-08-25 18:14:05,407] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.27 (forward_moe: 20.06, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.88)
[default0]:[2023-08-25 18:14:05,407] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.71 | backward_inner: 99.74 | backward_allreduce: 10.88 | step: 41.88
[default0]:[2023-08-25 18:14:05,648] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.34
[default0]:[2023-08-25 18:14:05,648] [INFO] [logging.py:96:log_dist] [Rank 0] step=1460, skipped=0, lr=[1.5936170666666668e-06, 1.5936170666666668e-06, 1.5936170666666668e-06, 1.5936170666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:05,648] [INFO] [timer.py:215:stop] epoch=0/micro_step=1460/global_step=1460, RunningAvgSamplesPerSec=4.922729299745152, CurrSamplesPerSec=5.005195766059261, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:05,648] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.07 | backward_microstep: 110.74 | backward_inner_microstep: 99.84 | backward_allreduce_microstep: 10.80 | step_microstep: 42.43
[default0]:[2023-08-25 18:14:05,648] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.07 (forward_moe: 20.20, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.91)
[default0]:[2023-08-25 18:14:05,649] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.73 | backward_inner: 99.84 | backward_allreduce: 10.81 | step: 42.44
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.5116], device='cuda:0'), 'moe loss': tensor([0.3000], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1460/439453125 | consumed samples:         1460 | consumed tokens:      2990080 | elapsed time per iteration (ms): 248.6 | learning rate: 1.594E-06 | global batch size:     1 | lm loss: 9.302322E+00 | moe loss: 5.999219E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.023 | TFLOPs: 10.00 |
[default0]:[2023-08-25 18:14:05,897] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.96 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:05,897] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.48 | backward_microstep: 110.92 | backward_inner_microstep: 100.02 | backward_allreduce_microstep: 10.80 | step_microstep: 42.18
[default0]:[2023-08-25 18:14:05,897] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.48 (forward_moe: 20.15, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.98)
[default0]:[2023-08-25 18:14:05,897] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.91 | backward_inner: 100.03 | backward_allreduce: 10.81 | step: 42.19
[default0]:[2023-08-25 18:14:06,190] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:14:06,190] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.47 | backward_microstep: 111.48 | backward_inner_microstep: 100.48 | backward_allreduce_microstep: 10.90 | step_microstep: 42.46
[default0]:[2023-08-25 18:14:06,191] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.47 (forward_moe: 20.27, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.05)
[default0]:[2023-08-25 18:14:06,191] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.48 | backward_inner: 100.48 | backward_allreduce: 10.91 | step: 42.46
[default0]:[2023-08-25 18:14:06,458] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:06,458] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.98 | backward_microstep: 114.43 | backward_inner_microstep: 103.41 | backward_allreduce_microstep: 10.93 | step_microstep: 42.72
[default0]:[2023-08-25 18:14:06,458] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.97 (forward_moe: 20.58, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:14:06,459] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.43 | backward_inner: 103.41 | backward_allreduce: 10.93 | step: 42.72
[default0]:[2023-08-25 18:14:06,705] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.40
[default0]:[2023-08-25 18:14:06,705] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.41 | backward_microstep: 113.10 | backward_inner_microstep: 102.03 | backward_allreduce_microstep: 10.97 | step_microstep: 42.90
[default0]:[2023-08-25 18:14:06,705] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.41 (forward_moe: 20.64, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.24)
[default0]:[2023-08-25 18:14:06,705] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.10 | backward_inner: 102.04 | backward_allreduce: 10.98 | step: 42.90
[default0]:[2023-08-25 18:14:06,957] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:14:06,958] [INFO] [logging.py:96:log_dist] [Rank 0] step=1465, skipped=0, lr=[1.5990784e-06, 1.5990784e-06, 1.5990784e-06, 1.5990784e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:06,958] [INFO] [timer.py:215:stop] epoch=0/micro_step=1465/global_step=1465, RunningAvgSamplesPerSec=4.922714525142158, CurrSamplesPerSec=4.8601662116626265, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:06,958] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.72 | backward_microstep: 113.54 | backward_inner_microstep: 102.46 | backward_allreduce_microstep: 10.98 | step_microstep: 43.95
[default0]:[2023-08-25 18:14:06,958] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.72 (forward_moe: 20.72, 1st alltoall: 0.88, 2nd alltoall: 0.85, top-k: 8.30)
[default0]:[2023-08-25 18:14:06,958] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.54 | backward_inner: 102.47 | backward_allreduce: 10.99 | step: 43.95
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.9493], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1465/439453125 | consumed samples:         1465 | consumed tokens:      3000320 | elapsed time per iteration (ms): 262.7 | learning rate: 1.599E-06 | global batch size:     1 | lm loss: 9.189864E+00 | moe loss: 6.016864E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.806 | TFLOPs: 9.46 |
[default0]:[2023-08-25 18:14:07,208] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:07,209] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.01 | backward_microstep: 110.21 | backward_inner_microstep: 99.32 | backward_allreduce_microstep: 10.80 | step_microstep: 41.67
[default0]:[2023-08-25 18:14:07,209] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.01 (forward_moe: 20.02, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.93)
[default0]:[2023-08-25 18:14:07,209] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.21 | backward_inner: 99.33 | backward_allreduce: 10.80 | step: 41.67
[default0]:[2023-08-25 18:14:07,450] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:07,450] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.13 | backward_microstep: 110.16 | backward_inner_microstep: 99.14 | backward_allreduce_microstep: 10.92 | step_microstep: 41.66
[default0]:[2023-08-25 18:14:07,450] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.12 (forward_moe: 19.95, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.84)
[default0]:[2023-08-25 18:14:07,451] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.16 | backward_inner: 99.15 | backward_allreduce: 10.93 | step: 41.66
[default0]:[2023-08-25 18:14:07,681] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.35
[default0]:[2023-08-25 18:14:07,681] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.99 | backward_microstep: 109.94 | backward_inner_microstep: 99.03 | backward_allreduce_microstep: 10.82 | step_microstep: 41.90
[default0]:[2023-08-25 18:14:07,681] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.99 (forward_moe: 19.96, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.87)
[default0]:[2023-08-25 18:14:07,681] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.94 | backward_inner: 99.03 | backward_allreduce: 10.82 | step: 41.90
[default0]:[2023-08-25 18:14:07,927] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:07,927] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.14 | backward_microstep: 109.98 | backward_inner_microstep: 99.13 | backward_allreduce_microstep: 10.76 | step_microstep: 41.79
[default0]:[2023-08-25 18:14:07,927] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.14 (forward_moe: 20.08, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:14:07,927] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.98 | backward_inner: 99.13 | backward_allreduce: 10.76 | step: 41.79
[default0]:[2023-08-25 18:14:08,162] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:08,162] [INFO] [logging.py:96:log_dist] [Rank 0] step=1470, skipped=0, lr=[1.6045397333333334e-06, 1.6045397333333334e-06, 1.6045397333333334e-06, 1.6045397333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:08,163] [INFO] [timer.py:215:stop] epoch=0/micro_step=1470/global_step=1470, RunningAvgSamplesPerSec=4.923046259554956, CurrSamplesPerSec=4.98308085098294, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:08,163] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.49 | backward_microstep: 111.42 | backward_inner_microstep: 100.52 | backward_allreduce_microstep: 10.81 | step_microstep: 42.20
[default0]:[2023-08-25 18:14:08,163] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.49 (forward_moe: 20.05, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:14:08,163] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.42 | backward_inner: 100.53 | backward_allreduce: 10.81 | step: 42.21
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.9024], device='cuda:0'), 'moe loss': tensor([0.3016], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1470/439453125 | consumed samples:         1470 | consumed tokens:      3010560 | elapsed time per iteration (ms): 240.1 | learning rate: 1.605E-06 | global batch size:     1 | lm loss: 9.180489E+00 | moe loss: 6.031770E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.164 | TFLOPs: 10.35 |
[default0]:[2023-08-25 18:14:08,424] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:08,424] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.36 | backward_microstep: 108.98 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.73 | step_microstep: 41.63
[default0]:[2023-08-25 18:14:08,424] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.36 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:14:08,424] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.98 | backward_inner: 98.16 | backward_allreduce: 10.73 | step: 41.63
[default0]:[2023-08-25 18:14:08,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:08,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 108.86 | backward_inner_microstep: 98.03 | backward_allreduce_microstep: 10.74 | step_microstep: 41.58
[default0]:[2023-08-25 18:14:08,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:08,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.86 | backward_inner: 98.03 | backward_allreduce: 10.74 | step: 41.58
[default0]:[2023-08-25 18:14:08,909] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:08,909] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 108.83 | backward_inner_microstep: 97.99 | backward_allreduce_microstep: 10.74 | step_microstep: 41.57
[default0]:[2023-08-25 18:14:08,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:08,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.82 | backward_inner: 98.00 | backward_allreduce: 10.74 | step: 41.58
[default0]:[2023-08-25 18:14:09,149] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:09,149] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.62 | backward_microstep: 109.18 | backward_inner_microstep: 98.38 | backward_allreduce_microstep: 10.70 | step_microstep: 41.50
[default0]:[2023-08-25 18:14:09,149] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.78)
[default0]:[2023-08-25 18:14:09,149] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.18 | backward_inner: 98.38 | backward_allreduce: 10.70 | step: 41.50
[default0]:[2023-08-25 18:14:09,392] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.73 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:09,393] [INFO] [logging.py:96:log_dist] [Rank 0] step=1475, skipped=0, lr=[1.6100010666666667e-06, 1.6100010666666667e-06, 1.6100010666666667e-06, 1.6100010666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:09,393] [INFO] [timer.py:215:stop] epoch=0/micro_step=1475/global_step=1475, RunningAvgSamplesPerSec=4.923567911074502, CurrSamplesPerSec=5.083653614235137, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:09,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 108.89 | backward_inner_microstep: 98.06 | backward_allreduce_microstep: 10.74 | step_microstep: 41.86
[default0]:[2023-08-25 18:14:09,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.41 (forward_moe: 19.68, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.69)
[default0]:[2023-08-25 18:14:09,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.89 | backward_inner: 98.06 | backward_allreduce: 10.75 | step: 41.86
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.5219], device='cuda:0'), 'moe loss': tensor([0.2998], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1475/439453125 | consumed samples:         1475 | consumed tokens:      3020800 | elapsed time per iteration (ms): 246.1 | learning rate: 1.610E-06 | global batch size:     1 | lm loss: 9.304387E+00 | moe loss: 5.996071E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.064 | TFLOPs: 10.10 |
[default0]:[2023-08-25 18:14:09,634] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:14:09,634] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 109.07 | backward_inner_microstep: 98.28 | backward_allreduce_microstep: 10.70 | step_microstep: 41.50
[default0]:[2023-08-25 18:14:09,634] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.40 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:14:09,634] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.06 | backward_inner: 98.28 | backward_allreduce: 10.70 | step: 41.51
[default0]:[2023-08-25 18:14:09,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:14:09,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 108.93 | backward_inner_microstep: 98.12 | backward_allreduce_microstep: 10.72 | step_microstep: 41.59
[default0]:[2023-08-25 18:14:09,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:14:09,910] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.93 | backward_inner: 98.12 | backward_allreduce: 10.72 | step: 41.59
[default0]:[2023-08-25 18:14:10,153] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:14:10,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.06 | backward_microstep: 111.41 | backward_inner_microstep: 100.41 | backward_allreduce_microstep: 10.90 | step_microstep: 42.11
[default0]:[2023-08-25 18:14:10,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.06 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.98)
[default0]:[2023-08-25 18:14:10,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.41 | backward_inner: 100.42 | backward_allreduce: 10.91 | step: 42.11
[default0]:[2023-08-25 18:14:10,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:14:10,394] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.49 | backward_microstep: 110.61 | backward_inner_microstep: 99.72 | backward_allreduce_microstep: 10.79 | step_microstep: 42.03
[default0]:[2023-08-25 18:14:10,394] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.49 (forward_moe: 20.24, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.08)
[default0]:[2023-08-25 18:14:10,394] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.61 | backward_inner: 99.73 | backward_allreduce: 10.79 | step: 42.03
[default0]:[2023-08-25 18:14:10,643] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 12.05
[default0]:[2023-08-25 18:14:10,643] [INFO] [logging.py:96:log_dist] [Rank 0] step=1480, skipped=0, lr=[1.6154624e-06, 1.6154624e-06, 1.6154624e-06, 1.6154624e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:10,644] [INFO] [timer.py:215:stop] epoch=0/micro_step=1480/global_step=1480, RunningAvgSamplesPerSec=4.923822455497565, CurrSamplesPerSec=4.853512987471346, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:10,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.39 | backward_microstep: 110.80 | backward_inner_microstep: 99.92 | backward_allreduce_microstep: 10.79 | step_microstep: 48.34
[default0]:[2023-08-25 18:14:10,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.39 (forward_moe: 20.27, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.99)
[default0]:[2023-08-25 18:14:10,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.80 | backward_inner: 99.93 | backward_allreduce: 10.79 | step: 48.34
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.3923], device='cuda:0'), 'moe loss': tensor([0.3018], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1480/439453125 | consumed samples:         1480 | consumed tokens:      3031040 | elapsed time per iteration (ms): 250.3 | learning rate: 1.615E-06 | global batch size:     1 | lm loss: 9.478452E+00 | moe loss: 6.035155E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.996 | TFLOPs: 9.93 |
[default0]:[2023-08-25 18:14:10,885] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:14:10,885] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.44 | backward_microstep: 110.81 | backward_inner_microstep: 99.91 | backward_allreduce_microstep: 10.81 | step_microstep: 42.05
[default0]:[2023-08-25 18:14:10,885] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.44 (forward_moe: 20.11, 1st alltoall: 0.89, 2nd alltoall: 0.80, top-k: 7.93)
[default0]:[2023-08-25 18:14:10,885] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.81 | backward_inner: 99.91 | backward_allreduce: 10.82 | step: 42.05
[default0]:[2023-08-25 18:14:11,152] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.36
[default0]:[2023-08-25 18:14:11,152] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.43 | backward_microstep: 111.03 | backward_inner_microstep: 100.10 | backward_allreduce_microstep: 10.84 | step_microstep: 42.77
[default0]:[2023-08-25 18:14:11,152] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.43 (forward_moe: 20.16, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.99)
[default0]:[2023-08-25 18:14:11,152] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.03 | backward_inner: 100.10 | backward_allreduce: 10.84 | step: 42.78
[default0]:[2023-08-25 18:14:11,396] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:14:11,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.49 | backward_microstep: 110.61 | backward_inner_microstep: 99.69 | backward_allreduce_microstep: 10.82 | step_microstep: 42.01
[default0]:[2023-08-25 18:14:11,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.49 (forward_moe: 20.08, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.93)
[default0]:[2023-08-25 18:14:11,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.61 | backward_inner: 99.70 | backward_allreduce: 10.83 | step: 42.01
[default0]:[2023-08-25 18:14:11,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:11,792] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.23 | backward_microstep: 110.68 | backward_inner_microstep: 99.76 | backward_allreduce_microstep: 10.83 | step_microstep: 42.13
[default0]:[2023-08-25 18:14:11,792] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.23 (forward_moe: 20.11, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.93)
[default0]:[2023-08-25 18:14:11,792] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.68 | backward_inner: 99.76 | backward_allreduce: 10.83 | step: 42.13
[default0]:[2023-08-25 18:14:12,035] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.33
[default0]:[2023-08-25 18:14:12,036] [INFO] [logging.py:96:log_dist] [Rank 0] step=1485, skipped=0, lr=[1.6209237333333333e-06, 1.6209237333333333e-06, 1.6209237333333333e-06, 1.6209237333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:12,036] [INFO] [timer.py:215:stop] epoch=0/micro_step=1485/global_step=1485, RunningAvgSamplesPerSec=4.923989230246223, CurrSamplesPerSec=4.893125505288836, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:12,036] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.72 | backward_microstep: 114.39 | backward_inner_microstep: 103.43 | backward_allreduce_microstep: 10.86 | step_microstep: 42.75
[default0]:[2023-08-25 18:14:12,036] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.72 (forward_moe: 20.14, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.95)
[default0]:[2023-08-25 18:14:12,037] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.39 | backward_inner: 103.44 | backward_allreduce: 10.87 | step: 42.75
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.1259], device='cuda:0'), 'moe loss': tensor([0.3004], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1485/439453125 | consumed samples:         1485 | consumed tokens:      3041280 | elapsed time per iteration (ms): 284.8 | learning rate: 1.621E-06 | global batch size:     1 | lm loss: 9.225175E+00 | moe loss: 6.008699E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.511 | TFLOPs: 8.72 |
[default0]:[2023-08-25 18:14:12,324] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.38
[default0]:[2023-08-25 18:14:12,325] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.15 | backward_microstep: 112.24 | backward_inner_microstep: 101.25 | backward_allreduce_microstep: 10.90 | step_microstep: 43.07
[default0]:[2023-08-25 18:14:12,325] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.15 (forward_moe: 20.42, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:14:12,325] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.24 | backward_inner: 101.25 | backward_allreduce: 10.90 | step: 43.07
[default0]:[2023-08-25 18:14:12,576] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:14:12,576] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.34 | backward_microstep: 112.63 | backward_inner_microstep: 101.64 | backward_allreduce_microstep: 10.89 | step_microstep: 42.63
[default0]:[2023-08-25 18:14:12,576] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.34 (forward_moe: 20.54, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.19)
[default0]:[2023-08-25 18:14:12,576] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.63 | backward_inner: 101.65 | backward_allreduce: 10.90 | step: 42.63
[default0]:[2023-08-25 18:14:12,810] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:12,811] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.03 | backward_microstep: 110.23 | backward_inner_microstep: 99.31 | backward_allreduce_microstep: 10.83 | step_microstep: 41.98
[default0]:[2023-08-25 18:14:12,811] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.03 (forward_moe: 20.09, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.99)
[default0]:[2023-08-25 18:14:12,811] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.23 | backward_inner: 99.32 | backward_allreduce: 10.83 | step: 41.99
[default0]:[2023-08-25 18:14:13,055] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 7.46
[default0]:[2023-08-25 18:14:13,056] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.35 | backward_microstep: 110.50 | backward_inner_microstep: 99.63 | backward_allreduce_microstep: 10.77 | step_microstep: 43.08
[default0]:[2023-08-25 18:14:13,056] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.35 (forward_moe: 20.01, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.88)
[default0]:[2023-08-25 18:14:13,056] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.50 | backward_inner: 99.63 | backward_allreduce: 10.78 | step: 43.08
[default0]:[2023-08-25 18:14:13,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:13,299] [INFO] [logging.py:96:log_dist] [Rank 0] step=1490, skipped=0, lr=[1.6263850666666666e-06, 1.6263850666666666e-06, 1.6263850666666666e-06, 1.6263850666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:13,299] [INFO] [timer.py:215:stop] epoch=0/micro_step=1490/global_step=1490, RunningAvgSamplesPerSec=4.924127121061987, CurrSamplesPerSec=4.987685092254784, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:13,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.40 | backward_microstep: 111.27 | backward_inner_microstep: 100.39 | backward_allreduce_microstep: 10.78 | step_microstep: 42.29
[default0]:[2023-08-25 18:14:13,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.40 (forward_moe: 20.56, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.28)
[default0]:[2023-08-25 18:14:13,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.27 | backward_inner: 100.40 | backward_allreduce: 10.78 | step: 42.30
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.0387], device='cuda:0'), 'moe loss': tensor([0.3011], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1490/439453125 | consumed samples:         1490 | consumed tokens:      3051520 | elapsed time per iteration (ms): 246.2 | learning rate: 1.626E-06 | global batch size:     1 | lm loss: 9.207745E+00 | moe loss: 6.021887E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.061 | TFLOPs: 10.09 |
[default0]:[2023-08-25 18:14:13,550] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.92 | optimizer_step: 6.35
[default0]:[2023-08-25 18:14:13,550] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.17 | backward_microstep: 110.71 | backward_inner_microstep: 99.84 | backward_allreduce_microstep: 10.78 | step_microstep: 41.94
[default0]:[2023-08-25 18:14:13,551] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.17 (forward_moe: 20.10, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.95)
[default0]:[2023-08-25 18:14:13,551] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.71 | backward_inner: 99.85 | backward_allreduce: 10.78 | step: 41.95
[default0]:[2023-08-25 18:14:13,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:14:13,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.09 | backward_microstep: 110.15 | backward_inner_microstep: 99.30 | backward_allreduce_microstep: 10.77 | step_microstep: 41.89
[default0]:[2023-08-25 18:14:13,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.09 (forward_moe: 20.02, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.91)
[default0]:[2023-08-25 18:14:13,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.15 | backward_inner: 99.30 | backward_allreduce: 10.77 | step: 41.89
[default0]:[2023-08-25 18:14:14,040] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.28
[default0]:[2023-08-25 18:14:14,040] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 109.07 | backward_inner_microstep: 98.23 | backward_allreduce_microstep: 10.74 | step_microstep: 41.51
[default0]:[2023-08-25 18:14:14,040] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:14:14,040] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.07 | backward_inner: 98.24 | backward_allreduce: 10.74 | step: 41.52
[default0]:[2023-08-25 18:14:14,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:14,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.48 | backward_microstep: 109.01 | backward_inner_microstep: 98.14 | backward_allreduce_microstep: 10.78 | step_microstep: 41.45
[default0]:[2023-08-25 18:14:14,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:14:14,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.01 | backward_inner: 98.15 | backward_allreduce: 10.78 | step: 41.46
[default0]:[2023-08-25 18:14:14,532] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.88 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:14,533] [INFO] [logging.py:96:log_dist] [Rank 0] step=1495, skipped=0, lr=[1.6318464e-06, 1.6318464e-06, 1.6318464e-06, 1.6318464e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:14,533] [INFO] [timer.py:215:stop] epoch=0/micro_step=1495/global_step=1495, RunningAvgSamplesPerSec=4.924517334503539, CurrSamplesPerSec=5.071188571912198, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:14,533] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 109.24 | backward_inner_microstep: 98.40 | backward_allreduce_microstep: 10.74 | step_microstep: 41.81
[default0]:[2023-08-25 18:14:14,533] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.75)
[default0]:[2023-08-25 18:14:14,533] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.24 | backward_inner: 98.41 | backward_allreduce: 10.73 | step: 41.81
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.0273], device='cuda:0'), 'moe loss': tensor([0.3019], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1495/439453125 | consumed samples:         1495 | consumed tokens:      3061760 | elapsed time per iteration (ms): 246.6 | learning rate: 1.632E-06 | global batch size:     1 | lm loss: 9.205469E+00 | moe loss: 6.038619E-02 | loss scale: 8192.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.055 | TFLOPs: 10.08 |
[default0]:[2023-08-25 18:14:14,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:14,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 109.00 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.73 | step_microstep: 41.57
[default0]:[2023-08-25 18:14:14,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 19.69, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:14:14,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.19 | backward_allreduce: 10.74 | step: 41.58
[default0]:[2023-08-25 18:14:15,026] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:15,026] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.89 | backward_microstep: 108.99 | backward_inner_microstep: 98.22 | backward_allreduce_microstep: 10.67 | step_microstep: 41.46
[default0]:[2023-08-25 18:14:15,027] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.89 (forward_moe: 19.94, 1st alltoall: 0.85, 2nd alltoall: 0.81, top-k: 7.72)
[default0]:[2023-08-25 18:14:15,027] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.99 | backward_inner: 98.23 | backward_allreduce: 10.68 | step: 41.47
[default0]:[2023-08-25 18:14:15,265] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.89 | optimizer_step: 6.28
[default0]:[2023-08-25 18:14:15,265] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.50 | backward_microstep: 109.03 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.76 | step_microstep: 41.51
[default0]:[2023-08-25 18:14:15,265] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.50 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:14:15,265] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.18 | backward_allreduce: 10.77 | step: 41.52
[default0]:[2023-08-25 18:14:15,510] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:15,511] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 109.23 | backward_inner_microstep: 98.40 | backward_allreduce_microstep: 10.73 | step_microstep: 41.42
[default0]:[2023-08-25 18:14:15,511] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:15,511] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.22 | backward_inner: 98.41 | backward_allreduce: 10.73 | step: 41.42
[default0]:[2023-08-25 18:14:15,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.44
[default0]:[2023-08-25 18:14:15,956] [INFO] [logging.py:96:log_dist] [Rank 0] step=1500, skipped=0, lr=[1.6373077333333335e-06, 1.6373077333333335e-06, 1.6373077333333335e-06, 1.6373077333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:15,956] [INFO] [timer.py:215:stop] epoch=0/micro_step=1500/global_step=1500, RunningAvgSamplesPerSec=4.924900954802168, CurrSamplesPerSec=4.906054807210934, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:15,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.55 | backward_microstep: 113.38 | backward_inner_microstep: 102.24 | backward_allreduce_microstep: 11.04 | step_microstep: 43.39
[default0]:[2023-08-25 18:14:15,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.55 (forward_moe: 20.77, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.27)
[default0]:[2023-08-25 18:14:15,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.38 | backward_inner: 102.25 | backward_allreduce: 11.04 | step: 43.39
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.6098], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1500/439453125 | consumed samples:         1500 | consumed tokens:      3072000 | elapsed time per iteration (ms): 285.0 | learning rate: 1.637E-06 | global batch size:     1 | lm loss: 9.321964E+00 | moe loss: 6.014928E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.508 | TFLOPs: 8.72 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1500 | lm loss value: 9.222281E+00 | lm loss PPL: 1.012012E+04 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration    1500 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:14:19,602] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1500 is about to be saved!
[default0]:[2023-08-25 18:14:19,604] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,615] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,615] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,625] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,625] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,634] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,634] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,643] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,644] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,653] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,653] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,662] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,662] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,671] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,671] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,679] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,680] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,690] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,690] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,699] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,699] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,708] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,708] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,717] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,717] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,726] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,727] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,736] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,736] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,745] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,745] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,754] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,755] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,765] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,765] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,775] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,776] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,785] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,785] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,794] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,795] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,804] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,804] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,814] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,814] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,823] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,823] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:19,832] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:19,832] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:14:19,835] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:14:19,837] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:14:19,837] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:20,117] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:20,119] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:14:23,903] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:14:23,924] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1500/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:14:23,924] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
[default0]:  successfully saved checkpoint at iteration    1500 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.68, Latency(second): 4.325
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4325.41, 4325.41)
[default0]:[2023-08-25 18:14:24,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.16 | optimizer_step: 10.01
[default0]:[2023-08-25 18:14:24,219] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2369.24 | backward_microstep: 117.14 | backward_inner_microstep: 106.00 | backward_allreduce_microstep: 11.05 | step_microstep: 47.83
[default0]:[2023-08-25 18:14:24,220] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2369.15 (forward_moe: 21.44, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.75)
[default0]:[2023-08-25 18:14:24,220] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.14 | backward_inner: 106.00 | backward_allreduce: 11.05 | step: 47.84
[default0]:[2023-08-25 18:14:24,474] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.44
[default0]:[2023-08-25 18:14:24,475] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.05 | backward_microstep: 116.51 | backward_inner_microstep: 105.44 | backward_allreduce_microstep: 10.98 | step_microstep: 43.86
[default0]:[2023-08-25 18:14:24,475] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.05 (forward_moe: 21.37, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.73)
[default0]:[2023-08-25 18:14:24,475] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.50 | backward_inner: 105.44 | backward_allreduce: 10.98 | step: 43.86
[default0]:[2023-08-25 18:14:24,722] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.05 | optimizer_step: 6.41
[default0]:[2023-08-25 18:14:24,722] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.92 | backward_microstep: 114.24 | backward_inner_microstep: 103.10 | backward_allreduce_microstep: 11.04 | step_microstep: 43.35
[default0]:[2023-08-25 18:14:24,722] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.92 (forward_moe: 20.89, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.40)
[default0]:[2023-08-25 18:14:24,723] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.23 | backward_inner: 103.10 | backward_allreduce: 11.04 | step: 43.35
[default0]:[2023-08-25 18:14:24,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.13 | optimizer_step: 6.42
[default0]:[2023-08-25 18:14:24,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.79 | backward_microstep: 114.49 | backward_inner_microstep: 103.33 | backward_allreduce_microstep: 11.07 | step_microstep: 43.84
[default0]:[2023-08-25 18:14:24,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.79 (forward_moe: 20.93, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.43)
[default0]:[2023-08-25 18:14:24,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.49 | backward_inner: 103.34 | backward_allreduce: 11.07 | step: 43.84
[default0]:[2023-08-25 18:14:25,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:14:25,237] [INFO] [logging.py:96:log_dist] [Rank 0] step=1505, skipped=0, lr=[1.6427690666666668e-06, 1.6427690666666668e-06, 1.6427690666666668e-06, 1.6427690666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:25,237] [INFO] [timer.py:215:stop] epoch=0/micro_step=1505/global_step=1505, RunningAvgSamplesPerSec=4.923800219288962, CurrSamplesPerSec=4.831718845217647, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:25,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.12 | backward_microstep: 114.66 | backward_inner_microstep: 103.52 | backward_allreduce_microstep: 11.05 | step_microstep: 43.61
[default0]:[2023-08-25 18:14:25,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.12 (forward_moe: 20.87, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.43)
[default0]:[2023-08-25 18:14:25,238] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.66 | backward_inner: 103.53 | backward_allreduce: 11.05 | step: 43.62
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.6782], device='cuda:0'), 'moe loss': tensor([0.3011], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1505/439453125 | consumed samples:         1505 | consumed tokens:      3082240 | elapsed time per iteration (ms): 1856.5 | learning rate: 1.643E-06 | global batch size:     1 | lm loss: 9.135642E+00 | moe loss: 6.021149E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.539 | TFLOPs: 1.34 |
[default0]:[2023-08-25 18:14:25,494] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.45
[default0]:[2023-08-25 18:14:25,495] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.66 | backward_microstep: 113.99 | backward_inner_microstep: 102.89 | backward_allreduce_microstep: 11.00 | step_microstep: 44.10
[default0]:[2023-08-25 18:14:25,496] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.66 (forward_moe: 20.81, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.36)
[default0]:[2023-08-25 18:14:25,496] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.99 | backward_inner: 102.89 | backward_allreduce: 11.01 | step: 44.11
[default0]:[2023-08-25 18:14:25,794] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.05 | optimizer_step: 6.41
[default0]:[2023-08-25 18:14:25,795] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.88 | backward_microstep: 113.93 | backward_inner_microstep: 102.85 | backward_allreduce_microstep: 10.98 | step_microstep: 43.73
[default0]:[2023-08-25 18:14:25,795] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.88 (forward_moe: 20.90, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.34)
[default0]:[2023-08-25 18:14:25,795] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.93 | backward_inner: 102.85 | backward_allreduce: 10.99 | step: 43.74
[default0]:[2023-08-25 18:14:26,052] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.43
[default0]:[2023-08-25 18:14:26,052] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.82 | backward_microstep: 113.92 | backward_inner_microstep: 102.84 | backward_allreduce_microstep: 10.98 | step_microstep: 43.36
[default0]:[2023-08-25 18:14:26,052] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.82 (forward_moe: 20.87, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.38)
[default0]:[2023-08-25 18:14:26,053] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.91 | backward_inner: 102.84 | backward_allreduce: 10.99 | step: 43.36
[default0]:[2023-08-25 18:14:26,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:26,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.97 | backward_microstep: 112.13 | backward_inner_microstep: 101.14 | backward_allreduce_microstep: 10.90 | step_microstep: 42.51
[default0]:[2023-08-25 18:14:26,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.96 (forward_moe: 20.52, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:14:26,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.13 | backward_inner: 101.14 | backward_allreduce: 10.90 | step: 42.52
[default0]:[2023-08-25 18:14:26,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:14:26,727] [INFO] [logging.py:96:log_dist] [Rank 0] step=1510, skipped=0, lr=[1.6482304000000001e-06, 1.6482304000000001e-06, 1.6482304000000001e-06, 1.6482304000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:26,727] [INFO] [timer.py:215:stop] epoch=0/micro_step=1510/global_step=1510, RunningAvgSamplesPerSec=4.923640883428628, CurrSamplesPerSec=4.899853505699727, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:26,727] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.77 | backward_microstep: 113.92 | backward_inner_microstep: 102.93 | backward_allreduce_microstep: 10.90 | step_microstep: 42.83
[default0]:[2023-08-25 18:14:26,727] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.77 (forward_moe: 20.63, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.12)
[default0]:[2023-08-25 18:14:26,727] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.92 | backward_inner: 102.93 | backward_allreduce: 10.90 | step: 42.83
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.5748], device='cuda:0'), 'moe loss': tensor([0.3014], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1510/439453125 | consumed samples:         1510 | consumed tokens:      3092480 | elapsed time per iteration (ms): 297.4 | learning rate: 1.648E-06 | global batch size:     1 | lm loss: 9.314969E+00 | moe loss: 6.028195E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.363 | TFLOPs: 8.36 |
[default0]:[2023-08-25 18:14:26,987] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:26,987] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.76 | backward_microstep: 112.12 | backward_inner_microstep: 101.12 | backward_allreduce_microstep: 10.91 | step_microstep: 42.48
[default0]:[2023-08-25 18:14:26,987] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.76 (forward_moe: 20.36, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.08)
[default0]:[2023-08-25 18:14:26,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.12 | backward_inner: 101.13 | backward_allreduce: 10.91 | step: 42.49
[default0]:[2023-08-25 18:14:27,379] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:14:27,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.68 | backward_microstep: 111.92 | backward_inner_microstep: 100.95 | backward_allreduce_microstep: 10.88 | step_microstep: 42.40
[default0]:[2023-08-25 18:14:27,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.68 (forward_moe: 20.47, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.23)
[default0]:[2023-08-25 18:14:27,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.92 | backward_inner: 100.95 | backward_allreduce: 10.89 | step: 42.41
[default0]:[2023-08-25 18:14:27,806] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.40
[default0]:[2023-08-25 18:14:27,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.80 | backward_microstep: 111.77 | backward_inner_microstep: 100.79 | backward_allreduce_microstep: 10.89 | step_microstep: 42.40
[default0]:[2023-08-25 18:14:27,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.36, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.09)
[default0]:[2023-08-25 18:14:27,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.77 | backward_inner: 100.79 | backward_allreduce: 10.90 | step: 42.41
[default0]:[2023-08-25 18:14:28,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.15 | optimizer_step: 6.49
[default0]:[2023-08-25 18:14:28,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.85 | backward_microstep: 117.13 | backward_inner_microstep: 105.84 | backward_allreduce_microstep: 11.20 | step_microstep: 44.42
[default0]:[2023-08-25 18:14:28,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.85 (forward_moe: 21.47, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.76)
[default0]:[2023-08-25 18:14:28,066] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.13 | backward_inner: 105.85 | backward_allreduce: 11.20 | step: 44.43
[default0]:[2023-08-25 18:14:28,302] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:14:28,302] [INFO] [logging.py:96:log_dist] [Rank 0] step=1515, skipped=0, lr=[1.6536917333333334e-06, 1.6536917333333334e-06, 1.6536917333333334e-06, 1.6536917333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:28,303] [INFO] [timer.py:215:stop] epoch=0/micro_step=1515/global_step=1515, RunningAvgSamplesPerSec=4.923556541322068, CurrSamplesPerSec=4.8841626725169895, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:28,303] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.31 | backward_microstep: 113.70 | backward_inner_microstep: 102.54 | backward_allreduce_microstep: 11.06 | step_microstep: 43.19
[default0]:[2023-08-25 18:14:28,303] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.31 (forward_moe: 20.85, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.46)
[default0]:[2023-08-25 18:14:28,303] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.69 | backward_inner: 102.54 | backward_allreduce: 11.07 | step: 43.19
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.8519], device='cuda:0'), 'moe loss': tensor([0.3014], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1515/439453125 | consumed samples:         1515 | consumed tokens:      3102720 | elapsed time per iteration (ms): 315.1 | learning rate: 1.654E-06 | global batch size:     1 | lm loss: 9.170372E+00 | moe loss: 6.028792E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.174 | TFLOPs: 7.89 |
[default0]:[2023-08-25 18:14:28,595] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:14:28,595] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.25 | backward_microstep: 113.29 | backward_inner_microstep: 102.21 | backward_allreduce_microstep: 10.98 | step_microstep: 42.89
[default0]:[2023-08-25 18:14:28,596] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.25 (forward_moe: 20.92, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.35)
[default0]:[2023-08-25 18:14:28,596] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.29 | backward_inner: 102.22 | backward_allreduce: 10.99 | step: 42.90
[default0]:[2023-08-25 18:14:28,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:28,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.48 | backward_microstep: 113.15 | backward_inner_microstep: 102.07 | backward_allreduce_microstep: 10.97 | step_microstep: 42.78
[default0]:[2023-08-25 18:14:28,834] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.48 (forward_moe: 20.62, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.27)
[default0]:[2023-08-25 18:14:28,835] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.14 | backward_inner: 102.08 | backward_allreduce: 10.98 | step: 42.79
[default0]:[2023-08-25 18:14:29,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.36
[default0]:[2023-08-25 18:14:29,090] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.34 | backward_microstep: 112.96 | backward_inner_microstep: 101.92 | backward_allreduce_microstep: 10.94 | step_microstep: 42.96
[default0]:[2023-08-25 18:14:29,090] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.33 (forward_moe: 20.57, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.23)
[default0]:[2023-08-25 18:14:29,090] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.95 | backward_inner: 101.93 | backward_allreduce: 10.94 | step: 42.96
[default0]:[2023-08-25 18:14:29,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.34
[default0]:[2023-08-25 18:14:29,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.30 | backward_microstep: 110.78 | backward_inner_microstep: 99.89 | backward_allreduce_microstep: 10.80 | step_microstep: 42.04
[default0]:[2023-08-25 18:14:29,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.31 (forward_moe: 20.17, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.97)
[default0]:[2023-08-25 18:14:29,378] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.78 | backward_inner: 99.89 | backward_allreduce: 10.80 | step: 42.04
[default0]:[2023-08-25 18:14:29,625] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.35
[default0]:[2023-08-25 18:14:29,625] [INFO] [logging.py:96:log_dist] [Rank 0] step=1520, skipped=0, lr=[1.6591530666666667e-06, 1.6591530666666667e-06, 1.6591530666666667e-06, 1.6591530666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.2670], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1520/439453125 | consumed samples:         1520 | consumed tokens:      3112960 | elapsed time per iteration (ms): 310.8 | learning rate: 1.659E-06 | global batch size:     1 | lm loss: 9.253393E+00 | moe loss: 6.014832E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.217 | TFLOPs: 7.99 |
[default0]:[2023-08-25 18:14:30,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:14:30,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.22 | backward_microstep: 116.31 | backward_inner_microstep: 104.78 | backward_allreduce_microstep: 11.42 | step_microstep: 42.27
[default0]:[2023-08-25 18:14:30,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.22 (forward_moe: 21.30, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.42)
[default0]:[2023-08-25 18:14:30,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.30 | backward_inner: 104.79 | backward_allreduce: 11.42 | step: 42.27
[default0]:[2023-08-25 18:14:30,383] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.35
[default0]:[2023-08-25 18:14:30,383] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.14 | backward_microstep: 110.67 | backward_inner_microstep: 99.76 | backward_allreduce_microstep: 10.80 | step_microstep: 41.91
[default0]:[2023-08-25 18:14:30,383] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.14 (forward_moe: 20.12, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.97)
[default0]:[2023-08-25 18:14:30,384] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.67 | backward_inner: 99.78 | backward_allreduce: 10.80 | step: 41.91
[default0]:[2023-08-25 18:14:30,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:14:30,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.19 | backward_microstep: 111.01 | backward_inner_microstep: 100.04 | backward_allreduce_microstep: 10.88 | step_microstep: 42.11
[default0]:[2023-08-25 18:14:30,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.18 (forward_moe: 20.13, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.96)
[default0]:[2023-08-25 18:14:30,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.01 | backward_inner: 100.05 | backward_allreduce: 10.88 | step: 42.11
[default0]:[2023-08-25 18:14:30,861] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:30,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.34 | backward_microstep: 110.58 | backward_inner_microstep: 99.65 | backward_allreduce_microstep: 10.84 | step_microstep: 41.98
[default0]:[2023-08-25 18:14:30,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.34 (forward_moe: 20.16, 1st alltoall: 0.86, 2nd alltoall: 0.82, top-k: 8.02)
[default0]:[2023-08-25 18:14:30,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.58 | backward_inner: 99.65 | backward_allreduce: 10.84 | step: 41.99
[default0]:[2023-08-25 18:14:31,105] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:31,105] [INFO] [logging.py:96:log_dist] [Rank 0] step=1525, skipped=0, lr=[1.6646144e-06, 1.6646144e-06, 1.6646144e-06, 1.6646144e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:31,106] [INFO] [timer.py:215:stop] epoch=0/micro_step=1525/global_step=1525, RunningAvgSamplesPerSec=4.920175100027457, CurrSamplesPerSec=4.9223662730858555, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:31,106] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.93 | backward_microstep: 112.79 | backward_inner_microstep: 101.78 | backward_allreduce_microstep: 10.92 | step_microstep: 43.08
[default0]:[2023-08-25 18:14:31,106] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.93 (forward_moe: 20.81, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.50)
[default0]:[2023-08-25 18:14:31,106] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.79 | backward_inner: 101.78 | backward_allreduce: 10.93 | step: 43.09
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.2080], device='cuda:0'), 'moe loss': tensor([0.3013], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1525/439453125 | consumed samples:         1525 | consumed tokens:      3123200 | elapsed time per iteration (ms): 250.6 | learning rate: 1.665E-06 | global batch size:     1 | lm loss: 9.441591E+00 | moe loss: 6.025100E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.990 | TFLOPs: 9.91 |
[default0]:[2023-08-25 18:14:31,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:31,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.89 | backward_microstep: 112.33 | backward_inner_microstep: 101.33 | backward_allreduce_microstep: 10.91 | step_microstep: 42.54
[default0]:[2023-08-25 18:14:31,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.89 (forward_moe: 20.45, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:14:31,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.33 | backward_inner: 101.34 | backward_allreduce: 10.91 | step: 42.55
[default0]:[2023-08-25 18:14:31,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:31,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.76 | backward_microstep: 112.43 | backward_inner_microstep: 101.41 | backward_allreduce_microstep: 10.92 | step_microstep: 42.53
[default0]:[2023-08-25 18:14:31,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.76 (forward_moe: 20.59, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.16)
[default0]:[2023-08-25 18:14:31,615] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.43 | backward_inner: 101.42 | backward_allreduce: 10.93 | step: 42.53
[default0]:[2023-08-25 18:14:31,866] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:31,867] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.83 | backward_microstep: 112.26 | backward_inner_microstep: 101.16 | backward_allreduce_microstep: 11.01 | step_microstep: 42.53
[default0]:[2023-08-25 18:14:31,867] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.83 (forward_moe: 20.45, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:14:31,867] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.26 | backward_inner: 101.17 | backward_allreduce: 11.01 | step: 42.54
[default0]:[2023-08-25 18:14:32,134] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.38
[default0]:[2023-08-25 18:14:32,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.84 | backward_microstep: 112.14 | backward_inner_microstep: 101.14 | backward_allreduce_microstep: 10.90 | step_microstep: 42.61
[default0]:[2023-08-25 18:14:32,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.83 (forward_moe: 20.48, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:14:32,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.14 | backward_inner: 101.15 | backward_allreduce: 10.91 | step: 42.61
[default0]:[2023-08-25 18:14:32,386] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:14:32,386] [INFO] [logging.py:96:log_dist] [Rank 0] step=1530, skipped=0, lr=[1.6700757333333334e-06, 1.6700757333333334e-06, 1.6700757333333334e-06, 1.6700757333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:32,387] [INFO] [timer.py:215:stop] epoch=0/micro_step=1530/global_step=1530, RunningAvgSamplesPerSec=4.92023110384673, CurrSamplesPerSec=4.933018602742014, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:32,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.84 | backward_microstep: 112.25 | backward_inner_microstep: 101.23 | backward_allreduce_microstep: 10.92 | step_microstep: 42.97
[default0]:[2023-08-25 18:14:32,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.83 (forward_moe: 20.55, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:14:32,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.24 | backward_inner: 101.24 | backward_allreduce: 10.92 | step: 42.97
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([47.1292], device='cuda:0'), 'moe loss': tensor([0.3028], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1530/439453125 | consumed samples:         1530 | consumed tokens:      3133440 | elapsed time per iteration (ms): 255.5 | learning rate: 1.670E-06 | global batch size:     1 | lm loss: 9.425839E+00 | moe loss: 6.056429E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.914 | TFLOPs: 9.73 |
[default0]:[2023-08-25 18:14:32,645] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.14 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:32,645] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.74 | backward_microstep: 112.37 | backward_inner_microstep: 101.36 | backward_allreduce_microstep: 10.91 | step_microstep: 42.85
[default0]:[2023-08-25 18:14:32,645] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.74 (forward_moe: 20.41, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:14:32,646] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.36 | backward_inner: 101.37 | backward_allreduce: 10.91 | step: 42.85
[default0]:[2023-08-25 18:14:32,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.43
[default0]:[2023-08-25 18:14:32,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.93 | backward_microstep: 112.92 | backward_inner_microstep: 101.94 | backward_allreduce_microstep: 10.89 | step_microstep: 42.92
[default0]:[2023-08-25 18:14:32,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.93 (forward_moe: 20.46, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.16)
[default0]:[2023-08-25 18:14:32,933] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.92 | backward_inner: 101.95 | backward_allreduce: 10.89 | step: 42.92
[default0]:[2023-08-25 18:14:33,193] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.45
[default0]:[2023-08-25 18:14:33,194] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.89 | backward_microstep: 115.97 | backward_inner_microstep: 104.73 | backward_allreduce_microstep: 11.14 | step_microstep: 43.66
[default0]:[2023-08-25 18:14:33,194] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.88 (forward_moe: 22.22, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 9.57)
[default0]:[2023-08-25 18:14:33,194] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.96 | backward_inner: 104.74 | backward_allreduce: 11.14 | step: 43.67
[default0]:[2023-08-25 18:14:33,445] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:14:33,445] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.44 | backward_microstep: 114.79 | backward_inner_microstep: 103.64 | backward_allreduce_microstep: 11.05 | step_microstep: 43.30
[default0]:[2023-08-25 18:14:33,445] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.44 (forward_moe: 21.01, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.49)
[default0]:[2023-08-25 18:14:33,446] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.79 | backward_inner: 103.65 | backward_allreduce: 11.06 | step: 43.30
[default0]:[2023-08-25 18:14:33,701] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.46
[default0]:[2023-08-25 18:14:33,701] [INFO] [logging.py:96:log_dist] [Rank 0] step=1535, skipped=0, lr=[1.6755370666666667e-06, 1.6755370666666667e-06, 1.6755370666666667e-06, 1.6755370666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:33,701] [INFO] [timer.py:215:stop] epoch=0/micro_step=1535/global_step=1535, RunningAvgSamplesPerSec=4.919960739743905, CurrSamplesPerSec=4.801633856735309, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:33,701] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.13 | backward_microstep: 115.49 | backward_inner_microstep: 104.26 | backward_allreduce_microstep: 11.13 | step_microstep: 44.09
[default0]:[2023-08-25 18:14:33,702] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.13 (forward_moe: 21.35, 1st alltoall: 0.91, 2nd alltoall: 0.83, top-k: 8.67)
[default0]:[2023-08-25 18:14:33,702] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.49 | backward_inner: 104.27 | backward_allreduce: 11.13 | step: 44.10
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.0959], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1535/439453125 | consumed samples:         1535 | consumed tokens:      3143680 | elapsed time per iteration (ms): 262.7 | learning rate: 1.676E-06 | global batch size:     1 | lm loss: 9.219176E+00 | moe loss: 6.019155E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.806 | TFLOPs: 9.46 |
[default0]:[2023-08-25 18:14:33,960] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:14:33,961] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.56 | backward_microstep: 127.25 | backward_inner_microstep: 116.28 | backward_allreduce_microstep: 10.87 | step_microstep: 42.63
[default0]:[2023-08-25 18:14:33,961] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.56 (forward_moe: 34.16, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.01)
[default0]:[2023-08-25 18:14:33,962] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 127.24 | backward_inner: 116.29 | backward_allreduce: 10.87 | step: 42.63
[default0]:[2023-08-25 18:14:34,198] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:34,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.92 | backward_microstep: 111.33 | backward_inner_microstep: 100.35 | backward_allreduce_microstep: 10.88 | step_microstep: 42.12
[default0]:[2023-08-25 18:14:34,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.92 (forward_moe: 20.27, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.05)
[default0]:[2023-08-25 18:14:34,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.33 | backward_inner: 100.36 | backward_allreduce: 10.89 | step: 42.12
[default0]:[2023-08-25 18:14:34,461] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 12.25
[default0]:[2023-08-25 18:14:34,462] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.33 | backward_microstep: 111.11 | backward_inner_microstep: 100.15 | backward_allreduce_microstep: 10.86 | step_microstep: 48.62
[default0]:[2023-08-25 18:14:34,462] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.33 (forward_moe: 20.25, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.06)
[default0]:[2023-08-25 18:14:34,462] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.10 | backward_inner: 100.15 | backward_allreduce: 10.87 | step: 48.62
[default0]:[2023-08-25 18:14:34,713] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:14:34,713] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.71 | backward_microstep: 111.36 | backward_inner_microstep: 100.40 | backward_allreduce_microstep: 10.87 | step_microstep: 42.14
[default0]:[2023-08-25 18:14:34,713] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.71 (forward_moe: 20.41, 1st alltoall: 0.87, 2nd alltoall: 0.98, top-k: 8.00)
[default0]:[2023-08-25 18:14:34,714] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.36 | backward_inner: 100.41 | backward_allreduce: 10.87 | step: 42.14
[default0]:[2023-08-25 18:14:34,951] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.88 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:34,952] [INFO] [logging.py:96:log_dist] [Rank 0] step=1540, skipped=0, lr=[1.6809984e-06, 1.6809984e-06, 1.6809984e-06, 1.6809984e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:34,952] [INFO] [timer.py:215:stop] epoch=0/micro_step=1540/global_step=1540, RunningAvgSamplesPerSec=4.919849240538356, CurrSamplesPerSec=5.0755701736871215, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:34,952] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.63 | backward_microstep: 109.01 | backward_inner_microstep: 98.22 | backward_allreduce_microstep: 10.69 | step_microstep: 41.84
[default0]:[2023-08-25 18:14:34,952] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.93, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.79)
[default0]:[2023-08-25 18:14:34,952] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.23 | backward_allreduce: 10.69 | step: 41.85
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.3263], device='cuda:0'), 'moe loss': tensor([0.3002], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1540/439453125 | consumed samples:         1540 | consumed tokens:      3153920 | elapsed time per iteration (ms): 250.1 | learning rate: 1.681E-06 | global batch size:     1 | lm loss: 9.265266E+00 | moe loss: 6.003953E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.998 | TFLOPs: 9.93 |
[default0]:[2023-08-25 18:14:35,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:14:35,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.87 | backward_microstep: 109.11 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.75 | step_microstep: 41.43
[default0]:[2023-08-25 18:14:35,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.87 (forward_moe: 19.85, 1st alltoall: 0.98, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:14:35,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.10 | backward_inner: 98.27 | backward_allreduce: 10.76 | step: 41.43
[default0]:[2023-08-25 18:14:35,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:35,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.30 | backward_microstep: 108.83 | backward_inner_microstep: 98.04 | backward_allreduce_microstep: 10.70 | step_microstep: 41.42
[default0]:[2023-08-25 18:14:35,500] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.30 (forward_moe: 19.70, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:14:35,500] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.83 | backward_inner: 98.05 | backward_allreduce: 10.70 | step: 41.42
[default0]:[2023-08-25 18:14:35,742] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.73 | optimizer_gradients: 4.05 | optimizer_step: 6.53
[default0]:[2023-08-25 18:14:35,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 109.04 | backward_inner_microstep: 98.22 | backward_allreduce_microstep: 10.72 | step_microstep: 42.41
[default0]:[2023-08-25 18:14:35,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.82, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.70)
[default0]:[2023-08-25 18:14:35,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.04 | backward_inner: 98.23 | backward_allreduce: 10.72 | step: 42.41
[default0]:[2023-08-25 18:14:35,984] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:35,985] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.84 | backward_microstep: 108.99 | backward_inner_microstep: 98.14 | backward_allreduce_microstep: 10.76 | step_microstep: 42.00
[default0]:[2023-08-25 18:14:35,985] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.84 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:14:35,985] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.99 | backward_inner: 98.14 | backward_allreduce: 10.77 | step: 42.01
[default0]:[2023-08-25 18:14:36,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:36,248] [INFO] [logging.py:96:log_dist] [Rank 0] step=1545, skipped=0, lr=[1.6864597333333335e-06, 1.6864597333333335e-06, 1.6864597333333335e-06, 1.6864597333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:36,248] [INFO] [timer.py:215:stop] epoch=0/micro_step=1545/global_step=1545, RunningAvgSamplesPerSec=4.92031729914695, CurrSamplesPerSec=5.068234958619665, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:36,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 109.42 | backward_inner_microstep: 98.56 | backward_allreduce_microstep: 10.76 | step_microstep: 41.75
[default0]:[2023-08-25 18:14:36,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:36,249] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.41 | backward_inner: 98.57 | backward_allreduce: 10.76 | step: 41.75
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.6904], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1545/439453125 | consumed samples:         1545 | consumed tokens:      3164160 | elapsed time per iteration (ms): 259.2 | learning rate: 1.686E-06 | global batch size:     1 | lm loss: 9.338075E+00 | moe loss: 6.013862E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.858 | TFLOPs: 9.59 |
[default0]:[2023-08-25 18:14:36,501] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:36,501] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 108.90 | backward_inner_microstep: 98.04 | backward_allreduce_microstep: 10.76 | step_microstep: 41.41
[default0]:[2023-08-25 18:14:36,501] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:14:36,501] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 98.05 | backward_allreduce: 10.76 | step: 41.42
[default0]:[2023-08-25 18:14:36,739] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:36,740] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 111.42 | backward_inner_microstep: 100.56 | backward_allreduce_microstep: 10.76 | step_microstep: 41.52
[default0]:[2023-08-25 18:14:36,740] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:14:36,740] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.42 | backward_inner: 100.57 | backward_allreduce: 10.77 | step: 41.53
[default0]:[2023-08-25 18:14:36,980] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:36,981] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.76 | backward_microstep: 109.06 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.70 | step_microstep: 41.39
[default0]:[2023-08-25 18:14:36,981] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.76 (forward_moe: 19.69, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.70)
[default0]:[2023-08-25 18:14:36,981] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.27 | backward_allreduce: 10.70 | step: 41.39
[default0]:[2023-08-25 18:14:37,216] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.36
[default0]:[2023-08-25 18:14:37,216] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.51 | backward_microstep: 109.01 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.74 | step_microstep: 41.52
[default0]:[2023-08-25 18:14:37,216] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.51 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:37,216] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.01 | backward_inner: 98.19 | backward_allreduce: 10.74 | step: 41.53
[default0]:[2023-08-25 18:14:37,461] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:37,461] [INFO] [logging.py:96:log_dist] [Rank 0] step=1550, skipped=0, lr=[1.6919210666666668e-06, 1.6919210666666668e-06, 1.6919210666666668e-06, 1.6919210666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:37,461] [INFO] [timer.py:215:stop] epoch=0/micro_step=1550/global_step=1550, RunningAvgSamplesPerSec=4.920750581026489, CurrSamplesPerSec=5.0295395079226894, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:37,462] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.42 | backward_microstep: 110.47 | backward_inner_microstep: 99.49 | backward_allreduce_microstep: 10.89 | step_microstep: 42.39
[default0]:[2023-08-25 18:14:37,462] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.42 (forward_moe: 20.15, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:14:37,462] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.47 | backward_inner: 99.49 | backward_allreduce: 10.89 | step: 42.40
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.7085], device='cuda:0'), 'moe loss': tensor([0.3009], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1550/439453125 | consumed samples:         1550 | consumed tokens:      3174400 | elapsed time per iteration (ms): 242.7 | learning rate: 1.692E-06 | global batch size:     1 | lm loss: 9.141696E+00 | moe loss: 6.017488E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.120 | TFLOPs: 10.24 |
[default0]:[2023-08-25 18:14:37,731] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.44
[default0]:[2023-08-25 18:14:37,731] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.35 | backward_microstep: 111.64 | backward_inner_microstep: 100.67 | backward_allreduce_microstep: 10.87 | step_microstep: 42.43
[default0]:[2023-08-25 18:14:37,731] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.35 (forward_moe: 20.49, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.22)
[default0]:[2023-08-25 18:14:37,731] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.64 | backward_inner: 100.68 | backward_allreduce: 10.88 | step: 42.43
[default0]:[2023-08-25 18:14:37,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:14:37,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.50 | backward_microstep: 109.06 | backward_inner_microstep: 98.26 | backward_allreduce_microstep: 10.70 | step_microstep: 41.51
[default0]:[2023-08-25 18:14:37,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.76)
[default0]:[2023-08-25 18:14:37,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.06 | backward_inner: 98.27 | backward_allreduce: 10.71 | step: 41.51
[default0]:[2023-08-25 18:14:38,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.28
[default0]:[2023-08-25 18:14:38,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.91 | backward_microstep: 109.56 | backward_inner_microstep: 98.76 | backward_allreduce_microstep: 10.70 | step_microstep: 42.74
[default0]:[2023-08-25 18:14:38,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.91 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:14:38,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.56 | backward_inner: 98.77 | backward_allreduce: 10.71 | step: 42.74
[default0]:[2023-08-25 18:14:38,508] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:38,508] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.53 | backward_microstep: 108.82 | backward_inner_microstep: 97.99 | backward_allreduce_microstep: 10.73 | step_microstep: 41.44
[default0]:[2023-08-25 18:14:38,508] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.70)
[default0]:[2023-08-25 18:14:38,508] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.82 | backward_inner: 97.99 | backward_allreduce: 10.74 | step: 41.45
[default0]:[2023-08-25 18:14:38,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:38,801] [INFO] [logging.py:96:log_dist] [Rank 0] step=1555, skipped=0, lr=[1.6973824000000002e-06, 1.6973824000000002e-06, 1.6973824000000002e-06, 1.6973824000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:38,801] [INFO] [timer.py:215:stop] epoch=0/micro_step=1555/global_step=1555, RunningAvgSamplesPerSec=4.921149917664596, CurrSamplesPerSec=5.082316903234562, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:38,802] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 108.93 | backward_inner_microstep: 98.14 | backward_allreduce_microstep: 10.69 | step_microstep: 41.83
[default0]:[2023-08-25 18:14:38,802] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:14:38,802] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.15 | backward_allreduce: 10.70 | step: 41.83
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.3143], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1555/439453125 | consumed samples:         1555 | consumed tokens:      3184640 | elapsed time per iteration (ms): 268.0 | learning rate: 1.697E-06 | global batch size:     1 | lm loss: 9.062862E+00 | moe loss: 6.014792E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.731 | TFLOPs: 9.27 |
[default0]:[2023-08-25 18:14:39,049] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:39,049] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.71 | backward_microstep: 108.90 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.72 | step_microstep: 41.38
[default0]:[2023-08-25 18:14:39,049] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.71 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:14:39,050] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 98.10 | backward_allreduce: 10.72 | step: 41.38
[default0]:[2023-08-25 18:14:39,285] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:14:39,285] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.38 | backward_microstep: 109.15 | backward_inner_microstep: 98.32 | backward_allreduce_microstep: 10.74 | step_microstep: 41.52
[default0]:[2023-08-25 18:14:39,285] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.38 (forward_moe: 19.78, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:14:39,286] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.15 | backward_inner: 98.32 | backward_allreduce: 10.75 | step: 41.52
[default0]:[2023-08-25 18:14:39,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:14:39,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 108.94 | backward_inner_microstep: 98.11 | backward_allreduce_microstep: 10.74 | step_microstep: 41.51
[default0]:[2023-08-25 18:14:39,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:14:39,517] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.94 | backward_inner: 98.11 | backward_allreduce: 10.74 | step: 41.52
[default0]:[2023-08-25 18:14:39,785] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.34
[default0]:[2023-08-25 18:14:39,785] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.87 | backward_microstep: 109.59 | backward_inner_microstep: 98.74 | backward_allreduce_microstep: 10.76 | step_microstep: 41.79
[default0]:[2023-08-25 18:14:39,785] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.86 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:14:39,785] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.59 | backward_inner: 98.75 | backward_allreduce: 10.76 | step: 41.79
[default0]:[2023-08-25 18:14:40,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.94 | optimizer_step: 6.35
[default0]:[2023-08-25 18:14:40,038] [INFO] [logging.py:96:log_dist] [Rank 0] step=1560, skipped=0, lr=[1.7028437333333335e-06, 1.7028437333333335e-06, 1.7028437333333335e-06, 1.7028437333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:40,039] [INFO] [timer.py:215:stop] epoch=0/micro_step=1560/global_step=1560, RunningAvgSamplesPerSec=4.921582624406201, CurrSamplesPerSec=5.005177847547652, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:40,039] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.09 | backward_microstep: 110.83 | backward_inner_microstep: 99.79 | backward_allreduce_microstep: 10.94 | step_microstep: 42.33
[default0]:[2023-08-25 18:14:40,039] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.09 (forward_moe: 20.26, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.95)
[default0]:[2023-08-25 18:14:40,039] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.83 | backward_inner: 99.79 | backward_allreduce: 10.95 | step: 42.33
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.6657], device='cuda:0'), 'moe loss': tensor([0.3052], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1560/439453125 | consumed samples:         1560 | consumed tokens:      3194880 | elapsed time per iteration (ms): 247.6 | learning rate: 1.703E-06 | global batch size:     1 | lm loss: 9.133134E+00 | moe loss: 6.104087E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.039 | TFLOPs: 10.03 |
[default0]:[2023-08-25 18:14:40,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.39
[default0]:[2023-08-25 18:14:40,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.20 | backward_microstep: 111.32 | backward_inner_microstep: 100.42 | backward_allreduce_microstep: 10.81 | step_microstep: 42.28
[default0]:[2023-08-25 18:14:40,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.20 (forward_moe: 20.28, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.05)
[default0]:[2023-08-25 18:14:40,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.32 | backward_inner: 100.42 | backward_allreduce: 10.81 | step: 42.29
[default0]:[2023-08-25 18:14:40,561] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.38
[default0]:[2023-08-25 18:14:40,562] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.91 | backward_microstep: 111.71 | backward_inner_microstep: 100.74 | backward_allreduce_microstep: 10.87 | step_microstep: 42.40
[default0]:[2023-08-25 18:14:40,562] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.91 (forward_moe: 20.33, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.09)
[default0]:[2023-08-25 18:14:40,562] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.71 | backward_inner: 100.75 | backward_allreduce: 10.88 | step: 42.41
[default0]:[2023-08-25 18:14:40,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.39
[default0]:[2023-08-25 18:14:40,802] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.91 | backward_microstep: 111.87 | backward_inner_microstep: 100.87 | backward_allreduce_microstep: 10.91 | step_microstep: 42.38
[default0]:[2023-08-25 18:14:40,802] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.90 (forward_moe: 20.39, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:14:40,802] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.87 | backward_inner: 100.87 | backward_allreduce: 10.91 | step: 42.38
[default0]:[2023-08-25 18:14:41,079] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:41,080] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.92 | backward_microstep: 113.04 | backward_inner_microstep: 102.00 | backward_allreduce_microstep: 10.94 | step_microstep: 42.72
[default0]:[2023-08-25 18:14:41,080] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.92 (forward_moe: 20.50, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.18)
[default0]:[2023-08-25 18:14:41,080] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.04 | backward_inner: 102.01 | backward_allreduce: 10.94 | step: 42.72
[default0]:[2023-08-25 18:14:41,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.40
[default0]:[2023-08-25 18:14:41,341] [INFO] [logging.py:96:log_dist] [Rank 0] step=1565, skipped=0, lr=[1.7083050666666668e-06, 1.7083050666666668e-06, 1.7083050666666668e-06, 1.7083050666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:41,341] [INFO] [timer.py:215:stop] epoch=0/micro_step=1565/global_step=1565, RunningAvgSamplesPerSec=4.921632598455673, CurrSamplesPerSec=4.882434288641073, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:41,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.44 | backward_microstep: 113.45 | backward_inner_microstep: 102.36 | backward_allreduce_microstep: 11.00 | step_microstep: 43.37
[default0]:[2023-08-25 18:14:41,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.44 (forward_moe: 20.88, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.31)
[default0]:[2023-08-25 18:14:41,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.45 | backward_inner: 102.36 | backward_allreduce: 11.00 | step: 43.37
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.2149], device='cuda:0'), 'moe loss': tensor([0.3006], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1565/439453125 | consumed samples:         1565 | consumed tokens:      3205120 | elapsed time per iteration (ms): 260.4 | learning rate: 1.708E-06 | global batch size:     1 | lm loss: 9.242989E+00 | moe loss: 6.012150E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.840 | TFLOPs: 9.54 |
[default0]:[2023-08-25 18:14:41,608] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:14:41,608] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.35 | backward_microstep: 110.27 | backward_inner_microstep: 99.35 | backward_allreduce_microstep: 10.82 | step_microstep: 41.92
[default0]:[2023-08-25 18:14:41,609] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.35 (forward_moe: 20.02, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.87)
[default0]:[2023-08-25 18:14:41,609] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.27 | backward_inner: 99.36 | backward_allreduce: 10.82 | step: 41.92
[default0]:[2023-08-25 18:14:41,864] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:41,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.07 | backward_microstep: 110.30 | backward_inner_microstep: 99.36 | backward_allreduce_microstep: 10.85 | step_microstep: 42.08
[default0]:[2023-08-25 18:14:41,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.07 (forward_moe: 19.99, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:14:41,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.30 | backward_inner: 99.37 | backward_allreduce: 10.85 | step: 42.08
[default0]:[2023-08-25 18:14:42,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:42,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.31 | backward_microstep: 110.35 | backward_inner_microstep: 99.50 | backward_allreduce_microstep: 10.75 | step_microstep: 41.94
[default0]:[2023-08-25 18:14:42,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.31 (forward_moe: 20.08, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.91)
[default0]:[2023-08-25 18:14:42,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.34 | backward_inner: 99.50 | backward_allreduce: 10.76 | step: 41.95
[default0]:[2023-08-25 18:14:42,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:14:42,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.13 | backward_microstep: 110.37 | backward_inner_microstep: 99.46 | backward_allreduce_microstep: 10.81 | step_microstep: 41.93
[default0]:[2023-08-25 18:14:42,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.13 (forward_moe: 20.08, 1st alltoall: 0.89, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:14:42,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.36 | backward_inner: 99.47 | backward_allreduce: 10.81 | step: 41.93
[default0]:[2023-08-25 18:14:42,615] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:42,615] [INFO] [logging.py:96:log_dist] [Rank 0] step=1570, skipped=0, lr=[1.7137664e-06, 1.7137664e-06, 1.7137664e-06, 1.7137664e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:42,616] [INFO] [timer.py:215:stop] epoch=0/micro_step=1570/global_step=1570, RunningAvgSamplesPerSec=4.921929595444318, CurrSamplesPerSec=5.014099189242823, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:42,616] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.30 | backward_microstep: 110.27 | backward_inner_microstep: 99.39 | backward_allreduce_microstep: 10.79 | step_microstep: 42.31
[default0]:[2023-08-25 18:14:42,616] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.30 (forward_moe: 20.19, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.91)
[default0]:[2023-08-25 18:14:42,616] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.27 | backward_inner: 99.40 | backward_allreduce: 10.79 | step: 42.32
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.5075], device='cuda:0'), 'moe loss': tensor([0.3023], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1570/439453125 | consumed samples:         1570 | consumed tokens:      3215360 | elapsed time per iteration (ms): 255.3 | learning rate: 1.714E-06 | global batch size:     1 | lm loss: 9.101507E+00 | moe loss: 6.045296E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.917 | TFLOPs: 9.73 |
[default0]:[2023-08-25 18:14:42,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.35
[default0]:[2023-08-25 18:14:42,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.11 | backward_microstep: 110.51 | backward_inner_microstep: 99.57 | backward_allreduce_microstep: 10.85 | step_microstep: 42.22
[default0]:[2023-08-25 18:14:42,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.11 (forward_moe: 20.03, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.89)
[default0]:[2023-08-25 18:14:42,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.51 | backward_inner: 99.58 | backward_allreduce: 10.85 | step: 42.23
[default0]:[2023-08-25 18:14:43,110] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:14:43,110] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.16 | backward_microstep: 110.51 | backward_inner_microstep: 99.64 | backward_allreduce_microstep: 10.77 | step_microstep: 41.99
[default0]:[2023-08-25 18:14:43,111] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.16 (forward_moe: 20.04, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.88)
[default0]:[2023-08-25 18:14:43,111] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.51 | backward_inner: 99.65 | backward_allreduce: 10.78 | step: 41.99
[default0]:[2023-08-25 18:14:43,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.40
[default0]:[2023-08-25 18:14:43,465] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.03 | backward_microstep: 113.41 | backward_inner_microstep: 102.29 | backward_allreduce_microstep: 11.02 | step_microstep: 43.25
[default0]:[2023-08-25 18:14:43,466] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.03 (forward_moe: 20.71, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.27)
[default0]:[2023-08-25 18:14:43,466] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.40 | backward_inner: 102.30 | backward_allreduce: 11.02 | step: 43.26
[default0]:[2023-08-25 18:14:43,729] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.44
[default0]:[2023-08-25 18:14:43,730] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.10 | backward_microstep: 115.07 | backward_inner_microstep: 103.88 | backward_allreduce_microstep: 11.09 | step_microstep: 43.50
[default0]:[2023-08-25 18:14:43,730] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.09 (forward_moe: 20.97, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.47)
[default0]:[2023-08-25 18:14:43,730] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.06 | backward_inner: 103.89 | backward_allreduce: 11.09 | step: 43.50
[default0]:[2023-08-25 18:14:43,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.42
[default0]:[2023-08-25 18:14:43,974] [INFO] [logging.py:96:log_dist] [Rank 0] step=1575, skipped=0, lr=[1.7192277333333334e-06, 1.7192277333333334e-06, 1.7192277333333334e-06, 1.7192277333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:43,975] [INFO] [timer.py:215:stop] epoch=0/micro_step=1575/global_step=1575, RunningAvgSamplesPerSec=4.921833322000489, CurrSamplesPerSec=4.809253645090422, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:43,975] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.03 | backward_microstep: 114.94 | backward_inner_microstep: 103.77 | backward_allreduce_microstep: 11.07 | step_microstep: 44.41
[default0]:[2023-08-25 18:14:43,975] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.03 (forward_moe: 21.01, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.49)
[default0]:[2023-08-25 18:14:43,975] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.94 | backward_inner: 103.77 | backward_allreduce: 11.08 | step: 44.41
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.5183], device='cuda:0'), 'moe loss': tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1575/439453125 | consumed samples:         1575 | consumed tokens:      3225600 | elapsed time per iteration (ms): 271.4 | learning rate: 1.719E-06 | global batch size:     1 | lm loss: 9.103670E+00 | moe loss: 6.010785E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.685 | TFLOPs: 9.16 |
[default0]:[2023-08-25 18:14:44,229] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:14:44,229] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.74 | backward_microstep: 112.89 | backward_inner_microstep: 101.89 | backward_allreduce_microstep: 10.91 | step_microstep: 42.68
[default0]:[2023-08-25 18:14:44,229] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.74 (forward_moe: 20.85, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.20)
[default0]:[2023-08-25 18:14:44,229] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.89 | backward_inner: 101.90 | backward_allreduce: 10.91 | step: 42.68
[default0]:[2023-08-25 18:14:44,511] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.06 | optimizer_step: 36.26
[default0]:[2023-08-25 18:14:44,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.99 | backward_microstep: 112.49 | backward_inner_microstep: 101.48 | backward_allreduce_microstep: 10.92 | step_microstep: 72.78
[default0]:[2023-08-25 18:14:44,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.99 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:14:44,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.49 | backward_inner: 101.49 | backward_allreduce: 10.92 | step: 72.78
[default0]:[2023-08-25 18:14:44,746] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.07 | optimizer_step: 6.36
[default0]:[2023-08-25 18:14:44,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.29 | backward_microstep: 112.79 | backward_inner_microstep: 101.77 | backward_allreduce_microstep: 10.93 | step_microstep: 42.84
[default0]:[2023-08-25 18:14:44,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.29 (forward_moe: 20.70, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.37)
[default0]:[2023-08-25 18:14:44,747] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.79 | backward_inner: 101.77 | backward_allreduce: 10.93 | step: 42.84
[default0]:[2023-08-25 18:14:44,998] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:44,999] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.97 | backward_microstep: 112.19 | backward_inner_microstep: 101.17 | backward_allreduce_microstep: 10.92 | step_microstep: 42.58
[default0]:[2023-08-25 18:14:44,999] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.96 (forward_moe: 20.46, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.12)
[default0]:[2023-08-25 18:14:44,999] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.19 | backward_inner: 101.18 | backward_allreduce: 10.93 | step: 42.58
[default0]:[2023-08-25 18:14:45,244] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:14:45,244] [INFO] [logging.py:96:log_dist] [Rank 0] step=1580, skipped=0, lr=[1.7246890666666667e-06, 1.7246890666666667e-06, 1.7246890666666667e-06, 1.7246890666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:45,245] [INFO] [timer.py:215:stop] epoch=0/micro_step=1580/global_step=1580, RunningAvgSamplesPerSec=4.921341857004619, CurrSamplesPerSec=4.916809486855463, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:45,245] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.09 | backward_microstep: 112.77 | backward_inner_microstep: 101.74 | backward_allreduce_microstep: 10.94 | step_microstep: 42.97
[default0]:[2023-08-25 18:14:45,245] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.09 (forward_moe: 20.73, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.30)
[default0]:[2023-08-25 18:14:45,245] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.77 | backward_inner: 101.74 | backward_allreduce: 10.94 | step: 42.97
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.0466], device='cuda:0'), 'moe loss': tensor([0.2993], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1580/439453125 | consumed samples:         1580 | consumed tokens:      3235840 | elapsed time per iteration (ms): 254.0 | learning rate: 1.725E-06 | global batch size:     1 | lm loss: 9.009314E+00 | moe loss: 5.986272E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.937 | TFLOPs: 9.78 |
[default0]:[2023-08-25 18:14:45,498] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.34
[default0]:[2023-08-25 18:14:45,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.82 | backward_microstep: 112.18 | backward_inner_microstep: 101.16 | backward_allreduce_microstep: 10.92 | step_microstep: 42.60
[default0]:[2023-08-25 18:14:45,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.82 (forward_moe: 20.55, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.24)
[default0]:[2023-08-25 18:14:45,499] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.17 | backward_inner: 101.17 | backward_allreduce: 10.92 | step: 42.60
[default0]:[2023-08-25 18:14:45,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:14:45,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.97 | backward_microstep: 112.42 | backward_inner_microstep: 101.37 | backward_allreduce_microstep: 10.96 | step_microstep: 42.64
[default0]:[2023-08-25 18:14:45,733] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.97 (forward_moe: 20.55, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:14:45,734] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.42 | backward_inner: 101.38 | backward_allreduce: 10.96 | step: 42.64
[default0]:[2023-08-25 18:14:46,063] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:14:46,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.07 | backward_microstep: 112.25 | backward_inner_microstep: 101.23 | backward_allreduce_microstep: 10.92 | step_microstep: 42.62
[default0]:[2023-08-25 18:14:46,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.07 (forward_moe: 20.44, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:14:46,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.25 | backward_inner: 101.23 | backward_allreduce: 10.93 | step: 42.62
[default0]:[2023-08-25 18:14:46,339] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:46,339] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.85 | backward_microstep: 112.35 | backward_inner_microstep: 101.32 | backward_allreduce_microstep: 10.94 | step_microstep: 42.64
[default0]:[2023-08-25 18:14:46,339] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.84 (forward_moe: 20.42, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:14:46,340] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.35 | backward_inner: 101.32 | backward_allreduce: 10.94 | step: 42.64
[default0]:[2023-08-25 18:14:46,586] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:14:46,587] [INFO] [logging.py:96:log_dist] [Rank 0] step=1585, skipped=0, lr=[1.7301504e-06, 1.7301504e-06, 1.7301504e-06, 1.7301504e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:46,587] [INFO] [timer.py:215:stop] epoch=0/micro_step=1585/global_step=1585, RunningAvgSamplesPerSec=4.921383572583687, CurrSamplesPerSec=4.936234916682064, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:46,587] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.97 | backward_microstep: 112.09 | backward_inner_microstep: 101.09 | backward_allreduce_microstep: 10.90 | step_microstep: 42.99
[default0]:[2023-08-25 18:14:46,587] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.97 (forward_moe: 20.44, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:14:46,587] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.08 | backward_inner: 101.09 | backward_allreduce: 10.91 | step: 43.00
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.8038], device='cuda:0'), 'moe loss': tensor([0.2998], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1585/439453125 | consumed samples:         1585 | consumed tokens:      3246080 | elapsed time per iteration (ms): 268.5 | learning rate: 1.730E-06 | global batch size:     1 | lm loss: 9.160751E+00 | moe loss: 5.996295E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.725 | TFLOPs: 9.26 |
[default0]:[2023-08-25 18:14:46,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:14:46,863] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.54 | backward_microstep: 111.60 | backward_inner_microstep: 100.62 | backward_allreduce_microstep: 10.89 | step_microstep: 42.31
[default0]:[2023-08-25 18:14:46,863] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.54 (forward_moe: 20.26, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.05)
[default0]:[2023-08-25 18:14:46,863] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.60 | backward_inner: 100.62 | backward_allreduce: 10.89 | step: 42.31
[default0]:[2023-08-25 18:14:47,098] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:14:47,098] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.47 | backward_microstep: 111.62 | backward_inner_microstep: 100.63 | backward_allreduce_microstep: 10.90 | step_microstep: 42.27
[default0]:[2023-08-25 18:14:47,098] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.47 (forward_moe: 20.35, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:14:47,098] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.62 | backward_inner: 100.64 | backward_allreduce: 10.91 | step: 42.27
[default0]:[2023-08-25 18:14:47,379] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:14:47,379] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.62 | backward_microstep: 111.49 | backward_inner_microstep: 100.54 | backward_allreduce_microstep: 10.85 | step_microstep: 42.23
[default0]:[2023-08-25 18:14:47,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.62 (forward_moe: 20.26, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.03)
[default0]:[2023-08-25 18:14:47,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.49 | backward_inner: 100.55 | backward_allreduce: 10.86 | step: 42.24
[default0]:[2023-08-25 18:14:47,622] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.88 | optimizer_step: 6.27
[default0]:[2023-08-25 18:14:47,622] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.43 | backward_microstep: 108.89 | backward_inner_microstep: 98.04 | backward_allreduce_microstep: 10.75 | step_microstep: 41.35
[default0]:[2023-08-25 18:14:47,622] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.43 (forward_moe: 19.83, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:47,622] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.88 | backward_inner: 98.05 | backward_allreduce: 10.76 | step: 41.36
[default0]:[2023-08-25 18:14:47,897] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:47,897] [INFO] [logging.py:96:log_dist] [Rank 0] step=1590, skipped=0, lr=[1.7356117333333336e-06, 1.7356117333333336e-06, 1.7356117333333336e-06, 1.7356117333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:47,897] [INFO] [timer.py:215:stop] epoch=0/micro_step=1590/global_step=1590, RunningAvgSamplesPerSec=4.921508737463802, CurrSamplesPerSec=4.910069361116801, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:47,898] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.70 | backward_microstep: 113.41 | backward_inner_microstep: 102.48 | backward_allreduce_microstep: 10.83 | step_microstep: 41.95
[default0]:[2023-08-25 18:14:47,898] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.70 (forward_moe: 21.02, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.09)
[default0]:[2023-08-25 18:14:47,898] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.41 | backward_inner: 102.49 | backward_allreduce: 10.83 | step: 41.96
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.2365], device='cuda:0'), 'moe loss': tensor([0.3015], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1590/439453125 | consumed samples:         1590 | consumed tokens:      3256320 | elapsed time per iteration (ms): 262.2 | learning rate: 1.736E-06 | global batch size:     1 | lm loss: 9.247299E+00 | moe loss: 6.029447E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.814 | TFLOPs: 9.48 |
[default0]:[2023-08-25 18:14:48,144] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:14:48,144] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.33 | backward_microstep: 108.89 | backward_inner_microstep: 98.08 | backward_allreduce_microstep: 10.72 | step_microstep: 41.52
[default0]:[2023-08-25 18:14:48,144] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.33 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:14:48,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.89 | backward_inner: 98.08 | backward_allreduce: 10.72 | step: 41.52
[default0]:[2023-08-25 18:14:48,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:48,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.89 | backward_microstep: 108.91 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.72 | step_microstep: 41.37
[default0]:[2023-08-25 18:14:48,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.89 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:14:48,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.91 | backward_inner: 98.10 | backward_allreduce: 10.73 | step: 41.38
[default0]:[2023-08-25 18:14:48,667] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:48,668] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 108.92 | backward_inner_microstep: 98.08 | backward_allreduce_microstep: 10.74 | step_microstep: 41.47
[default0]:[2023-08-25 18:14:48,668] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:14:48,668] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.09 | backward_allreduce: 10.75 | step: 41.47
[default0]:[2023-08-25 18:14:48,904] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:48,905] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 109.13 | backward_inner_microstep: 98.32 | backward_allreduce_microstep: 10.72 | step_microstep: 41.48
[default0]:[2023-08-25 18:14:48,905] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.64 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:14:48,905] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.13 | backward_inner: 98.33 | backward_allreduce: 10.72 | step: 41.49
[default0]:[2023-08-25 18:14:49,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:14:49,135] [INFO] [logging.py:96:log_dist] [Rank 0] step=1595, skipped=0, lr=[1.7410730666666669e-06, 1.7410730666666669e-06, 1.7410730666666669e-06, 1.7410730666666669e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:49,135] [INFO] [timer.py:215:stop] epoch=0/micro_step=1595/global_step=1595, RunningAvgSamplesPerSec=4.921984997016297, CurrSamplesPerSec=5.06645342558748, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:49,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.67 | backward_microstep: 109.25 | backward_inner_microstep: 98.40 | backward_allreduce_microstep: 10.75 | step_microstep: 41.91
[default0]:[2023-08-25 18:14:49,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.89, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:49,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.25 | backward_inner: 98.40 | backward_allreduce: 10.76 | step: 41.92
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.3036], device='cuda:0'), 'moe loss': tensor([0.3006], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1595/439453125 | consumed samples:         1595 | consumed tokens:      3266560 | elapsed time per iteration (ms): 247.3 | learning rate: 1.741E-06 | global batch size:     1 | lm loss: 9.060721E+00 | moe loss: 6.012227E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.044 | TFLOPs: 10.05 |
[default0]:[2023-08-25 18:14:49,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.05 | optimizer_step: 6.34
[default0]:[2023-08-25 18:14:49,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.47 | backward_microstep: 111.62 | backward_inner_microstep: 100.65 | backward_allreduce_microstep: 10.88 | step_microstep: 42.38
[default0]:[2023-08-25 18:14:49,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.47 (forward_moe: 20.38, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.08)
[default0]:[2023-08-25 18:14:49,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.62 | backward_inner: 100.65 | backward_allreduce: 10.88 | step: 42.38
[default0]:[2023-08-25 18:14:49,647] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:14:49,648] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.74 | backward_microstep: 108.88 | backward_inner_microstep: 98.00 | backward_allreduce_microstep: 10.79 | step_microstep: 41.41
[default0]:[2023-08-25 18:14:49,648] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.74 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:14:49,648] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.88 | backward_inner: 98.01 | backward_allreduce: 10.79 | step: 41.42
[default0]:[2023-08-25 18:14:49,892] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:14:49,892] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.81 | backward_microstep: 112.36 | backward_inner_microstep: 101.50 | backward_allreduce_microstep: 10.77 | step_microstep: 41.63
[default0]:[2023-08-25 18:14:49,892] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.81 (forward_moe: 20.51, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 7.94)
[default0]:[2023-08-25 18:14:49,892] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.36 | backward_inner: 101.51 | backward_allreduce: 10.77 | step: 41.63
[default0]:[2023-08-25 18:14:50,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.28
[default0]:[2023-08-25 18:14:50,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 109.37 | backward_inner_microstep: 98.53 | backward_allreduce_microstep: 10.75 | step_microstep: 41.55
[default0]:[2023-08-25 18:14:50,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.76)
[default0]:[2023-08-25 18:14:50,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.37 | backward_inner: 98.54 | backward_allreduce: 10.75 | step: 41.56
[default0]:[2023-08-25 18:14:50,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:14:50,367] [INFO] [logging.py:96:log_dist] [Rank 0] step=1600, skipped=0, lr=[1.7465344000000002e-06, 1.7465344000000002e-06, 1.7465344000000002e-06, 1.7465344000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:50,367] [INFO] [timer.py:215:stop] epoch=0/micro_step=1600/global_step=1600, RunningAvgSamplesPerSec=4.922327809532088, CurrSamplesPerSec=5.070808453636415, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:50,368] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 109.20 | backward_inner_microstep: 98.37 | backward_allreduce_microstep: 10.74 | step_microstep: 41.78
[default0]:[2023-08-25 18:14:50,368] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.95, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:14:50,368] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.20 | backward_inner: 98.37 | backward_allreduce: 10.74 | step: 41.78
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.5108], device='cuda:0'), 'moe loss': tensor([0.3018], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1600/439453125 | consumed samples:         1600 | consumed tokens:      3276800 | elapsed time per iteration (ms): 246.7 | learning rate: 1.747E-06 | global batch size:     1 | lm loss: 9.102155E+00 | moe loss: 6.036395E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.054 | TFLOPs: 10.07 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1600 | lm loss value: 9.127398E+00 | lm loss PPL: 9.204038E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration    1600 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:14:54,135] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1600 is about to be saved!
[default0]:[2023-08-25 18:14:54,137] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,147] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,148] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,157] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,157] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,166] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,166] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,175] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,176] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,184] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,184] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,193] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,193] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,202] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,203] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,211] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,212] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,222] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,222] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,231] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,231] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,240] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,240] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,250] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,251] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,260] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,260] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,269] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,269] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,278] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,278] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,287] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,288] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,297] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,297] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,306] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,306] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,315] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,315] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,324] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,325] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,333] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,334] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,344] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,344] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,353] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,353] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,363] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,363] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:14:54,365] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:14:54,366] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:14:54,366] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:14:54,649] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:14:54,651] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:14:58,353] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:14:58,362] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1600/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:14:58,362] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1600 is ready now!
[default0]:  successfully saved checkpoint at iteration    1600 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.7, Latency(second): 4.23
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4230.27, 4230.27)
[default0]:[2023-08-25 18:14:58,624] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.18 | optimizer_step: 10.14
[default0]:[2023-08-25 18:14:58,625] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2298.83 | backward_microstep: 117.23 | backward_inner_microstep: 106.13 | backward_allreduce_microstep: 11.01 | step_microstep: 47.23
[default0]:[2023-08-25 18:14:58,625] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2298.74 (forward_moe: 21.61, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.77)
[default0]:[2023-08-25 18:14:58,626] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.23 | backward_inner: 106.14 | backward_allreduce: 11.01 | step: 47.24
[default0]:[2023-08-25 18:14:58,881] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.06 | optimizer_step: 6.44
[default0]:[2023-08-25 18:14:58,882] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.92 | backward_microstep: 114.37 | backward_inner_microstep: 103.39 | backward_allreduce_microstep: 10.89 | step_microstep: 43.42
[default0]:[2023-08-25 18:14:58,882] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.92 (forward_moe: 20.92, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.45)
[default0]:[2023-08-25 18:14:58,882] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.37 | backward_inner: 103.40 | backward_allreduce: 10.89 | step: 43.43
[default0]:[2023-08-25 18:14:59,149] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.06 | optimizer_step: 6.43
[default0]:[2023-08-25 18:14:59,149] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.98 | backward_microstep: 114.18 | backward_inner_microstep: 103.23 | backward_allreduce_microstep: 10.86 | step_microstep: 42.73
[default0]:[2023-08-25 18:14:59,150] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.99 (forward_moe: 20.84, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.42)
[default0]:[2023-08-25 18:14:59,150] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.17 | backward_inner: 103.23 | backward_allreduce: 10.86 | step: 42.74
[default0]:[2023-08-25 18:14:59,409] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.44
[default0]:[2023-08-25 18:14:59,409] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.84 | backward_microstep: 114.25 | backward_inner_microstep: 103.32 | backward_allreduce_microstep: 10.84 | step_microstep: 43.57
[default0]:[2023-08-25 18:14:59,410] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.84 (forward_moe: 20.97, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.52)
[default0]:[2023-08-25 18:14:59,410] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.25 | backward_inner: 103.32 | backward_allreduce: 10.85 | step: 43.57
[default0]:[2023-08-25 18:14:59,663] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.05 | optimizer_step: 6.41
[default0]:[2023-08-25 18:14:59,664] [INFO] [logging.py:96:log_dist] [Rank 0] step=1605, skipped=0, lr=[1.7519957333333335e-06, 1.7519957333333335e-06, 1.7519957333333335e-06, 1.7519957333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:14:59,664] [INFO] [timer.py:215:stop] epoch=0/micro_step=1605/global_step=1605, RunningAvgSamplesPerSec=4.9218932941664555, CurrSamplesPerSec=4.802799483341425, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:14:59,664] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.69 | backward_microstep: 115.20 | backward_inner_microstep: 104.02 | backward_allreduce_microstep: 11.08 | step_microstep: 43.76
[default0]:[2023-08-25 18:14:59,664] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.69 (forward_moe: 21.09, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.53)
[default0]:[2023-08-25 18:14:59,664] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.20 | backward_inner: 104.03 | backward_allreduce: 11.08 | step: 43.77
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.4861], device='cuda:0'), 'moe loss': tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1605/439453125 | consumed samples:         1605 | consumed tokens:      3287040 | elapsed time per iteration (ms): 1859.1 | learning rate: 1.752E-06 | global batch size:     1 | lm loss: 9.097218E+00 | moe loss: 6.009386E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.538 | TFLOPs: 1.34 |
[default0]:[2023-08-25 18:14:59,914] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.05 | optimizer_step: 6.47
[default0]:[2023-08-25 18:14:59,915] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.56 | backward_microstep: 113.36 | backward_inner_microstep: 102.25 | backward_allreduce_microstep: 11.01 | step_microstep: 43.19
[default0]:[2023-08-25 18:14:59,915] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.56 (forward_moe: 20.67, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.29)
[default0]:[2023-08-25 18:14:59,915] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.36 | backward_inner: 102.26 | backward_allreduce: 11.01 | step: 43.19
[default0]:[2023-08-25 18:15:00,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.38
[default0]:[2023-08-25 18:15:00,238] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.34 | backward_microstep: 113.50 | backward_inner_microstep: 102.39 | backward_allreduce_microstep: 11.01 | step_microstep: 43.65
[default0]:[2023-08-25 18:15:00,238] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.34 (forward_moe: 20.69, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.29)
[default0]:[2023-08-25 18:15:00,238] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.50 | backward_inner: 102.40 | backward_allreduce: 11.02 | step: 43.66
[default0]:[2023-08-25 18:15:00,497] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.34
[default0]:[2023-08-25 18:15:00,497] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.79 | backward_microstep: 110.96 | backward_inner_microstep: 100.03 | backward_allreduce_microstep: 10.83 | step_microstep: 42.21
[default0]:[2023-08-25 18:15:00,497] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.17, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.97)
[default0]:[2023-08-25 18:15:00,497] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.95 | backward_inner: 100.04 | backward_allreduce: 10.83 | step: 42.21
[default0]:[2023-08-25 18:15:00,761] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:00,761] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.34 | backward_microstep: 111.13 | backward_inner_microstep: 100.16 | backward_allreduce_microstep: 10.87 | step_microstep: 42.07
[default0]:[2023-08-25 18:15:00,761] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.34 (forward_moe: 20.20, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.99)
[default0]:[2023-08-25 18:15:00,761] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.13 | backward_inner: 100.17 | backward_allreduce: 10.88 | step: 42.08
[default0]:[2023-08-25 18:15:01,018] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.33
[default0]:[2023-08-25 18:15:01,018] [INFO] [logging.py:96:log_dist] [Rank 0] step=1610, skipped=0, lr=[1.7574570666666668e-06, 1.7574570666666668e-06, 1.7574570666666668e-06, 1.7574570666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:01,018] [INFO] [timer.py:215:stop] epoch=0/micro_step=1610/global_step=1610, RunningAvgSamplesPerSec=4.9219292755082265, CurrSamplesPerSec=4.948307268317084, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:01,018] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.61 | backward_microstep: 111.76 | backward_inner_microstep: 100.83 | backward_allreduce_microstep: 10.83 | step_microstep: 43.23
[default0]:[2023-08-25 18:15:01,018] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.60 (forward_moe: 20.50, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.15)
[default0]:[2023-08-25 18:15:01,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.75 | backward_inner: 100.83 | backward_allreduce: 10.83 | step: 43.24
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.7030], device='cuda:0'), 'moe loss': tensor([0.3006], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1610/439453125 | consumed samples:         1610 | consumed tokens:      3297280 | elapsed time per iteration (ms): 270.7 | learning rate: 1.757E-06 | global batch size:     1 | lm loss: 8.940595E+00 | moe loss: 6.011541E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.693 | TFLOPs: 9.18 |
[default0]:[2023-08-25 18:15:01,269] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:01,269] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.32 | backward_microstep: 112.17 | backward_inner_microstep: 101.27 | backward_allreduce_microstep: 10.81 | step_microstep: 42.39
[default0]:[2023-08-25 18:15:01,269] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.32 (forward_moe: 20.69, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.99)
[default0]:[2023-08-25 18:15:01,270] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.16 | backward_inner: 101.27 | backward_allreduce: 10.81 | step: 42.40
[default0]:[2023-08-25 18:15:01,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.39
[default0]:[2023-08-25 18:15:01,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.72 | backward_microstep: 111.10 | backward_inner_microstep: 100.18 | backward_allreduce_microstep: 10.83 | step_microstep: 42.19
[default0]:[2023-08-25 18:15:01,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.72 (forward_moe: 20.22, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.01)
[default0]:[2023-08-25 18:15:01,502] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.10 | backward_inner: 100.19 | backward_allreduce: 10.83 | step: 42.19
[default0]:[2023-08-25 18:15:01,743] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:01,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.67 | backward_microstep: 111.00 | backward_inner_microstep: 100.05 | backward_allreduce_microstep: 10.85 | step_microstep: 42.04
[default0]:[2023-08-25 18:15:01,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.67 (forward_moe: 20.21, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.01)
[default0]:[2023-08-25 18:15:01,744] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.00 | backward_inner: 100.05 | backward_allreduce: 10.86 | step: 42.04
[default0]:[2023-08-25 18:15:01,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:01,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.52 | backward_microstep: 111.46 | backward_inner_microstep: 100.53 | backward_allreduce_microstep: 10.83 | step_microstep: 42.26
[default0]:[2023-08-25 18:15:01,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.51 (forward_moe: 20.20, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.01)
[default0]:[2023-08-25 18:15:01,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.46 | backward_inner: 100.54 | backward_allreduce: 10.83 | step: 42.27
[default0]:[2023-08-25 18:15:02,225] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:15:02,225] [INFO] [logging.py:96:log_dist] [Rank 0] step=1615, skipped=0, lr=[1.7629184000000001e-06, 1.7629184000000001e-06, 1.7629184000000001e-06, 1.7629184000000001e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:02,225] [INFO] [timer.py:215:stop] epoch=0/micro_step=1615/global_step=1615, RunningAvgSamplesPerSec=4.922069173979385, CurrSamplesPerSec=4.939321640291769, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:02,226] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.33 | backward_microstep: 112.63 | backward_inner_microstep: 101.60 | backward_allreduce_microstep: 10.94 | step_microstep: 42.94
[default0]:[2023-08-25 18:15:02,226] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.33 (forward_moe: 20.58, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:15:02,226] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.63 | backward_inner: 101.61 | backward_allreduce: 10.94 | step: 42.95
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.6788], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1615/439453125 | consumed samples:         1615 | consumed tokens:      3307520 | elapsed time per iteration (ms): 241.8 | learning rate: 1.763E-06 | global batch size:     1 | lm loss: 9.135751E+00 | moe loss: 6.015673E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.136 | TFLOPs: 10.28 |
[default0]:[2023-08-25 18:15:02,523] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:15:02,523] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.07 | backward_microstep: 112.48 | backward_inner_microstep: 101.45 | backward_allreduce_microstep: 10.94 | step_microstep: 43.00
[default0]:[2023-08-25 18:15:02,523] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.07 (forward_moe: 20.49, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.19)
[default0]:[2023-08-25 18:15:02,523] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.47 | backward_inner: 101.45 | backward_allreduce: 10.94 | step: 43.01
[default0]:[2023-08-25 18:15:02,771] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.40
[default0]:[2023-08-25 18:15:02,771] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.53 | backward_microstep: 113.32 | backward_inner_microstep: 102.16 | backward_allreduce_microstep: 11.06 | step_microstep: 42.93
[default0]:[2023-08-25 18:15:02,771] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.53 (forward_moe: 20.73, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.27)
[default0]:[2023-08-25 18:15:02,772] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.32 | backward_inner: 102.17 | backward_allreduce: 11.07 | step: 42.93
[default0]:[2023-08-25 18:15:03,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.41
[default0]:[2023-08-25 18:15:03,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.50 | backward_microstep: 114.31 | backward_inner_microstep: 103.14 | backward_allreduce_microstep: 11.08 | step_microstep: 43.55
[default0]:[2023-08-25 18:15:03,024] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.50 (forward_moe: 20.98, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.42)
[default0]:[2023-08-25 18:15:03,025] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.31 | backward_inner: 103.14 | backward_allreduce: 11.08 | step: 43.56
[default0]:[2023-08-25 18:15:03,270] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.41
[default0]:[2023-08-25 18:15:03,271] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.84 | backward_microstep: 116.52 | backward_inner_microstep: 105.27 | backward_allreduce_microstep: 11.16 | step_microstep: 43.14
[default0]:[2023-08-25 18:15:03,271] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.84 (forward_moe: 21.26, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.76)
[default0]:[2023-08-25 18:15:03,271] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.52 | backward_inner: 105.27 | backward_allreduce: 11.16 | step: 43.14
[default0]:[2023-08-25 18:15:03,531] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.94 | optimizer_step: 6.39
[default0]:[2023-08-25 18:15:03,532] [INFO] [logging.py:96:log_dist] [Rank 0] step=1620, skipped=0, lr=[1.7683797333333335e-06, 1.7683797333333335e-06, 1.7683797333333335e-06, 1.7683797333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:03,532] [INFO] [timer.py:215:stop] epoch=0/micro_step=1620/global_step=1620, RunningAvgSamplesPerSec=4.9219276460672345, CurrSamplesPerSec=5.008441131199945, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:03,532] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.31 | backward_microstep: 110.45 | backward_inner_microstep: 99.56 | backward_allreduce_microstep: 10.79 | step_microstep: 42.37
[default0]:[2023-08-25 18:15:03,532] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.30 (forward_moe: 20.17, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:15:03,532] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.45 | backward_inner: 99.57 | backward_allreduce: 10.80 | step: 42.37
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.9799], device='cuda:0'), 'moe loss': tensor([0.3021], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1620/439453125 | consumed samples:         1620 | consumed tokens:      3317760 | elapsed time per iteration (ms): 261.5 | learning rate: 1.768E-06 | global batch size:     1 | lm loss: 9.195981E+00 | moe loss: 6.042265E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.824 | TFLOPs: 9.50 |
[default0]:[2023-08-25 18:15:03,786] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:03,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.28 | backward_microstep: 110.46 | backward_inner_microstep: 99.54 | backward_allreduce_microstep: 10.82 | step_microstep: 41.94
[default0]:[2023-08-25 18:15:03,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.28 (forward_moe: 20.02, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.89)
[default0]:[2023-08-25 18:15:03,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.45 | backward_inner: 99.55 | backward_allreduce: 10.82 | step: 41.95
[default0]:[2023-08-25 18:15:04,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:04,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.30 | backward_microstep: 110.59 | backward_inner_microstep: 99.64 | backward_allreduce_microstep: 10.86 | step_microstep: 42.35
[default0]:[2023-08-25 18:15:04,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.30 (forward_moe: 20.27, 1st alltoall: 0.86, 2nd alltoall: 0.83, top-k: 8.12)
[default0]:[2023-08-25 18:15:04,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.59 | backward_inner: 99.64 | backward_allreduce: 10.86 | step: 42.36
[default0]:[2023-08-25 18:15:04,290] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:15:04,392] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.13 | backward_microstep: 113.08 | backward_inner_microstep: 102.17 | backward_allreduce_microstep: 10.82 | step_microstep: 143.50
[default0]:[2023-08-25 18:15:04,392] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.13 (forward_moe: 20.16, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.91)
[default0]:[2023-08-25 18:15:04,392] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.08 | backward_inner: 102.17 | backward_allreduce: 10.82 | step: 143.52
[default0]:[2023-08-25 18:15:04,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:04,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.20 | backward_microstep: 110.74 | backward_inner_microstep: 99.88 | backward_allreduce_microstep: 10.77 | step_microstep: 42.00
[default0]:[2023-08-25 18:15:04,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.20 (forward_moe: 20.07, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.91)
[default0]:[2023-08-25 18:15:04,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.74 | backward_inner: 99.88 | backward_allreduce: 10.77 | step: 42.00
[default0]:[2023-08-25 18:15:04,889] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:04,889] [INFO] [logging.py:96:log_dist] [Rank 0] step=1625, skipped=0, lr=[1.7738410666666668e-06, 1.7738410666666668e-06, 1.7738410666666668e-06, 1.7738410666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:04,889] [INFO] [timer.py:215:stop] epoch=0/micro_step=1625/global_step=1625, RunningAvgSamplesPerSec=4.920602608206524, CurrSamplesPerSec=5.0058827390720575, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:04,890] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.37 | backward_microstep: 110.44 | backward_inner_microstep: 99.49 | backward_allreduce_microstep: 10.86 | step_microstep: 42.43
[default0]:[2023-08-25 18:15:04,890] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.37 (forward_moe: 20.17, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 8.02)
[default0]:[2023-08-25 18:15:04,890] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.44 | backward_inner: 99.49 | backward_allreduce: 10.86 | step: 42.43
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.8454], device='cuda:0'), 'moe loss': tensor([0.3016], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1625/439453125 | consumed samples:         1625 | consumed tokens:      3328000 | elapsed time per iteration (ms): 271.1 | learning rate: 1.774E-06 | global batch size:     1 | lm loss: 9.169075E+00 | moe loss: 6.031342E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.689 | TFLOPs: 9.17 |
[default0]:[2023-08-25 18:15:05,138] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:05,139] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.29 | backward_microstep: 110.76 | backward_inner_microstep: 99.81 | backward_allreduce_microstep: 10.86 | step_microstep: 42.48
[default0]:[2023-08-25 18:15:05,139] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.29 (forward_moe: 20.06, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:15:05,139] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.76 | backward_inner: 99.82 | backward_allreduce: 10.86 | step: 42.48
[default0]:[2023-08-25 18:15:05,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:05,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.76 | backward_microstep: 111.77 | backward_inner_microstep: 100.80 | backward_allreduce_microstep: 10.87 | step_microstep: 42.22
[default0]:[2023-08-25 18:15:05,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.76 (forward_moe: 20.44, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:15:05,380] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.77 | backward_inner: 100.81 | backward_allreduce: 10.88 | step: 42.23
[default0]:[2023-08-25 18:15:05,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:05,627] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.72 | backward_microstep: 111.84 | backward_inner_microstep: 100.81 | backward_allreduce_microstep: 10.93 | step_microstep: 42.54
[default0]:[2023-08-25 18:15:05,628] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.72 (forward_moe: 20.41, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.09)
[default0]:[2023-08-25 18:15:05,628] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.84 | backward_inner: 100.82 | backward_allreduce: 10.93 | step: 42.55
[default0]:[2023-08-25 18:15:05,943] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:15:05,943] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.07 | backward_microstep: 112.63 | backward_inner_microstep: 101.59 | backward_allreduce_microstep: 10.95 | step_microstep: 42.86
[default0]:[2023-08-25 18:15:05,943] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.07 (forward_moe: 20.64, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:15:05,943] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.63 | backward_inner: 101.59 | backward_allreduce: 10.96 | step: 42.86
[default0]:[2023-08-25 18:15:06,190] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.39
[default0]:[2023-08-25 18:15:06,190] [INFO] [logging.py:96:log_dist] [Rank 0] step=1630, skipped=0, lr=[1.7793024e-06, 1.7793024e-06, 1.7793024e-06, 1.7793024e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:06,191] [INFO] [timer.py:215:stop] epoch=0/micro_step=1630/global_step=1630, RunningAvgSamplesPerSec=4.92066107686393, CurrSamplesPerSec=4.877925787401117, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:06,191] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.68 | backward_microstep: 113.44 | backward_inner_microstep: 102.24 | backward_allreduce_microstep: 11.10 | step_microstep: 43.34
[default0]:[2023-08-25 18:15:06,191] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.68 (forward_moe: 20.80, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.26)
[default0]:[2023-08-25 18:15:06,191] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.44 | backward_inner: 102.25 | backward_allreduce: 11.10 | step: 43.35
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.3965], device='cuda:0'), 'moe loss': tensor([0.3006], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1630/439453125 | consumed samples:         1630 | consumed tokens:      3338240 | elapsed time per iteration (ms): 260.8 | learning rate: 1.779E-06 | global batch size:     1 | lm loss: 9.079294E+00 | moe loss: 6.012347E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.834 | TFLOPs: 9.53 |
[default0]:[2023-08-25 18:15:06,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.42
[default0]:[2023-08-25 18:15:06,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.55 | backward_microstep: 113.98 | backward_inner_microstep: 102.88 | backward_allreduce_microstep: 11.00 | step_microstep: 43.23
[default0]:[2023-08-25 18:15:06,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.55 (forward_moe: 20.88, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.42)
[default0]:[2023-08-25 18:15:06,453] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.98 | backward_inner: 102.89 | backward_allreduce: 11.01 | step: 43.23
[default0]:[2023-08-25 18:15:06,706] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.41
[default0]:[2023-08-25 18:15:06,707] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.88 | backward_microstep: 114.58 | backward_inner_microstep: 103.43 | backward_allreduce_microstep: 11.05 | step_microstep: 43.21
[default0]:[2023-08-25 18:15:06,707] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.88 (forward_moe: 20.92, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.45)
[default0]:[2023-08-25 18:15:06,707] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.57 | backward_inner: 103.44 | backward_allreduce: 11.05 | step: 43.22
[default0]:[2023-08-25 18:15:06,957] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.45
[default0]:[2023-08-25 18:15:06,957] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.77 | backward_microstep: 113.49 | backward_inner_microstep: 102.39 | backward_allreduce_microstep: 11.00 | step_microstep: 43.12
[default0]:[2023-08-25 18:15:06,957] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.76 (forward_moe: 20.71, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.32)
[default0]:[2023-08-25 18:15:06,958] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.49 | backward_inner: 102.40 | backward_allreduce: 11.01 | step: 43.12
[default0]:[2023-08-25 18:15:07,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:15:07,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.48 | backward_microstep: 113.62 | backward_inner_microstep: 102.55 | backward_allreduce_microstep: 10.97 | step_microstep: 43.13
[default0]:[2023-08-25 18:15:07,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.48 (forward_moe: 20.85, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.31)
[default0]:[2023-08-25 18:15:07,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.61 | backward_inner: 102.55 | backward_allreduce: 10.98 | step: 43.13
[default0]:[2023-08-25 18:15:07,479] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:15:07,479] [INFO] [logging.py:96:log_dist] [Rank 0] step=1635, skipped=0, lr=[1.7847637333333336e-06, 1.7847637333333336e-06, 1.7847637333333336e-06, 1.7847637333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:07,480] [INFO] [timer.py:215:stop] epoch=0/micro_step=1635/global_step=1635, RunningAvgSamplesPerSec=4.920493071694096, CurrSamplesPerSec=4.873952274985329, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:07,480] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.63 | backward_microstep: 113.57 | backward_inner_microstep: 102.43 | backward_allreduce_microstep: 11.05 | step_microstep: 43.41
[default0]:[2023-08-25 18:15:07,480] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.63 (forward_moe: 20.73, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:15:07,480] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.57 | backward_inner: 102.43 | backward_allreduce: 11.05 | step: 43.41
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.1407], device='cuda:0'), 'moe loss': tensor([0.3003], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1635/439453125 | consumed samples:         1635 | consumed tokens:      3348480 | elapsed time per iteration (ms): 258.1 | learning rate: 1.785E-06 | global batch size:     1 | lm loss: 9.028142E+00 | moe loss: 6.005715E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.874 | TFLOPs: 9.63 |
[default0]:[2023-08-25 18:15:07,740] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.37
[default0]:[2023-08-25 18:15:07,740] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.70 | backward_microstep: 111.33 | backward_inner_microstep: 100.32 | backward_allreduce_microstep: 10.92 | step_microstep: 42.35
[default0]:[2023-08-25 18:15:07,740] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.70 (forward_moe: 20.26, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.06)
[default0]:[2023-08-25 18:15:07,741] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.33 | backward_inner: 100.32 | backward_allreduce: 10.92 | step: 42.36
[default0]:[2023-08-25 18:15:07,987] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.39
[default0]:[2023-08-25 18:15:07,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.62 | backward_microstep: 111.33 | backward_inner_microstep: 100.39 | backward_allreduce_microstep: 10.85 | step_microstep: 42.84
[default0]:[2023-08-25 18:15:07,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.62 (forward_moe: 20.38, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.05)
[default0]:[2023-08-25 18:15:07,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.33 | backward_inner: 100.39 | backward_allreduce: 10.86 | step: 42.84
[default0]:[2023-08-25 18:15:08,222] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:15:08,222] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.76 | backward_microstep: 111.76 | backward_inner_microstep: 100.74 | backward_allreduce_microstep: 10.92 | step_microstep: 43.91
[default0]:[2023-08-25 18:15:08,222] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.76 (forward_moe: 20.29, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.04)
[default0]:[2023-08-25 18:15:08,223] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.75 | backward_inner: 100.74 | backward_allreduce: 10.93 | step: 43.92
[default0]:[2023-08-25 18:15:08,471] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:15:08,471] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.95 | backward_microstep: 111.60 | backward_inner_microstep: 100.68 | backward_allreduce_microstep: 10.82 | step_microstep: 42.48
[default0]:[2023-08-25 18:15:08,471] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.95 (forward_moe: 20.35, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.04)
[default0]:[2023-08-25 18:15:08,472] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.60 | backward_inner: 100.69 | backward_allreduce: 10.83 | step: 42.48
[default0]:[2023-08-25 18:15:08,770] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.01 | optimizer_step: 10.01
[default0]:[2023-08-25 18:15:08,771] [INFO] [logging.py:96:log_dist] [Rank 0] step=1640, skipped=0, lr=[1.790225066666667e-06, 1.790225066666667e-06, 1.790225066666667e-06, 1.790225066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:08,771] [INFO] [timer.py:215:stop] epoch=0/micro_step=1640/global_step=1640, RunningAvgSamplesPerSec=4.9204630184330425, CurrSamplesPerSec=4.755063934762621, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:08,772] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.04 | backward_microstep: 111.51 | backward_inner_microstep: 100.55 | backward_allreduce_microstep: 10.86 | step_microstep: 49.24
[default0]:[2023-08-25 18:15:08,772] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.04 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.04)
[default0]:[2023-08-25 18:15:08,772] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.51 | backward_inner: 100.56 | backward_allreduce: 10.87 | step: 49.25
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.9032], device='cuda:0'), 'moe loss': tensor([0.3004], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1640/439453125 | consumed samples:         1640 | consumed tokens:      3358720 | elapsed time per iteration (ms): 258.7 | learning rate: 1.790E-06 | global batch size:     1 | lm loss: 8.980634E+00 | moe loss: 6.008823E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.866 | TFLOPs: 9.61 |
[default0]:[2023-08-25 18:15:09,062] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.96 | optimizer_step: 6.37
[default0]:[2023-08-25 18:15:09,063] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.46 | backward_microstep: 111.65 | backward_inner_microstep: 100.66 | backward_allreduce_microstep: 10.89 | step_microstep: 42.93
[default0]:[2023-08-25 18:15:09,063] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.46 (forward_moe: 20.57, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.21)
[default0]:[2023-08-25 18:15:09,063] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.65 | backward_inner: 100.67 | backward_allreduce: 10.89 | step: 42.94
[default0]:[2023-08-25 18:15:09,320] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:15:09,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.68 | backward_microstep: 111.66 | backward_inner_microstep: 100.71 | backward_allreduce_microstep: 10.86 | step_microstep: 42.41
[default0]:[2023-08-25 18:15:09,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.68 (forward_moe: 20.45, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.03)
[default0]:[2023-08-25 18:15:09,321] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.66 | backward_inner: 100.72 | backward_allreduce: 10.86 | step: 42.41
[default0]:[2023-08-25 18:15:09,580] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.36
[default0]:[2023-08-25 18:15:09,580] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.95 | backward_microstep: 112.27 | backward_inner_microstep: 101.24 | backward_allreduce_microstep: 10.94 | step_microstep: 42.78
[default0]:[2023-08-25 18:15:09,581] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.94 (forward_moe: 20.54, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:15:09,581] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.27 | backward_inner: 101.25 | backward_allreduce: 10.94 | step: 42.78
[default0]:[2023-08-25 18:15:09,822] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:15:09,822] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.19 | backward_microstep: 113.04 | backward_inner_microstep: 102.00 | backward_allreduce_microstep: 10.95 | step_microstep: 42.82
[default0]:[2023-08-25 18:15:09,822] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.19 (forward_moe: 20.58, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.23)
[default0]:[2023-08-25 18:15:09,822] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.04 | backward_inner: 102.01 | backward_allreduce: 10.95 | step: 42.82
[default0]:[2023-08-25 18:15:10,071] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:15:10,071] [INFO] [logging.py:96:log_dist] [Rank 0] step=1645, skipped=0, lr=[1.7956864000000002e-06, 1.7956864000000002e-06, 1.7956864000000002e-06, 1.7956864000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:10,071] [INFO] [timer.py:215:stop] epoch=0/micro_step=1645/global_step=1645, RunningAvgSamplesPerSec=4.920478476837297, CurrSamplesPerSec=4.877177070324401, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:10,071] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.53 | backward_microstep: 113.70 | backward_inner_microstep: 102.51 | backward_allreduce_microstep: 11.09 | step_microstep: 43.25
[default0]:[2023-08-25 18:15:10,071] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.54 (forward_moe: 20.69, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.29)
[default0]:[2023-08-25 18:15:10,072] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.70 | backward_inner: 102.52 | backward_allreduce: 11.09 | step: 43.26
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([46.4189], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1645/439453125 | consumed samples:         1645 | consumed tokens:      3368960 | elapsed time per iteration (ms): 258.9 | learning rate: 1.796E-06 | global batch size:     1 | lm loss: 9.283778E+00 | moe loss: 6.014621E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.862 | TFLOPs: 9.60 |
[default0]:[2023-08-25 18:15:10,328] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.38
[default0]:[2023-08-25 18:15:10,328] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.50 | backward_microstep: 113.75 | backward_inner_microstep: 102.65 | backward_allreduce_microstep: 11.00 | step_microstep: 42.99
[default0]:[2023-08-25 18:15:10,328] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.50 (forward_moe: 20.86, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.43)
[default0]:[2023-08-25 18:15:10,328] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.75 | backward_inner: 102.65 | backward_allreduce: 11.00 | step: 42.99
[default0]:[2023-08-25 18:15:10,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.41
[default0]:[2023-08-25 18:15:10,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.08 | backward_microstep: 113.43 | backward_inner_microstep: 102.35 | backward_allreduce_microstep: 10.99 | step_microstep: 42.90
[default0]:[2023-08-25 18:15:10,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.08 (forward_moe: 20.68, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.30)
[default0]:[2023-08-25 18:15:10,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.43 | backward_inner: 102.35 | backward_allreduce: 10.99 | step: 42.90
[default0]:[2023-08-25 18:15:10,830] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.40
[default0]:[2023-08-25 18:15:10,830] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.64 | backward_microstep: 113.54 | backward_inner_microstep: 102.44 | backward_allreduce_microstep: 11.00 | step_microstep: 42.97
[default0]:[2023-08-25 18:15:10,830] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.64 (forward_moe: 20.76, 1st alltoall: 0.91, 2nd alltoall: 0.83, top-k: 8.33)
[default0]:[2023-08-25 18:15:10,830] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.54 | backward_inner: 102.44 | backward_allreduce: 11.01 | step: 42.98
[default0]:[2023-08-25 18:15:11,079] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.05 | optimizer_step: 6.40
[default0]:[2023-08-25 18:15:11,079] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.81 | backward_microstep: 114.62 | backward_inner_microstep: 103.50 | backward_allreduce_microstep: 11.03 | step_microstep: 43.04
[default0]:[2023-08-25 18:15:11,079] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.81 (forward_moe: 21.08, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.66)
[default0]:[2023-08-25 18:15:11,080] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.62 | backward_inner: 103.50 | backward_allreduce: 11.04 | step: 43.04
[default0]:[2023-08-25 18:15:11,347] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.38
[default0]:[2023-08-25 18:15:11,347] [INFO] [logging.py:96:log_dist] [Rank 0] step=1650, skipped=0, lr=[1.8011477333333336e-06, 1.8011477333333336e-06, 1.8011477333333336e-06, 1.8011477333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:11,347] [INFO] [timer.py:215:stop] epoch=0/micro_step=1650/global_step=1650, RunningAvgSamplesPerSec=4.920321911566341, CurrSamplesPerSec=4.87145019088336, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:11,347] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.66 | backward_microstep: 113.77 | backward_inner_microstep: 102.70 | backward_allreduce_microstep: 10.98 | step_microstep: 43.28
[default0]:[2023-08-25 18:15:11,347] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.66 (forward_moe: 20.87, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:15:11,348] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.77 | backward_inner: 102.70 | backward_allreduce: 10.99 | step: 43.28
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.5562], device='cuda:0'), 'moe loss': tensor([0.3004], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1650/439453125 | consumed samples:         1650 | consumed tokens:      3379200 | elapsed time per iteration (ms): 255.6 | learning rate: 1.801E-06 | global batch size:     1 | lm loss: 9.111249E+00 | moe loss: 6.008258E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.912 | TFLOPs: 9.72 |
[default0]:[2023-08-25 18:15:11,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.10 | optimizer_step: 6.41
[default0]:[2023-08-25 18:15:11,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.50 | backward_microstep: 113.47 | backward_inner_microstep: 102.40 | backward_allreduce_microstep: 10.97 | step_microstep: 43.05
[default0]:[2023-08-25 18:15:11,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.49 (forward_moe: 20.75, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.32)
[default0]:[2023-08-25 18:15:11,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.47 | backward_inner: 102.40 | backward_allreduce: 10.97 | step: 43.06
[default0]:[2023-08-25 18:15:11,872] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.40
[default0]:[2023-08-25 18:15:11,873] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.72 | backward_microstep: 113.53 | backward_inner_microstep: 102.48 | backward_allreduce_microstep: 10.96 | step_microstep: 42.97
[default0]:[2023-08-25 18:15:11,873] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.72 (forward_moe: 20.71, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:15:11,873] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.53 | backward_inner: 102.48 | backward_allreduce: 10.96 | step: 42.98
[default0]:[2023-08-25 18:15:12,144] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.06 | optimizer_step: 6.42
[default0]:[2023-08-25 18:15:12,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.67 | backward_microstep: 113.62 | backward_inner_microstep: 102.47 | backward_allreduce_microstep: 11.05 | step_microstep: 43.09
[default0]:[2023-08-25 18:15:12,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.67 (forward_moe: 20.83, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.31)
[default0]:[2023-08-25 18:15:12,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.62 | backward_inner: 102.48 | backward_allreduce: 11.06 | step: 43.10
[default0]:[2023-08-25 18:15:12,406] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.43
[default0]:[2023-08-25 18:15:12,407] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.31 | backward_microstep: 114.66 | backward_inner_microstep: 103.50 | backward_allreduce_microstep: 11.07 | step_microstep: 43.41
[default0]:[2023-08-25 18:15:12,407] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.31 (forward_moe: 21.14, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.55)
[default0]:[2023-08-25 18:15:12,407] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.66 | backward_inner: 103.50 | backward_allreduce: 11.07 | step: 43.41
[default0]:[2023-08-25 18:15:12,665] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:15:12,665] [INFO] [logging.py:96:log_dist] [Rank 0] step=1655, skipped=0, lr=[1.8066090666666669e-06, 1.8066090666666669e-06, 1.8066090666666669e-06, 1.8066090666666669e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:12,665] [INFO] [timer.py:215:stop] epoch=0/micro_step=1655/global_step=1655, RunningAvgSamplesPerSec=4.920117291963721, CurrSamplesPerSec=4.811013370986668, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:12,665] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.21 | backward_microstep: 115.09 | backward_inner_microstep: 103.91 | backward_allreduce_microstep: 11.09 | step_microstep: 44.01
[default0]:[2023-08-25 18:15:12,665] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.21 (forward_moe: 21.13, 1st alltoall: 0.95, 2nd alltoall: 0.83, top-k: 8.54)
[default0]:[2023-08-25 18:15:12,666] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.09 | backward_inner: 103.91 | backward_allreduce: 11.09 | step: 44.01
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.1939], device='cuda:0'), 'moe loss': tensor([0.2998], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1655/439453125 | consumed samples:         1655 | consumed tokens:      3389440 | elapsed time per iteration (ms): 262.9 | learning rate: 1.807E-06 | global batch size:     1 | lm loss: 9.038773E+00 | moe loss: 5.995030E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.804 | TFLOPs: 9.45 |
[default0]:[2023-08-25 18:15:12,918] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.44
[default0]:[2023-08-25 18:15:12,918] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.60 | backward_microstep: 115.30 | backward_inner_microstep: 104.08 | backward_allreduce_microstep: 11.13 | step_microstep: 43.56
[default0]:[2023-08-25 18:15:12,918] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.60 (forward_moe: 21.07, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.53)
[default0]:[2023-08-25 18:15:12,918] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.30 | backward_inner: 104.09 | backward_allreduce: 11.13 | step: 43.56
[default0]:[2023-08-25 18:15:13,158] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.43
[default0]:[2023-08-25 18:15:13,158] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.47 | backward_microstep: 110.92 | backward_inner_microstep: 99.98 | backward_allreduce_microstep: 10.84 | step_microstep: 42.51
[default0]:[2023-08-25 18:15:13,158] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.47 (forward_moe: 20.20, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.01)
[default0]:[2023-08-25 18:15:13,159] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.92 | backward_inner: 99.99 | backward_allreduce: 10.85 | step: 42.52
[default0]:[2023-08-25 18:15:13,409] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.33
[default0]:[2023-08-25 18:15:13,410] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 51.16 | backward_microstep: 111.75 | backward_inner_microstep: 100.41 | backward_allreduce_microstep: 11.24 | step_microstep: 42.94
[default0]:[2023-08-25 18:15:13,410] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 51.15 (forward_moe: 20.21, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.01)
[default0]:[2023-08-25 18:15:13,410] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.74 | backward_inner: 100.42 | backward_allreduce: 11.24 | step: 42.95
[default0]:[2023-08-25 18:15:13,653] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:15:13,653] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.51 | backward_microstep: 111.08 | backward_inner_microstep: 100.10 | backward_allreduce_microstep: 10.88 | step_microstep: 42.12
[default0]:[2023-08-25 18:15:13,653] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.51 (forward_moe: 20.29, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.98)
[default0]:[2023-08-25 18:15:13,653] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.08 | backward_inner: 100.11 | backward_allreduce: 10.88 | step: 42.12
[default0]:[2023-08-25 18:15:13,895] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:15:13,895] [INFO] [logging.py:96:log_dist] [Rank 0] step=1660, skipped=0, lr=[1.8120704000000002e-06, 1.8120704000000002e-06, 1.8120704000000002e-06, 1.8120704000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:13,895] [INFO] [timer.py:215:stop] epoch=0/micro_step=1660/global_step=1660, RunningAvgSamplesPerSec=4.920107967896381, CurrSamplesPerSec=4.983566354216298, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:13,895] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.59 | backward_microstep: 111.10 | backward_inner_microstep: 100.21 | backward_allreduce_microstep: 10.80 | step_microstep: 42.45
[default0]:[2023-08-25 18:15:13,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.58 (forward_moe: 20.28, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.96)
[default0]:[2023-08-25 18:15:13,896] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.10 | backward_inner: 100.21 | backward_allreduce: 10.80 | step: 42.46
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.0467], device='cuda:0'), 'moe loss': tensor([0.3000], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1660/439453125 | consumed samples:         1660 | consumed tokens:      3399680 | elapsed time per iteration (ms): 246.1 | learning rate: 1.812E-06 | global batch size:     1 | lm loss: 9.009332E+00 | moe loss: 5.999884E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.063 | TFLOPs: 10.10 |
[default0]:[2023-08-25 18:15:14,146] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:15:14,147] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.64 | backward_microstep: 111.15 | backward_inner_microstep: 100.16 | backward_allreduce_microstep: 10.89 | step_microstep: 42.13
[default0]:[2023-08-25 18:15:14,147] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.64 (forward_moe: 20.20, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.01)
[default0]:[2023-08-25 18:15:14,147] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.14 | backward_inner: 100.17 | backward_allreduce: 10.89 | step: 42.14
[default0]:[2023-08-25 18:15:14,426] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:15:14,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.07 | backward_microstep: 111.11 | backward_inner_microstep: 100.14 | backward_allreduce_microstep: 10.87 | step_microstep: 42.91
[default0]:[2023-08-25 18:15:14,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.07 (forward_moe: 20.19, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 7.99)
[default0]:[2023-08-25 18:15:14,427] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.11 | backward_inner: 100.15 | backward_allreduce: 10.88 | step: 42.92
[default0]:[2023-08-25 18:15:14,685] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:14,685] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.57 | backward_microstep: 110.93 | backward_inner_microstep: 99.98 | backward_allreduce_microstep: 10.86 | step_microstep: 42.19
[default0]:[2023-08-25 18:15:14,686] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.57 (forward_moe: 20.17, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.98)
[default0]:[2023-08-25 18:15:14,686] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.93 | backward_inner: 99.98 | backward_allreduce: 10.86 | step: 42.20
[default0]:[2023-08-25 18:15:14,916] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:15:14,916] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.90 | backward_microstep: 112.48 | backward_inner_microstep: 101.48 | backward_allreduce_microstep: 10.91 | step_microstep: 42.71
[default0]:[2023-08-25 18:15:14,916] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.90 (forward_moe: 20.49, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.18)
[default0]:[2023-08-25 18:15:14,916] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.48 | backward_inner: 101.48 | backward_allreduce: 10.91 | step: 42.71
[default0]:[2023-08-25 18:15:15,153] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:15,153] [INFO] [logging.py:96:log_dist] [Rank 0] step=1665, skipped=0, lr=[1.8175317333333335e-06, 1.8175317333333335e-06, 1.8175317333333335e-06, 1.8175317333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:15,153] [INFO] [timer.py:215:stop] epoch=0/micro_step=1665/global_step=1665, RunningAvgSamplesPerSec=4.920221594376277, CurrSamplesPerSec=4.964889623848682, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:15,153] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.79 | backward_microstep: 111.47 | backward_inner_microstep: 100.49 | backward_allreduce_microstep: 10.89 | step_microstep: 42.59
[default0]:[2023-08-25 18:15:15,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.38, 1st alltoall: 0.87, 2nd alltoall: 0.84, top-k: 8.15)
[default0]:[2023-08-25 18:15:15,154] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.47 | backward_inner: 100.50 | backward_allreduce: 10.89 | step: 42.59
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.0425], device='cuda:0'), 'moe loss': tensor([0.3023], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1665/439453125 | consumed samples:         1665 | consumed tokens:      3409920 | elapsed time per iteration (ms): 251.7 | learning rate: 1.818E-06 | global batch size:     1 | lm loss: 9.008505E+00 | moe loss: 6.045055E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.974 | TFLOPs: 9.87 |
[default0]:[2023-08-25 18:15:15,396] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:15,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.99 | backward_microstep: 111.48 | backward_inner_microstep: 100.52 | backward_allreduce_microstep: 10.87 | step_microstep: 42.26
[default0]:[2023-08-25 18:15:15,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.99 (forward_moe: 20.30, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.06)
[default0]:[2023-08-25 18:15:15,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.48 | backward_inner: 100.52 | backward_allreduce: 10.87 | step: 42.26
[default0]:[2023-08-25 18:15:15,637] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:15:15,638] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.56 | backward_microstep: 111.41 | backward_inner_microstep: 100.46 | backward_allreduce_microstep: 10.85 | step_microstep: 42.19
[default0]:[2023-08-25 18:15:15,638] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.56 (forward_moe: 20.37, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.02)
[default0]:[2023-08-25 18:15:15,638] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.41 | backward_inner: 100.47 | backward_allreduce: 10.85 | step: 42.19
[default0]:[2023-08-25 18:15:15,968] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:15,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.61 | backward_microstep: 111.27 | backward_inner_microstep: 100.31 | backward_allreduce_microstep: 10.87 | step_microstep: 42.18
[default0]:[2023-08-25 18:15:15,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.61 (forward_moe: 20.25, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.05)
[default0]:[2023-08-25 18:15:15,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.27 | backward_inner: 100.31 | backward_allreduce: 10.87 | step: 42.19
[default0]:[2023-08-25 18:15:16,244] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.36
[default0]:[2023-08-25 18:15:16,245] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.57 | backward_microstep: 111.85 | backward_inner_microstep: 100.87 | backward_allreduce_microstep: 10.88 | step_microstep: 42.30
[default0]:[2023-08-25 18:15:16,245] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.57 (forward_moe: 20.78, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.55)
[default0]:[2023-08-25 18:15:16,245] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.85 | backward_inner: 100.88 | backward_allreduce: 10.88 | step: 42.31
[default0]:[2023-08-25 18:15:16,511] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:16,511] [INFO] [logging.py:96:log_dist] [Rank 0] step=1670, skipped=0, lr=[1.8229930666666668e-06, 1.8229930666666668e-06, 1.8229930666666668e-06, 1.8229930666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:16,511] [INFO] [timer.py:215:stop] epoch=0/micro_step=1670/global_step=1670, RunningAvgSamplesPerSec=4.920360498399382, CurrSamplesPerSec=4.958497757370413, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:16,511] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.91 | backward_microstep: 111.62 | backward_inner_microstep: 100.61 | backward_allreduce_microstep: 10.91 | step_microstep: 42.60
[default0]:[2023-08-25 18:15:16,511] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.91 (forward_moe: 20.48, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:15:16,512] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.61 | backward_inner: 100.62 | backward_allreduce: 10.91 | step: 42.60
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.7547], device='cuda:0'), 'moe loss': tensor([0.3020], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1670/439453125 | consumed samples:         1670 | consumed tokens:      3420160 | elapsed time per iteration (ms): 272.4 | learning rate: 1.823E-06 | global batch size:     1 | lm loss: 8.950932E+00 | moe loss: 6.040076E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.671 | TFLOPs: 9.12 |
[default0]:[2023-08-25 18:15:16,800] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:15:16,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.31 | backward_microstep: 111.95 | backward_inner_microstep: 100.85 | backward_allreduce_microstep: 11.00 | step_microstep: 42.85
[default0]:[2023-08-25 18:15:16,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.30 (forward_moe: 20.45, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:15:16,801] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.94 | backward_inner: 100.86 | backward_allreduce: 11.00 | step: 42.85
[default0]:[2023-08-25 18:15:17,058] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:15:17,059] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.22 | backward_microstep: 113.20 | backward_inner_microstep: 102.12 | backward_allreduce_microstep: 10.99 | step_microstep: 42.85
[default0]:[2023-08-25 18:15:17,059] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.22 (forward_moe: 20.64, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.29)
[default0]:[2023-08-25 18:15:17,059] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.20 | backward_inner: 102.12 | backward_allreduce: 10.99 | step: 42.85
[default0]:[2023-08-25 18:15:17,306] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.40
[default0]:[2023-08-25 18:15:17,307] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.92 | backward_microstep: 114.37 | backward_inner_microstep: 103.27 | backward_allreduce_microstep: 11.01 | step_microstep: 43.15
[default0]:[2023-08-25 18:15:17,307] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.92 (forward_moe: 20.89, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.36)
[default0]:[2023-08-25 18:15:17,307] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.37 | backward_inner: 103.27 | backward_allreduce: 11.01 | step: 43.15
[default0]:[2023-08-25 18:15:17,593] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.43
[default0]:[2023-08-25 18:15:17,593] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.12 | backward_microstep: 114.39 | backward_inner_microstep: 103.16 | backward_allreduce_microstep: 11.13 | step_microstep: 43.48
[default0]:[2023-08-25 18:15:17,593] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.12 (forward_moe: 20.89, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.42)
[default0]:[2023-08-25 18:15:17,593] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.39 | backward_inner: 103.17 | backward_allreduce: 11.14 | step: 43.49
[default0]:[2023-08-25 18:15:17,841] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.43
[default0]:[2023-08-25 18:15:17,841] [INFO] [logging.py:96:log_dist] [Rank 0] step=1675, skipped=0, lr=[1.8284544000000003e-06, 1.8284544000000003e-06, 1.8284544000000003e-06, 1.8284544000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:17,841] [INFO] [timer.py:215:stop] epoch=0/micro_step=1675/global_step=1675, RunningAvgSamplesPerSec=4.920184804965998, CurrSamplesPerSec=4.827875796530259, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:17,841] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.22 | backward_microstep: 114.52 | backward_inner_microstep: 103.36 | backward_allreduce_microstep: 11.07 | step_microstep: 43.80
[default0]:[2023-08-25 18:15:17,841] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.22 (forward_moe: 20.92, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.43)
[default0]:[2023-08-25 18:15:17,842] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.52 | backward_inner: 103.36 | backward_allreduce: 11.07 | step: 43.81
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.4858], device='cuda:0'), 'moe loss': tensor([0.3003], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1675/439453125 | consumed samples:         1675 | consumed tokens:      3430400 | elapsed time per iteration (ms): 265.0 | learning rate: 1.828E-06 | global batch size:     1 | lm loss: 9.097160E+00 | moe loss: 6.005985E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.773 | TFLOPs: 9.38 |
[default0]:[2023-08-25 18:15:18,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.10 | optimizer_step: 6.45
[default0]:[2023-08-25 18:15:18,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.05 | backward_microstep: 115.63 | backward_inner_microstep: 104.43 | backward_allreduce_microstep: 11.11 | step_microstep: 43.73
[default0]:[2023-08-25 18:15:18,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.05 (forward_moe: 21.35, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.54)
[default0]:[2023-08-25 18:15:18,112] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.63 | backward_inner: 104.44 | backward_allreduce: 11.11 | step: 43.73
[default0]:[2023-08-25 18:15:18,366] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.07 | optimizer_step: 6.39
[default0]:[2023-08-25 18:15:18,366] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.31 | backward_microstep: 117.49 | backward_inner_microstep: 106.24 | backward_allreduce_microstep: 11.15 | step_microstep: 43.66
[default0]:[2023-08-25 18:15:18,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.31 (forward_moe: 21.37, 1st alltoall: 0.90, 2nd alltoall: 0.92, top-k: 8.64)
[default0]:[2023-08-25 18:15:18,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.48 | backward_inner: 106.24 | backward_allreduce: 11.16 | step: 43.66
[default0]:[2023-08-25 18:15:18,611] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.42
[default0]:[2023-08-25 18:15:18,612] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.40 | backward_microstep: 113.06 | backward_inner_microstep: 101.99 | backward_allreduce_microstep: 10.98 | step_microstep: 43.12
[default0]:[2023-08-25 18:15:18,612] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.39 (forward_moe: 20.64, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.27)
[default0]:[2023-08-25 18:15:18,612] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.06 | backward_inner: 102.00 | backward_allreduce: 10.98 | step: 43.13
[default0]:[2023-08-25 18:15:18,866] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 9.91
[default0]:[2023-08-25 18:15:18,866] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.89 | backward_microstep: 113.58 | backward_inner_microstep: 102.45 | backward_allreduce_microstep: 11.03 | step_microstep: 46.52
[default0]:[2023-08-25 18:15:18,866] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.89 (forward_moe: 20.75, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.27)
[default0]:[2023-08-25 18:15:18,866] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.57 | backward_inner: 102.45 | backward_allreduce: 11.04 | step: 46.52
[default0]:[2023-08-25 18:15:19,114] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.38
[default0]:[2023-08-25 18:15:19,114] [INFO] [logging.py:96:log_dist] [Rank 0] step=1680, skipped=0, lr=[1.8339157333333336e-06, 1.8339157333333336e-06, 1.8339157333333336e-06, 1.8339157333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:19,114] [INFO] [timer.py:215:stop] epoch=0/micro_step=1680/global_step=1680, RunningAvgSamplesPerSec=4.919849068853427, CurrSamplesPerSec=4.8835314431687324, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:19,114] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.78 | backward_microstep: 113.24 | backward_inner_microstep: 102.17 | backward_allreduce_microstep: 10.98 | step_microstep: 43.18
[default0]:[2023-08-25 18:15:19,114] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.78 (forward_moe: 20.79, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.27)
[default0]:[2023-08-25 18:15:19,115] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.24 | backward_inner: 102.18 | backward_allreduce: 10.98 | step: 43.19
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.7523], device='cuda:0'), 'moe loss': tensor([0.3028], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1680/439453125 | consumed samples:         1680 | consumed tokens:      3440640 | elapsed time per iteration (ms): 254.7 | learning rate: 1.834E-06 | global batch size:     1 | lm loss: 9.150455E+00 | moe loss: 6.056321E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.926 | TFLOPs: 9.75 |
[default0]:[2023-08-25 18:15:19,374] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:15:19,374] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.44 | backward_microstep: 113.26 | backward_inner_microstep: 102.21 | backward_allreduce_microstep: 10.94 | step_microstep: 42.82
[default0]:[2023-08-25 18:15:19,374] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.44 (forward_moe: 20.63, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.25)
[default0]:[2023-08-25 18:15:19,375] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.25 | backward_inner: 102.22 | backward_allreduce: 10.95 | step: 42.83
[default0]:[2023-08-25 18:15:19,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:15:19,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.36 | backward_microstep: 112.54 | backward_inner_microstep: 101.53 | backward_allreduce_microstep: 10.92 | step_microstep: 42.48
[default0]:[2023-08-25 18:15:19,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.35 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:15:19,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.54 | backward_inner: 101.54 | backward_allreduce: 10.92 | step: 42.49
[default0]:[2023-08-25 18:15:19,883] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.05 | optimizer_step: 6.42
[default0]:[2023-08-25 18:15:19,883] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.00 | backward_microstep: 117.27 | backward_inner_microstep: 105.71 | backward_allreduce_microstep: 11.46 | step_microstep: 44.15
[default0]:[2023-08-25 18:15:19,883] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.01 (forward_moe: 21.46, 1st alltoall: 0.93, 2nd alltoall: 0.86, top-k: 8.46)
[default0]:[2023-08-25 18:15:19,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.27 | backward_inner: 105.72 | backward_allreduce: 11.46 | step: 44.16
[default0]:[2023-08-25 18:15:20,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:15:20,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.46 | backward_microstep: 112.63 | backward_inner_microstep: 101.63 | backward_allreduce_microstep: 10.90 | step_microstep: 42.64
[default0]:[2023-08-25 18:15:20,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.46 (forward_moe: 20.54, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:15:20,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.62 | backward_inner: 101.63 | backward_allreduce: 10.91 | step: 42.64
[default0]:[2023-08-25 18:15:20,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:15:20,387] [INFO] [logging.py:96:log_dist] [Rank 0] step=1685, skipped=0, lr=[1.839377066666667e-06, 1.839377066666667e-06, 1.839377066666667e-06, 1.839377066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:20,388] [INFO] [timer.py:215:stop] epoch=0/micro_step=1685/global_step=1685, RunningAvgSamplesPerSec=4.919743826151066, CurrSamplesPerSec=4.946568198489955, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:20,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.83 | backward_microstep: 111.89 | backward_inner_microstep: 100.89 | backward_allreduce_microstep: 10.91 | step_microstep: 42.88
[default0]:[2023-08-25 18:15:20,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.83 (forward_moe: 20.46, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:15:20,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.89 | backward_inner: 100.90 | backward_allreduce: 10.91 | step: 42.89
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.1478], device='cuda:0'), 'moe loss': tensor([0.3011], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1685/439453125 | consumed samples:         1685 | consumed tokens:      3450880 | elapsed time per iteration (ms): 254.7 | learning rate: 1.839E-06 | global batch size:     1 | lm loss: 9.029564E+00 | moe loss: 6.021680E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.926 | TFLOPs: 9.75 |
[default0]:[2023-08-25 18:15:20,656] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:15:20,656] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.98 | backward_microstep: 111.94 | backward_inner_microstep: 100.97 | backward_allreduce_microstep: 10.87 | step_microstep: 42.32
[default0]:[2023-08-25 18:15:20,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.98 (forward_moe: 20.38, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.10)
[default0]:[2023-08-25 18:15:20,657] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.94 | backward_inner: 100.98 | backward_allreduce: 10.88 | step: 42.32
[default0]:[2023-08-25 18:15:20,913] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:15:20,914] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.83 | backward_microstep: 111.86 | backward_inner_microstep: 100.88 | backward_allreduce_microstep: 10.89 | step_microstep: 42.54
[default0]:[2023-08-25 18:15:20,914] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.83 (forward_moe: 20.37, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.09)
[default0]:[2023-08-25 18:15:20,914] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.86 | backward_inner: 100.89 | backward_allreduce: 10.89 | step: 42.54
[default0]:[2023-08-25 18:15:21,189] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:15:21,190] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.46 | backward_microstep: 112.30 | backward_inner_microstep: 101.15 | backward_allreduce_microstep: 11.05 | step_microstep: 43.03
[default0]:[2023-08-25 18:15:21,190] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.46 (forward_moe: 20.51, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.12)
[default0]:[2023-08-25 18:15:21,190] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.29 | backward_inner: 101.16 | backward_allreduce: 11.05 | step: 43.03
[default0]:[2023-08-25 18:15:21,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:15:21,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 112.07 | backward_inner_microstep: 101.04 | backward_allreduce_microstep: 10.92 | step_microstep: 42.45
[default0]:[2023-08-25 18:15:21,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.02 (forward_moe: 20.37, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.11)
[default0]:[2023-08-25 18:15:21,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.06 | backward_inner: 101.05 | backward_allreduce: 10.93 | step: 42.45
[default0]:[2023-08-25 18:15:21,669] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.38
[default0]:[2023-08-25 18:15:21,669] [INFO] [logging.py:96:log_dist] [Rank 0] step=1690, skipped=0, lr=[1.8448383999999999e-06, 1.8448383999999999e-06, 1.8448383999999999e-06, 1.8448383999999999e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:21,669] [INFO] [timer.py:215:stop] epoch=0/micro_step=1690/global_step=1690, RunningAvgSamplesPerSec=4.919788990196822, CurrSamplesPerSec=4.925042389400066, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:21,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.31 | backward_microstep: 112.06 | backward_inner_microstep: 101.02 | backward_allreduce_microstep: 10.93 | step_microstep: 43.16
[default0]:[2023-08-25 18:15:21,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.31 (forward_moe: 20.50, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:15:21,670] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.06 | backward_inner: 101.03 | backward_allreduce: 10.94 | step: 43.17
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.5662], device='cuda:0'), 'moe loss': tensor([0.3011], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1690/439453125 | consumed samples:         1690 | consumed tokens:      3461120 | elapsed time per iteration (ms): 256.4 | learning rate: 1.845E-06 | global batch size:     1 | lm loss: 9.113243E+00 | moe loss: 6.021692E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.900 | TFLOPs: 9.69 |
[default0]:[2023-08-25 18:15:21,934] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.34
[default0]:[2023-08-25 18:15:21,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.59 | backward_microstep: 111.94 | backward_inner_microstep: 100.97 | backward_allreduce_microstep: 10.87 | step_microstep: 42.59
[default0]:[2023-08-25 18:15:21,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.59 (forward_moe: 20.35, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.09)
[default0]:[2023-08-25 18:15:21,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.94 | backward_inner: 100.98 | backward_allreduce: 10.88 | step: 42.59
[default0]:[2023-08-25 18:15:22,195] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.85 | optimizer_gradients: 4.05 | optimizer_step: 6.40
[default0]:[2023-08-25 18:15:22,195] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.80 | backward_microstep: 113.91 | backward_inner_microstep: 102.81 | backward_allreduce_microstep: 11.01 | step_microstep: 43.39
[default0]:[2023-08-25 18:15:22,195] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.80 (forward_moe: 20.81, 1st alltoall: 0.93, 2nd alltoall: 0.82, top-k: 8.35)
[default0]:[2023-08-25 18:15:22,195] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.91 | backward_inner: 102.81 | backward_allreduce: 11.01 | step: 43.39
[default0]:[2023-08-25 18:15:22,447] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.09 | optimizer_step: 6.43
[default0]:[2023-08-25 18:15:22,447] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.80 | backward_microstep: 114.00 | backward_inner_microstep: 102.90 | backward_allreduce_microstep: 11.00 | step_microstep: 43.34
[default0]:[2023-08-25 18:15:22,447] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.79 (forward_moe: 20.86, 1st alltoall: 0.88, 2nd alltoall: 0.85, top-k: 8.39)
[default0]:[2023-08-25 18:15:22,448] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.00 | backward_inner: 102.91 | backward_allreduce: 11.00 | step: 43.34
[default0]:[2023-08-25 18:15:22,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.43
[default0]:[2023-08-25 18:15:22,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.85 | backward_microstep: 114.62 | backward_inner_microstep: 103.50 | backward_allreduce_microstep: 11.02 | step_microstep: 43.43
[default0]:[2023-08-25 18:15:22,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.85 (forward_moe: 21.09, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.55)
[default0]:[2023-08-25 18:15:22,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.62 | backward_inner: 103.51 | backward_allreduce: 11.03 | step: 43.44
[default0]:[2023-08-25 18:15:22,985] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.08 | optimizer_step: 6.40
[default0]:[2023-08-25 18:15:22,985] [INFO] [logging.py:96:log_dist] [Rank 0] step=1695, skipped=0, lr=[1.8502997333333334e-06, 1.8502997333333334e-06, 1.8502997333333334e-06, 1.8502997333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:22,986] [INFO] [timer.py:215:stop] epoch=0/micro_step=1695/global_step=1695, RunningAvgSamplesPerSec=4.919613415652179, CurrSamplesPerSec=4.806294253605892, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:22,986] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.45 | backward_microstep: 115.24 | backward_inner_microstep: 104.02 | backward_allreduce_microstep: 11.13 | step_microstep: 43.81
[default0]:[2023-08-25 18:15:22,986] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.45 (forward_moe: 21.11, 1st alltoall: 0.91, 2nd alltoall: 0.82, top-k: 8.53)
[default0]:[2023-08-25 18:15:22,986] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.24 | backward_inner: 104.02 | backward_allreduce: 11.13 | step: 43.82
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.7714], device='cuda:0'), 'moe loss': tensor([0.2997], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1695/439453125 | consumed samples:         1695 | consumed tokens:      3471360 | elapsed time per iteration (ms): 263.3 | learning rate: 1.850E-06 | global batch size:     1 | lm loss: 9.154288E+00 | moe loss: 5.993400E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.797 | TFLOPs: 9.44 |
[default0]:[2023-08-25 18:15:23,248] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.50
[default0]:[2023-08-25 18:15:23,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.29 | backward_microstep: 112.07 | backward_inner_microstep: 100.80 | backward_allreduce_microstep: 11.18 | step_microstep: 43.91
[default0]:[2023-08-25 18:15:23,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.29 (forward_moe: 20.21, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.00)
[default0]:[2023-08-25 18:15:23,250] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.07 | backward_inner: 100.81 | backward_allreduce: 11.18 | step: 43.91
[default0]:[2023-08-25 18:15:23,569] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:23,569] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.16 | backward_microstep: 111.04 | backward_inner_microstep: 100.10 | backward_allreduce_microstep: 10.84 | step_microstep: 42.26
[default0]:[2023-08-25 18:15:23,569] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.16 (forward_moe: 20.13, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.97)
[default0]:[2023-08-25 18:15:23,569] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.03 | backward_inner: 100.10 | backward_allreduce: 10.85 | step: 42.26
[default0]:[2023-08-25 18:15:23,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:23,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.15 | backward_microstep: 110.00 | backward_inner_microstep: 98.99 | backward_allreduce_microstep: 10.91 | step_microstep: 42.54
[default0]:[2023-08-25 18:15:23,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.15 (forward_moe: 20.07, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.86)
[default0]:[2023-08-25 18:15:23,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.00 | backward_inner: 99.00 | backward_allreduce: 10.92 | step: 42.55
[default0]:[2023-08-25 18:15:24,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:24,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.04 | backward_microstep: 109.97 | backward_inner_microstep: 99.08 | backward_allreduce_microstep: 10.79 | step_microstep: 41.88
[default0]:[2023-08-25 18:15:24,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.03 (forward_moe: 19.95, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:15:24,065] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.97 | backward_inner: 99.09 | backward_allreduce: 10.80 | step: 41.88
[default0]:[2023-08-25 18:15:24,377] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:24,378] [INFO] [logging.py:96:log_dist] [Rank 0] step=1700, skipped=0, lr=[1.8557610666666667e-06, 1.8557610666666667e-06, 1.8557610666666667e-06, 1.8557610666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:24,378] [INFO] [timer.py:215:stop] epoch=0/micro_step=1700/global_step=1700, RunningAvgSamplesPerSec=4.919756621703769, CurrSamplesPerSec=4.9572436224731, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:24,379] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.09 | backward_microstep: 112.28 | backward_inner_microstep: 101.38 | backward_allreduce_microstep: 10.81 | step_microstep: 42.81
[default0]:[2023-08-25 18:15:24,379] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.09 (forward_moe: 20.31, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.00)
[default0]:[2023-08-25 18:15:24,379] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.28 | backward_inner: 101.38 | backward_allreduce: 10.81 | step: 42.81
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.8006], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1700/439453125 | consumed samples:         1700 | consumed tokens:      3481600 | elapsed time per iteration (ms): 278.4 | learning rate: 1.856E-06 | global batch size:     1 | lm loss: 8.960117E+00 | moe loss: 6.020353E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.592 | TFLOPs: 8.93 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1700 | lm loss value: 9.018354E+00 | lm loss PPL: 8.253185E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration    1700 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:15:28,145] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1700 is about to be saved!
[default0]:[2023-08-25 18:15:28,147] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,159] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,159] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,168] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,168] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,177] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,177] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,186] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,187] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,196] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,196] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,205] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,205] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,214] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,214] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,223] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,224] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,233] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,233] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,243] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,243] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,253] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,253] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,263] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,264] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,272] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,273] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,281] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,281] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,290] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,290] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,299] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,300] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,309] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,309] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,317] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,317] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,326] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,326] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,335] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,336] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,345] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,345] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,354] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,355] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,363] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,364] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,372] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,373] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:15:28,374] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:15:28,375] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:15:28,376] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:15:28,653] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:15:28,655] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:15:32,323] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:15:32,333] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1700/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:15:32,333] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1700 is ready now!
[default0]:  successfully saved checkpoint at iteration    1700 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.7, Latency(second): 4.192
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4191.72, 4191.72)
[default0]:[2023-08-25 18:15:32,584] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.17 | optimizer_step: 10.20
[default0]:[2023-08-25 18:15:32,585] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2239.87 | backward_microstep: 117.27 | backward_inner_microstep: 106.10 | backward_allreduce_microstep: 11.08 | step_microstep: 47.42
[default0]:[2023-08-25 18:15:32,586] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2239.74 (forward_moe: 21.46, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.75)
[default0]:[2023-08-25 18:15:32,586] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.27 | backward_inner: 106.10 | backward_allreduce: 11.08 | step: 47.43
[default0]:[2023-08-25 18:15:32,859] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:15:32,859] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.06 | backward_microstep: 116.75 | backward_inner_microstep: 105.60 | backward_allreduce_microstep: 11.06 | step_microstep: 43.59
[default0]:[2023-08-25 18:15:32,859] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.06 (forward_moe: 21.44, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.73)
[default0]:[2023-08-25 18:15:32,860] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.75 | backward_inner: 105.60 | backward_allreduce: 11.06 | step: 43.60
[default0]:[2023-08-25 18:15:33,107] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.45
[default0]:[2023-08-25 18:15:33,108] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.10 | backward_microstep: 114.80 | backward_inner_microstep: 103.78 | backward_allreduce_microstep: 10.93 | step_microstep: 43.45
[default0]:[2023-08-25 18:15:33,108] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.10 (forward_moe: 20.97, 1st alltoall: 0.91, 2nd alltoall: 0.82, top-k: 8.48)
[default0]:[2023-08-25 18:15:33,108] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.80 | backward_inner: 103.79 | backward_allreduce: 10.93 | step: 43.45
[default0]:[2023-08-25 18:15:33,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.10 | optimizer_step: 6.44
[default0]:[2023-08-25 18:15:33,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.26 | backward_microstep: 116.15 | backward_inner_microstep: 105.20 | backward_allreduce_microstep: 10.86 | step_microstep: 43.27
[default0]:[2023-08-25 18:15:33,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.26 (forward_moe: 20.98, 1st alltoall: 0.90, 2nd alltoall: 0.82, top-k: 8.52)
[default0]:[2023-08-25 18:15:33,370] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.15 | backward_inner: 105.21 | backward_allreduce: 10.86 | step: 43.27
[default0]:[2023-08-25 18:15:33,632] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.46
[default0]:[2023-08-25 18:15:33,632] [INFO] [logging.py:96:log_dist] [Rank 0] step=1705, skipped=0, lr=[1.8612224e-06, 1.8612224e-06, 1.8612224e-06, 1.8612224e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:33,633] [INFO] [timer.py:215:stop] epoch=0/micro_step=1705/global_step=1705, RunningAvgSamplesPerSec=4.919163860948341, CurrSamplesPerSec=4.676888767471552, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:33,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 51.70 | backward_microstep: 116.75 | backward_inner_microstep: 105.22 | backward_allreduce_microstep: 11.44 | step_microstep: 44.75
[default0]:[2023-08-25 18:15:33,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 51.70 (forward_moe: 21.37, 1st alltoall: 0.91, 2nd alltoall: 0.84, top-k: 8.66)
[default0]:[2023-08-25 18:15:33,633] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.75 | backward_inner: 105.22 | backward_allreduce: 11.44 | step: 44.75
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.6176], device='cuda:0'), 'moe loss': tensor([0.3016], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1705/439453125 | consumed samples:         1705 | consumed tokens:      3491840 | elapsed time per iteration (ms): 1851.9 | learning rate: 1.861E-06 | global batch size:     1 | lm loss: 8.923522E+00 | moe loss: 6.032364E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.540 | TFLOPs: 1.34 |
[default0]:[2023-08-25 18:15:33,898] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:33,899] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.47 | backward_microstep: 111.28 | backward_inner_microstep: 100.31 | backward_allreduce_microstep: 10.87 | step_microstep: 42.27
[default0]:[2023-08-25 18:15:33,899] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.47 (forward_moe: 20.28, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.05)
[default0]:[2023-08-25 18:15:33,899] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.28 | backward_inner: 100.32 | backward_allreduce: 10.88 | step: 42.27
[default0]:[2023-08-25 18:15:34,148] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:15:34,149] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.35 | backward_microstep: 111.34 | backward_inner_microstep: 100.44 | backward_allreduce_microstep: 10.80 | step_microstep: 42.31
[default0]:[2023-08-25 18:15:34,149] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.35 (forward_moe: 20.28, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.03)
[default0]:[2023-08-25 18:15:34,149] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.34 | backward_inner: 100.45 | backward_allreduce: 10.81 | step: 42.32
[default0]:[2023-08-25 18:15:34,394] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:34,395] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.83 | backward_microstep: 113.62 | backward_inner_microstep: 102.64 | backward_allreduce_microstep: 10.89 | step_microstep: 42.60
[default0]:[2023-08-25 18:15:34,395] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.82 (forward_moe: 20.33, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.09)
[default0]:[2023-08-25 18:15:34,395] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.62 | backward_inner: 102.64 | backward_allreduce: 10.89 | step: 42.60
[default0]:[2023-08-25 18:15:34,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.36
[default0]:[2023-08-25 18:15:34,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.65 | backward_microstep: 111.35 | backward_inner_microstep: 100.37 | backward_allreduce_microstep: 10.89 | step_microstep: 42.12
[default0]:[2023-08-25 18:15:34,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.65 (forward_moe: 20.22, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.03)
[default0]:[2023-08-25 18:15:34,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.35 | backward_inner: 100.38 | backward_allreduce: 10.89 | step: 42.12
[default0]:[2023-08-25 18:15:34,878] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:34,878] [INFO] [logging.py:96:log_dist] [Rank 0] step=1710, skipped=0, lr=[1.8666837333333333e-06, 1.8666837333333333e-06, 1.8666837333333333e-06, 1.8666837333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:34,878] [INFO] [timer.py:215:stop] epoch=0/micro_step=1710/global_step=1710, RunningAvgSamplesPerSec=4.919350176303128, CurrSamplesPerSec=5.079983964207724, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:34,878] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 109.02 | backward_inner_microstep: 98.11 | backward_allreduce_microstep: 10.70 | step_microstep: 41.79
[default0]:[2023-08-25 18:15:34,878] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:15:34,879] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.91 | backward_inner: 98.12 | backward_allreduce: 10.70 | step: 41.80
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.7652], device='cuda:0'), 'moe loss': tensor([0.3006], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1710/439453125 | consumed samples:         1710 | consumed tokens:      3502080 | elapsed time per iteration (ms): 247.9 | learning rate: 1.867E-06 | global batch size:     1 | lm loss: 9.153048E+00 | moe loss: 6.011933E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.034 | TFLOPs: 10.02 |
[default0]:[2023-08-25 18:15:35,125] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:15:35,126] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.78 | backward_microstep: 109.12 | backward_inner_microstep: 98.27 | backward_allreduce_microstep: 10.76 | step_microstep: 41.57
[default0]:[2023-08-25 18:15:35,126] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:15:35,126] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.12 | backward_inner: 98.27 | backward_allreduce: 10.76 | step: 41.57
[default0]:[2023-08-25 18:15:35,381] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:35,381] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 109.04 | backward_inner_microstep: 98.21 | backward_allreduce_microstep: 10.74 | step_microstep: 41.43
[default0]:[2023-08-25 18:15:35,381] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.73, 1st alltoall: 0.85, 2nd alltoall: 0.79, top-k: 7.70)
[default0]:[2023-08-25 18:15:35,381] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.04 | backward_inner: 98.21 | backward_allreduce: 10.75 | step: 41.44
[default0]:[2023-08-25 18:15:35,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:35,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.57 | backward_microstep: 113.28 | backward_inner_microstep: 100.86 | backward_allreduce_microstep: 12.32 | step_microstep: 42.62
[default0]:[2023-08-25 18:15:35,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.56 (forward_moe: 20.39, 1st alltoall: 0.87, 2nd alltoall: 0.86, top-k: 8.07)
[default0]:[2023-08-25 18:15:35,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.28 | backward_inner: 100.87 | backward_allreduce: 12.32 | step: 42.62
[default0]:[2023-08-25 18:15:36,057] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:36,058] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.62 | backward_microstep: 108.94 | backward_inner_microstep: 98.15 | backward_allreduce_microstep: 10.70 | step_microstep: 41.45
[default0]:[2023-08-25 18:15:36,058] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:15:36,058] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.94 | backward_inner: 98.16 | backward_allreduce: 10.70 | step: 41.45
[default0]:[2023-08-25 18:15:36,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:36,298] [INFO] [logging.py:96:log_dist] [Rank 0] step=1715, skipped=0, lr=[1.8721450666666666e-06, 1.8721450666666666e-06, 1.8721450666666666e-06, 1.8721450666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:36,298] [INFO] [timer.py:215:stop] epoch=0/micro_step=1715/global_step=1715, RunningAvgSamplesPerSec=4.9197194773309025, CurrSamplesPerSec=5.072464223820472, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:36,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 109.20 | backward_inner_microstep: 98.28 | backward_allreduce_microstep: 10.83 | step_microstep: 41.87
[default0]:[2023-08-25 18:15:36,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:15:36,299] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.20 | backward_inner: 98.28 | backward_allreduce: 10.83 | step: 41.87
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.3732], device='cuda:0'), 'moe loss': tensor([0.3002], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1715/439453125 | consumed samples:         1715 | consumed tokens:      3512320 | elapsed time per iteration (ms): 284.0 | learning rate: 1.872E-06 | global batch size:     1 | lm loss: 8.874641E+00 | moe loss: 6.004153E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.521 | TFLOPs: 8.75 |
[default0]:[2023-08-25 18:15:36,548] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:15:36,548] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.44 | backward_microstep: 109.59 | backward_inner_microstep: 98.71 | backward_allreduce_microstep: 10.79 | step_microstep: 41.69
[default0]:[2023-08-25 18:15:36,548] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:15:36,549] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.59 | backward_inner: 98.71 | backward_allreduce: 10.80 | step: 41.70
[default0]:[2023-08-25 18:15:36,779] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:36,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.38 | backward_microstep: 109.89 | backward_inner_microstep: 99.01 | backward_allreduce_microstep: 10.78 | step_microstep: 41.79
[default0]:[2023-08-25 18:15:36,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.38 (forward_moe: 19.96, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.86)
[default0]:[2023-08-25 18:15:36,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.88 | backward_inner: 99.01 | backward_allreduce: 10.79 | step: 41.79
[default0]:[2023-08-25 18:15:37,031] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:37,031] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.02 | backward_microstep: 110.91 | backward_inner_microstep: 99.85 | backward_allreduce_microstep: 10.96 | step_microstep: 42.13
[default0]:[2023-08-25 18:15:37,032] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.02 (forward_moe: 20.09, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.95)
[default0]:[2023-08-25 18:15:37,032] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.91 | backward_inner: 99.86 | backward_allreduce: 10.97 | step: 42.13
[default0]:[2023-08-25 18:15:37,277] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.34
[default0]:[2023-08-25 18:15:37,277] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.51 | backward_microstep: 110.69 | backward_inner_microstep: 99.75 | backward_allreduce_microstep: 10.85 | step_microstep: 42.25
[default0]:[2023-08-25 18:15:37,277] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.51 (forward_moe: 20.16, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.95)
[default0]:[2023-08-25 18:15:37,277] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.69 | backward_inner: 99.76 | backward_allreduce: 10.85 | step: 42.25
[default0]:[2023-08-25 18:15:37,605] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:15:37,605] [INFO] [logging.py:96:log_dist] [Rank 0] step=1720, skipped=0, lr=[1.8776064e-06, 1.8776064e-06, 1.8776064e-06, 1.8776064e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:37,605] [INFO] [timer.py:215:stop] epoch=0/micro_step=1720/global_step=1720, RunningAvgSamplesPerSec=4.91996409535326, CurrSamplesPerSec=4.940316491852131, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:37,605] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.42 | backward_microstep: 112.36 | backward_inner_microstep: 101.30 | backward_allreduce_microstep: 10.96 | step_microstep: 43.07
[default0]:[2023-08-25 18:15:37,605] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.42 (forward_moe: 20.69, 1st alltoall: 0.98, 2nd alltoall: 0.80, top-k: 8.16)
[default0]:[2023-08-25 18:15:37,606] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.36 | backward_inner: 101.31 | backward_allreduce: 10.97 | step: 43.07
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.9974], device='cuda:0'), 'moe loss': tensor([0.2996], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1720/439453125 | consumed samples:         1720 | consumed tokens:      3522560 | elapsed time per iteration (ms): 261.5 | learning rate: 1.878E-06 | global batch size:     1 | lm loss: 8.999478E+00 | moe loss: 5.991237E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.824 | TFLOPs: 9.50 |
[default0]:[2023-08-25 18:15:37,861] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.40
[default0]:[2023-08-25 18:15:37,861] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.23 | backward_microstep: 113.13 | backward_inner_microstep: 102.02 | backward_allreduce_microstep: 11.02 | step_microstep: 42.96
[default0]:[2023-08-25 18:15:37,861] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.23 (forward_moe: 20.60, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.24)
[default0]:[2023-08-25 18:15:37,861] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.13 | backward_inner: 102.02 | backward_allreduce: 11.02 | step: 42.97
[default0]:[2023-08-25 18:15:38,091] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:38,091] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.90 | backward_microstep: 109.07 | backward_inner_microstep: 98.23 | backward_allreduce_microstep: 10.75 | step_microstep: 41.47
[default0]:[2023-08-25 18:15:38,091] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.90 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:15:38,092] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.07 | backward_inner: 98.23 | backward_allreduce: 10.75 | step: 41.48
[default0]:[2023-08-25 18:15:38,356] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:38,530] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.62 | backward_microstep: 110.08 | backward_inner_microstep: 99.25 | backward_allreduce_microstep: 10.74 | step_microstep: 214.64
[default0]:[2023-08-25 18:15:38,530] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.84, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:15:38,530] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.08 | backward_inner: 99.25 | backward_allreduce: 10.74 | step: 214.65
[default0]:[2023-08-25 18:15:38,818] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:38,818] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.13 | backward_microstep: 109.40 | backward_inner_microstep: 98.58 | backward_allreduce_microstep: 10.73 | step_microstep: 41.53
[default0]:[2023-08-25 18:15:38,818] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.13 (forward_moe: 19.84, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:15:38,818] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.40 | backward_inner: 98.59 | backward_allreduce: 10.73 | step: 41.53
[default0]:[2023-08-25 18:15:39,072] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:15:39,073] [INFO] [logging.py:96:log_dist] [Rank 0] step=1725, skipped=0, lr=[1.8830677333333333e-06, 1.8830677333333333e-06, 1.8830677333333333e-06, 1.8830677333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:39,073] [INFO] [timer.py:215:stop] epoch=0/micro_step=1725/global_step=1725, RunningAvgSamplesPerSec=4.917838905435148, CurrSamplesPerSec=5.070544856683471, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:39,073] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 109.23 | backward_inner_microstep: 98.39 | backward_allreduce_microstep: 10.74 | step_microstep: 41.98
[default0]:[2023-08-25 18:15:39,073] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.81, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:15:39,073] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.23 | backward_inner: 98.40 | backward_allreduce: 10.75 | step: 41.99
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.1320], device='cuda:0'), 'moe loss': tensor([0.2999], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1725/439453125 | consumed samples:         1725 | consumed tokens:      3532800 | elapsed time per iteration (ms): 293.4 | learning rate: 1.883E-06 | global batch size:     1 | lm loss: 9.026394E+00 | moe loss: 5.998169E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.409 | TFLOPs: 8.47 |
[default0]:[2023-08-25 18:15:39,316] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:15:39,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.67 | backward_microstep: 109.41 | backward_inner_microstep: 98.59 | backward_allreduce_microstep: 10.72 | step_microstep: 41.67
[default0]:[2023-08-25 18:15:39,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.67 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:15:39,317] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.40 | backward_inner: 98.60 | backward_allreduce: 10.72 | step: 41.67
[default0]:[2023-08-25 18:15:39,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:39,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.43 | backward_microstep: 109.01 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.73 | step_microstep: 41.38
[default0]:[2023-08-25 18:15:39,564] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.43 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.70)
[default0]:[2023-08-25 18:15:39,565] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.18 | backward_allreduce: 10.74 | step: 41.38
[default0]:[2023-08-25 18:15:39,815] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:39,815] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 108.88 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.69 | step_microstep: 41.55
[default0]:[2023-08-25 18:15:39,815] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:15:39,815] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.88 | backward_inner: 98.11 | backward_allreduce: 10.69 | step: 41.55
[default0]:[2023-08-25 18:15:40,057] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:40,057] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.76 | backward_microstep: 108.81 | backward_inner_microstep: 97.97 | backward_allreduce_microstep: 10.75 | step_microstep: 41.44
[default0]:[2023-08-25 18:15:40,057] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.76 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:15:40,057] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.81 | backward_inner: 97.97 | backward_allreduce: 10.76 | step: 41.45
[default0]:[2023-08-25 18:15:40,297] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:40,297] [INFO] [logging.py:96:log_dist] [Rank 0] step=1730, skipped=0, lr=[1.8885290666666666e-06, 1.8885290666666666e-06, 1.8885290666666666e-06, 1.8885290666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:40,297] [INFO] [timer.py:215:stop] epoch=0/micro_step=1730/global_step=1730, RunningAvgSamplesPerSec=4.9182890167772655, CurrSamplesPerSec=5.079516403081398, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:40,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.42 | backward_microstep: 109.03 | backward_inner_microstep: 98.22 | backward_allreduce_microstep: 10.72 | step_microstep: 41.88
[default0]:[2023-08-25 18:15:40,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.42 (forward_moe: 19.85, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:15:40,298] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.23 | backward_allreduce: 10.72 | step: 41.89
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.7301], device='cuda:0'), 'moe loss': tensor([0.3006], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1730/439453125 | consumed samples:         1730 | consumed tokens:      3543040 | elapsed time per iteration (ms): 245.1 | learning rate: 1.889E-06 | global batch size:     1 | lm loss: 8.946022E+00 | moe loss: 6.012591E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.081 | TFLOPs: 10.14 |
[default0]:[2023-08-25 18:15:40,549] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.27
[default0]:[2023-08-25 18:15:40,550] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.59 | backward_microstep: 109.25 | backward_inner_microstep: 98.40 | backward_allreduce_microstep: 10.75 | step_microstep: 41.60
[default0]:[2023-08-25 18:15:40,550] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.59 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:15:40,550] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.25 | backward_inner: 98.41 | backward_allreduce: 10.76 | step: 41.60
[default0]:[2023-08-25 18:15:40,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.27
[default0]:[2023-08-25 18:15:40,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.69 | backward_microstep: 108.82 | backward_inner_microstep: 97.94 | backward_allreduce_microstep: 10.79 | step_microstep: 41.30
[default0]:[2023-08-25 18:15:40,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:15:40,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.82 | backward_inner: 97.94 | backward_allreduce: 10.79 | step: 41.30
[default0]:[2023-08-25 18:15:41,021] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:41,022] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.50 | backward_microstep: 110.11 | backward_inner_microstep: 99.22 | backward_allreduce_microstep: 10.80 | step_microstep: 42.69
[default0]:[2023-08-25 18:15:41,022] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.50 (forward_moe: 20.10, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.97)
[default0]:[2023-08-25 18:15:41,022] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.11 | backward_inner: 99.22 | backward_allreduce: 10.80 | step: 42.70
[default0]:[2023-08-25 18:15:41,264] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.94 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:41,265] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.27 | backward_microstep: 111.53 | backward_inner_microstep: 100.59 | backward_allreduce_microstep: 10.84 | step_microstep: 42.05
[default0]:[2023-08-25 18:15:41,265] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.27 (forward_moe: 20.59, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.38)
[default0]:[2023-08-25 18:15:41,265] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.53 | backward_inner: 100.60 | backward_allreduce: 10.85 | step: 42.06
[default0]:[2023-08-25 18:15:41,524] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:41,524] [INFO] [logging.py:96:log_dist] [Rank 0] step=1735, skipped=0, lr=[1.8939904e-06, 1.8939904e-06, 1.8939904e-06, 1.8939904e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:41,524] [INFO] [timer.py:215:stop] epoch=0/micro_step=1735/global_step=1735, RunningAvgSamplesPerSec=4.918616629642675, CurrSamplesPerSec=5.013475877533749, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:41,524] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.05 | backward_microstep: 110.33 | backward_inner_microstep: 99.42 | backward_allreduce_microstep: 10.81 | step_microstep: 42.54
[default0]:[2023-08-25 18:15:41,525] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.05 (forward_moe: 20.04, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.89)
[default0]:[2023-08-25 18:15:41,525] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.32 | backward_inner: 99.42 | backward_allreduce: 10.81 | step: 42.55
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.9306], device='cuda:0'), 'moe loss': tensor([0.2997], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1735/439453125 | consumed samples:         1735 | consumed tokens:      3553280 | elapsed time per iteration (ms): 245.8 | learning rate: 1.894E-06 | global batch size:     1 | lm loss: 8.986116E+00 | moe loss: 5.993244E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.068 | TFLOPs: 10.11 |
[default0]:[2023-08-25 18:15:41,773] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:15:41,773] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.22 | backward_microstep: 110.31 | backward_inner_microstep: 99.39 | backward_allreduce_microstep: 10.83 | step_microstep: 41.84
[default0]:[2023-08-25 18:15:41,773] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.22 (forward_moe: 20.03, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.90)
[default0]:[2023-08-25 18:15:41,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.30 | backward_inner: 99.39 | backward_allreduce: 10.83 | step: 41.84
[default0]:[2023-08-25 18:15:42,004] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:15:42,004] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.42 | backward_microstep: 110.38 | backward_inner_microstep: 99.48 | backward_allreduce_microstep: 10.81 | step_microstep: 41.97
[default0]:[2023-08-25 18:15:42,004] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.42 (forward_moe: 20.07, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.91)
[default0]:[2023-08-25 18:15:42,004] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.38 | backward_inner: 99.49 | backward_allreduce: 10.81 | step: 41.97
[default0]:[2023-08-25 18:15:42,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.37
[default0]:[2023-08-25 18:15:42,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.60 | backward_microstep: 110.26 | backward_inner_microstep: 99.34 | backward_allreduce_microstep: 10.83 | step_microstep: 41.84
[default0]:[2023-08-25 18:15:42,238] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.60 (forward_moe: 20.04, 1st alltoall: 0.87, 2nd alltoall: 0.83, top-k: 7.88)
[default0]:[2023-08-25 18:15:42,238] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.26 | backward_inner: 99.34 | backward_allreduce: 10.84 | step: 41.85
[default0]:[2023-08-25 18:15:42,639] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:42,640] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.91 | backward_microstep: 110.68 | backward_inner_microstep: 99.74 | backward_allreduce_microstep: 10.85 | step_microstep: 42.64
[default0]:[2023-08-25 18:15:42,640] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.90 (forward_moe: 20.11, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:15:42,640] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.68 | backward_inner: 99.75 | backward_allreduce: 10.85 | step: 42.65
[default0]:[2023-08-25 18:15:42,880] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 9.82
[default0]:[2023-08-25 18:15:42,881] [INFO] [logging.py:96:log_dist] [Rank 0] step=1740, skipped=0, lr=[1.8994517333333334e-06, 1.8994517333333334e-06, 1.8994517333333334e-06, 1.8994517333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:42,881] [INFO] [timer.py:215:stop] epoch=0/micro_step=1740/global_step=1740, RunningAvgSamplesPerSec=4.918777106713543, CurrSamplesPerSec=4.914424442392685, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:42,881] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.13 | backward_microstep: 110.97 | backward_inner_microstep: 100.07 | backward_allreduce_microstep: 10.80 | step_microstep: 45.83
[default0]:[2023-08-25 18:15:42,881] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.13 (forward_moe: 20.39, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.91)
[default0]:[2023-08-25 18:15:42,881] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.96 | backward_inner: 100.08 | backward_allreduce: 10.80 | step: 45.83
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.9181], device='cuda:0'), 'moe loss': tensor([0.3002], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1740/439453125 | consumed samples:         1740 | consumed tokens:      3563520 | elapsed time per iteration (ms): 270.7 | learning rate: 1.899E-06 | global batch size:     1 | lm loss: 8.983614E+00 | moe loss: 6.004184E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.694 | TFLOPs: 9.18 |
[default0]:[2023-08-25 18:15:43,132] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:43,133] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.80 | backward_microstep: 109.25 | backward_inner_microstep: 98.29 | backward_allreduce_microstep: 10.86 | step_microstep: 41.49
[default0]:[2023-08-25 18:15:43,133] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.80 (forward_moe: 19.89, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:15:43,133] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.24 | backward_inner: 98.29 | backward_allreduce: 10.87 | step: 41.49
[default0]:[2023-08-25 18:15:43,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:43,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.53 | backward_microstep: 109.41 | backward_inner_microstep: 98.55 | backward_allreduce_microstep: 10.77 | step_microstep: 43.08
[default0]:[2023-08-25 18:15:43,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.53 (forward_moe: 19.81, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.76)
[default0]:[2023-08-25 18:15:43,388] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.40 | backward_inner: 98.55 | backward_allreduce: 10.77 | step: 43.09
[default0]:[2023-08-25 18:15:43,632] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:43,634] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.74 | backward_microstep: 109.69 | backward_inner_microstep: 98.84 | backward_allreduce_microstep: 10.75 | step_microstep: 42.81
[default0]:[2023-08-25 18:15:43,634] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.74 (forward_moe: 20.01, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:15:43,634] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.69 | backward_inner: 98.85 | backward_allreduce: 10.76 | step: 42.82
[default0]:[2023-08-25 18:15:43,873] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.33
[default0]:[2023-08-25 18:15:43,873] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 109.18 | backward_inner_microstep: 98.31 | backward_allreduce_microstep: 10.78 | step_microstep: 41.48
[default0]:[2023-08-25 18:15:43,873] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.76, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:15:43,873] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.18 | backward_inner: 98.32 | backward_allreduce: 10.78 | step: 41.49
[default0]:[2023-08-25 18:15:44,113] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:44,113] [INFO] [logging.py:96:log_dist] [Rank 0] step=1745, skipped=0, lr=[1.9049130666666667e-06, 1.9049130666666667e-06, 1.9049130666666667e-06, 1.9049130666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:44,113] [INFO] [timer.py:215:stop] epoch=0/micro_step=1745/global_step=1745, RunningAvgSamplesPerSec=4.919090988536623, CurrSamplesPerSec=5.032822568065372, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:44,113] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.50 | backward_microstep: 110.66 | backward_inner_microstep: 99.81 | backward_allreduce_microstep: 10.76 | step_microstep: 41.99
[default0]:[2023-08-25 18:15:44,113] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.50 (forward_moe: 20.18, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.83)
[default0]:[2023-08-25 18:15:44,114] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.66 | backward_inner: 99.82 | backward_allreduce: 10.76 | step: 42.00
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.2387], device='cuda:0'), 'moe loss': tensor([0.3006], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1745/439453125 | consumed samples:         1745 | consumed tokens:      3573760 | elapsed time per iteration (ms): 246.6 | learning rate: 1.905E-06 | global batch size:     1 | lm loss: 9.047742E+00 | moe loss: 6.011645E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.056 | TFLOPs: 10.08 |
[default0]:[2023-08-25 18:15:44,362] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:44,362] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.94 | backward_microstep: 109.43 | backward_inner_microstep: 98.41 | backward_allreduce_microstep: 10.93 | step_microstep: 41.54
[default0]:[2023-08-25 18:15:44,364] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.94 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.78)
[default0]:[2023-08-25 18:15:44,364] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.43 | backward_inner: 98.42 | backward_allreduce: 10.93 | step: 41.54
[default0]:[2023-08-25 18:15:44,607] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:44,607] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.39 | backward_microstep: 109.41 | backward_inner_microstep: 98.55 | backward_allreduce_microstep: 10.77 | step_microstep: 41.52
[default0]:[2023-08-25 18:15:44,607] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.39 (forward_moe: 19.93, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:15:44,607] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.41 | backward_inner: 98.56 | backward_allreduce: 10.77 | step: 41.52
[default0]:[2023-08-25 18:15:44,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:44,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.78 | backward_microstep: 111.16 | backward_inner_microstep: 100.20 | backward_allreduce_microstep: 10.87 | step_microstep: 42.23
[default0]:[2023-08-25 18:15:44,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.78 (forward_moe: 20.28, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.05)
[default0]:[2023-08-25 18:15:44,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.16 | backward_inner: 100.20 | backward_allreduce: 10.87 | step: 42.23
[default0]:[2023-08-25 18:15:45,093] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.34
[default0]:[2023-08-25 18:15:45,094] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.67 | backward_microstep: 111.16 | backward_inner_microstep: 100.21 | backward_allreduce_microstep: 10.86 | step_microstep: 42.32
[default0]:[2023-08-25 18:15:45,094] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.67 (forward_moe: 20.26, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.05)
[default0]:[2023-08-25 18:15:45,094] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.16 | backward_inner: 100.21 | backward_allreduce: 10.86 | step: 42.32
[default0]:[2023-08-25 18:15:45,340] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:15:45,340] [INFO] [logging.py:96:log_dist] [Rank 0] step=1750, skipped=0, lr=[1.9103744e-06, 1.9103744e-06, 1.9103744e-06, 1.9103744e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:45,340] [INFO] [timer.py:215:stop] epoch=0/micro_step=1750/global_step=1750, RunningAvgSamplesPerSec=4.91938211790988, CurrSamplesPerSec=5.060780466851515, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:45,340] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 109.31 | backward_inner_microstep: 98.51 | backward_allreduce_microstep: 10.71 | step_microstep: 42.05
[default0]:[2023-08-25 18:15:45,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.97, 1st alltoall: 0.86, 2nd alltoall: 0.83, top-k: 7.76)
[default0]:[2023-08-25 18:15:45,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.31 | backward_inner: 98.51 | backward_allreduce: 10.72 | step: 42.06
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.5731], device='cuda:0'), 'moe loss': tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1750/439453125 | consumed samples:         1750 | consumed tokens:      3584000 | elapsed time per iteration (ms): 245.6 | learning rate: 1.910E-06 | global batch size:     1 | lm loss: 8.914613E+00 | moe loss: 6.010240E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.072 | TFLOPs: 10.12 |
[default0]:[2023-08-25 18:15:45,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:15:45,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.53 | backward_microstep: 109.41 | backward_inner_microstep: 98.55 | backward_allreduce_microstep: 10.77 | step_microstep: 41.75
[default0]:[2023-08-25 18:15:45,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.53 (forward_moe: 19.95, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.87)
[default0]:[2023-08-25 18:15:45,611] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.41 | backward_inner: 98.55 | backward_allreduce: 10.77 | step: 41.75
[default0]:[2023-08-25 18:15:45,855] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:45,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.67 | backward_microstep: 109.20 | backward_inner_microstep: 98.34 | backward_allreduce_microstep: 10.77 | step_microstep: 41.63
[default0]:[2023-08-25 18:15:45,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.67 (forward_moe: 19.89, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:15:45,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.20 | backward_inner: 98.34 | backward_allreduce: 10.78 | step: 41.64
[default0]:[2023-08-25 18:15:46,117] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:15:46,117] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 109.15 | backward_inner_microstep: 98.30 | backward_allreduce_microstep: 10.76 | step_microstep: 41.49
[default0]:[2023-08-25 18:15:46,117] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.54 (forward_moe: 19.90, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.88)
[default0]:[2023-08-25 18:15:46,118] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.15 | backward_inner: 98.31 | backward_allreduce: 10.76 | step: 41.49
[default0]:[2023-08-25 18:15:46,360] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:15:46,360] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 109.17 | backward_inner_microstep: 98.34 | backward_allreduce_microstep: 10.74 | step_microstep: 41.66
[default0]:[2023-08-25 18:15:46,361] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:15:46,361] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.17 | backward_inner: 98.34 | backward_allreduce: 10.74 | step: 41.66
[default0]:[2023-08-25 18:15:46,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 3.98 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:46,613] [INFO] [logging.py:96:log_dist] [Rank 0] step=1755, skipped=0, lr=[1.915835733333333e-06, 1.915835733333333e-06, 1.915835733333333e-06, 1.915835733333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:46,613] [INFO] [timer.py:215:stop] epoch=0/micro_step=1755/global_step=1755, RunningAvgSamplesPerSec=4.919769368670709, CurrSamplesPerSec=5.017962381170007, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:46,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.41 | backward_microstep: 109.40 | backward_inner_microstep: 98.55 | backward_allreduce_microstep: 10.75 | step_microstep: 42.92
[default0]:[2023-08-25 18:15:46,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.41 (forward_moe: 19.83, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:15:46,614] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.40 | backward_inner: 98.56 | backward_allreduce: 10.75 | step: 42.93
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.6644], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1755/439453125 | consumed samples:         1755 | consumed tokens:      3594240 | elapsed time per iteration (ms): 254.5 | learning rate: 1.916E-06 | global batch size:     1 | lm loss: 8.932875E+00 | moe loss: 6.015083E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.930 | TFLOPs: 9.76 |
[default0]:[2023-08-25 18:15:46,868] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:46,868] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.85 | backward_microstep: 109.21 | backward_inner_microstep: 98.39 | backward_allreduce_microstep: 10.73 | step_microstep: 41.84
[default0]:[2023-08-25 18:15:46,868] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.84 (forward_moe: 19.92, 1st alltoall: 0.86, 2nd alltoall: 0.89, top-k: 7.75)
[default0]:[2023-08-25 18:15:46,869] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.21 | backward_inner: 98.39 | backward_allreduce: 10.73 | step: 41.84
[default0]:[2023-08-25 18:15:47,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:47,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.85 | backward_microstep: 111.64 | backward_inner_microstep: 100.67 | backward_allreduce_microstep: 10.88 | step_microstep: 42.23
[default0]:[2023-08-25 18:15:47,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.85 (forward_moe: 20.61, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:15:47,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.64 | backward_inner: 100.67 | backward_allreduce: 10.88 | step: 42.24
[default0]:[2023-08-25 18:15:47,373] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:47,374] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.79 | backward_microstep: 111.92 | backward_inner_microstep: 100.93 | backward_allreduce_microstep: 10.89 | step_microstep: 42.52
[default0]:[2023-08-25 18:15:47,374] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.35, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.08)
[default0]:[2023-08-25 18:15:47,374] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.91 | backward_inner: 100.93 | backward_allreduce: 10.90 | step: 42.52
[default0]:[2023-08-25 18:15:47,619] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.36
[default0]:[2023-08-25 18:15:47,619] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.79 | backward_microstep: 112.45 | backward_inner_microstep: 101.45 | backward_allreduce_microstep: 10.90 | step_microstep: 42.62
[default0]:[2023-08-25 18:15:47,619] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.79 (forward_moe: 20.43, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:15:47,619] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.45 | backward_inner: 101.46 | backward_allreduce: 10.91 | step: 42.62
[default0]:[2023-08-25 18:15:47,864] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:15:47,864] [INFO] [logging.py:96:log_dist] [Rank 0] step=1760, skipped=0, lr=[1.9212970666666665e-06, 1.9212970666666665e-06, 1.9212970666666665e-06, 1.9212970666666665e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:47,864] [INFO] [timer.py:215:stop] epoch=0/micro_step=1760/global_step=1760, RunningAvgSamplesPerSec=4.9198065466801735, CurrSamplesPerSec=4.76995668228864, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:47,864] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.22 | backward_microstep: 117.25 | backward_inner_microstep: 105.69 | backward_allreduce_microstep: 11.45 | step_microstep: 43.61
[default0]:[2023-08-25 18:15:47,864] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.22 (forward_moe: 21.60, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.43)
[default0]:[2023-08-25 18:15:47,865] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.25 | backward_inner: 105.70 | backward_allreduce: 11.45 | step: 43.61
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.6881], device='cuda:0'), 'moe loss': tensor([0.2999], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1760/439453125 | consumed samples:         1760 | consumed tokens:      3604480 | elapsed time per iteration (ms): 250.0 | learning rate: 1.921E-06 | global batch size:     1 | lm loss: 8.937617E+00 | moe loss: 5.998001E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.001 | TFLOPs: 9.94 |
[default0]:[2023-08-25 18:15:48,122] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.40
[default0]:[2023-08-25 18:15:48,123] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.17 | backward_microstep: 113.13 | backward_inner_microstep: 102.06 | backward_allreduce_microstep: 10.96 | step_microstep: 42.99
[default0]:[2023-08-25 18:15:48,123] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.16 (forward_moe: 20.58, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.25)
[default0]:[2023-08-25 18:15:48,123] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.12 | backward_inner: 102.07 | backward_allreduce: 10.97 | step: 42.99
[default0]:[2023-08-25 18:15:48,370] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:48,371] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.69 | backward_microstep: 109.14 | backward_inner_microstep: 98.33 | backward_allreduce_microstep: 10.72 | step_microstep: 41.39
[default0]:[2023-08-25 18:15:48,371] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:15:48,371] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.14 | backward_inner: 98.34 | backward_allreduce: 10.72 | step: 41.40
[default0]:[2023-08-25 18:15:48,616] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:48,616] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.54 | backward_microstep: 108.92 | backward_inner_microstep: 98.11 | backward_allreduce_microstep: 10.72 | step_microstep: 41.50
[default0]:[2023-08-25 18:15:48,616] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.54 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:15:48,617] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.12 | backward_allreduce: 10.72 | step: 41.51
[default0]:[2023-08-25 18:15:48,886] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:48,886] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.05 | backward_microstep: 108.87 | backward_inner_microstep: 98.04 | backward_allreduce_microstep: 10.74 | step_microstep: 41.43
[default0]:[2023-08-25 18:15:48,886] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.05 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:15:48,886] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.87 | backward_inner: 98.04 | backward_allreduce: 10.74 | step: 41.44
[default0]:[2023-08-25 18:15:49,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:49,131] [INFO] [logging.py:96:log_dist] [Rank 0] step=1765, skipped=0, lr=[1.9267584e-06, 1.9267584e-06, 1.9267584e-06, 1.9267584e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:49,131] [INFO] [timer.py:215:stop] epoch=0/micro_step=1765/global_step=1765, RunningAvgSamplesPerSec=4.920142345386002, CurrSamplesPerSec=5.081350227941524, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:49,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 108.88 | backward_inner_microstep: 98.04 | backward_allreduce_microstep: 10.75 | step_microstep: 41.89
[default0]:[2023-08-25 18:15:49,132] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.76, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:15:49,132] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.88 | backward_inner: 98.04 | backward_allreduce: 10.75 | step: 41.90
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.4921], device='cuda:0'), 'moe loss': tensor([0.2994], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1765/439453125 | consumed samples:         1765 | consumed tokens:      3614720 | elapsed time per iteration (ms): 253.8 | learning rate: 1.927E-06 | global batch size:     1 | lm loss: 9.098415E+00 | moe loss: 5.988072E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.941 | TFLOPs: 9.79 |
[default0]:[2023-08-25 18:15:49,389] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.71 | optimizer_gradients: 3.98 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:49,390] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 109.29 | backward_inner_microstep: 98.48 | backward_allreduce_microstep: 10.71 | step_microstep: 41.73
[default0]:[2023-08-25 18:15:49,390] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.78)
[default0]:[2023-08-25 18:15:49,390] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.29 | backward_inner: 98.49 | backward_allreduce: 10.72 | step: 41.74
[default0]:[2023-08-25 18:15:49,643] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:49,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 108.97 | backward_inner_microstep: 98.11 | backward_allreduce_microstep: 10.77 | step_microstep: 41.74
[default0]:[2023-08-25 18:15:49,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 19.79, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:15:49,644] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.97 | backward_inner: 98.11 | backward_allreduce: 10.77 | step: 41.75
[default0]:[2023-08-25 18:15:49,883] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:15:49,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 112.95 | backward_inner_microstep: 102.09 | backward_allreduce_microstep: 10.76 | step_microstep: 41.59
[default0]:[2023-08-25 18:15:49,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 20.70, 1st alltoall: 0.91, 2nd alltoall: 0.83, top-k: 7.99)
[default0]:[2023-08-25 18:15:49,884] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.94 | backward_inner: 102.09 | backward_allreduce: 10.77 | step: 41.59
[default0]:[2023-08-25 18:15:50,119] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:50,119] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.86 | backward_microstep: 108.90 | backward_inner_microstep: 98.06 | backward_allreduce_microstep: 10.75 | step_microstep: 41.47
[default0]:[2023-08-25 18:15:50,119] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.86 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:15:50,120] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 98.06 | backward_allreduce: 10.75 | step: 41.47
[default0]:[2023-08-25 18:15:50,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:50,358] [INFO] [logging.py:96:log_dist] [Rank 0] step=1770, skipped=0, lr=[1.9322197333333335e-06, 1.9322197333333335e-06, 1.9322197333333335e-06, 1.9322197333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:50,358] [INFO] [timer.py:215:stop] epoch=0/micro_step=1770/global_step=1770, RunningAvgSamplesPerSec=4.9205107484057615, CurrSamplesPerSec=5.07407196820769, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:50,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 109.01 | backward_inner_microstep: 98.20 | backward_allreduce_microstep: 10.72 | step_microstep: 41.92
[default0]:[2023-08-25 18:15:50,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.90, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:15:50,359] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.20 | backward_allreduce: 10.72 | step: 41.93
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.9745], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1770/439453125 | consumed samples:         1770 | consumed tokens:      3624960 | elapsed time per iteration (ms): 245.0 | learning rate: 1.932E-06 | global batch size:     1 | lm loss: 8.794896E+00 | moe loss: 6.015241E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.081 | TFLOPs: 10.14 |
[default0]:[2023-08-25 18:15:50,605] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:50,606] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 109.23 | backward_inner_microstep: 98.43 | backward_allreduce_microstep: 10.70 | step_microstep: 41.51
[default0]:[2023-08-25 18:15:50,606] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.80, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:15:50,606] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.23 | backward_inner: 98.44 | backward_allreduce: 10.71 | step: 41.51
[default0]:[2023-08-25 18:15:50,852] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:15:50,853] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 108.77 | backward_inner_microstep: 97.91 | backward_allreduce_microstep: 10.76 | step_microstep: 41.46
[default0]:[2023-08-25 18:15:50,853] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.64 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.75)
[default0]:[2023-08-25 18:15:50,853] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.76 | backward_inner: 97.92 | backward_allreduce: 10.76 | step: 41.46
[default0]:[2023-08-25 18:15:51,102] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.28
[default0]:[2023-08-25 18:15:51,102] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 109.51 | backward_inner_microstep: 98.71 | backward_allreduce_microstep: 10.71 | step_microstep: 41.46
[default0]:[2023-08-25 18:15:51,103] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 20.06, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 8.04)
[default0]:[2023-08-25 18:15:51,103] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.51 | backward_inner: 98.71 | backward_allreduce: 10.71 | step: 41.46
[default0]:[2023-08-25 18:15:51,341] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.88 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:51,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 108.95 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.75 | step_microstep: 41.47
[default0]:[2023-08-25 18:15:51,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:15:51,342] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.95 | backward_inner: 98.11 | backward_allreduce: 10.76 | step: 41.47
[default0]:[2023-08-25 18:15:51,798] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:51,799] [INFO] [logging.py:96:log_dist] [Rank 0] step=1775, skipped=0, lr=[1.937681066666667e-06, 1.937681066666667e-06, 1.937681066666667e-06, 1.937681066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:51,799] [INFO] [timer.py:215:stop] epoch=0/micro_step=1775/global_step=1775, RunningAvgSamplesPerSec=4.920940055923947, CurrSamplesPerSec=5.082310744903214, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:51,799] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 108.79 | backward_inner_microstep: 97.95 | backward_allreduce_microstep: 10.75 | step_microstep: 41.96
[default0]:[2023-08-25 18:15:51,799] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.73, 1st alltoall: 0.85, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:15:51,799] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.79 | backward_inner: 97.96 | backward_allreduce: 10.75 | step: 41.97
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.2539], device='cuda:0'), 'moe loss': tensor([0.3003], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1775/439453125 | consumed samples:         1775 | consumed tokens:      3635200 | elapsed time per iteration (ms): 288.1 | learning rate: 1.938E-06 | global batch size:     1 | lm loss: 8.850778E+00 | moe loss: 6.006013E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.470 | TFLOPs: 8.62 |
[default0]:[2023-08-25 18:15:52,048] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:52,048] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.81 | backward_microstep: 108.85 | backward_inner_microstep: 97.98 | backward_allreduce_microstep: 10.78 | step_microstep: 41.59
[default0]:[2023-08-25 18:15:52,048] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.81 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:15:52,049] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.85 | backward_inner: 97.98 | backward_allreduce: 10.78 | step: 41.59
[default0]:[2023-08-25 18:15:52,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.28
[default0]:[2023-08-25 18:15:52,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.85 | backward_microstep: 108.86 | backward_inner_microstep: 98.05 | backward_allreduce_microstep: 10.72 | step_microstep: 41.39
[default0]:[2023-08-25 18:15:52,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.85 (forward_moe: 19.76, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:15:52,301] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.86 | backward_inner: 98.05 | backward_allreduce: 10.72 | step: 41.39
[default0]:[2023-08-25 18:15:52,536] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.28
[default0]:[2023-08-25 18:15:52,536] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 109.07 | backward_inner_microstep: 98.20 | backward_allreduce_microstep: 10.78 | step_microstep: 41.53
[default0]:[2023-08-25 18:15:52,536] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.49 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:15:52,536] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.07 | backward_inner: 98.20 | backward_allreduce: 10.78 | step: 41.53
[default0]:[2023-08-25 18:15:52,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.28
[default0]:[2023-08-25 18:15:52,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.94 | backward_microstep: 109.18 | backward_inner_microstep: 98.25 | backward_allreduce_microstep: 10.84 | step_microstep: 41.61
[default0]:[2023-08-25 18:15:52,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.94 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:15:52,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.18 | backward_inner: 98.26 | backward_allreduce: 10.84 | step: 41.62
[default0]:[2023-08-25 18:15:53,036] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 10.25
[default0]:[2023-08-25 18:15:53,037] [INFO] [logging.py:96:log_dist] [Rank 0] step=1780, skipped=0, lr=[1.9431424e-06, 1.9431424e-06, 1.9431424e-06, 1.9431424e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:53,037] [INFO] [timer.py:215:stop] epoch=0/micro_step=1780/global_step=1780, RunningAvgSamplesPerSec=4.921269697145233, CurrSamplesPerSec=4.964260859273287, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:53,037] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 109.21 | backward_inner_microstep: 98.40 | backward_allreduce_microstep: 10.72 | step_microstep: 46.04
[default0]:[2023-08-25 18:15:53,037] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.64 (forward_moe: 20.05, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:15:53,038] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.21 | backward_inner: 98.41 | backward_allreduce: 10.72 | step: 46.04
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.5851], device='cuda:0'), 'moe loss': tensor([0.3049], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1780/439453125 | consumed samples:         1780 | consumed tokens:      3645440 | elapsed time per iteration (ms): 248.0 | learning rate: 1.943E-06 | global batch size:     1 | lm loss: 9.117016E+00 | moe loss: 6.098976E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.033 | TFLOPs: 10.02 |
[default0]:[2023-08-25 18:15:53,353] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.27
[default0]:[2023-08-25 18:15:53,354] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.85 | backward_microstep: 109.49 | backward_inner_microstep: 98.64 | backward_allreduce_microstep: 10.76 | step_microstep: 41.54
[default0]:[2023-08-25 18:15:53,354] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.85 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.76)
[default0]:[2023-08-25 18:15:53,354] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.49 | backward_inner: 98.64 | backward_allreduce: 10.76 | step: 41.55
[default0]:[2023-08-25 18:15:53,612] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:15:53,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.30 | backward_microstep: 112.23 | backward_inner_microstep: 101.40 | backward_allreduce_microstep: 10.74 | step_microstep: 41.93
[default0]:[2023-08-25 18:15:53,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.30 (forward_moe: 19.70, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:15:53,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.22 | backward_inner: 101.40 | backward_allreduce: 10.74 | step: 41.93
[default0]:[2023-08-25 18:15:53,882] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:15:53,882] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.36 | backward_microstep: 110.33 | backward_inner_microstep: 99.47 | backward_allreduce_microstep: 10.77 | step_microstep: 41.46
[default0]:[2023-08-25 18:15:53,883] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.35 (forward_moe: 20.06, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.83)
[default0]:[2023-08-25 18:15:53,883] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.32 | backward_inner: 99.47 | backward_allreduce: 10.77 | step: 41.46
[default0]:[2023-08-25 18:15:54,123] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:54,123] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.34 | backward_microstep: 108.97 | backward_inner_microstep: 98.11 | backward_allreduce_microstep: 10.77 | step_microstep: 41.63
[default0]:[2023-08-25 18:15:54,124] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.34 (forward_moe: 19.70, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:15:54,124] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.11 | backward_allreduce: 10.77 | step: 41.64
[default0]:[2023-08-25 18:15:54,368] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.88 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:54,368] [INFO] [logging.py:96:log_dist] [Rank 0] step=1785, skipped=0, lr=[1.9486037333333335e-06, 1.9486037333333335e-06, 1.9486037333333335e-06, 1.9486037333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:54,368] [INFO] [timer.py:215:stop] epoch=0/micro_step=1785/global_step=1785, RunningAvgSamplesPerSec=4.921624802025199, CurrSamplesPerSec=5.074084244985259, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:54,368] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.94 | backward_microstep: 108.88 | backward_inner_microstep: 98.00 | backward_allreduce_microstep: 10.78 | step_microstep: 41.72
[default0]:[2023-08-25 18:15:54,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.93 (forward_moe: 19.71, 1st alltoall: 0.85, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:15:54,369] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.88 | backward_inner: 98.01 | backward_allreduce: 10.79 | step: 41.72
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.9753], device='cuda:0'), 'moe loss': tensor([0.3019], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1785/439453125 | consumed samples:         1785 | consumed tokens:      3655680 | elapsed time per iteration (ms): 266.5 | learning rate: 1.949E-06 | global batch size:     1 | lm loss: 8.995068E+00 | moe loss: 6.038800E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.752 | TFLOPs: 9.32 |
[default0]:[2023-08-25 18:15:54,620] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:54,621] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.07 | backward_microstep: 109.15 | backward_inner_microstep: 98.29 | backward_allreduce_microstep: 10.76 | step_microstep: 41.89
[default0]:[2023-08-25 18:15:54,621] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.07 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:15:54,621] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.14 | backward_inner: 98.30 | backward_allreduce: 10.76 | step: 41.89
[default0]:[2023-08-25 18:15:54,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:54,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.38 | backward_microstep: 109.09 | backward_inner_microstep: 98.20 | backward_allreduce_microstep: 10.80 | step_microstep: 41.37
[default0]:[2023-08-25 18:15:54,858] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.37 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:15:54,859] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.09 | backward_inner: 98.20 | backward_allreduce: 10.80 | step: 41.37
[default0]:[2023-08-25 18:15:55,088] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:55,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.67 | backward_microstep: 109.04 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.78 | step_microstep: 41.44
[default0]:[2023-08-25 18:15:55,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.67 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.84, top-k: 7.72)
[default0]:[2023-08-25 18:15:55,089] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.04 | backward_inner: 98.17 | backward_allreduce: 10.78 | step: 41.44
[default0]:[2023-08-25 18:15:55,320] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:55,320] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.85 | backward_microstep: 111.07 | backward_inner_microstep: 100.14 | backward_allreduce_microstep: 10.84 | step_microstep: 42.08
[default0]:[2023-08-25 18:15:55,320] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.85 (forward_moe: 20.24, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.99)
[default0]:[2023-08-25 18:15:55,320] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.07 | backward_inner: 100.14 | backward_allreduce: 10.85 | step: 42.08
[default0]:[2023-08-25 18:15:55,593] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:15:55,594] [INFO] [logging.py:96:log_dist] [Rank 0] step=1790, skipped=0, lr=[1.9540650666666668e-06, 1.9540650666666668e-06, 1.9540650666666668e-06, 1.9540650666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:55,594] [INFO] [timer.py:215:stop] epoch=0/micro_step=1790/global_step=1790, RunningAvgSamplesPerSec=4.921920468583814, CurrSamplesPerSec=4.959723202703645, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:55,594] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.74 | backward_microstep: 111.42 | backward_inner_microstep: 100.47 | backward_allreduce_microstep: 10.86 | step_microstep: 42.91
[default0]:[2023-08-25 18:15:55,594] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.74 (forward_moe: 20.39, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.02)
[default0]:[2023-08-25 18:15:55,594] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.42 | backward_inner: 100.48 | backward_allreduce: 10.86 | step: 42.91
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.1427], device='cuda:0'), 'moe loss': tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1790/439453125 | consumed samples:         1790 | consumed tokens:      3665920 | elapsed time per iteration (ms): 244.6 | learning rate: 1.954E-06 | global batch size:     1 | lm loss: 8.828535E+00 | moe loss: 6.010702E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.089 | TFLOPs: 10.16 |
[default0]:[2023-08-25 18:15:55,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.41
[default0]:[2023-08-25 18:15:55,856] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.71 | backward_microstep: 111.96 | backward_inner_microstep: 100.91 | backward_allreduce_microstep: 10.96 | step_microstep: 42.69
[default0]:[2023-08-25 18:15:55,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.71 (forward_moe: 20.38, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:15:55,857] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.96 | backward_inner: 100.91 | backward_allreduce: 10.96 | step: 42.70
[default0]:[2023-08-25 18:15:56,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.37
[default0]:[2023-08-25 18:15:56,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.03 | backward_microstep: 112.30 | backward_inner_microstep: 101.30 | backward_allreduce_microstep: 10.91 | step_microstep: 42.67
[default0]:[2023-08-25 18:15:56,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.03 (forward_moe: 20.48, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.18)
[default0]:[2023-08-25 18:15:56,096] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.30 | backward_inner: 101.31 | backward_allreduce: 10.91 | step: 42.67
[default0]:[2023-08-25 18:15:56,351] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.42
[default0]:[2023-08-25 18:15:56,357] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.22 | backward_microstep: 113.09 | backward_inner_microstep: 102.03 | backward_allreduce_microstep: 10.97 | step_microstep: 48.99
[default0]:[2023-08-25 18:15:56,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.22 (forward_moe: 20.60, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.24)
[default0]:[2023-08-25 18:15:56,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.10 | backward_inner: 102.04 | backward_allreduce: 10.97 | step: 49.00
[default0]:[2023-08-25 18:15:56,621] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.32
[default0]:[2023-08-25 18:15:56,622] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.65 | backward_microstep: 111.15 | backward_inner_microstep: 100.21 | backward_allreduce_microstep: 10.84 | step_microstep: 42.28
[default0]:[2023-08-25 18:15:56,622] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.66 (forward_moe: 20.41, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 8.10)
[default0]:[2023-08-25 18:15:56,622] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.15 | backward_inner: 100.22 | backward_allreduce: 10.85 | step: 42.29
[default0]:[2023-08-25 18:15:56,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.36
[default0]:[2023-08-25 18:15:56,862] [INFO] [logging.py:96:log_dist] [Rank 0] step=1795, skipped=0, lr=[1.9595264e-06, 1.9595264e-06, 1.9595264e-06, 1.9595264e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:56,862] [INFO] [timer.py:215:stop] epoch=0/micro_step=1795/global_step=1795, RunningAvgSamplesPerSec=4.921910907484335, CurrSamplesPerSec=4.990189289835933, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:56,862] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.40 | backward_microstep: 110.98 | backward_inner_microstep: 100.07 | backward_allreduce_microstep: 10.82 | step_microstep: 42.48
[default0]:[2023-08-25 18:15:56,863] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.40 (forward_moe: 20.22, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.01)
[default0]:[2023-08-25 18:15:56,863] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.98 | backward_inner: 100.08 | backward_allreduce: 10.82 | step: 42.48
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.5548], device='cuda:0'), 'moe loss': tensor([0.3035], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1795/439453125 | consumed samples:         1795 | consumed tokens:      3676160 | elapsed time per iteration (ms): 253.7 | learning rate: 1.960E-06 | global batch size:     1 | lm loss: 9.110967E+00 | moe loss: 6.070647E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.942 | TFLOPs: 9.79 |
[default0]:[2023-08-25 18:15:57,118] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.33
[default0]:[2023-08-25 18:15:57,119] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.26 | backward_microstep: 111.60 | backward_inner_microstep: 100.64 | backward_allreduce_microstep: 10.86 | step_microstep: 42.66
[default0]:[2023-08-25 18:15:57,119] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.26 (forward_moe: 20.41, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.21)
[default0]:[2023-08-25 18:15:57,119] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.60 | backward_inner: 100.65 | backward_allreduce: 10.86 | step: 42.67
[default0]:[2023-08-25 18:15:57,372] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.33
[default0]:[2023-08-25 18:15:57,373] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.75 | backward_microstep: 111.10 | backward_inner_microstep: 100.12 | backward_allreduce_microstep: 10.88 | step_microstep: 41.99
[default0]:[2023-08-25 18:15:57,373] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.75 (forward_moe: 20.20, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.02)
[default0]:[2023-08-25 18:15:57,373] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.10 | backward_inner: 100.13 | backward_allreduce: 10.89 | step: 42.00
[default0]:[2023-08-25 18:15:57,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.31
[default0]:[2023-08-25 18:15:57,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.76 | backward_microstep: 108.77 | backward_inner_microstep: 97.94 | backward_allreduce_microstep: 10.73 | step_microstep: 41.68
[default0]:[2023-08-25 18:15:57,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.76 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.73)
[default0]:[2023-08-25 18:15:57,613] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.76 | backward_inner: 97.95 | backward_allreduce: 10.73 | step: 41.68
[default0]:[2023-08-25 18:15:57,879] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:15:57,880] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.69 | backward_microstep: 108.94 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.69 | step_microstep: 41.44
[default0]:[2023-08-25 18:15:57,880] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.69 (forward_moe: 19.88, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:15:57,880] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.94 | backward_inner: 98.16 | backward_allreduce: 10.69 | step: 41.44
[default0]:[2023-08-25 18:15:58,122] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:15:58,122] [INFO] [logging.py:96:log_dist] [Rank 0] step=1800, skipped=0, lr=[1.9649877333333334e-06, 1.9649877333333334e-06, 1.9649877333333334e-06, 1.9649877333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:15:58,122] [INFO] [timer.py:215:stop] epoch=0/micro_step=1800/global_step=1800, RunningAvgSamplesPerSec=4.922218641188165, CurrSamplesPerSec=5.072973437156051, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:15:58,122] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.65 | backward_microstep: 109.09 | backward_inner_microstep: 98.27 | backward_allreduce_microstep: 10.73 | step_microstep: 41.83
[default0]:[2023-08-25 18:15:58,122] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.65 (forward_moe: 19.88, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:15:58,123] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.09 | backward_inner: 98.28 | backward_allreduce: 10.73 | step: 41.84
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.0997], device='cuda:0'), 'moe loss': tensor([0.3009], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1800/439453125 | consumed samples:         1800 | consumed tokens:      3686400 | elapsed time per iteration (ms): 252.1 | learning rate: 1.965E-06 | global batch size:     1 | lm loss: 8.819940E+00 | moe loss: 6.018457E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.967 | TFLOPs: 9.86 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1800 | lm loss value: 8.896043E+00 | lm loss PPL: 7.303017E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration    1800 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:16:01,967] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1800 is about to be saved!
[default0]:[2023-08-25 18:16:01,973] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:01,982] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:01,983] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:01,992] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:01,992] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,002] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,002] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,011] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,011] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,020] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,020] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,029] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,030] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,038] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,039] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,047] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,048] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,057] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,057] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,066] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,066] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,076] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,076] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,084] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,085] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,094] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,094] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,103] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,103] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,112] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,112] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,120] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,121] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,132] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,132] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,141] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,141] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,151] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,152] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,161] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,162] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,172] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,172] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,181] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,181] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,190] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,190] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,199] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,200] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:16:02,202] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:16:02,203] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:16:02,204] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:02,480] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:02,481] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:16:06,191] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:16:06,226] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1800/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:16:06,226] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1800 is ready now!
[default0]:  successfully saved checkpoint at iteration    1800 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.69, Latency(second): 4.262
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4262.12, 4262.12)
[default0]:[2023-08-25 18:16:06,494] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.16 | optimizer_step: 10.06
[default0]:[2023-08-25 18:16:06,495] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2297.66 | backward_microstep: 117.18 | backward_inner_microstep: 106.06 | backward_allreduce_microstep: 11.03 | step_microstep: 47.68
[default0]:[2023-08-25 18:16:06,496] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2297.64 (forward_moe: 21.48, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.77)
[default0]:[2023-08-25 18:16:06,496] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.18 | backward_inner: 106.07 | backward_allreduce: 11.03 | step: 47.69
[default0]:[2023-08-25 18:16:06,755] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.12 | optimizer_step: 6.52
[default0]:[2023-08-25 18:16:06,755] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.47 | backward_microstep: 116.71 | backward_inner_microstep: 105.64 | backward_allreduce_microstep: 10.98 | step_microstep: 43.57
[default0]:[2023-08-25 18:16:06,755] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.47 (forward_moe: 21.37, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.72)
[default0]:[2023-08-25 18:16:06,755] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.71 | backward_inner: 105.64 | backward_allreduce: 10.98 | step: 43.58
[default0]:[2023-08-25 18:16:07,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.13 | optimizer_step: 6.55
[default0]:[2023-08-25 18:16:07,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.81 | backward_microstep: 116.68 | backward_inner_microstep: 105.54 | backward_allreduce_microstep: 11.05 | step_microstep: 43.63
[default0]:[2023-08-25 18:16:07,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.80 (forward_moe: 21.39, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.72)
[default0]:[2023-08-25 18:16:07,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.68 | backward_inner: 105.54 | backward_allreduce: 11.06 | step: 43.63
[default0]:[2023-08-25 18:16:07,262] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:16:07,262] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.23 | backward_microstep: 112.77 | backward_inner_microstep: 101.79 | backward_allreduce_microstep: 10.89 | step_microstep: 43.00
[default0]:[2023-08-25 18:16:07,262] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.23 (forward_moe: 20.53, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.23)
[default0]:[2023-08-25 18:16:07,263] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.77 | backward_inner: 101.79 | backward_allreduce: 10.89 | step: 43.01
[default0]:[2023-08-25 18:16:07,508] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.38
[default0]:[2023-08-25 18:16:07,509] [INFO] [logging.py:96:log_dist] [Rank 0] step=1805, skipped=0, lr=[1.9704490666666667e-06, 1.9704490666666667e-06, 1.9704490666666667e-06, 1.9704490666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:07,509] [INFO] [timer.py:215:stop] epoch=0/micro_step=1805/global_step=1805, RunningAvgSamplesPerSec=4.921644649531238, CurrSamplesPerSec=4.848704562584679, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:07,509] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.95 | backward_microstep: 113.75 | backward_inner_microstep: 102.62 | backward_allreduce_microstep: 11.04 | step_microstep: 44.00
[default0]:[2023-08-25 18:16:07,510] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.95 (forward_moe: 21.03, 1st alltoall: 0.94, 2nd alltoall: 0.83, top-k: 8.30)
[default0]:[2023-08-25 18:16:07,510] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.75 | backward_inner: 102.62 | backward_allreduce: 11.04 | step: 44.00
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.3164], device='cuda:0'), 'moe loss': tensor([0.3009], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1805/439453125 | consumed samples:         1805 | consumed tokens:      3696640 | elapsed time per iteration (ms): 1877.4 | learning rate: 1.970E-06 | global batch size:     1 | lm loss: 9.063287E+00 | moe loss: 6.018109E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.533 | TFLOPs: 1.32 |
[default0]:[2023-08-25 18:16:07,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:16:07,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.45 | backward_microstep: 113.77 | backward_inner_microstep: 102.67 | backward_allreduce_microstep: 11.01 | step_microstep: 43.02
[default0]:[2023-08-25 18:16:07,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.45 (forward_moe: 20.79, 1st alltoall: 0.94, 2nd alltoall: 0.82, top-k: 8.30)
[default0]:[2023-08-25 18:16:07,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.77 | backward_inner: 102.67 | backward_allreduce: 11.01 | step: 43.03
[default0]:[2023-08-25 18:16:08,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.43
[default0]:[2023-08-25 18:16:08,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.48 | backward_microstep: 113.54 | backward_inner_microstep: 102.40 | backward_allreduce_microstep: 11.04 | step_microstep: 43.08
[default0]:[2023-08-25 18:16:08,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.48 (forward_moe: 20.74, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.33)
[default0]:[2023-08-25 18:16:08,034] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.54 | backward_inner: 102.41 | backward_allreduce: 11.05 | step: 43.08
[default0]:[2023-08-25 18:16:08,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:08,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 109.92 | backward_inner_microstep: 99.08 | backward_allreduce_microstep: 10.75 | step_microstep: 42.03
[default0]:[2023-08-25 18:16:08,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.99 (forward_moe: 19.92, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.84)
[default0]:[2023-08-25 18:16:08,281] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.92 | backward_inner: 99.08 | backward_allreduce: 10.75 | step: 42.03
[default0]:[2023-08-25 18:16:08,545] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:08,545] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.75 | backward_microstep: 110.18 | backward_inner_microstep: 99.25 | backward_allreduce_microstep: 10.84 | step_microstep: 41.74
[default0]:[2023-08-25 18:16:08,546] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.75 (forward_moe: 19.94, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:16:08,546] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.18 | backward_inner: 99.26 | backward_allreduce: 10.84 | step: 41.74
[default0]:[2023-08-25 18:16:08,779] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:16:08,779] [INFO] [logging.py:96:log_dist] [Rank 0] step=1810, skipped=0, lr=[1.9759104e-06, 1.9759104e-06, 1.9759104e-06, 1.9759104e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:08,779] [INFO] [timer.py:215:stop] epoch=0/micro_step=1810/global_step=1810, RunningAvgSamplesPerSec=4.9217427539399425, CurrSamplesPerSec=5.014542793880645, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:08,779] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.41 | backward_microstep: 110.18 | backward_inner_microstep: 99.26 | backward_allreduce_microstep: 10.81 | step_microstep: 42.30
[default0]:[2023-08-25 18:16:08,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.41 (forward_moe: 20.07, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.87)
[default0]:[2023-08-25 18:16:08,780] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.17 | backward_inner: 99.27 | backward_allreduce: 10.82 | step: 42.30
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.9295], device='cuda:0'), 'moe loss': tensor([0.3039], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1810/439453125 | consumed samples:         1810 | consumed tokens:      3706880 | elapsed time per iteration (ms): 253.8 | learning rate: 1.976E-06 | global batch size:     1 | lm loss: 9.185898E+00 | moe loss: 6.077596E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.939 | TFLOPs: 9.79 |
[default0]:[2023-08-25 18:16:09,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:09,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.05 | backward_microstep: 109.94 | backward_inner_microstep: 99.06 | backward_allreduce_microstep: 10.78 | step_microstep: 41.71
[default0]:[2023-08-25 18:16:09,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.05 (forward_moe: 20.03, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:16:09,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.94 | backward_inner: 99.07 | backward_allreduce: 10.79 | step: 41.71
[default0]:[2023-08-25 18:16:09,284] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:16:09,284] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.38 | backward_microstep: 108.92 | backward_inner_microstep: 98.11 | backward_allreduce_microstep: 10.71 | step_microstep: 41.44
[default0]:[2023-08-25 18:16:09,284] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.38 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:16:09,285] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.12 | backward_allreduce: 10.71 | step: 41.45
[default0]:[2023-08-25 18:16:09,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:16:09,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 109.19 | backward_inner_microstep: 98.40 | backward_allreduce_microstep: 10.70 | step_microstep: 41.60
[default0]:[2023-08-25 18:16:09,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.64 (forward_moe: 19.69, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:16:09,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.19 | backward_inner: 98.41 | backward_allreduce: 10.70 | step: 41.61
[default0]:[2023-08-25 18:16:09,760] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:09,760] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.74 | backward_microstep: 109.04 | backward_inner_microstep: 98.22 | backward_allreduce_microstep: 10.73 | step_microstep: 41.57
[default0]:[2023-08-25 18:16:09,761] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.74 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.82)
[default0]:[2023-08-25 18:16:09,761] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.04 | backward_inner: 98.23 | backward_allreduce: 10.73 | step: 41.57
[default0]:[2023-08-25 18:16:10,011] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.31
[default0]:[2023-08-25 18:16:10,011] [INFO] [logging.py:96:log_dist] [Rank 0] step=1815, skipped=0, lr=[1.9813717333333334e-06, 1.9813717333333334e-06, 1.9813717333333334e-06, 1.9813717333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:10,012] [INFO] [timer.py:215:stop] epoch=0/micro_step=1815/global_step=1815, RunningAvgSamplesPerSec=4.922135714997012, CurrSamplesPerSec=5.075662305350236, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:10,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 109.11 | backward_inner_microstep: 98.28 | backward_allreduce_microstep: 10.74 | step_microstep: 41.85
[default0]:[2023-08-25 18:16:10,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:16:10,012] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.11 | backward_inner: 98.28 | backward_allreduce: 10.74 | step: 41.86
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.7999], device='cuda:0'), 'moe loss': tensor([0.3013], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1815/439453125 | consumed samples:         1815 | consumed tokens:      3717120 | elapsed time per iteration (ms): 246.8 | learning rate: 1.981E-06 | global batch size:     1 | lm loss: 8.959973E+00 | moe loss: 6.026711E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.051 | TFLOPs: 10.07 |
[default0]:[2023-08-25 18:16:10,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.28
[default0]:[2023-08-25 18:16:10,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.69 | backward_microstep: 109.05 | backward_inner_microstep: 98.22 | backward_allreduce_microstep: 10.74 | step_microstep: 41.42
[default0]:[2023-08-25 18:16:10,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.77, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:16:10,292] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.22 | backward_allreduce: 10.74 | step: 41.43
[default0]:[2023-08-25 18:16:10,527] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:10,527] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.72 | backward_microstep: 108.93 | backward_inner_microstep: 98.13 | backward_allreduce_microstep: 10.70 | step_microstep: 41.76
[default0]:[2023-08-25 18:16:10,527] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.72 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.72)
[default0]:[2023-08-25 18:16:10,527] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.14 | backward_allreduce: 10.70 | step: 41.76
[default0]:[2023-08-25 18:16:10,766] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:10,767] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.65 | backward_microstep: 109.23 | backward_inner_microstep: 98.38 | backward_allreduce_microstep: 10.76 | step_microstep: 41.54
[default0]:[2023-08-25 18:16:10,767] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.66 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:16:10,767] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.23 | backward_inner: 98.39 | backward_allreduce: 10.76 | step: 41.54
[default0]:[2023-08-25 18:16:11,014] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.34
[default0]:[2023-08-25 18:16:11,014] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.93 | backward_microstep: 111.80 | backward_inner_microstep: 100.82 | backward_allreduce_microstep: 10.88 | step_microstep: 43.29
[default0]:[2023-08-25 18:16:11,014] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.93 (forward_moe: 20.44, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:16:11,014] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.79 | backward_inner: 100.82 | backward_allreduce: 10.89 | step: 43.29
[default0]:[2023-08-25 18:16:11,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:16:11,260] [INFO] [logging.py:96:log_dist] [Rank 0] step=1820, skipped=0, lr=[1.9868330666666667e-06, 1.9868330666666667e-06, 1.9868330666666667e-06, 1.9868330666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:11,260] [INFO] [timer.py:215:stop] epoch=0/micro_step=1820/global_step=1820, RunningAvgSamplesPerSec=4.9223958309475275, CurrSamplesPerSec=4.9247590342348095, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:11,260] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.75 | backward_microstep: 112.95 | backward_inner_microstep: 101.97 | backward_allreduce_microstep: 10.89 | step_microstep: 42.80
[default0]:[2023-08-25 18:16:11,260] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.75 (forward_moe: 20.99, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.38)
[default0]:[2023-08-25 18:16:11,260] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.95 | backward_inner: 101.97 | backward_allreduce: 10.89 | step: 42.80
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.6757], device='cuda:0'), 'moe loss': tensor([0.3011], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1820/439453125 | consumed samples:         1820 | consumed tokens:      3727360 | elapsed time per iteration (ms): 249.8 | learning rate: 1.987E-06 | global batch size:     1 | lm loss: 8.935148E+00 | moe loss: 6.022654E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.003 | TFLOPs: 9.95 |
[default0]:[2023-08-25 18:16:11,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.39
[default0]:[2023-08-25 18:16:11,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.94 | backward_microstep: 112.02 | backward_inner_microstep: 101.02 | backward_allreduce_microstep: 10.91 | step_microstep: 42.58
[default0]:[2023-08-25 18:16:11,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.94 (forward_moe: 20.36, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.10)
[default0]:[2023-08-25 18:16:11,516] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.02 | backward_inner: 101.03 | backward_allreduce: 10.91 | step: 42.58
[default0]:[2023-08-25 18:16:11,775] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:11,775] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.89 | backward_microstep: 112.32 | backward_inner_microstep: 101.26 | backward_allreduce_microstep: 10.93 | step_microstep: 42.67
[default0]:[2023-08-25 18:16:11,775] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.89 (forward_moe: 20.48, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.17)
[default0]:[2023-08-25 18:16:11,776] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.32 | backward_inner: 101.26 | backward_allreduce: 10.97 | step: 42.67
[default0]:[2023-08-25 18:16:12,022] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:16:12,022] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.34 | backward_microstep: 112.85 | backward_inner_microstep: 101.82 | backward_allreduce_microstep: 10.94 | step_microstep: 42.81
[default0]:[2023-08-25 18:16:12,366] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.33 (forward_moe: 20.65, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.25)
[default0]:[2023-08-25 18:16:12,367] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.85 | backward_inner: 101.82 | backward_allreduce: 10.94 | step: 42.82
[default0]:[2023-08-25 18:16:12,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.17 | optimizer_step: 6.54
[default0]:[2023-08-25 18:16:12,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.94 | backward_microstep: 117.94 | backward_inner_microstep: 106.56 | backward_allreduce_microstep: 11.28 | step_microstep: 44.56
[default0]:[2023-08-25 18:16:12,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.93 (forward_moe: 21.57, 1st alltoall: 0.90, 2nd alltoall: 0.86, top-k: 8.83)
[default0]:[2023-08-25 18:16:12,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.94 | backward_inner: 106.57 | backward_allreduce: 11.28 | step: 44.57
[default0]:[2023-08-25 18:16:12,886] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.42
[default0]:[2023-08-25 18:16:12,887] [INFO] [logging.py:96:log_dist] [Rank 0] step=1825, skipped=0, lr=[1.9922944e-06, 1.9922944e-06, 1.9922944e-06, 1.9922944e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:12,887] [INFO] [timer.py:215:stop] epoch=0/micro_step=1825/global_step=1825, RunningAvgSamplesPerSec=4.922214207981973, CurrSamplesPerSec=4.824249701813046, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:12,887] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.07 | backward_microstep: 114.81 | backward_inner_microstep: 103.67 | backward_allreduce_microstep: 11.04 | step_microstep: 43.84
[default0]:[2023-08-25 18:16:12,887] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.07 (forward_moe: 21.15, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.48)
[default0]:[2023-08-25 18:16:12,887] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.81 | backward_inner: 103.68 | backward_allreduce: 11.05 | step: 43.84
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.0154], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1825/439453125 | consumed samples:         1825 | consumed tokens:      3737600 | elapsed time per iteration (ms): 325.6 | learning rate: 1.992E-06 | global batch size:     1 | lm loss: 8.803073E+00 | moe loss: 6.015460E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.071 | TFLOPs: 7.63 |
[default0]:[2023-08-25 18:16:13,148] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.42
[default0]:[2023-08-25 18:16:13,148] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.27 | backward_microstep: 114.80 | backward_inner_microstep: 103.66 | backward_allreduce_microstep: 11.05 | step_microstep: 43.45
[default0]:[2023-08-25 18:16:13,149] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.27 (forward_moe: 21.05, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.49)
[default0]:[2023-08-25 18:16:13,149] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.80 | backward_inner: 103.66 | backward_allreduce: 11.06 | step: 43.46
[default0]:[2023-08-25 18:16:13,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 7.69
[default0]:[2023-08-25 18:16:13,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.17 | backward_microstep: 114.89 | backward_inner_microstep: 103.69 | backward_allreduce_microstep: 11.11 | step_microstep: 44.82
[default0]:[2023-08-25 18:16:13,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.17 (forward_moe: 21.02, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.48)
[default0]:[2023-08-25 18:16:13,403] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.89 | backward_inner: 103.69 | backward_allreduce: 11.11 | step: 44.82
[default0]:[2023-08-25 18:16:13,649] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.08 | optimizer_step: 6.46
[default0]:[2023-08-25 18:16:13,649] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.64 | backward_microstep: 115.20 | backward_inner_microstep: 104.02 | backward_allreduce_microstep: 11.09 | step_microstep: 43.54
[default0]:[2023-08-25 18:16:13,650] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.64 (forward_moe: 21.01, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.50)
[default0]:[2023-08-25 18:16:13,650] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.20 | backward_inner: 104.02 | backward_allreduce: 11.09 | step: 43.55
[default0]:[2023-08-25 18:16:13,889] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.75 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:16:13,890] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.58 | backward_microstep: 111.35 | backward_inner_microstep: 100.37 | backward_allreduce_microstep: 10.89 | step_microstep: 42.41
[default0]:[2023-08-25 18:16:13,890] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.57 (forward_moe: 20.28, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 8.05)
[default0]:[2023-08-25 18:16:13,890] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.35 | backward_inner: 100.37 | backward_allreduce: 10.90 | step: 42.41
[default0]:[2023-08-25 18:16:14,137] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:16:14,137] [INFO] [logging.py:96:log_dist] [Rank 0] step=1830, skipped=0, lr=[1.9977557333333333e-06, 1.9977557333333333e-06, 1.9977557333333333e-06, 1.9977557333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:14,137] [INFO] [timer.py:215:stop] epoch=0/micro_step=1830/global_step=1830, RunningAvgSamplesPerSec=4.922026141185164, CurrSamplesPerSec=4.9607849630747545, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:14,137] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.53 | backward_microstep: 111.71 | backward_inner_microstep: 100.75 | backward_allreduce_microstep: 10.86 | step_microstep: 42.79
[default0]:[2023-08-25 18:16:14,138] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.53 (forward_moe: 20.42, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.04)
[default0]:[2023-08-25 18:16:14,138] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.71 | backward_inner: 100.76 | backward_allreduce: 10.87 | step: 42.80
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.9368], device='cuda:0'), 'moe loss': tensor([0.3015], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1830/439453125 | consumed samples:         1830 | consumed tokens:      3747840 | elapsed time per iteration (ms): 249.7 | learning rate: 1.998E-06 | global batch size:     1 | lm loss: 8.987361E+00 | moe loss: 6.030406E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.005 | TFLOPs: 9.95 |
[default0]:[2023-08-25 18:16:14,397] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.97 | optimizer_step: 6.35
[default0]:[2023-08-25 18:16:14,398] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.66 | backward_microstep: 111.73 | backward_inner_microstep: 100.75 | backward_allreduce_microstep: 10.88 | step_microstep: 42.35
[default0]:[2023-08-25 18:16:14,398] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.66 (forward_moe: 20.34, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.04)
[default0]:[2023-08-25 18:16:14,398] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.72 | backward_inner: 100.76 | backward_allreduce: 10.88 | step: 42.36
[default0]:[2023-08-25 18:16:14,662] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.36
[default0]:[2023-08-25 18:16:14,662] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.52 | backward_microstep: 111.62 | backward_inner_microstep: 100.58 | backward_allreduce_microstep: 10.85 | step_microstep: 42.18
[default0]:[2023-08-25 18:16:14,662] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.52 (forward_moe: 20.27, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.06)
[default0]:[2023-08-25 18:16:14,663] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.61 | backward_inner: 100.58 | backward_allreduce: 10.86 | step: 42.18
[default0]:[2023-08-25 18:16:14,892] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:14,892] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.97 | backward_microstep: 109.06 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.79 | step_microstep: 41.50
[default0]:[2023-08-25 18:16:14,892] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.97 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:16:14,893] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.06 | backward_inner: 98.19 | backward_allreduce: 10.79 | step: 41.51
[default0]:[2023-08-25 18:16:15,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:16:15,131] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.49 | backward_microstep: 108.92 | backward_inner_microstep: 98.12 | backward_allreduce_microstep: 10.70 | step_microstep: 41.36
[default0]:[2023-08-25 18:16:15,132] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.48 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:16:15,132] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.91 | backward_inner: 98.13 | backward_allreduce: 10.70 | step: 41.36
[default0]:[2023-08-25 18:16:15,386] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:16:15,386] [INFO] [logging.py:96:log_dist] [Rank 0] step=1835, skipped=0, lr=[2.0032170666666666e-06, 2.0032170666666666e-06, 2.0032170666666666e-06, 2.0032170666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:15,386] [INFO] [timer.py:215:stop] epoch=0/micro_step=1835/global_step=1835, RunningAvgSamplesPerSec=4.92232437346162, CurrSamplesPerSec=5.085089667613939, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:15,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.62 | backward_microstep: 108.78 | backward_inner_microstep: 97.99 | backward_allreduce_microstep: 10.69 | step_microstep: 41.72
[default0]:[2023-08-25 18:16:15,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:16:15,387] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.78 | backward_inner: 98.00 | backward_allreduce: 10.70 | step: 41.73
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.9512], device='cuda:0'), 'moe loss': tensor([0.3002], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1835/439453125 | consumed samples:         1835 | consumed tokens:      3758080 | elapsed time per iteration (ms): 249.6 | learning rate: 2.003E-06 | global batch size:     1 | lm loss: 8.990240E+00 | moe loss: 6.004390E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.007 | TFLOPs: 9.96 |
[default0]:[2023-08-25 18:16:15,674] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:15,675] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 109.03 | backward_inner_microstep: 98.19 | backward_allreduce_microstep: 10.74 | step_microstep: 41.45
[default0]:[2023-08-25 18:16:15,675] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.44 (forward_moe: 19.76, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:16:15,675] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.20 | backward_allreduce: 10.75 | step: 41.45
[default0]:[2023-08-25 18:16:15,915] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:16:15,915] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.64 | backward_microstep: 108.99 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.73 | step_microstep: 41.56
[default0]:[2023-08-25 18:16:15,915] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.64 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:16:15,915] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.99 | backward_inner: 98.18 | backward_allreduce: 10.73 | step: 41.56
[default0]:[2023-08-25 18:16:16,150] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.40
[default0]:[2023-08-25 18:16:16,151] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.53 | backward_microstep: 108.79 | backward_inner_microstep: 97.99 | backward_allreduce_microstep: 10.71 | step_microstep: 41.51
[default0]:[2023-08-25 18:16:16,151] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.53 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:16:16,151] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.79 | backward_inner: 97.99 | backward_allreduce: 10.72 | step: 41.52
[default0]:[2023-08-25 18:16:16,391] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:16:16,392] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.50 | backward_microstep: 110.83 | backward_inner_microstep: 100.00 | backward_allreduce_microstep: 10.74 | step_microstep: 42.58
[default0]:[2023-08-25 18:16:16,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.50 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:16:16,393] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.83 | backward_inner: 100.00 | backward_allreduce: 10.74 | step: 42.59
[default0]:[2023-08-25 18:16:16,722] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.89 | optimizer_step: 10.50
[default0]:[2023-08-25 18:16:16,722] [INFO] [logging.py:96:log_dist] [Rank 0] step=1840, skipped=0, lr=[2.0086784e-06, 2.0086784e-06, 2.0086784e-06, 2.0086784e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:16,723] [INFO] [timer.py:215:stop] epoch=0/micro_step=1840/global_step=1840, RunningAvgSamplesPerSec=4.922556619676032, CurrSamplesPerSec=4.806107003184359, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:16,723] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.35 | backward_microstep: 112.72 | backward_inner_microstep: 101.59 | backward_allreduce_microstep: 11.03 | step_microstep: 46.47
[default0]:[2023-08-25 18:16:16,723] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.34 (forward_moe: 20.62, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 7.91)
[default0]:[2023-08-25 18:16:16,723] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.71 | backward_inner: 101.60 | backward_allreduce: 11.03 | step: 46.47
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.7474], device='cuda:0'), 'moe loss': tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1840/439453125 | consumed samples:         1840 | consumed tokens:      3768320 | elapsed time per iteration (ms): 267.4 | learning rate: 2.009E-06 | global batch size:     1 | lm loss: 8.749485E+00 | moe loss: 6.009726E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.740 | TFLOPs: 9.29 |
[default0]:[2023-08-25 18:16:16,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:16,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.84 | backward_microstep: 109.28 | backward_inner_microstep: 98.41 | backward_allreduce_microstep: 10.77 | step_microstep: 41.51
[default0]:[2023-08-25 18:16:16,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.84 (forward_moe: 19.89, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.85)
[default0]:[2023-08-25 18:16:16,967] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.27 | backward_inner: 98.41 | backward_allreduce: 10.78 | step: 41.51
[default0]:[2023-08-25 18:16:17,200] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:17,201] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.00 | backward_microstep: 108.82 | backward_inner_microstep: 98.00 | backward_allreduce_microstep: 10.72 | step_microstep: 41.48
[default0]:[2023-08-25 18:16:17,201] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.99 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:16:17,201] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.82 | backward_inner: 98.01 | backward_allreduce: 10.72 | step: 41.49
[default0]:[2023-08-25 18:16:17,472] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:17,473] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 108.98 | backward_inner_microstep: 98.15 | backward_allreduce_microstep: 10.74 | step_microstep: 41.49
[default0]:[2023-08-25 18:16:17,473] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.67 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:16:17,473] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.98 | backward_inner: 98.15 | backward_allreduce: 10.74 | step: 41.49
[default0]:[2023-08-25 18:16:17,704] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 3.95 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:17,705] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.11 | backward_microstep: 109.13 | backward_inner_microstep: 98.32 | backward_allreduce_microstep: 10.72 | step_microstep: 42.23
[default0]:[2023-08-25 18:16:17,705] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.10 (forward_moe: 19.77, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:16:17,705] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.13 | backward_inner: 98.33 | backward_allreduce: 10.72 | step: 42.24
[default0]:[2023-08-25 18:16:17,953] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:17,954] [INFO] [logging.py:96:log_dist] [Rank 0] step=1845, skipped=0, lr=[2.0141397333333332e-06, 2.0141397333333332e-06, 2.0141397333333332e-06, 2.0141397333333332e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:17,954] [INFO] [timer.py:215:stop] epoch=0/micro_step=1845/global_step=1845, RunningAvgSamplesPerSec=4.922877985983085, CurrSamplesPerSec=4.961882397477834, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:17,954] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.22 | backward_microstep: 111.21 | backward_inner_microstep: 100.39 | backward_allreduce_microstep: 10.72 | step_microstep: 42.55
[default0]:[2023-08-25 18:16:17,955] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.22 (forward_moe: 20.34, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 7.86)
[default0]:[2023-08-25 18:16:17,955] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.21 | backward_inner: 100.40 | backward_allreduce: 10.73 | step: 42.56
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.2696], device='cuda:0'), 'moe loss': tensor([0.3034], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1845/439453125 | consumed samples:         1845 | consumed tokens:      3778560 | elapsed time per iteration (ms): 246.3 | learning rate: 2.014E-06 | global batch size:     1 | lm loss: 8.853914E+00 | moe loss: 6.067114E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.060 | TFLOPs: 10.09 |
[default0]:[2023-08-25 18:16:18,291] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:18,291] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 108.91 | backward_inner_microstep: 98.07 | backward_allreduce_microstep: 10.75 | step_microstep: 41.62
[default0]:[2023-08-25 18:16:18,291] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.71, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:16:18,291] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.91 | backward_inner: 98.08 | backward_allreduce: 10.75 | step: 41.62
[default0]:[2023-08-25 18:16:18,528] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:16:18,528] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.98 | backward_microstep: 110.46 | backward_inner_microstep: 99.66 | backward_allreduce_microstep: 10.71 | step_microstep: 41.51
[default0]:[2023-08-25 18:16:18,528] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.98 (forward_moe: 19.86, 1st alltoall: 0.93, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:16:18,529] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.46 | backward_inner: 99.66 | backward_allreduce: 10.71 | step: 41.51
[default0]:[2023-08-25 18:16:18,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:18,775] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 108.97 | backward_inner_microstep: 98.07 | backward_allreduce_microstep: 10.80 | step_microstep: 41.51
[default0]:[2023-08-25 18:16:18,775] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 19.72, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.70)
[default0]:[2023-08-25 18:16:18,775] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.97 | backward_inner: 98.07 | backward_allreduce: 10.81 | step: 41.51
[default0]:[2023-08-25 18:16:19,018] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:16:19,018] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 109.03 | backward_inner_microstep: 98.17 | backward_allreduce_microstep: 10.76 | step_microstep: 41.50
[default0]:[2023-08-25 18:16:19,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:16:19,019] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.18 | backward_allreduce: 10.76 | step: 41.50
[default0]:[2023-08-25 18:16:19,256] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:16:19,256] [INFO] [logging.py:96:log_dist] [Rank 0] step=1850, skipped=0, lr=[2.0196010666666666e-06, 2.0196010666666666e-06, 2.0196010666666666e-06, 2.0196010666666666e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:19,256] [INFO] [timer.py:215:stop] epoch=0/micro_step=1850/global_step=1850, RunningAvgSamplesPerSec=4.9232596241408, CurrSamplesPerSec=5.068675943661291, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:19,257] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.60 | backward_microstep: 109.20 | backward_inner_microstep: 98.37 | backward_allreduce_microstep: 10.74 | step_microstep: 41.98
[default0]:[2023-08-25 18:16:19,257] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.60 (forward_moe: 19.90, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:16:19,257] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.20 | backward_inner: 98.37 | backward_allreduce: 10.74 | step: 41.99
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.7049], device='cuda:0'), 'moe loss': tensor([0.3023], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1850/439453125 | consumed samples:         1850 | consumed tokens:      3788800 | elapsed time per iteration (ms): 260.3 | learning rate: 2.020E-06 | global batch size:     1 | lm loss: 8.740982E+00 | moe loss: 6.045476E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.842 | TFLOPs: 9.55 |
[default0]:[2023-08-25 18:16:19,498] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:19,498] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.41 | backward_microstep: 109.18 | backward_inner_microstep: 98.35 | backward_allreduce_microstep: 10.73 | step_microstep: 41.55
[default0]:[2023-08-25 18:16:19,498] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.41 (forward_moe: 19.76, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:16:19,498] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.18 | backward_inner: 98.36 | backward_allreduce: 10.74 | step: 41.55
[default0]:[2023-08-25 18:16:19,758] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 3.95 | optimizer_step: 6.34
[default0]:[2023-08-25 18:16:19,758] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.82 | backward_microstep: 108.92 | backward_inner_microstep: 98.09 | backward_allreduce_microstep: 10.74 | step_microstep: 42.08
[default0]:[2023-08-25 18:16:19,758] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.82 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.72)
[default0]:[2023-08-25 18:16:19,758] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 98.10 | backward_allreduce: 10.74 | step: 42.09
[default0]:[2023-08-25 18:16:20,008] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:20,009] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.24 | backward_microstep: 109.05 | backward_inner_microstep: 98.24 | backward_allreduce_microstep: 10.72 | step_microstep: 41.63
[default0]:[2023-08-25 18:16:20,009] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.24 (forward_moe: 19.84, 1st alltoall: 0.85, 2nd alltoall: 0.81, top-k: 7.73)
[default0]:[2023-08-25 18:16:20,009] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.25 | backward_allreduce: 10.72 | step: 41.63
[default0]:[2023-08-25 18:16:20,236] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:20,236] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.52 | backward_microstep: 110.23 | backward_inner_microstep: 99.37 | backward_allreduce_microstep: 10.76 | step_microstep: 41.93
[default0]:[2023-08-25 18:16:20,236] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.52 (forward_moe: 19.96, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.85)
[default0]:[2023-08-25 18:16:20,237] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.23 | backward_inner: 99.38 | backward_allreduce: 10.77 | step: 41.94
[default0]:[2023-08-25 18:16:20,492] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:20,492] [INFO] [logging.py:96:log_dist] [Rank 0] step=1855, skipped=0, lr=[2.0250624000000003e-06, 2.0250624000000003e-06, 2.0250624000000003e-06, 2.0250624000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:20,493] [INFO] [timer.py:215:stop] epoch=0/micro_step=1855/global_step=1855, RunningAvgSamplesPerSec=4.923576529756667, CurrSamplesPerSec=4.985657467127238, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:20,493] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.58 | backward_microstep: 110.99 | backward_inner_microstep: 100.08 | backward_allreduce_microstep: 10.82 | step_microstep: 42.45
[default0]:[2023-08-25 18:16:20,493] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.58 (forward_moe: 20.25, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.04)
[default0]:[2023-08-25 18:16:20,493] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.99 | backward_inner: 100.08 | backward_allreduce: 10.82 | step: 42.45
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.5527], device='cuda:0'), 'moe loss': tensor([0.3011], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1855/439453125 | consumed samples:         1855 | consumed tokens:      3799040 | elapsed time per iteration (ms): 247.2 | learning rate: 2.025E-06 | global batch size:     1 | lm loss: 8.910542E+00 | moe loss: 6.021073E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.045 | TFLOPs: 10.05 |
[default0]:[2023-08-25 18:16:20,728] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:20,728] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.51 | backward_microstep: 109.20 | backward_inner_microstep: 98.36 | backward_allreduce_microstep: 10.74 | step_microstep: 41.68
[default0]:[2023-08-25 18:16:20,728] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.51 (forward_moe: 19.80, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.70)
[default0]:[2023-08-25 18:16:20,729] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.20 | backward_inner: 98.37 | backward_allreduce: 10.75 | step: 41.69
[default0]:[2023-08-25 18:16:20,973] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:16:20,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.65 | backward_microstep: 109.21 | backward_inner_microstep: 98.39 | backward_allreduce_microstep: 10.72 | step_microstep: 41.46
[default0]:[2023-08-25 18:16:20,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.65 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:16:20,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.20 | backward_inner: 98.40 | backward_allreduce: 10.73 | step: 41.46
[default0]:[2023-08-25 18:16:21,216] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:16:21,216] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.54 | backward_microstep: 110.03 | backward_inner_microstep: 99.19 | backward_allreduce_microstep: 10.74 | step_microstep: 41.35
[default0]:[2023-08-25 18:16:21,216] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.54 (forward_moe: 19.91, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:16:21,216] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.02 | backward_inner: 99.19 | backward_allreduce: 10.75 | step: 41.36
[default0]:[2023-08-25 18:16:21,452] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:21,452] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.50 | backward_microstep: 108.90 | backward_inner_microstep: 98.08 | backward_allreduce_microstep: 10.72 | step_microstep: 41.54
[default0]:[2023-08-25 18:16:21,452] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.50 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:16:21,452] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 98.09 | backward_allreduce: 10.72 | step: 41.54
[default0]:[2023-08-25 18:16:21,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.31
[default0]:[2023-08-25 18:16:21,692] [INFO] [logging.py:96:log_dist] [Rank 0] step=1860, skipped=0, lr=[2.0305237333333336e-06, 2.0305237333333336e-06, 2.0305237333333336e-06, 2.0305237333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:21,692] [INFO] [timer.py:215:stop] epoch=0/micro_step=1860/global_step=1860, RunningAvgSamplesPerSec=4.923962243442353, CurrSamplesPerSec=5.0713173345714475, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:21,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 109.31 | backward_inner_microstep: 98.46 | backward_allreduce_microstep: 10.76 | step_microstep: 41.88
[default0]:[2023-08-25 18:16:21,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 19.89, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:16:21,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.30 | backward_inner: 98.46 | backward_allreduce: 10.76 | step: 41.89
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.1231], device='cuda:0'), 'moe loss': tensor([0.3006], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1860/439453125 | consumed samples:         1860 | consumed tokens:      3809280 | elapsed time per iteration (ms): 240.1 | learning rate: 2.031E-06 | global batch size:     1 | lm loss: 8.824611E+00 | moe loss: 6.012210E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.165 | TFLOPs: 10.35 |
[default0]:[2023-08-25 18:16:21,937] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:21,937] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 109.00 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.72 | step_microstep: 41.52
[default0]:[2023-08-25 18:16:21,937] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.70 (forward_moe: 19.82, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.79)
[default0]:[2023-08-25 18:16:21,937] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.03 | backward_inner: 98.19 | backward_allreduce: 10.72 | step: 41.53
[default0]:[2023-08-25 18:16:22,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:22,183] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 109.20 | backward_inner_microstep: 98.37 | backward_allreduce_microstep: 10.73 | step_microstep: 41.61
[default0]:[2023-08-25 18:16:22,184] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.46 (forward_moe: 20.06, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:16:22,184] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.19 | backward_inner: 98.37 | backward_allreduce: 10.74 | step: 41.62
[default0]:[2023-08-25 18:16:22,423] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.31
[default0]:[2023-08-25 18:16:22,424] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 108.90 | backward_inner_microstep: 98.07 | backward_allreduce_microstep: 10.74 | step_microstep: 41.45
[default0]:[2023-08-25 18:16:22,424] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 19.74, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.75)
[default0]:[2023-08-25 18:16:22,424] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 98.07 | backward_allreduce: 10.75 | step: 41.45
[default0]:[2023-08-25 18:16:22,650] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:22,650] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.87 | backward_microstep: 108.92 | backward_inner_microstep: 97.97 | backward_allreduce_microstep: 10.85 | step_microstep: 41.37
[default0]:[2023-08-25 18:16:22,650] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.87 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:16:22,651] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.92 | backward_inner: 97.98 | backward_allreduce: 10.85 | step: 41.37
[default0]:[2023-08-25 18:16:22,937] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:22,937] [INFO] [logging.py:96:log_dist] [Rank 0] step=1865, skipped=0, lr=[2.035985066666667e-06, 2.035985066666667e-06, 2.035985066666667e-06, 2.035985066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:22,937] [INFO] [timer.py:215:stop] epoch=0/micro_step=1865/global_step=1865, RunningAvgSamplesPerSec=4.924361981515673, CurrSamplesPerSec=5.07986706585666, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:22,938] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.46 | backward_microstep: 109.00 | backward_inner_microstep: 98.15 | backward_allreduce_microstep: 10.75 | step_microstep: 41.88
[default0]:[2023-08-25 18:16:22,938] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.75, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.73)
[default0]:[2023-08-25 18:16:22,938] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.16 | backward_allreduce: 10.75 | step: 41.88
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.5142], device='cuda:0'), 'moe loss': tensor([0.3037], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1865/439453125 | consumed samples:         1865 | consumed tokens:      3819520 | elapsed time per iteration (ms): 249.0 | learning rate: 2.036E-06 | global batch size:     1 | lm loss: 9.102843E+00 | moe loss: 6.073014E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.016 | TFLOPs: 9.98 |
[default0]:[2023-08-25 18:16:23,233] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:16:23,234] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.35 | backward_microstep: 109.38 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 11.12 | step_microstep: 42.07
[default0]:[2023-08-25 18:16:23,234] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.35 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:16:23,234] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.38 | backward_inner: 98.17 | backward_allreduce: 11.13 | step: 42.07
[default0]:[2023-08-25 18:16:23,462] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 3.90 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:23,462] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.76 | backward_microstep: 109.06 | backward_inner_microstep: 98.24 | backward_allreduce_microstep: 10.73 | step_microstep: 42.68
[default0]:[2023-08-25 18:16:23,462] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.76 (forward_moe: 19.73, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.71)
[default0]:[2023-08-25 18:16:23,462] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.06 | backward_inner: 98.25 | backward_allreduce: 10.73 | step: 42.68
[default0]:[2023-08-25 18:16:23,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.35
[default0]:[2023-08-25 18:16:23,692] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.33 | backward_microstep: 111.33 | backward_inner_microstep: 100.26 | backward_allreduce_microstep: 10.98 | step_microstep: 42.38
[default0]:[2023-08-25 18:16:23,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.33 (forward_moe: 20.47, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.03)
[default0]:[2023-08-25 18:16:23,693] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.33 | backward_inner: 100.27 | backward_allreduce: 10.98 | step: 42.38
[default0]:[2023-08-25 18:16:23,955] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:23,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.39 | backward_microstep: 111.18 | backward_inner_microstep: 100.17 | backward_allreduce_microstep: 10.91 | step_microstep: 42.25
[default0]:[2023-08-25 18:16:23,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.38 (forward_moe: 20.18, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.99)
[default0]:[2023-08-25 18:16:23,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.18 | backward_inner: 100.18 | backward_allreduce: 10.91 | step: 42.25
[default0]:[2023-08-25 18:16:24,199] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:24,199] [INFO] [logging.py:96:log_dist] [Rank 0] step=1870, skipped=0, lr=[2.0414464000000002e-06, 2.0414464000000002e-06, 2.0414464000000002e-06, 2.0414464000000002e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:24,200] [INFO] [timer.py:215:stop] epoch=0/micro_step=1870/global_step=1870, RunningAvgSamplesPerSec=4.924518970020526, CurrSamplesPerSec=4.929806477394938, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:24,200] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.80 | backward_microstep: 112.62 | backward_inner_microstep: 101.62 | backward_allreduce_microstep: 10.90 | step_microstep: 42.83
[default0]:[2023-08-25 18:16:24,200] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.80 (forward_moe: 20.63, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:16:24,200] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.62 | backward_inner: 101.63 | backward_allreduce: 10.91 | step: 42.83
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.0916], device='cuda:0'), 'moe loss': tensor([0.3037], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1870/439453125 | consumed samples:         1870 | consumed tokens:      3829760 | elapsed time per iteration (ms): 252.7 | learning rate: 2.041E-06 | global batch size:     1 | lm loss: 8.818323E+00 | moe loss: 6.073080E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.957 | TFLOPs: 9.83 |
[default0]:[2023-08-25 18:16:24,455] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:24,455] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.80 | backward_microstep: 111.97 | backward_inner_microstep: 100.95 | backward_allreduce_microstep: 10.92 | step_microstep: 42.57
[default0]:[2023-08-25 18:16:24,455] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.80 (forward_moe: 20.45, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.14)
[default0]:[2023-08-25 18:16:24,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.96 | backward_inner: 100.96 | backward_allreduce: 10.92 | step: 42.57
[default0]:[2023-08-25 18:16:24,701] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.35
[default0]:[2023-08-25 18:16:24,701] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.09 | backward_microstep: 112.48 | backward_inner_microstep: 101.32 | backward_allreduce_microstep: 11.07 | step_microstep: 42.61
[default0]:[2023-08-25 18:16:24,701] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.09 (forward_moe: 20.50, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.19)
[default0]:[2023-08-25 18:16:24,702] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.48 | backward_inner: 101.32 | backward_allreduce: 11.07 | step: 42.61
[default0]:[2023-08-25 18:16:24,957] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:16:24,957] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.05 | backward_microstep: 112.82 | backward_inner_microstep: 101.63 | backward_allreduce_microstep: 11.09 | step_microstep: 42.89
[default0]:[2023-08-25 18:16:24,957] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.05 (forward_moe: 20.57, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.25)
[default0]:[2023-08-25 18:16:24,957] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.82 | backward_inner: 101.64 | backward_allreduce: 11.10 | step: 42.89
[default0]:[2023-08-25 18:16:25,210] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:25,211] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.30 | backward_microstep: 112.56 | backward_inner_microstep: 101.55 | backward_allreduce_microstep: 10.91 | step_microstep: 42.66
[default0]:[2023-08-25 18:16:25,211] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.30 (forward_moe: 20.63, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.20)
[default0]:[2023-08-25 18:16:25,211] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.56 | backward_inner: 101.56 | backward_allreduce: 10.92 | step: 42.67
[default0]:[2023-08-25 18:16:25,456] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:16:25,457] [INFO] [logging.py:96:log_dist] [Rank 0] step=1875, skipped=0, lr=[2.0469077333333335e-06, 2.0469077333333335e-06, 2.0469077333333335e-06, 2.0469077333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:25,457] [INFO] [timer.py:215:stop] epoch=0/micro_step=1875/global_step=1875, RunningAvgSamplesPerSec=4.924517162891431, CurrSamplesPerSec=4.917310986239796, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:25,457] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.22 | backward_microstep: 112.52 | backward_inner_microstep: 101.49 | backward_allreduce_microstep: 10.93 | step_microstep: 43.05
[default0]:[2023-08-25 18:16:25,457] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.22 (forward_moe: 20.52, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:16:25,457] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.52 | backward_inner: 101.50 | backward_allreduce: 10.94 | step: 43.06
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([42.9439], device='cuda:0'), 'moe loss': tensor([0.3015], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1875/439453125 | consumed samples:         1875 | consumed tokens:      3840000 | elapsed time per iteration (ms): 252.3 | learning rate: 2.047E-06 | global batch size:     1 | lm loss: 8.588788E+00 | moe loss: 6.029955E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.963 | TFLOPs: 9.85 |
[default0]:[2023-08-25 18:16:25,719] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:16:25,719] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.40 | backward_microstep: 112.67 | backward_inner_microstep: 101.66 | backward_allreduce_microstep: 10.91 | step_microstep: 42.67
[default0]:[2023-08-25 18:16:25,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.40 (forward_moe: 20.61, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.22)
[default0]:[2023-08-25 18:16:25,720] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.66 | backward_inner: 101.67 | backward_allreduce: 10.91 | step: 42.67
[default0]:[2023-08-25 18:16:25,953] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.31
[default0]:[2023-08-25 18:16:25,953] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.19 | backward_microstep: 110.38 | backward_inner_microstep: 99.50 | backward_allreduce_microstep: 10.79 | step_microstep: 42.02
[default0]:[2023-08-25 18:16:25,953] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.19 (forward_moe: 20.06, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.91)
[default0]:[2023-08-25 18:16:25,954] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.38 | backward_inner: 99.50 | backward_allreduce: 10.80 | step: 42.03
[default0]:[2023-08-25 18:16:26,193] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:26,193] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.05 | backward_microstep: 110.37 | backward_inner_microstep: 99.47 | backward_allreduce_microstep: 10.81 | step_microstep: 41.79
[default0]:[2023-08-25 18:16:26,193] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.05 (forward_moe: 20.02, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.91)
[default0]:[2023-08-25 18:16:26,194] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.37 | backward_inner: 99.48 | backward_allreduce: 10.81 | step: 41.80
[default0]:[2023-08-25 18:16:26,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.34
[default0]:[2023-08-25 18:16:26,436] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.28 | backward_microstep: 112.20 | backward_inner_microstep: 101.29 | backward_allreduce_microstep: 10.81 | step_microstep: 42.54
[default0]:[2023-08-25 18:16:26,436] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.28 (forward_moe: 20.03, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:16:26,437] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.19 | backward_inner: 101.30 | backward_allreduce: 10.81 | step: 42.54
[default0]:[2023-08-25 18:16:26,690] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.34
[default0]:[2023-08-25 18:16:26,690] [INFO] [logging.py:96:log_dist] [Rank 0] step=1880, skipped=0, lr=[2.052369066666667e-06, 2.052369066666667e-06, 2.052369066666667e-06, 2.052369066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:26,691] [INFO] [timer.py:215:stop] epoch=0/micro_step=1880/global_step=1880, RunningAvgSamplesPerSec=4.924667154496691, CurrSamplesPerSec=5.0036373353565935, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:26,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.21 | backward_microstep: 110.53 | backward_inner_microstep: 99.64 | backward_allreduce_microstep: 10.80 | step_microstep: 42.56
[default0]:[2023-08-25 18:16:26,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.21 (forward_moe: 20.24, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.98)
[default0]:[2023-08-25 18:16:26,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.53 | backward_inner: 99.64 | backward_allreduce: 10.80 | step: 42.57
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.5859], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1880/439453125 | consumed samples:         1880 | consumed tokens:      3850240 | elapsed time per iteration (ms): 245.7 | learning rate: 2.052E-06 | global batch size:     1 | lm loss: 8.717181E+00 | moe loss: 6.013663E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.069 | TFLOPs: 10.11 |
[default0]:[2023-08-25 18:16:26,955] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 9.97
[default0]:[2023-08-25 18:16:26,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.09 | backward_microstep: 110.53 | backward_inner_microstep: 99.62 | backward_allreduce_microstep: 10.82 | step_microstep: 46.76
[default0]:[2023-08-25 18:16:26,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.09 (forward_moe: 20.10, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.90)
[default0]:[2023-08-25 18:16:26,956] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.53 | backward_inner: 99.62 | backward_allreduce: 10.82 | step: 46.76
[default0]:[2023-08-25 18:16:27,206] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:27,206] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.14 | backward_microstep: 110.57 | backward_inner_microstep: 99.67 | backward_allreduce_microstep: 10.81 | step_microstep: 41.93
[default0]:[2023-08-25 18:16:27,206] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.14 (forward_moe: 20.08, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.89)
[default0]:[2023-08-25 18:16:27,206] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.57 | backward_inner: 99.68 | backward_allreduce: 10.81 | step: 41.93
[default0]:[2023-08-25 18:16:27,461] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:27,461] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.03 | backward_microstep: 110.44 | backward_inner_microstep: 99.56 | backward_allreduce_microstep: 10.78 | step_microstep: 41.95
[default0]:[2023-08-25 18:16:27,461] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.03 (forward_moe: 20.04, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:16:27,461] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.44 | backward_inner: 99.57 | backward_allreduce: 10.79 | step: 41.96
[default0]:[2023-08-25 18:16:27,731] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:27,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.02 | backward_microstep: 112.86 | backward_inner_microstep: 101.83 | backward_allreduce_microstep: 10.93 | step_microstep: 43.22
[default0]:[2023-08-25 18:16:27,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.02 (forward_moe: 20.59, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.25)
[default0]:[2023-08-25 18:16:27,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.86 | backward_inner: 101.84 | backward_allreduce: 10.94 | step: 43.23
[default0]:[2023-08-25 18:16:27,973] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.34
[default0]:[2023-08-25 18:16:27,974] [INFO] [logging.py:96:log_dist] [Rank 0] step=1885, skipped=0, lr=[2.0578304e-06, 2.0578304e-06, 2.0578304e-06, 2.0578304e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:27,974] [INFO] [timer.py:215:stop] epoch=0/micro_step=1885/global_step=1885, RunningAvgSamplesPerSec=4.924747300514028, CurrSamplesPerSec=4.992404810167866, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:27,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.27 | backward_microstep: 110.66 | backward_inner_microstep: 99.74 | backward_allreduce_microstep: 10.83 | step_microstep: 42.82
[default0]:[2023-08-25 18:16:27,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.27 (forward_moe: 20.15, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 8.00)
[default0]:[2023-08-25 18:16:27,974] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.66 | backward_inner: 99.75 | backward_allreduce: 10.83 | step: 42.82
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.9564], device='cuda:0'), 'moe loss': tensor([0.3009], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1885/439453125 | consumed samples:         1885 | consumed tokens:      3860480 | elapsed time per iteration (ms): 256.9 | learning rate: 2.058E-06 | global batch size:     1 | lm loss: 8.791280E+00 | moe loss: 6.018410E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.893 | TFLOPs: 9.67 |
[default0]:[2023-08-25 18:16:28,228] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:28,228] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.36 | backward_microstep: 110.71 | backward_inner_microstep: 99.78 | backward_allreduce_microstep: 10.83 | step_microstep: 42.00
[default0]:[2023-08-25 18:16:28,228] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.36 (forward_moe: 20.15, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.96)
[default0]:[2023-08-25 18:16:28,229] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.71 | backward_inner: 99.79 | backward_allreduce: 10.83 | step: 42.01
[default0]:[2023-08-25 18:16:28,477] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.36
[default0]:[2023-08-25 18:16:28,477] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.27 | backward_microstep: 110.61 | backward_inner_microstep: 99.69 | backward_allreduce_microstep: 10.82 | step_microstep: 43.71
[default0]:[2023-08-25 18:16:28,477] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.27 (forward_moe: 20.09, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.92)
[default0]:[2023-08-25 18:16:28,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.61 | backward_inner: 99.70 | backward_allreduce: 10.82 | step: 43.71
[default0]:[2023-08-25 18:16:28,725] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.35
[default0]:[2023-08-25 18:16:28,725] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.35 | backward_microstep: 110.57 | backward_inner_microstep: 99.68 | backward_allreduce_microstep: 10.79 | step_microstep: 42.00
[default0]:[2023-08-25 18:16:28,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.34 (forward_moe: 20.23, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.07)
[default0]:[2023-08-25 18:16:28,726] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.56 | backward_inner: 99.69 | backward_allreduce: 10.80 | step: 42.00
[default0]:[2023-08-25 18:16:28,972] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.34
[default0]:[2023-08-25 18:16:28,972] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.22 | backward_microstep: 110.77 | backward_inner_microstep: 99.83 | backward_allreduce_microstep: 10.84 | step_microstep: 42.38
[default0]:[2023-08-25 18:16:28,973] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.22 (forward_moe: 20.25, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 7.97)
[default0]:[2023-08-25 18:16:28,973] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.77 | backward_inner: 99.84 | backward_allreduce: 10.84 | step: 42.38
[default0]:[2023-08-25 18:16:29,217] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.31
[default0]:[2023-08-25 18:16:29,218] [INFO] [logging.py:96:log_dist] [Rank 0] step=1890, skipped=0, lr=[2.0632917333333335e-06, 2.0632917333333335e-06, 2.0632917333333335e-06, 2.0632917333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:29,218] [INFO] [timer.py:215:stop] epoch=0/micro_step=1890/global_step=1890, RunningAvgSamplesPerSec=4.924929195955513, CurrSamplesPerSec=5.002288673392353, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:29,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.20 | backward_microstep: 110.89 | backward_inner_microstep: 99.99 | backward_allreduce_microstep: 10.80 | step_microstep: 42.27
[default0]:[2023-08-25 18:16:29,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.20 (forward_moe: 20.24, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 7.93)
[default0]:[2023-08-25 18:16:29,218] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.89 | backward_inner: 100.00 | backward_allreduce: 10.81 | step: 42.27
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.1515], device='cuda:0'), 'moe loss': tensor([0.2997], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1890/439453125 | consumed samples:         1890 | consumed tokens:      3870720 | elapsed time per iteration (ms): 248.1 | learning rate: 2.063E-06 | global batch size:     1 | lm loss: 8.830306E+00 | moe loss: 5.993425E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.030 | TFLOPs: 10.01 |
[default0]:[2023-08-25 18:16:29,463] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:29,463] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.09 | backward_microstep: 110.63 | backward_inner_microstep: 99.71 | backward_allreduce_microstep: 10.83 | step_microstep: 42.02
[default0]:[2023-08-25 18:16:29,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.09 (forward_moe: 20.20, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.03)
[default0]:[2023-08-25 18:16:29,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.63 | backward_inner: 99.72 | backward_allreduce: 10.83 | step: 42.02
[default0]:[2023-08-25 18:16:29,727] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:16:29,727] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.38 | backward_microstep: 112.58 | backward_inner_microstep: 101.57 | backward_allreduce_microstep: 10.92 | step_microstep: 43.20
[default0]:[2023-08-25 18:16:29,728] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.38 (forward_moe: 20.50, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:16:29,728] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.58 | backward_inner: 101.57 | backward_allreduce: 10.92 | step: 43.20
[default0]:[2023-08-25 18:16:29,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.38
[default0]:[2023-08-25 18:16:29,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.18 | backward_microstep: 112.69 | backward_inner_microstep: 101.61 | backward_allreduce_microstep: 10.98 | step_microstep: 42.58
[default0]:[2023-08-25 18:16:29,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.17 (forward_moe: 20.56, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.18)
[default0]:[2023-08-25 18:16:29,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.68 | backward_inner: 101.62 | backward_allreduce: 10.98 | step: 42.59
[default0]:[2023-08-25 18:16:30,213] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:30,214] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.11 | backward_microstep: 112.64 | backward_inner_microstep: 101.54 | backward_allreduce_microstep: 11.01 | step_microstep: 42.63
[default0]:[2023-08-25 18:16:30,214] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.11 (forward_moe: 20.55, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:16:30,214] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.64 | backward_inner: 101.55 | backward_allreduce: 11.01 | step: 42.63
[default0]:[2023-08-25 18:16:30,463] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.36
[default0]:[2023-08-25 18:16:30,464] [INFO] [logging.py:96:log_dist] [Rank 0] step=1895, skipped=0, lr=[2.068753066666667e-06, 2.068753066666667e-06, 2.068753066666667e-06, 2.068753066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:30,464] [INFO] [timer.py:215:stop] epoch=0/micro_step=1895/global_step=1895, RunningAvgSamplesPerSec=4.924964738953978, CurrSamplesPerSec=4.91508672261069, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:30,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.34 | backward_microstep: 112.50 | backward_inner_microstep: 101.50 | backward_allreduce_microstep: 10.91 | step_microstep: 43.07
[default0]:[2023-08-25 18:16:30,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.34 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.20)
[default0]:[2023-08-25 18:16:30,464] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.50 | backward_inner: 101.50 | backward_allreduce: 10.91 | step: 43.08
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([45.0859], device='cuda:0'), 'moe loss': tensor([0.3018], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1895/439453125 | consumed samples:         1895 | consumed tokens:      3880960 | elapsed time per iteration (ms): 249.2 | learning rate: 2.069E-06 | global batch size:     1 | lm loss: 9.017181E+00 | moe loss: 6.036850E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.012 | TFLOPs: 9.97 |
[default0]:[2023-08-25 18:16:30,759] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.39
[default0]:[2023-08-25 18:16:30,759] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.08 | backward_microstep: 112.52 | backward_inner_microstep: 101.49 | backward_allreduce_microstep: 10.93 | step_microstep: 42.76
[default0]:[2023-08-25 18:16:30,759] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.08 (forward_moe: 20.51, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.19)
[default0]:[2023-08-25 18:16:30,760] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.51 | backward_inner: 101.50 | backward_allreduce: 10.92 | step: 42.77
[default0]:[2023-08-25 18:16:31,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.29
[default0]:[2023-08-25 18:16:31,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.34 | backward_microstep: 109.43 | backward_inner_microstep: 98.25 | backward_allreduce_microstep: 11.09 | step_microstep: 41.84
[default0]:[2023-08-25 18:16:31,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.33 (forward_moe: 19.78, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:16:31,033] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.43 | backward_inner: 98.25 | backward_allreduce: 11.10 | step: 41.85
[default0]:[2023-08-25 18:16:31,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:16:31,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.97 | backward_microstep: 109.39 | backward_inner_microstep: 98.55 | backward_allreduce_microstep: 10.74 | step_microstep: 41.57
[default0]:[2023-08-25 18:16:31,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.96 (forward_moe: 19.71, 1st alltoall: 0.85, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:16:31,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.39 | backward_inner: 98.56 | backward_allreduce: 10.74 | step: 41.57
[default0]:[2023-08-25 18:16:31,537] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.28
[default0]:[2023-08-25 18:16:31,537] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.61 | backward_microstep: 108.90 | backward_inner_microstep: 98.10 | backward_allreduce_microstep: 10.71 | step_microstep: 41.60
[default0]:[2023-08-25 18:16:31,537] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.61 (forward_moe: 19.71, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.71)
[default0]:[2023-08-25 18:16:31,537] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.90 | backward_inner: 98.11 | backward_allreduce: 10.71 | step: 41.61
[default0]:[2023-08-25 18:16:31,773] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.28
[default0]:[2023-08-25 18:16:31,774] [INFO] [logging.py:96:log_dist] [Rank 0] step=1900, skipped=0, lr=[2.0742144e-06, 2.0742144e-06, 2.0742144e-06, 2.0742144e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:31,774] [INFO] [timer.py:215:stop] epoch=0/micro_step=1900/global_step=1900, RunningAvgSamplesPerSec=4.925257975901087, CurrSamplesPerSec=5.076442487494387, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:31,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.54 | backward_microstep: 109.00 | backward_inner_microstep: 98.18 | backward_allreduce_microstep: 10.72 | step_microstep: 41.89
[default0]:[2023-08-25 18:16:31,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.54 (forward_moe: 19.89, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:16:31,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.00 | backward_inner: 98.19 | backward_allreduce: 10.73 | step: 41.89
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.5288], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1900/439453125 | consumed samples:         1900 | consumed tokens:      3891200 | elapsed time per iteration (ms): 262.2 | learning rate: 2.074E-06 | global batch size:     1 | lm loss: 8.705751E+00 | moe loss: 6.020195E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.813 | TFLOPs: 9.48 |
[default0]:------------------------------------------------------------------------------------------------
[default0]: validation loss at iteration 1900 | lm loss value: 8.852325E+00 | lm loss PPL: 6.990626E+03 | 
[default0]:------------------------------------------------------------------------------------------------
[default0]:saving checkpoint at iteration    1900 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:[2023-08-25 18:16:35,757] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1900 is about to be saved!
[default0]:[2023-08-25 18:16:35,759] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_0_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,769] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_0_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,769] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_0_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,778] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_0_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,778] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_0_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,788] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_0_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,788] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_0_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,798] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_0_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,799] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_1_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,807] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_1_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,807] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_1_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,816] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_1_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,816] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_1_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,825] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_1_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,825] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_1_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,834] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_1_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,835] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_2_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,844] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_2_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,844] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_2_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,853] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_2_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,853] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_2_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,862] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_2_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,862] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_2_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,870] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_2_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,871] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_3_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,881] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_3_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,881] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_3_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,890] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_3_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,890] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_3_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,899] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_3_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,899] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_3_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,908] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_3_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,909] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_4_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,918] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_4_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,918] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_4_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,928] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_4_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,928] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_4_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,937] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_4_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,937] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_4_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,946] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_4_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,947] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_5_expert_0_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,957] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_5_expert_0_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,957] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_5_expert_1_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,967] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_5_expert_1_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,968] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_5_expert_2_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,977] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_5_expert_2_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,977] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_5_expert_3_mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:35,986] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/layer_5_expert_3_mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:35,986] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/expp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:16:35,988] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/expp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:16:35,989] [INFO] [engine.py:3081:_save_moe_checkpoint] Saving model checkpoint: /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/mp_rank_00_model_states.pt
[default0]:[2023-08-25 18:16:35,989] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/mp_rank_00_model_states.pt...
[default0]:[2023-08-25 18:16:36,265] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/mp_rank_00_model_states.pt.
[default0]:[2023-08-25 18:16:36,266] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[default0]:[2023-08-25 18:16:39,977] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[default0]:[2023-08-25 18:16:39,988] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true/global_step1900/zero_pp_rank_0_mp_rank_00_optim_states.pt
[default0]:[2023-08-25 18:16:39,988] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1900 is ready now!
[default0]:  successfully saved checkpoint at iteration    1900 to /scratch/hpc-prf-lola/nikit/repos/Megatron-DeepSpeed-Microsoft/lola_ws/output/checkpoint/gpt-0.125B-lr-2.0e-4-minlr-2e-06-bs-1-gpus-1-mp-1-pp-1-ep-4-mlc-0.01-cap-1.0-drop-true
[default0]:Checkpoint Save GB: 2.944, GB/Sec: 0.7, Latency(second): 4.235
[default0]:(min, max) time across ranks (ms):
[default0]:    save-checkpoint ................................: (4234.68, 4234.68)
[default0]:[2023-08-25 18:16:40,253] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.66 | optimizer_gradients: 4.16 | optimizer_step: 10.07
[default0]:[2023-08-25 18:16:40,254] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 2334.95 | backward_microstep: 117.38 | backward_inner_microstep: 106.20 | backward_allreduce_microstep: 11.08 | step_microstep: 47.39
[default0]:[2023-08-25 18:16:40,255] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 2334.85 (forward_moe: 21.43, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.74)
[default0]:[2023-08-25 18:16:40,255] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.38 | backward_inner: 106.21 | backward_allreduce: 11.09 | step: 47.39
[default0]:[2023-08-25 18:16:40,503] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.14 | optimizer_step: 6.50
[default0]:[2023-08-25 18:16:40,504] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.41 | backward_microstep: 116.67 | backward_inner_microstep: 105.60 | backward_allreduce_microstep: 10.98 | step_microstep: 43.66
[default0]:[2023-08-25 18:16:40,504] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.41 (forward_moe: 21.43, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.80)
[default0]:[2023-08-25 18:16:40,504] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.67 | backward_inner: 105.60 | backward_allreduce: 10.98 | step: 43.67
[default0]:[2023-08-25 18:16:40,764] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.13 | optimizer_step: 6.76
[default0]:[2023-08-25 18:16:40,765] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.28 | backward_microstep: 116.56 | backward_inner_microstep: 105.49 | backward_allreduce_microstep: 10.98 | step_microstep: 43.77
[default0]:[2023-08-25 18:16:40,765] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.27 (forward_moe: 21.37, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.73)
[default0]:[2023-08-25 18:16:40,765] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.56 | backward_inner: 105.49 | backward_allreduce: 10.98 | step: 43.77
[default0]:[2023-08-25 18:16:41,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.41
[default0]:[2023-08-25 18:16:41,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.08 | backward_microstep: 116.60 | backward_inner_microstep: 105.51 | backward_allreduce_microstep: 11.00 | step_microstep: 44.47
[default0]:[2023-08-25 18:16:41,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.08 (forward_moe: 21.36, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.72)
[default0]:[2023-08-25 18:16:41,028] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.59 | backward_inner: 105.51 | backward_allreduce: 11.00 | step: 44.47
[default0]:[2023-08-25 18:16:41,287] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.40
[default0]:[2023-08-25 18:16:41,287] [INFO] [logging.py:96:log_dist] [Rank 0] step=1905, skipped=0, lr=[2.0796757333333334e-06, 2.0796757333333334e-06, 2.0796757333333334e-06, 2.0796757333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:41,287] [INFO] [timer.py:215:stop] epoch=0/micro_step=1905/global_step=1905, RunningAvgSamplesPerSec=4.9247213317704395, CurrSamplesPerSec=4.8386193976044, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:41,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.85 | backward_microstep: 114.68 | backward_inner_microstep: 103.54 | backward_allreduce_microstep: 11.05 | step_microstep: 43.59
[default0]:[2023-08-25 18:16:41,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.85 (forward_moe: 20.97, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.53)
[default0]:[2023-08-25 18:16:41,288] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.68 | backward_inner: 103.54 | backward_allreduce: 11.05 | step: 43.59
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([42.6608], device='cuda:0'), 'moe loss': tensor([0.3015], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1905/439453125 | consumed samples:         1905 | consumed tokens:      3901440 | elapsed time per iteration (ms): 1902.4 | learning rate: 2.080E-06 | global batch size:     1 | lm loss: 8.532152E+00 | moe loss: 6.030680E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.526 | TFLOPs: 1.31 |
[default0]:[2023-08-25 18:16:41,653] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:16:41,654] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.55 | backward_microstep: 113.85 | backward_inner_microstep: 102.76 | backward_allreduce_microstep: 11.00 | step_microstep: 43.24
[default0]:[2023-08-25 18:16:41,654] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.54 (forward_moe: 20.80, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.36)
[default0]:[2023-08-25 18:16:41,654] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.85 | backward_inner: 102.77 | backward_allreduce: 11.00 | step: 43.24
[default0]:[2023-08-25 18:16:41,901] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.05 | optimizer_step: 6.40
[default0]:[2023-08-25 18:16:41,902] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.79 | backward_microstep: 114.41 | backward_inner_microstep: 103.24 | backward_allreduce_microstep: 11.07 | step_microstep: 43.17
[default0]:[2023-08-25 18:16:41,902] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.79 (forward_moe: 21.15, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.58)
[default0]:[2023-08-25 18:16:41,902] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.41 | backward_inner: 103.25 | backward_allreduce: 11.08 | step: 43.17
[default0]:[2023-08-25 18:16:42,147] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.07 | optimizer_step: 6.41
[default0]:[2023-08-25 18:16:42,147] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.67 | backward_microstep: 114.30 | backward_inner_microstep: 102.96 | backward_allreduce_microstep: 11.25 | step_microstep: 43.27
[default0]:[2023-08-25 18:16:42,148] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.67 (forward_moe: 20.80, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.36)
[default0]:[2023-08-25 18:16:42,148] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.30 | backward_inner: 102.97 | backward_allreduce: 11.25 | step: 43.28
[default0]:[2023-08-25 18:16:42,406] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.40
[default0]:[2023-08-25 18:16:42,407] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.92 | backward_microstep: 113.99 | backward_inner_microstep: 102.88 | backward_allreduce_microstep: 11.01 | step_microstep: 43.16
[default0]:[2023-08-25 18:16:42,407] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.92 (forward_moe: 20.86, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.38)
[default0]:[2023-08-25 18:16:42,407] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.99 | backward_inner: 102.89 | backward_allreduce: 11.02 | step: 43.16
[default0]:[2023-08-25 18:16:42,673] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:16:42,674] [INFO] [logging.py:96:log_dist] [Rank 0] step=1910, skipped=0, lr=[2.0851370666666668e-06, 2.0851370666666668e-06, 2.0851370666666668e-06, 2.0851370666666668e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:42,674] [INFO] [timer.py:215:stop] epoch=0/micro_step=1910/global_step=1910, RunningAvgSamplesPerSec=4.9245844099563705, CurrSamplesPerSec=4.93984519642529, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:42,674] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.86 | backward_microstep: 112.21 | backward_inner_microstep: 101.27 | backward_allreduce_microstep: 10.85 | step_microstep: 42.82
[default0]:[2023-08-25 18:16:42,674] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.86 (forward_moe: 20.54, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:16:42,674] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.21 | backward_inner: 101.27 | backward_allreduce: 10.85 | step: 42.82
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.7523], device='cuda:0'), 'moe loss': tensor([0.3000], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1910/439453125 | consumed samples:         1910 | consumed tokens:      3911680 | elapsed time per iteration (ms): 277.7 | learning rate: 2.085E-06 | global batch size:     1 | lm loss: 8.750464E+00 | moe loss: 6.000525E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.601 | TFLOPs: 8.95 |
[default0]:[2023-08-25 18:16:42,924] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:42,924] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.08 | backward_microstep: 112.49 | backward_inner_microstep: 101.43 | backward_allreduce_microstep: 10.97 | step_microstep: 42.50
[default0]:[2023-08-25 18:16:42,924] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.07 (forward_moe: 20.47, 1st alltoall: 0.89, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:16:42,924] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.49 | backward_inner: 101.43 | backward_allreduce: 10.98 | step: 42.51
[default0]:[2023-08-25 18:16:43,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:16:43,174] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.81 | backward_microstep: 112.52 | backward_inner_microstep: 101.45 | backward_allreduce_microstep: 10.97 | step_microstep: 42.57
[default0]:[2023-08-25 18:16:43,175] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.81 (forward_moe: 20.48, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.15)
[default0]:[2023-08-25 18:16:43,175] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.52 | backward_inner: 101.46 | backward_allreduce: 10.97 | step: 42.58
[default0]:[2023-08-25 18:16:43,438] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:16:43,438] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.00 | backward_microstep: 112.12 | backward_inner_microstep: 101.13 | backward_allreduce_microstep: 10.89 | step_microstep: 42.43
[default0]:[2023-08-25 18:16:43,438] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.00 (forward_moe: 20.43, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.14)
[default0]:[2023-08-25 18:16:43,438] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.12 | backward_inner: 101.14 | backward_allreduce: 10.90 | step: 42.43
[default0]:[2023-08-25 18:16:43,701] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.94 | optimizer_step: 6.35
[default0]:[2023-08-25 18:16:43,701] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.32 | backward_microstep: 112.47 | backward_inner_microstep: 101.49 | backward_allreduce_microstep: 10.89 | step_microstep: 42.21
[default0]:[2023-08-25 18:16:43,701] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.32 (forward_moe: 20.21, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.98)
[default0]:[2023-08-25 18:16:43,702] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.47 | backward_inner: 101.49 | backward_allreduce: 10.89 | step: 42.22
[default0]:[2023-08-25 18:16:43,941] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:43,942] [INFO] [logging.py:96:log_dist] [Rank 0] step=1915, skipped=0, lr=[2.0905984e-06, 2.0905984e-06, 2.0905984e-06, 2.0905984e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:43,942] [INFO] [timer.py:215:stop] epoch=0/micro_step=1915/global_step=1915, RunningAvgSamplesPerSec=4.924642560254229, CurrSamplesPerSec=4.976901919184009, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:43,942] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.48 | backward_microstep: 111.21 | backward_inner_microstep: 100.15 | backward_allreduce_microstep: 10.96 | step_microstep: 42.70
[default0]:[2023-08-25 18:16:43,942] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.48 (forward_moe: 20.20, 1st alltoall: 0.90, 2nd alltoall: 0.81, top-k: 7.98)
[default0]:[2023-08-25 18:16:43,942] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.21 | backward_inner: 100.16 | backward_allreduce: 10.97 | step: 42.70
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.7144], device='cuda:0'), 'moe loss': tensor([0.3008], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1915/439453125 | consumed samples:         1915 | consumed tokens:      3921920 | elapsed time per iteration (ms): 253.3 | learning rate: 2.091E-06 | global batch size:     1 | lm loss: 8.942885E+00 | moe loss: 6.016789E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.947 | TFLOPs: 9.81 |
[default0]:[2023-08-25 18:16:44,196] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.36
[default0]:[2023-08-25 18:16:44,197] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.71 | backward_microstep: 112.06 | backward_inner_microstep: 101.15 | backward_allreduce_microstep: 10.82 | step_microstep: 42.15
[default0]:[2023-08-25 18:16:44,197] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.71 (forward_moe: 20.24, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.01)
[default0]:[2023-08-25 18:16:44,197] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.06 | backward_inner: 101.16 | backward_allreduce: 10.82 | step: 42.16
[default0]:[2023-08-25 18:16:44,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:44,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.39 | backward_microstep: 111.02 | backward_inner_microstep: 100.09 | backward_allreduce_microstep: 10.83 | step_microstep: 42.16
[default0]:[2023-08-25 18:16:44,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.39 (forward_moe: 20.17, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 7.98)
[default0]:[2023-08-25 18:16:44,694] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.02 | backward_inner: 100.10 | backward_allreduce: 10.83 | step: 42.17
[default0]:[2023-08-25 18:16:44,969] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.39
[default0]:[2023-08-25 18:16:44,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.53 | backward_microstep: 111.31 | backward_inner_microstep: 100.38 | backward_allreduce_microstep: 10.84 | step_microstep: 42.68
[default0]:[2023-08-25 18:16:44,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.53 (forward_moe: 20.26, 1st alltoall: 0.89, 2nd alltoall: 0.80, top-k: 8.00)
[default0]:[2023-08-25 18:16:44,970] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.31 | backward_inner: 100.38 | backward_allreduce: 10.84 | step: 42.68
[default0]:[2023-08-25 18:16:45,213] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:45,214] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.72 | backward_microstep: 111.16 | backward_inner_microstep: 100.25 | backward_allreduce_microstep: 10.82 | step_microstep: 42.12
[default0]:[2023-08-25 18:16:45,214] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.72 (forward_moe: 20.34, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.02)
[default0]:[2023-08-25 18:16:45,214] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.16 | backward_inner: 100.25 | backward_allreduce: 10.82 | step: 42.13
[default0]:[2023-08-25 18:16:45,477] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:45,478] [INFO] [logging.py:96:log_dist] [Rank 0] step=1920, skipped=0, lr=[2.0960597333333334e-06, 2.0960597333333334e-06, 2.0960597333333334e-06, 2.0960597333333334e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:45,478] [INFO] [timer.py:215:stop] epoch=0/micro_step=1920/global_step=1920, RunningAvgSamplesPerSec=4.924728506351386, CurrSamplesPerSec=4.969795926105415, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:45,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.40 | backward_microstep: 111.46 | backward_inner_microstep: 100.53 | backward_allreduce_microstep: 10.84 | step_microstep: 42.80
[default0]:[2023-08-25 18:16:45,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.40 (forward_moe: 20.42, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.03)
[default0]:[2023-08-25 18:16:45,478] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.46 | backward_inner: 100.53 | backward_allreduce: 10.84 | step: 42.81
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.0163], device='cuda:0'), 'moe loss': tensor([0.2998], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1920/439453125 | consumed samples:         1920 | consumed tokens:      3932160 | elapsed time per iteration (ms): 307.4 | learning rate: 2.096E-06 | global batch size:     1 | lm loss: 8.803265E+00 | moe loss: 5.996559E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.253 | TFLOPs: 8.08 |
[default0]:[2023-08-25 18:16:45,731] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.35
[default0]:[2023-08-25 18:16:45,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.98 | backward_microstep: 111.96 | backward_inner_microstep: 100.96 | backward_allreduce_microstep: 10.92 | step_microstep: 42.75
[default0]:[2023-08-25 18:16:45,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.98 (forward_moe: 20.35, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.09)
[default0]:[2023-08-25 18:16:45,732] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.96 | backward_inner: 100.96 | backward_allreduce: 10.92 | step: 42.75
[default0]:[2023-08-25 18:16:45,988] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 4.02 | optimizer_step: 6.45
[default0]:[2023-08-25 18:16:45,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.39 | backward_microstep: 113.13 | backward_inner_microstep: 102.04 | backward_allreduce_microstep: 11.00 | step_microstep: 44.80
[default0]:[2023-08-25 18:16:45,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.39 (forward_moe: 20.64, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.18)
[default0]:[2023-08-25 18:16:45,991] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.13 | backward_inner: 102.05 | backward_allreduce: 11.00 | step: 44.81
[default0]:[2023-08-25 18:16:46,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.03 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:46,268] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.67 | backward_microstep: 114.48 | backward_inner_microstep: 103.37 | backward_allreduce_microstep: 11.01 | step_microstep: 42.93
[default0]:[2023-08-25 18:16:46,269] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.67 (forward_moe: 20.99, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.39)
[default0]:[2023-08-25 18:16:46,269] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.47 | backward_inner: 103.37 | backward_allreduce: 11.01 | step: 42.94
[default0]:[2023-08-25 18:16:46,521] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:16:46,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.51 | backward_microstep: 113.62 | backward_inner_microstep: 102.46 | backward_allreduce_microstep: 11.06 | step_microstep: 43.23
[default0]:[2023-08-25 18:16:46,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.50 (forward_moe: 20.83, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.33)
[default0]:[2023-08-25 18:16:46,522] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.62 | backward_inner: 102.47 | backward_allreduce: 11.07 | step: 43.24
[default0]:[2023-08-25 18:16:46,765] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.04 | optimizer_step: 6.41
[default0]:[2023-08-25 18:16:46,765] [INFO] [logging.py:96:log_dist] [Rank 0] step=1925, skipped=0, lr=[2.1015210666666667e-06, 2.1015210666666667e-06, 2.1015210666666667e-06, 2.1015210666666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:46,765] [INFO] [timer.py:215:stop] epoch=0/micro_step=1925/global_step=1925, RunningAvgSamplesPerSec=4.924530192514254, CurrSamplesPerSec=4.779942562793454, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:46,766] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.39 | backward_microstep: 116.64 | backward_inner_microstep: 105.55 | backward_allreduce_microstep: 11.00 | step_microstep: 43.57
[default0]:[2023-08-25 18:16:46,766] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.40 (forward_moe: 21.49, 1st alltoall: 0.93, 2nd alltoall: 0.86, top-k: 8.54)
[default0]:[2023-08-25 18:16:46,766] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.64 | backward_inner: 105.55 | backward_allreduce: 11.00 | step: 43.57
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.9402], device='cuda:0'), 'moe loss': tensor([0.3012], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1925/439453125 | consumed samples:         1925 | consumed tokens:      3942400 | elapsed time per iteration (ms): 257.3 | learning rate: 2.102E-06 | global batch size:     1 | lm loss: 8.788044E+00 | moe loss: 6.024183E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.887 | TFLOPs: 9.66 |
[default0]:[2023-08-25 18:16:47,017] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.44
[default0]:[2023-08-25 18:16:47,017] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.67 | backward_microstep: 114.68 | backward_inner_microstep: 103.53 | backward_allreduce_microstep: 11.06 | step_microstep: 43.31
[default0]:[2023-08-25 18:16:47,017] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.67 (forward_moe: 20.97, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.42)
[default0]:[2023-08-25 18:16:47,017] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.68 | backward_inner: 103.54 | backward_allreduce: 11.06 | step: 43.31
[default0]:[2023-08-25 18:16:47,262] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.04 | optimizer_step: 6.38
[default0]:[2023-08-25 18:16:47,262] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.80 | backward_microstep: 114.91 | backward_inner_microstep: 103.78 | backward_allreduce_microstep: 11.03 | step_microstep: 43.43
[default0]:[2023-08-25 18:16:47,263] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.79 (forward_moe: 20.96, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.42)
[default0]:[2023-08-25 18:16:47,263] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.91 | backward_inner: 103.79 | backward_allreduce: 11.03 | step: 43.44
[default0]:[2023-08-25 18:16:47,518] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:16:47,518] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.48 | backward_microstep: 113.06 | backward_inner_microstep: 102.02 | backward_allreduce_microstep: 10.95 | step_microstep: 42.96
[default0]:[2023-08-25 18:16:47,518] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.47 (forward_moe: 20.65, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.26)
[default0]:[2023-08-25 18:16:47,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.06 | backward_inner: 102.02 | backward_allreduce: 10.96 | step: 42.96
[default0]:[2023-08-25 18:16:47,770] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.68 | optimizer_gradients: 4.07 | optimizer_step: 6.42
[default0]:[2023-08-25 18:16:47,770] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.34 | backward_microstep: 115.21 | backward_inner_microstep: 103.59 | backward_allreduce_microstep: 11.53 | step_microstep: 44.28
[default0]:[2023-08-25 18:16:47,770] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.34 (forward_moe: 20.99, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.36)
[default0]:[2023-08-25 18:16:47,771] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.21 | backward_inner: 103.59 | backward_allreduce: 11.53 | step: 44.28
[default0]:[2023-08-25 18:16:48,022] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:16:48,022] [INFO] [logging.py:96:log_dist] [Rank 0] step=1930, skipped=0, lr=[2.1069824e-06, 2.1069824e-06, 2.1069824e-06, 2.1069824e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:48,022] [INFO] [timer.py:215:stop] epoch=0/micro_step=1930/global_step=1930, RunningAvgSamplesPerSec=4.9243287189989235, CurrSamplesPerSec=4.85624405894224, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:48,023] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.80 | backward_microstep: 113.35 | backward_inner_microstep: 102.32 | backward_allreduce_microstep: 10.95 | step_microstep: 43.22
[default0]:[2023-08-25 18:16:48,023] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.80 (forward_moe: 20.78, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.24)
[default0]:[2023-08-25 18:16:48,023] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.35 | backward_inner: 102.32 | backward_allreduce: 10.95 | step: 43.22
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.4885], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1930/439453125 | consumed samples:         1930 | consumed tokens:      3952640 | elapsed time per iteration (ms): 251.6 | learning rate: 2.107E-06 | global batch size:     1 | lm loss: 8.697699E+00 | moe loss: 6.020048E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.974 | TFLOPs: 9.87 |
[default0]:[2023-08-25 18:16:48,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:16:48,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 50.31 | backward_microstep: 113.47 | backward_inner_microstep: 102.37 | backward_allreduce_microstep: 11.00 | step_microstep: 42.99
[default0]:[2023-08-25 18:16:48,280] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 50.30 (forward_moe: 20.64, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:16:48,281] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.46 | backward_inner: 102.38 | backward_allreduce: 11.00 | step: 42.99
[default0]:[2023-08-25 18:16:48,537] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:16:48,538] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.48 | backward_microstep: 113.06 | backward_inner_microstep: 102.02 | backward_allreduce_microstep: 10.94 | step_microstep: 42.77
[default0]:[2023-08-25 18:16:48,538] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.47 (forward_moe: 20.65, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.26)
[default0]:[2023-08-25 18:16:48,538] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.06 | backward_inner: 102.03 | backward_allreduce: 10.94 | step: 42.77
[default0]:[2023-08-25 18:16:48,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:16:48,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.24 | backward_microstep: 113.14 | backward_inner_microstep: 102.07 | backward_allreduce_microstep: 10.98 | step_microstep: 43.05
[default0]:[2023-08-25 18:16:48,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.24 (forward_moe: 20.72, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.27)
[default0]:[2023-08-25 18:16:48,792] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.14 | backward_inner: 102.07 | backward_allreduce: 10.98 | step: 43.06
[default0]:[2023-08-25 18:16:49,048] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.38
[default0]:[2023-08-25 18:16:49,048] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.41 | backward_microstep: 113.37 | backward_inner_microstep: 102.28 | backward_allreduce_microstep: 11.00 | step_microstep: 42.93
[default0]:[2023-08-25 18:16:49,048] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.41 (forward_moe: 20.76, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.35)
[default0]:[2023-08-25 18:16:49,048] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.37 | backward_inner: 102.29 | backward_allreduce: 11.00 | step: 42.93
[default0]:[2023-08-25 18:16:49,293] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:49,293] [INFO] [logging.py:96:log_dist] [Rank 0] step=1935, skipped=0, lr=[2.1124437333333333e-06, 2.1124437333333333e-06, 2.1124437333333333e-06, 2.1124437333333333e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:49,293] [INFO] [timer.py:215:stop] epoch=0/micro_step=1935/global_step=1935, RunningAvgSamplesPerSec=4.924262005185704, CurrSamplesPerSec=4.995508655752935, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:49,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.33 | backward_microstep: 110.74 | backward_inner_microstep: 99.80 | backward_allreduce_microstep: 10.85 | step_microstep: 42.56
[default0]:[2023-08-25 18:16:49,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.33 (forward_moe: 20.10, 1st alltoall: 0.91, 2nd alltoall: 0.80, top-k: 7.94)
[default0]:[2023-08-25 18:16:49,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.74 | backward_inner: 99.81 | backward_allreduce: 10.85 | step: 42.57
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.4681], device='cuda:0'), 'moe loss': tensor([0.3016], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1935/439453125 | consumed samples:         1935 | consumed tokens:      3962880 | elapsed time per iteration (ms): 253.8 | learning rate: 2.112E-06 | global batch size:     1 | lm loss: 8.693614E+00 | moe loss: 6.031869E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.940 | TFLOPs: 9.79 |
[default0]:[2023-08-25 18:16:49,531] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:49,531] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.43 | backward_microstep: 110.66 | backward_inner_microstep: 99.75 | backward_allreduce_microstep: 10.82 | step_microstep: 42.03
[default0]:[2023-08-25 18:16:49,532] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.43 (forward_moe: 20.22, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.06)
[default0]:[2023-08-25 18:16:49,532] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.66 | backward_inner: 99.76 | backward_allreduce: 10.82 | step: 42.03
[default0]:[2023-08-25 18:16:49,773] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.67 | optimizer_gradients: 4.01 | optimizer_step: 6.36
[default0]:[2023-08-25 18:16:49,773] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.24 | backward_microstep: 110.70 | backward_inner_microstep: 99.78 | backward_allreduce_microstep: 10.83 | step_microstep: 43.07
[default0]:[2023-08-25 18:16:49,773] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.23 (forward_moe: 20.17, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.02)
[default0]:[2023-08-25 18:16:49,774] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.70 | backward_inner: 99.78 | backward_allreduce: 10.83 | step: 43.08
[default0]:[2023-08-25 18:16:50,013] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:50,013] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.32 | backward_microstep: 110.87 | backward_inner_microstep: 99.93 | backward_allreduce_microstep: 10.85 | step_microstep: 42.37
[default0]:[2023-08-25 18:16:50,044] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.32 (forward_moe: 20.20, 1st alltoall: 0.86, 2nd alltoall: 0.82, top-k: 7.94)
[default0]:[2023-08-25 18:16:50,044] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.87 | backward_inner: 99.93 | backward_allreduce: 10.86 | step: 42.38
[default0]:[2023-08-25 18:16:50,293] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:50,293] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.46 | backward_microstep: 110.98 | backward_inner_microstep: 100.03 | backward_allreduce_microstep: 10.85 | step_microstep: 42.13
[default0]:[2023-08-25 18:16:50,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.46 (forward_moe: 20.23, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 8.06)
[default0]:[2023-08-25 18:16:50,294] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.98 | backward_inner: 100.03 | backward_allreduce: 10.85 | step: 42.13
[default0]:[2023-08-25 18:16:50,556] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 10.92
[default0]:[2023-08-25 18:16:50,556] [INFO] [logging.py:96:log_dist] [Rank 0] step=1940, skipped=0, lr=[2.117905066666667e-06, 2.117905066666667e-06, 2.117905066666667e-06, 2.117905066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:50,556] [INFO] [timer.py:215:stop] epoch=0/micro_step=1940/global_step=1940, RunningAvgSamplesPerSec=4.924348328285555, CurrSamplesPerSec=4.8787655314723875, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:50,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.37 | backward_microstep: 111.11 | backward_inner_microstep: 100.17 | backward_allreduce_microstep: 10.84 | step_microstep: 46.93
[default0]:[2023-08-25 18:16:50,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.37 (forward_moe: 20.30, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.96)
[default0]:[2023-08-25 18:16:50,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.11 | backward_inner: 100.18 | backward_allreduce: 10.85 | step: 46.94
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.1518], device='cuda:0'), 'moe loss': tensor([0.2999], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1940/439453125 | consumed samples:         1940 | consumed tokens:      3973120 | elapsed time per iteration (ms): 252.6 | learning rate: 2.118E-06 | global batch size:     1 | lm loss: 8.630351E+00 | moe loss: 5.997072E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.959 | TFLOPs: 9.84 |
[default0]:[2023-08-25 18:16:50,847] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.31
[default0]:[2023-08-25 18:16:50,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.16 | backward_microstep: 110.56 | backward_inner_microstep: 99.65 | backward_allreduce_microstep: 10.82 | step_microstep: 41.93
[default0]:[2023-08-25 18:16:50,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.16 (forward_moe: 20.08, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 7.95)
[default0]:[2023-08-25 18:16:50,848] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.56 | backward_inner: 99.65 | backward_allreduce: 10.82 | step: 41.94
[default0]:[2023-08-25 18:16:51,100] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:51,100] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.11 | backward_microstep: 111.17 | backward_inner_microstep: 100.26 | backward_allreduce_microstep: 10.82 | step_microstep: 42.00
[default0]:[2023-08-25 18:16:51,100] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.11 (forward_moe: 20.03, 1st alltoall: 0.86, 2nd alltoall: 0.82, top-k: 7.88)
[default0]:[2023-08-25 18:16:51,100] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.17 | backward_inner: 100.26 | backward_allreduce: 10.82 | step: 42.00
[default0]:[2023-08-25 18:16:51,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.94 | optimizer_step: 6.31
[default0]:[2023-08-25 18:16:51,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.19 | backward_microstep: 110.42 | backward_inner_microstep: 99.48 | backward_allreduce_microstep: 10.85 | step_microstep: 41.95
[default0]:[2023-08-25 18:16:51,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.19 (forward_moe: 20.22, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.93)
[default0]:[2023-08-25 18:16:51,344] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.42 | backward_inner: 99.49 | backward_allreduce: 10.85 | step: 41.95
[default0]:[2023-08-25 18:16:51,584] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.34
[default0]:[2023-08-25 18:16:51,584] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.15 | backward_microstep: 110.26 | backward_inner_microstep: 99.36 | backward_allreduce_microstep: 10.80 | step_microstep: 41.95
[default0]:[2023-08-25 18:16:51,585] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.15 (forward_moe: 20.02, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:16:51,585] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.26 | backward_inner: 99.36 | backward_allreduce: 10.81 | step: 41.95
[default0]:[2023-08-25 18:16:51,945] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.34
[default0]:[2023-08-25 18:16:51,946] [INFO] [logging.py:96:log_dist] [Rank 0] step=1945, skipped=0, lr=[2.1233664000000004e-06, 2.1233664000000004e-06, 2.1233664000000004e-06, 2.1233664000000004e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:51,946] [INFO] [timer.py:215:stop] epoch=0/micro_step=1945/global_step=1945, RunningAvgSamplesPerSec=4.92456549574728, CurrSamplesPerSec=5.004210438403398, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:51,946] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.14 | backward_microstep: 110.24 | backward_inner_microstep: 99.35 | backward_allreduce_microstep: 10.80 | step_microstep: 42.90
[default0]:[2023-08-25 18:16:51,946] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.14 (forward_moe: 20.04, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:16:51,947] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.24 | backward_inner: 99.35 | backward_allreduce: 10.80 | step: 42.91
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.3469], device='cuda:0'), 'moe loss': tensor([0.2999], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1945/439453125 | consumed samples:         1945 | consumed tokens:      3983360 | elapsed time per iteration (ms): 278.0 | learning rate: 2.123E-06 | global batch size:     1 | lm loss: 8.669379E+00 | moe loss: 5.997415E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.597 | TFLOPs: 8.94 |
[default0]:[2023-08-25 18:16:52,192] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:52,193] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.27 | backward_microstep: 110.59 | backward_inner_microstep: 99.70 | backward_allreduce_microstep: 10.80 | step_microstep: 41.86
[default0]:[2023-08-25 18:16:52,193] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.27 (forward_moe: 20.24, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 7.89)
[default0]:[2023-08-25 18:16:52,193] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.59 | backward_inner: 99.70 | backward_allreduce: 10.80 | step: 41.86
[default0]:[2023-08-25 18:16:52,432] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:52,433] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.09 | backward_microstep: 110.15 | backward_inner_microstep: 99.28 | backward_allreduce_microstep: 10.78 | step_microstep: 41.92
[default0]:[2023-08-25 18:16:52,433] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.09 (forward_moe: 19.99, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.88)
[default0]:[2023-08-25 18:16:52,433] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.15 | backward_inner: 99.28 | backward_allreduce: 10.78 | step: 41.92
[default0]:[2023-08-25 18:16:52,690] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.95 | optimizer_step: 6.36
[default0]:[2023-08-25 18:16:52,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.97 | backward_microstep: 110.31 | backward_inner_microstep: 99.39 | backward_allreduce_microstep: 10.82 | step_microstep: 41.91
[default0]:[2023-08-25 18:16:52,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.97 (forward_moe: 20.03, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:16:52,691] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.31 | backward_inner: 99.40 | backward_allreduce: 10.83 | step: 41.91
[default0]:[2023-08-25 18:16:52,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.96 | optimizer_step: 6.36
[default0]:[2023-08-25 18:16:52,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.74 | backward_microstep: 111.41 | backward_inner_microstep: 100.43 | backward_allreduce_microstep: 10.88 | step_microstep: 42.41
[default0]:[2023-08-25 18:16:52,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.74 (forward_moe: 20.34, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.06)
[default0]:[2023-08-25 18:16:52,935] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.41 | backward_inner: 100.44 | backward_allreduce: 10.88 | step: 42.42
[default0]:[2023-08-25 18:16:53,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.59
[default0]:[2023-08-25 18:16:53,186] [INFO] [logging.py:96:log_dist] [Rank 0] step=1950, skipped=0, lr=[2.1288277333333337e-06, 2.1288277333333337e-06, 2.1288277333333337e-06, 2.1288277333333337e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:53,186] [INFO] [timer.py:215:stop] epoch=0/micro_step=1950/global_step=1950, RunningAvgSamplesPerSec=4.924734456079551, CurrSamplesPerSec=4.929169188461832, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:53,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.67 | backward_microstep: 112.34 | backward_inner_microstep: 101.32 | backward_allreduce_microstep: 10.93 | step_microstep: 43.31
[default0]:[2023-08-25 18:16:53,186] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.67 (forward_moe: 20.52, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:16:53,187] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.34 | backward_inner: 101.32 | backward_allreduce: 10.93 | step: 43.31
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.2206], device='cuda:0'), 'moe loss': tensor([0.3013], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1950/439453125 | consumed samples:         1950 | consumed tokens:      3993600 | elapsed time per iteration (ms): 248.1 | learning rate: 2.129E-06 | global batch size:     1 | lm loss: 8.844119E+00 | moe loss: 6.026701E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.031 | TFLOPs: 10.02 |
[default0]:[2023-08-25 18:16:53,434] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.39
[default0]:[2023-08-25 18:16:53,434] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.00 | backward_microstep: 112.73 | backward_inner_microstep: 101.69 | backward_allreduce_microstep: 10.94 | step_microstep: 42.66
[default0]:[2023-08-25 18:16:53,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.00 (forward_moe: 20.50, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.19)
[default0]:[2023-08-25 18:16:53,435] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.72 | backward_inner: 101.69 | backward_allreduce: 10.95 | step: 42.66
[default0]:[2023-08-25 18:16:53,721] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:16:53,722] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.55 | backward_microstep: 112.94 | backward_inner_microstep: 101.89 | backward_allreduce_microstep: 10.95 | step_microstep: 42.85
[default0]:[2023-08-25 18:16:53,722] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.55 (forward_moe: 20.59, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.24)
[default0]:[2023-08-25 18:16:53,722] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.94 | backward_inner: 101.90 | backward_allreduce: 10.96 | step: 42.85
[default0]:[2023-08-25 18:16:53,985] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.03 | optimizer_step: 6.41
[default0]:[2023-08-25 18:16:53,985] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.55 | backward_microstep: 113.60 | backward_inner_microstep: 102.45 | backward_allreduce_microstep: 11.05 | step_microstep: 43.03
[default0]:[2023-08-25 18:16:53,985] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.55 (forward_moe: 20.73, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.32)
[default0]:[2023-08-25 18:16:53,985] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.60 | backward_inner: 102.41 | backward_allreduce: 11.06 | step: 43.03
[default0]:[2023-08-25 18:16:54,239] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.07 | optimizer_step: 6.41
[default0]:[2023-08-25 18:16:54,240] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.62 | backward_microstep: 117.36 | backward_inner_microstep: 106.11 | backward_allreduce_microstep: 11.15 | step_microstep: 43.83
[default0]:[2023-08-25 18:16:54,240] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.62 (forward_moe: 20.80, 1st alltoall: 0.89, 2nd alltoall: 0.83, top-k: 8.37)
[default0]:[2023-08-25 18:16:54,240] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 117.35 | backward_inner: 106.11 | backward_allreduce: 11.15 | step: 43.83
[default0]:[2023-08-25 18:16:54,558] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.43
[default0]:[2023-08-25 18:16:54,558] [INFO] [logging.py:96:log_dist] [Rank 0] step=1955, skipped=0, lr=[2.134289066666667e-06, 2.134289066666667e-06, 2.134289066666667e-06, 2.134289066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:54,558] [INFO] [timer.py:215:stop] epoch=0/micro_step=1955/global_step=1955, RunningAvgSamplesPerSec=4.924551876368912, CurrSamplesPerSec=4.83291583224061, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:54,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.77 | backward_microstep: 114.57 | backward_inner_microstep: 103.36 | backward_allreduce_microstep: 11.12 | step_microstep: 44.06
[default0]:[2023-08-25 18:16:54,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.77 (forward_moe: 20.95, 1st alltoall: 0.89, 2nd alltoall: 0.84, top-k: 8.43)
[default0]:[2023-08-25 18:16:54,559] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 114.57 | backward_inner: 103.36 | backward_allreduce: 11.12 | step: 44.06
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.4400], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1955/439453125 | consumed samples:         1955 | consumed tokens:      4003840 | elapsed time per iteration (ms): 275.5 | learning rate: 2.134E-06 | global batch size:     1 | lm loss: 8.687999E+00 | moe loss: 6.020715E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.630 | TFLOPs: 9.02 |
[default0]:[2023-08-25 18:16:54,823] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.11 | optimizer_step: 6.45
[default0]:[2023-08-25 18:16:54,823] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.06 | backward_microstep: 115.89 | backward_inner_microstep: 104.67 | backward_allreduce_microstep: 11.13 | step_microstep: 43.76
[default0]:[2023-08-25 18:16:54,823] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.06 (forward_moe: 21.15, 1st alltoall: 0.90, 2nd alltoall: 0.84, top-k: 8.57)
[default0]:[2023-08-25 18:16:54,823] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.89 | backward_inner: 104.66 | backward_allreduce: 11.13 | step: 43.76
[default0]:[2023-08-25 18:16:55,081] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.80 | optimizer_gradients: 4.12 | optimizer_step: 6.49
[default0]:[2023-08-25 18:16:55,082] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.58 | backward_microstep: 116.19 | backward_inner_microstep: 104.97 | backward_allreduce_microstep: 11.13 | step_microstep: 44.23
[default0]:[2023-08-25 18:16:55,082] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.58 (forward_moe: 21.39, 1st alltoall: 0.91, 2nd alltoall: 0.85, top-k: 8.68)
[default0]:[2023-08-25 18:16:55,082] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 116.19 | backward_inner: 104.97 | backward_allreduce: 11.14 | step: 44.23
[default0]:[2023-08-25 18:16:55,323] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:55,324] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.03 | backward_microstep: 112.13 | backward_inner_microstep: 101.14 | backward_allreduce_microstep: 10.90 | step_microstep: 42.47
[default0]:[2023-08-25 18:16:55,324] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.03 (forward_moe: 20.48, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.11)
[default0]:[2023-08-25 18:16:55,324] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.13 | backward_inner: 101.15 | backward_allreduce: 10.90 | step: 42.47
[default0]:[2023-08-25 18:16:55,572] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:55,573] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.76 | backward_microstep: 111.84 | backward_inner_microstep: 100.86 | backward_allreduce_microstep: 10.89 | step_microstep: 42.48
[default0]:[2023-08-25 18:16:55,573] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.76 (forward_moe: 20.47, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.09)
[default0]:[2023-08-25 18:16:55,573] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.84 | backward_inner: 100.86 | backward_allreduce: 10.89 | step: 42.48
[default0]:[2023-08-25 18:16:55,807] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 3.98 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:55,807] [INFO] [logging.py:96:log_dist] [Rank 0] step=1960, skipped=0, lr=[2.1397504000000003e-06, 2.1397504000000003e-06, 2.1397504000000003e-06, 2.1397504000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:55,807] [INFO] [timer.py:215:stop] epoch=0/micro_step=1960/global_step=1960, RunningAvgSamplesPerSec=4.924422016889138, CurrSamplesPerSec=4.947554299424478, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:55,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.95 | backward_microstep: 111.93 | backward_inner_microstep: 100.93 | backward_allreduce_microstep: 10.91 | step_microstep: 42.72
[default0]:[2023-08-25 18:16:55,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.95 (forward_moe: 20.49, 1st alltoall: 0.88, 2nd alltoall: 0.80, top-k: 8.09)
[default0]:[2023-08-25 18:16:55,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.93 | backward_inner: 100.93 | backward_allreduce: 10.91 | step: 42.73
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.4983], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1960/439453125 | consumed samples:         1960 | consumed tokens:      4014080 | elapsed time per iteration (ms): 249.4 | learning rate: 2.140E-06 | global batch size:     1 | lm loss: 8.699663E+00 | moe loss: 6.019406E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.009 | TFLOPs: 9.96 |
[default0]:[2023-08-25 18:16:56,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.06 | optimizer_step: 6.33
[default0]:[2023-08-25 18:16:56,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.85 | backward_microstep: 111.88 | backward_inner_microstep: 100.93 | backward_allreduce_microstep: 10.86 | step_microstep: 42.50
[default0]:[2023-08-25 18:16:56,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.85 (forward_moe: 20.36, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.09)
[default0]:[2023-08-25 18:16:56,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.88 | backward_inner: 100.94 | backward_allreduce: 10.86 | step: 42.50
[default0]:[2023-08-25 18:16:56,319] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:16:56,320] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.70 | backward_microstep: 111.95 | backward_inner_microstep: 100.97 | backward_allreduce_microstep: 10.88 | step_microstep: 42.47
[default0]:[2023-08-25 18:16:56,320] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.70 (forward_moe: 20.37, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.10)
[default0]:[2023-08-25 18:16:56,320] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.95 | backward_inner: 100.98 | backward_allreduce: 10.89 | step: 42.47
[default0]:[2023-08-25 18:16:56,553] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.34
[default0]:[2023-08-25 18:16:56,553] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.00 | backward_microstep: 111.83 | backward_inner_microstep: 100.88 | backward_allreduce_microstep: 10.86 | step_microstep: 42.40
[default0]:[2023-08-25 18:16:56,554] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.00 (forward_moe: 20.39, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.10)
[default0]:[2023-08-25 18:16:56,554] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.83 | backward_inner: 100.88 | backward_allreduce: 10.86 | step: 42.40
[default0]:[2023-08-25 18:16:56,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 6.36
[default0]:[2023-08-25 18:16:56,808] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.77 | backward_microstep: 111.76 | backward_inner_microstep: 100.77 | backward_allreduce_microstep: 10.89 | step_microstep: 42.47
[default0]:[2023-08-25 18:16:56,809] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.77 (forward_moe: 20.34, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.11)
[default0]:[2023-08-25 18:16:56,809] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.75 | backward_inner: 100.78 | backward_allreduce: 10.90 | step: 42.48
[default0]:[2023-08-25 18:16:57,042] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.40
[default0]:[2023-08-25 18:16:57,042] [INFO] [logging.py:96:log_dist] [Rank 0] step=1965, skipped=0, lr=[2.1452117333333336e-06, 2.1452117333333336e-06, 2.1452117333333336e-06, 2.1452117333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:57,043] [INFO] [timer.py:215:stop] epoch=0/micro_step=1965/global_step=1965, RunningAvgSamplesPerSec=4.9244763331455905, CurrSamplesPerSec=4.921661603378498, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:57,043] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.97 | backward_microstep: 112.57 | backward_inner_microstep: 101.55 | backward_allreduce_microstep: 10.93 | step_microstep: 43.09
[default0]:[2023-08-25 18:16:57,043] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.97 (forward_moe: 20.52, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.18)
[default0]:[2023-08-25 18:16:57,043] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.57 | backward_inner: 101.56 | backward_allreduce: 10.93 | step: 43.10
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.0148], device='cuda:0'), 'moe loss': tensor([0.3005], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1965/439453125 | consumed samples:         1965 | consumed tokens:      4024320 | elapsed time per iteration (ms): 246.3 | learning rate: 2.145E-06 | global batch size:     1 | lm loss: 8.602968E+00 | moe loss: 6.009233E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.061 | TFLOPs: 10.09 |
[default0]:[2023-08-25 18:16:57,313] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:57,314] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.42 | backward_microstep: 113.66 | backward_inner_microstep: 102.49 | backward_allreduce_microstep: 11.07 | step_microstep: 43.10
[default0]:[2023-08-25 18:16:57,314] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.42 (forward_moe: 20.84, 1st alltoall: 0.88, 2nd alltoall: 0.84, top-k: 8.42)
[default0]:[2023-08-25 18:16:57,314] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.66 | backward_inner: 102.50 | backward_allreduce: 11.08 | step: 43.11
[default0]:[2023-08-25 18:16:57,578] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.00 | optimizer_step: 6.35
[default0]:[2023-08-25 18:16:57,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.35 | backward_microstep: 112.62 | backward_inner_microstep: 101.63 | backward_allreduce_microstep: 10.90 | step_microstep: 42.60
[default0]:[2023-08-25 18:16:57,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.35 (forward_moe: 20.54, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.21)
[default0]:[2023-08-25 18:16:57,579] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.62 | backward_inner: 101.64 | backward_allreduce: 10.90 | step: 42.60
[default0]:[2023-08-25 18:16:57,821] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.37
[default0]:[2023-08-25 18:16:57,821] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.09 | backward_microstep: 112.49 | backward_inner_microstep: 101.48 | backward_allreduce_microstep: 10.92 | step_microstep: 42.80
[default0]:[2023-08-25 18:16:57,822] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.09 (forward_moe: 20.61, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.29)
[default0]:[2023-08-25 18:16:57,822] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.49 | backward_inner: 101.48 | backward_allreduce: 10.93 | step: 42.80
[default0]:[2023-08-25 18:16:58,063] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.99 | optimizer_step: 6.36
[default0]:[2023-08-25 18:16:58,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.34 | backward_microstep: 112.56 | backward_inner_microstep: 101.46 | backward_allreduce_microstep: 11.00 | step_microstep: 42.68
[default0]:[2023-08-25 18:16:58,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.34 (forward_moe: 20.53, 1st alltoall: 0.88, 2nd alltoall: 0.81, top-k: 8.21)
[default0]:[2023-08-25 18:16:58,064] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.56 | backward_inner: 101.47 | backward_allreduce: 11.00 | step: 42.69
[default0]:[2023-08-25 18:16:58,303] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.01 | optimizer_step: 6.38
[default0]:[2023-08-25 18:16:58,303] [INFO] [logging.py:96:log_dist] [Rank 0] step=1970, skipped=0, lr=[2.150673066666667e-06, 2.150673066666667e-06, 2.150673066666667e-06, 2.150673066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:58,303] [INFO] [timer.py:215:stop] epoch=0/micro_step=1970/global_step=1970, RunningAvgSamplesPerSec=4.924409583675251, CurrSamplesPerSec=4.861039287655547, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:58,304] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 49.33 | backward_microstep: 112.71 | backward_inner_microstep: 101.57 | backward_allreduce_microstep: 11.05 | step_microstep: 43.12
[default0]:[2023-08-25 18:16:58,304] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 49.33 (forward_moe: 20.66, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.19)
[default0]:[2023-08-25 18:16:58,304] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.71 | backward_inner: 101.57 | backward_allreduce: 11.05 | step: 43.13
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([44.0023], device='cuda:0'), 'moe loss': tensor([0.3010], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1970/439453125 | consumed samples:         1970 | consumed tokens:      4034560 | elapsed time per iteration (ms): 252.2 | learning rate: 2.151E-06 | global batch size:     1 | lm loss: 8.800458E+00 | moe loss: 6.020049E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.965 | TFLOPs: 9.85 |
[default0]:[2023-08-25 18:16:58,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 7.54
[default0]:[2023-08-25 18:16:58,558] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.55 | backward_microstep: 109.37 | backward_inner_microstep: 98.53 | backward_allreduce_microstep: 10.75 | step_microstep: 42.93
[default0]:[2023-08-25 18:16:58,558] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.55 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.74)
[default0]:[2023-08-25 18:16:58,558] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.37 | backward_inner: 98.54 | backward_allreduce: 10.75 | step: 42.93
[default0]:[2023-08-25 18:16:58,786] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:16:58,786] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.84 | backward_microstep: 109.27 | backward_inner_microstep: 98.48 | backward_allreduce_microstep: 10.70 | step_microstep: 41.64
[default0]:[2023-08-25 18:16:58,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.84 (forward_moe: 19.94, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.77)
[default0]:[2023-08-25 18:16:58,787] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.27 | backward_inner: 98.49 | backward_allreduce: 10.70 | step: 41.64
[default0]:[2023-08-25 18:16:59,046] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.89 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:59,047] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 109.29 | backward_inner_microstep: 98.40 | backward_allreduce_microstep: 10.80 | step_microstep: 41.70
[default0]:[2023-08-25 18:16:59,047] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.85, 1st alltoall: 0.87, 2nd alltoall: 0.79, top-k: 7.75)
[default0]:[2023-08-25 18:16:59,047] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.29 | backward_inner: 98.40 | backward_allreduce: 10.80 | step: 41.70
[default0]:[2023-08-25 18:16:59,283] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:16:59,283] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 109.35 | backward_inner_microstep: 98.53 | backward_allreduce_microstep: 10.73 | step_microstep: 41.94
[default0]:[2023-08-25 18:16:59,283] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.77 (forward_moe: 19.81, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:16:59,283] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.35 | backward_inner: 98.53 | backward_allreduce: 10.74 | step: 41.95
[default0]:[2023-08-25 18:16:59,525] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:16:59,525] [INFO] [logging.py:96:log_dist] [Rank 0] step=1975, skipped=0, lr=[2.1561344000000003e-06, 2.1561344000000003e-06, 2.1561344000000003e-06, 2.1561344000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:16:59,525] [INFO] [timer.py:215:stop] epoch=0/micro_step=1975/global_step=1975, RunningAvgSamplesPerSec=4.924740412139309, CurrSamplesPerSec=5.07464290121739, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:16:59,525] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.56 | backward_microstep: 109.04 | backward_inner_microstep: 98.22 | backward_allreduce_microstep: 10.72 | step_microstep: 41.90
[default0]:[2023-08-25 18:16:59,526] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.56 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.82)
[default0]:[2023-08-25 18:16:59,526] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.04 | backward_inner: 98.23 | backward_allreduce: 10.72 | step: 41.91
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([42.7962], device='cuda:0'), 'moe loss': tensor([0.3007], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1975/439453125 | consumed samples:         1975 | consumed tokens:      4044800 | elapsed time per iteration (ms): 244.2 | learning rate: 2.156E-06 | global batch size:     1 | lm loss: 8.559230E+00 | moe loss: 6.014019E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.094 | TFLOPs: 10.17 |
[default0]:[2023-08-25 18:16:59,758] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:16:59,758] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.62 | backward_microstep: 109.32 | backward_inner_microstep: 98.46 | backward_allreduce_microstep: 10.77 | step_microstep: 41.63
[default0]:[2023-08-25 18:16:59,758] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.62 (forward_moe: 19.97, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.79)
[default0]:[2023-08-25 18:16:59,759] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.32 | backward_inner: 98.46 | backward_allreduce: 10.78 | step: 41.63
[default0]:[2023-08-25 18:17:00,259] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.08 | optimizer_step: 6.44
[default0]:[2023-08-25 18:17:00,261] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.89 | backward_microstep: 115.42 | backward_inner_microstep: 104.33 | backward_allreduce_microstep: 10.99 | step_microstep: 44.60
[default0]:[2023-08-25 18:17:00,261] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.89 (forward_moe: 20.79, 1st alltoall: 0.88, 2nd alltoall: 0.82, top-k: 8.37)
[default0]:[2023-08-25 18:17:00,261] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.42 | backward_inner: 104.34 | backward_allreduce: 11.00 | step: 44.61
[default0]:[2023-08-25 18:17:00,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 4.09 | optimizer_step: 6.46
[default0]:[2023-08-25 18:17:00,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.50 | backward_microstep: 115.35 | backward_inner_microstep: 104.15 | backward_allreduce_microstep: 11.10 | step_microstep: 43.65
[default0]:[2023-08-25 18:17:00,519] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.50 (forward_moe: 21.15, 1st alltoall: 0.90, 2nd alltoall: 0.83, top-k: 8.54)
[default0]:[2023-08-25 18:17:00,520] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 115.34 | backward_inner: 104.16 | backward_allreduce: 11.10 | step: 43.65
[default0]:[2023-08-25 18:17:00,823] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.97 | optimizer_step: 62.07
[default0]:[2023-08-25 18:17:00,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.11 | backward_microstep: 110.31 | backward_inner_microstep: 99.41 | backward_allreduce_microstep: 10.80 | step_microstep: 98.26
[default0]:[2023-08-25 18:17:00,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.11 (forward_moe: 20.17, 1st alltoall: 0.86, 2nd alltoall: 0.82, top-k: 7.91)
[default0]:[2023-08-25 18:17:00,824] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.31 | backward_inner: 99.42 | backward_allreduce: 10.80 | step: 98.26
[default0]:[2023-08-25 18:17:01,060] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.73 | optimizer_gradients: 3.92 | optimizer_step: 6.31
[default0]:[2023-08-25 18:17:01,060] [INFO] [logging.py:96:log_dist] [Rank 0] step=1980, skipped=0, lr=[2.1615957333333336e-06, 2.1615957333333336e-06, 2.1615957333333336e-06, 2.1615957333333336e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:17:01,060] [INFO] [timer.py:215:stop] epoch=0/micro_step=1980/global_step=1980, RunningAvgSamplesPerSec=4.924094688649555, CurrSamplesPerSec=4.9998855617013165, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:17:01,061] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.19 | backward_microstep: 111.03 | backward_inner_microstep: 100.08 | backward_allreduce_microstep: 10.85 | step_microstep: 42.24
[default0]:[2023-08-25 18:17:01,061] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.19 (forward_moe: 20.54, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.88)
[default0]:[2023-08-25 18:17:01,061] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.02 | backward_inner: 100.09 | backward_allreduce: 10.85 | step: 42.24
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.8882], device='cuda:0'), 'moe loss': tensor([0.3003], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1980/439453125 | consumed samples:         1980 | consumed tokens:      4055040 | elapsed time per iteration (ms): 307.9 | learning rate: 2.162E-06 | global batch size:     1 | lm loss: 8.777638E+00 | moe loss: 6.006004E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.248 | TFLOPs: 8.07 |
[default0]:[2023-08-25 18:17:01,314] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.93 | optimizer_step: 6.31
[default0]:[2023-08-25 18:17:01,314] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.74 | backward_microstep: 110.25 | backward_inner_microstep: 99.36 | backward_allreduce_microstep: 10.80 | step_microstep: 42.14
[default0]:[2023-08-25 18:17:01,314] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.74 (forward_moe: 20.03, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.90)
[default0]:[2023-08-25 18:17:01,314] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 110.25 | backward_inner: 99.37 | backward_allreduce: 10.80 | step: 42.14
[default0]:[2023-08-25 18:17:01,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:17:01,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.47 | backward_microstep: 108.86 | backward_inner_microstep: 98.04 | backward_allreduce_microstep: 10.71 | step_microstep: 41.31
[default0]:[2023-08-25 18:17:01,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.47 (forward_moe: 19.83, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.73)
[default0]:[2023-08-25 18:17:01,557] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.86 | backward_inner: 98.05 | backward_allreduce: 10.71 | step: 41.31
[default0]:[2023-08-25 18:17:01,790] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:17:01,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 108.96 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.71 | step_microstep: 41.48
[default0]:[2023-08-25 18:17:01,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:17:01,791] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.96 | backward_inner: 98.17 | backward_allreduce: 10.71 | step: 41.49
[default0]:[2023-08-25 18:17:02,040] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.88 | optimizer_step: 6.30
[default0]:[2023-08-25 18:17:02,041] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.70 | backward_microstep: 109.05 | backward_inner_microstep: 98.25 | backward_allreduce_microstep: 10.71 | step_microstep: 41.40
[default0]:[2023-08-25 18:17:02,041] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.70 (forward_moe: 19.77, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.73)
[default0]:[2023-08-25 18:17:02,041] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.05 | backward_inner: 98.26 | backward_allreduce: 10.71 | step: 41.41
[default0]:[2023-08-25 18:17:02,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.28
[default0]:[2023-08-25 18:17:02,358] [INFO] [logging.py:96:log_dist] [Rank 0] step=1985, skipped=0, lr=[2.167057066666667e-06, 2.167057066666667e-06, 2.167057066666667e-06, 2.167057066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:17:02,358] [INFO] [timer.py:215:stop] epoch=0/micro_step=1985/global_step=1985, RunningAvgSamplesPerSec=4.924440922222979, CurrSamplesPerSec=5.075416628347669, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:17:02,358] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.53 | backward_microstep: 108.97 | backward_inner_microstep: 98.16 | backward_allreduce_microstep: 10.72 | step_microstep: 41.98
[default0]:[2023-08-25 18:17:02,359] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.53 (forward_moe: 19.75, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.72)
[default0]:[2023-08-25 18:17:02,359] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.97 | backward_inner: 98.17 | backward_allreduce: 10.72 | step: 41.99
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([42.9083], device='cuda:0'), 'moe loss': tensor([0.3009], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1985/439453125 | consumed samples:         1985 | consumed tokens:      4065280 | elapsed time per iteration (ms): 259.5 | learning rate: 2.167E-06 | global batch size:     1 | lm loss: 8.581659E+00 | moe loss: 6.017675E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.854 | TFLOPs: 9.58 |
[default0]:[2023-08-25 18:17:02,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.89 | optimizer_step: 6.30
[default0]:[2023-08-25 18:17:02,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.43 | backward_microstep: 108.86 | backward_inner_microstep: 98.03 | backward_allreduce_microstep: 10.74 | step_microstep: 41.48
[default0]:[2023-08-25 18:17:02,610] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.42 (forward_moe: 19.76, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.72)
[default0]:[2023-08-25 18:17:02,611] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.86 | backward_inner: 98.03 | backward_allreduce: 10.74 | step: 41.49
[default0]:[2023-08-25 18:17:02,850] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.88 | optimizer_step: 6.31
[default0]:[2023-08-25 18:17:02,850] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.63 | backward_microstep: 109.02 | backward_inner_microstep: 98.20 | backward_allreduce_microstep: 10.73 | step_microstep: 41.54
[default0]:[2023-08-25 18:17:02,851] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.63 (forward_moe: 19.85, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.74)
[default0]:[2023-08-25 18:17:02,851] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.02 | backward_inner: 98.20 | backward_allreduce: 10.73 | step: 41.54
[default0]:[2023-08-25 18:17:03,099] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.91 | optimizer_step: 6.31
[default0]:[2023-08-25 18:17:03,100] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.45 | backward_microstep: 108.82 | backward_inner_microstep: 98.01 | backward_allreduce_microstep: 10.71 | step_microstep: 42.12
[default0]:[2023-08-25 18:17:03,100] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.45 (forward_moe: 19.84, 1st alltoall: 0.86, 2nd alltoall: 0.79, top-k: 7.76)
[default0]:[2023-08-25 18:17:03,100] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 108.82 | backward_inner: 98.02 | backward_allreduce: 10.71 | step: 42.12
[default0]:[2023-08-25 18:17:03,360] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.34
[default0]:[2023-08-25 18:17:03,360] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.00 | backward_microstep: 111.22 | backward_inner_microstep: 100.28 | backward_allreduce_microstep: 10.85 | step_microstep: 42.35
[default0]:[2023-08-25 18:17:03,360] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.00 (forward_moe: 20.27, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.02)
[default0]:[2023-08-25 18:17:03,360] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.22 | backward_inner: 100.29 | backward_allreduce: 10.85 | step: 42.36
[default0]:[2023-08-25 18:17:03,608] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.35
[default0]:[2023-08-25 18:17:03,608] [INFO] [logging.py:96:log_dist] [Rank 0] step=1990, skipped=0, lr=[2.1725184e-06, 2.1725184e-06, 2.1725184e-06, 2.1725184e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:17:03,609] [INFO] [timer.py:215:stop] epoch=0/micro_step=1990/global_step=1990, RunningAvgSamplesPerSec=4.924686856773781, CurrSamplesPerSec=4.926210850972368, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:17:03,609] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.78 | backward_microstep: 111.50 | backward_inner_microstep: 100.51 | backward_allreduce_microstep: 10.90 | step_microstep: 44.11
[default0]:[2023-08-25 18:17:03,609] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.78 (forward_moe: 20.42, 1st alltoall: 0.87, 2nd alltoall: 0.81, top-k: 8.06)
[default0]:[2023-08-25 18:17:03,609] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 111.50 | backward_inner: 100.51 | backward_allreduce: 10.90 | step: 44.11
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.0513], device='cuda:0'), 'moe loss': tensor([0.2999], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1990/439453125 | consumed samples:         1990 | consumed tokens:      4075520 | elapsed time per iteration (ms): 249.5 | learning rate: 2.173E-06 | global batch size:     1 | lm loss: 8.610263E+00 | moe loss: 5.997533E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.008 | TFLOPs: 9.96 |
[default0]:[2023-08-25 18:17:03,870] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.98 | optimizer_step: 6.36
[default0]:[2023-08-25 18:17:03,870] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.62 | backward_microstep: 112.15 | backward_inner_microstep: 101.13 | backward_allreduce_microstep: 10.93 | step_microstep: 42.70
[default0]:[2023-08-25 18:17:03,870] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.62 (forward_moe: 20.45, 1st alltoall: 0.87, 2nd alltoall: 0.82, top-k: 8.13)
[default0]:[2023-08-25 18:17:03,870] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.15 | backward_inner: 101.13 | backward_allreduce: 10.94 | step: 42.70
[default0]:[2023-08-25 18:17:04,135] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.02 | optimizer_step: 6.39
[default0]:[2023-08-25 18:17:04,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.34 | backward_microstep: 113.16 | backward_inner_microstep: 101.94 | backward_allreduce_microstep: 11.13 | step_microstep: 43.32
[default0]:[2023-08-25 18:17:04,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.34 (forward_moe: 20.64, 1st alltoall: 0.89, 2nd alltoall: 0.82, top-k: 8.25)
[default0]:[2023-08-25 18:17:04,136] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 113.16 | backward_inner: 101.95 | backward_allreduce: 11.13 | step: 43.33
[default0]:[2023-08-25 18:17:04,390] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.63 | optimizer_gradients: 3.90 | optimizer_step: 6.29
[default0]:[2023-08-25 18:17:04,390] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 48.46 | backward_microstep: 109.75 | backward_inner_microstep: 98.70 | backward_allreduce_microstep: 10.95 | step_microstep: 41.44
[default0]:[2023-08-25 18:17:04,390] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 48.46 (forward_moe: 19.98, 1st alltoall: 0.86, 2nd alltoall: 0.81, top-k: 7.80)
[default0]:[2023-08-25 18:17:04,390] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.75 | backward_inner: 98.71 | backward_allreduce: 10.95 | step: 41.44
[default0]:[2023-08-25 18:17:04,635] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.90 | optimizer_step: 6.32
[default0]:[2023-08-25 18:17:04,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 47.11 | backward_microstep: 109.67 | backward_inner_microstep: 98.84 | backward_allreduce_microstep: 10.74 | step_microstep: 41.57
[default0]:[2023-08-25 18:17:04,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 47.10 (forward_moe: 19.93, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.84)
[default0]:[2023-08-25 18:17:04,636] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.67 | backward_inner: 98.84 | backward_allreduce: 10.75 | step: 41.57
[default0]:[2023-08-25 18:17:04,868] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.32
[default0]:[2023-08-25 18:17:04,868] [INFO] [logging.py:96:log_dist] [Rank 0] step=1995, skipped=0, lr=[2.1779797333333335e-06, 2.1779797333333335e-06, 2.1779797333333335e-06, 2.1779797333333335e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:17:04,869] [INFO] [timer.py:215:stop] epoch=0/micro_step=1995/global_step=1995, RunningAvgSamplesPerSec=4.924819113588138, CurrSamplesPerSec=5.053646217389837, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:17:04,869] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.76 | backward_microstep: 109.50 | backward_inner_microstep: 98.60 | backward_allreduce_microstep: 10.81 | step_microstep: 42.08
[default0]:[2023-08-25 18:17:04,869] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.76 (forward_moe: 19.85, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.78)
[default0]:[2023-08-25 18:17:04,869] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.50 | backward_inner: 98.61 | backward_allreduce: 10.81 | step: 42.08
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.9723], device='cuda:0'), 'moe loss': tensor([0.3045], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     1995/439453125 | consumed samples:         1995 | consumed tokens:      4085760 | elapsed time per iteration (ms): 252.1 | learning rate: 2.178E-06 | global batch size:     1 | lm loss: 8.794465E+00 | moe loss: 6.089702E-02 | loss scale: 16384.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.967 | TFLOPs: 9.86 |
[default0]:[2023-08-25 18:17:05,120] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:17:05,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.80 | backward_microstep: 109.60 | backward_inner_microstep: 98.76 | backward_allreduce_microstep: 10.74 | step_microstep: 41.88
[default0]:[2023-08-25 18:17:05,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.80 (forward_moe: 19.85, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:17:05,121] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.59 | backward_inner: 98.76 | backward_allreduce: 10.75 | step: 41.88
[default0]:[2023-08-25 18:17:05,359] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.39
[default0]:[2023-08-25 18:17:05,359] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.07 | backward_microstep: 109.69 | backward_inner_microstep: 98.80 | backward_allreduce_microstep: 10.80 | step_microstep: 41.59
[default0]:[2023-08-25 18:17:05,359] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.07 (forward_moe: 19.93, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.87)
[default0]:[2023-08-25 18:17:05,359] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.69 | backward_inner: 98.80 | backward_allreduce: 10.81 | step: 41.60
[default0]:[2023-08-25 18:17:05,653] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.92 | optimizer_step: 6.32
[default0]:[2023-08-25 18:17:05,654] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.68 | backward_microstep: 109.53 | backward_inner_microstep: 98.66 | backward_allreduce_microstep: 10.78 | step_microstep: 41.67
[default0]:[2023-08-25 18:17:05,654] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.68 (forward_moe: 19.87, 1st alltoall: 0.87, 2nd alltoall: 0.80, top-k: 7.80)
[default0]:[2023-08-25 18:17:05,654] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.53 | backward_inner: 98.67 | backward_allreduce: 10.78 | step: 41.68
[default0]:[2023-08-25 18:17:05,890] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 3.91 | optimizer_step: 6.30
[default0]:[2023-08-25 18:17:05,891] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 45.77 | backward_microstep: 109.56 | backward_inner_microstep: 98.68 | backward_allreduce_microstep: 10.78 | step_microstep: 41.72
[default0]:[2023-08-25 18:17:05,891] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 45.76 (forward_moe: 19.87, 1st alltoall: 0.86, 2nd alltoall: 0.80, top-k: 7.81)
[default0]:[2023-08-25 18:17:05,891] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 109.56 | backward_inner: 98.69 | backward_allreduce: 10.78 | step: 41.73
[default0]:[2023-08-25 18:17:06,144] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | optimizer_allgather: 1.64 | optimizer_gradients: 4.00 | optimizer_step: 6.35
[default0]:[2023-08-25 18:17:06,145] [INFO] [logging.py:96:log_dist] [Rank 0] step=2000, skipped=0, lr=[2.183441066666667e-06, 2.183441066666667e-06, 2.183441066666667e-06, 2.183441066666667e-06], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
[default0]:[2023-08-25 18:17:06,145] [INFO] [timer.py:215:stop] epoch=0/micro_step=2000/global_step=2000, RunningAvgSamplesPerSec=4.925069632020397, CurrSamplesPerSec=4.930878653217653, MemAllocated=2.87GB, MaxMemAllocated=4.39GB
[default0]:[2023-08-25 18:17:06,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward_microstep: 46.85 | backward_microstep: 112.28 | backward_inner_microstep: 101.29 | backward_allreduce_microstep: 10.90 | step_microstep: 43.14
[default0]:[2023-08-25 18:17:06,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 46.85 (forward_moe: 20.74, 1st alltoall: 0.88, 2nd alltoall: 0.83, top-k: 8.15)
[default0]:[2023-08-25 18:17:06,145] [INFO] [logging.py:96:log_dist] [Rank 0] rank=0 time (ms) | forward: 0.00 | backward: 112.28 | backward_inner: 101.29 | backward_allreduce: 10.90 | step: 43.14
[default0]:LOLA: following loss dict obtained: {'advanced iterations': 5, 'skipped iterations': 0, 'lm loss': tensor([43.3657], device='cuda:0'), 'moe loss': tensor([0.2999], device='cuda:0', grad_fn=<AddBackward0>), 'nan iterations': 0}
[default0]: iteration     2000/439453125 | consumed samples:         2000 | consumed tokens:      4096000 | elapsed time per iteration (ms): 255.0 | learning rate: 2.183E-06 | global batch size:     1 | lm loss: 8.673147E+00 | moe loss: 5.997277E-02 | loss scale: 32768.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.922 | TFLOPs: 9.75 |
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 4647847 ON n2gpu1232 CANCELLED AT 2023-08-25T18:17:10 ***
slurmstepd: error: *** STEP 4647847.0 ON n2gpu1232 CANCELLED AT 2023-08-25T18:17:10 ***
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 2575539 closing signal SIGTERM
